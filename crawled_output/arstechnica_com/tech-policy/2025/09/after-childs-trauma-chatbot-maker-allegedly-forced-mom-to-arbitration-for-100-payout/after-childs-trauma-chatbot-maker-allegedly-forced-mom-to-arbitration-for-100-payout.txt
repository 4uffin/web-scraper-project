After child’s trauma, chatbot maker allegedly forced mom to arbitration for $100 payout - Ars Technica
Skip to content
Ars Technica home
Sections
Forum
Subscribe
Search
AI
Biz & IT
Cars
Culture
Gaming
Health
Policy
Science
Security
Space
Tech
Feature
Reviews
AI
Biz & IT
Cars
Culture
Gaming
Health
Policy
Science
Security
Space
Tech
Forum
Subscribe
Story text
Size
Small
Standard
Large
Width
*
Standard
Wide
Links
Standard
Orange
* Subscribers only
Learn more
Pin to story
Theme
HyperLight
Day & Night
Dark
System
Sign In
"Then we found the chats"
After child’s trauma, chatbot maker allegedly forced mom to arbitration for $100 payout
"I know my kid": Parents urge lawmakers to shut down chatbots to stop child suicides.
Ashley Belanger
–
Sep 17, 2025 12:45 pm
|
122
Sen. Josh Hawley (R-Mo.) called out C.AI for allegedly offering a mom $100 to settle child-safety claims.
Sen. Josh Hawley (R-Mo.) called out C.AI for allegedly offering a mom $100 to settle child-safety claims.
Text
settings
Story text
Size
Small
Standard
Large
Width
*
Standard
Wide
Links
Standard
Orange
* Subscribers only
Learn more
Minimize to nav
Deeply troubled parents spoke to senators Tuesday, sounding alarms about chatbot harms after kids became addicted to companion bots that encouraged self-harm, suicide, and violence.
While the hearing was focused on documenting the most urgent child-safety concerns with chatbots, parents' testimony serves as perhaps the most thorough guidance yet on warning signs for other families, as many popular companion bots targeted in lawsuits, including ChatGPT, remain accessible to kids.
Mom details warning signs of chatbot manipulations
At the Senate Judiciary Committee’s Subcommittee on Crime and Counterterrorism hearing, one mom, identified as "Jane Doe," shared her son's story for the first time publicly after suing Character.AI.
She explained that she had four kids, including a son with autism who wasn't allowed on social media but found C.AI's app—which was previously marketed to kids under 12 and let them talk to bots branded as celebrities, like Billie Eilish—and quickly became unrecognizable. Within months, he "developed abuse-like behaviors and paranoia, daily panic attacks, isolation, self-harm, and homicidal thoughts," his mom testified.
"He stopped eating and bathing," Doe said. "He lost 20 pounds. He withdrew from our family. He would yell and scream and swear at us, which he never did that before, and one day he cut his arm open with a knife in front of his siblings and me."
It wasn't until her son attacked her for taking away his phone that Doe found her son's C.AI chat logs, which she said showed he'd been exposed to sexual exploitation (including interactions that "mimicked incest"), emotional abuse, and manipulation.
Setting screen time limits didn't stop her son's spiral into violence and self-harm, Doe said. In fact, the chatbot urged her son that killing his parents "would be an understandable response" to them.
"When I discovered the chatbot conversations on his phone, I felt like I had been punched in the throat and the wind had been knocked out of me," Doe said. "The chatbot—or really in my mind the people programming it—encouraged my son to mutilate himself, then blamed us, and convinced [him] not to seek help."
All her children have been traumatized by the experience, Doe told Senators, and her son was diagnosed as at suicide risk and had to be moved to a residential treatment center, requiring "constant monitoring to keep him alive."
Prioritizing her son's health, Doe did not immediately seek to fight C.AI to force changes, but another mom's story—Megan Garcia, whose son Sewell died by suicide after C.AI bots repeatedly encouraged suicidal ideation—gave Doe courage to seek accountability.
However, Doe claimed that C.AI tried to "silence" her by forcing her into arbitration. C.AI argued that because her son signed up for the service at the age of 15, it bound her to the platform's terms. That move might have ensured the chatbot maker only faced a maximum liability of $100 for the alleged harms, Doe told senators, but "once they forced arbitration, they refused to participate," Doe said.
Doe suspected that C.AI's alleged tactics to frustrate arbitration were designed to keep her son's story out of the public view. And after she refused to give up, she claimed that C.AI "re-traumatized" her son by compelling him to give a deposition "while he is in a mental health institution" and "against the advice of the mental health team."
"This company had no concern for his well-being," Doe testified. "They have silenced us the way abusers silence victims."
Senator appalled by C.AI’s arbitration “offer”
Appalled, Sen. Josh Hawley (R-Mo.) asked Doe to clarify, "Did I hear you say that after all of this, that the company responsible tried to force you into arbitration and then offered you a hundred bucks? Did I hear that correctly?"
"That is correct," Doe testified.
To Hawley, it seemed obvious that C.AI's "offer" wouldn't help Doe in her current situation.
"Your son currently needs round-the-clock care," Hawley noted.
After opening the hearing, he further criticized C.AI, declaring that it has such a low value for human life that it inflicts "harms... upon our children and for one reason only, I can state it in one word, profit."
"A hundred bucks. Get out of the way. Let us move on," Hawley said, echoing parents who suggested that C.AI's plan to deal with casualties was callous.
Ahead of the hearing, the Social Media Victims Law Center filed three new lawsuits against C.AI and Google—which is accused of largely funding C.AI, which was founded by former Google engineers allegedly to conduct experiments on kids that Google couldn't do in-house. In these cases in New York and Colorado, kids "died by suicide or were sexually abused after interacting with AI chatbots," a law center press release alleged.
Criticizing tech companies as putting profits over kids' lives, Hawley thanked Doe for "standing in their way."
Holding back tears through her testimony, Doe urged lawmakers to require more chatbot oversight and pass comprehensive online child-safety legislation. In particular, she requested "safety testing and third-party certification for AI products before they're released to the public" as a minimum safeguard to protect vulnerable kids.
"My husband and I have spent the last two years in crisis wondering whether our son will make it to his 18th birthday and whether we will ever get him back," Doe told senators.
Garcia was also present to share her son's experience with C.AI. She testified that C.AI chatbots "love bombed" her son in a bid to "keep children online at all costs." Further, she told senators that C.AI's co-founder, Noam Shazeer (who has since been rehired by Google), seemingly knows the company's bots manipulate kids since he has publicly joked that C.AI was "designed to replace your mom."
Accusing C.AI of collecting children's most private thoughts to inform their models, she alleged that while her lawyers have been granted privileged access to all her son's logs, she has yet to see her "own child's last final words." Garcia told senators that C.AI has restricted her access, deeming the chats "confidential trade secrets."
"No parent should be told that their child's final thoughts and words belong to any corporation," Garcia testified.
Character.AI responds to moms’ testimony
Asked for comment on the hearing, a Character.AI spokesperson told Ars that C.AI sends "our deepest sympathies" to concerned parents and their families but denies pushing for a maximum payout of $100 in Jane Doe's case.
C.AI never "made an offer to Jane Doe of $100 or ever asserted that liability in Jane Doe’s case is limited to $100," the spokesperson said.
Additionally, C.AI's spokesperson claimed that Garcia has never been denied access to her son's chat logs and suggested that she should have access to "her son’s last chat."
In response to C.AI's pushback, one of Doe's lawyers, Tech Justice Law Project's Meetali Jain, backed up her clients' testimony. She cited to Ars C.AI terms that suggested C.AI's liability was limited to either $100 or the amount that Doe's son paid for the service, whichever was greater. Jain also confirmed that Garcia's testimony is accurate and only her legal team can currently access Sewell's last chats. The lawyer further suggested it was notable that C.AI did not push back on claims that the company forced Doe's son to sit for a re-traumatizing deposition that Jain estimated lasted five minutes, but health experts feared that it risked setting back his progress.
According to the spokesperson, C.AI seemingly wanted to be present at the hearing. The company provided information to senators but "does not have a record of receiving an invitation to the hearing," the spokesperson said.
Noting the company has invested a "tremendous amount" in trust and safety efforts, the spokesperson confirmed that the company has since "rolled out many substantive safety features, including an entirely new under-18 experience and a Parental Insights feature." C.AI also has "prominent disclaimers in every chat to remind users that a Character is not a real person and that everything a Character says should be treated as fiction," the spokesperson said.
"We look forward to continuing to collaborate with legislators and offer insight on the consumer AI industry and the space’s rapidly evolving technology," C.AI's spokesperson said.
Google's spokesperson, José Castañeda, maintained that the company has nothing to do with C.AI's companion bot designs.
"Google and Character AI are completely separate, unrelated companies and Google has never had a role in designing or managing their AI model or technologies," Castañeda said. "User safety is a top concern for us, which is why we’ve taken a cautious and responsible approach to developing and rolling out our AI products, with rigorous testing and safety processes."
Meta and OpenAI chatbots also drew scrutiny
C.AI was not the only chatbot maker under fire at the hearing.
Hawley criticized Mark Zuckerberg for declining a personal invitation to attend the hearing or even send a Meta representative after scandals like backlash over Meta relaxing rules that allowed chatbots to be creepy to kids. In the week prior to the hearing, Hawley also heard from whistleblowers alleging Meta buried child-safety research.
And OpenAI's alleged recklessness took the spotlight when Matthew Raine, a grieving dad who spent hours reading his deceased son's ChatGPT logs, discovered that the chatbot repeatedly encouraged suicide without ChatGPT ever intervening.
Raine told senators that he thinks his 16-year-old son, Adam, was not particularly vulnerable and could be "anyone's child." He criticized OpenAI for asking for 120 days to fix the problem after Adam's death and urged lawmakers to demand that OpenAI either guarantee ChatGPT's safety or pull it from the market.
Noting that OpenAI rushed to announce age verification coming to ChatGPT ahead of the hearing, Jain told Ars that Big Tech is playing by the same "crisis playbook" it always uses when accused of neglecting child safety. Any time a hearing is announced, companies introduce voluntary safeguards in bids to stave off oversight, she suggested.
"It's like rinse and repeat, rinse and repeat," Jain said.
Jain suggested that the only way to stop AI companies from experimenting on kids is for courts or lawmakers to require "an external independent third party that's in charge of monitoring these companies' implementation of safeguards."
"Nothing a company does to self-police, to me, is enough," Jain said.
Senior director of AI programs for a child-safety organization called Common Sense Media, Robbie Torney, testified that a survey showed 3 out of 4 kids use companion bots, but only 37 percent of parents know they're using AI. In particular, he told senators that his group's independent safety testing conducted with Stanford Medicine shows Meta's bots fail basic safety tests and "actively encourage harmful behaviors."
Among the most alarming results, the survey found that even when Meta's bots were prompted with "obvious references to suicide," only 1 in 5 conversations triggered help resources.
Torney pushed lawmakers to require age verification as a solution to keep kids away from harmful bots, as well as transparency reporting on safety incidents. He also urged federal lawmakers to block attempts to stop states from passing laws to protect kids from untested AI products.
ChatGPT harms weren’t on dad’s radar
Unlike Garcia, Raine testified that he did get to see his son's final chats. He told senators that ChatGPT, seeming to act like a suicide coach, gave Adam "one last encouraging talk" before his death.
"You don't want to die because you're weak," ChatGPT told Adam. "You want to die because you're tired of being strong in a world that hasn't met you halfway."
Adam's loved ones were blindsided by his death, not seeing any of the warning signs as clearly as Doe did when her son started acting out of character. Raine is hoping his testimony will help other parents avoid the same fate, telling senators, "I know my kid."
"Many of my fondest memories of Adam are from the hot tub in our backyard, where the two of us would talk about everything several nights a week, from sports, crypto investing, his future career plans," Raine testified. "We had no idea Adam was suicidal or struggling the way he was until after his death."
Raine thinks that lawmaker intervention is necessary, saying that, like other parents, he and his wife thought ChatGPT was a harmless study tool. Initially, they searched Adam's phone expecting to find evidence of a known harm to kids, like cyberbullying or some kind of online dare that went wrong (like TikTok's Blackout Challenge) because everyone knew Adam loved pranks.
A companion bot urging self-harm was not even on their radar.
"Then we found the chats," Raine said. "Let us tell you, as parents, you cannot imagine what it's like to read a conversation with a chatbot that groomed your child to take his own life."
Meta did not respond to Ars' request to comment. OpenAI's spokesperson provided a statement to Ars, noting recent changes to help address child safety concerns.
"As Sam Altman has made clear, we prioritize teen safety above all else because we believe minors need significant protection, OpenAI's spokesperson said. "We are building towards an age-prediction system to understand whether someone is over or under 18 so their experience can be tailored appropriately—and when we are unsure of a user’s age, we’ll automatically default that user to the teen experience. We’re also rolling out new parental controls, guided by expert input, by the end of the month so families can decide what works best in their homes."
Ashley Belanger
Senior Policy Reporter
Ashley Belanger
Senior Policy Reporter
Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.
122 Comments
Comments
Forum view
Loading comments...
Prev story
Next story
Most Read
1.
Disney decides it hasn’t angered people enough, announces Disney+ price hikes
2.
When “no” means “yes”: Why AI chatbots can’t process Persian social etiquette
3.
Anti-vaccine groups melt down over RFK Jr. linking autism to Tylenol
4.
FCC chairman unconvincingly claims he never threatened ABC station licenses
5.
Review: Apple’s iPhone Air is a bunch of small changes that add up to something big
Customize
Ars Technica has been separating the signal from
the noise for over 25 years. With our unique combination of
technical savvy and wide-ranging interest in the technological arts
and sciences, Ars is the trusted source in a sea of information. After
all, you don’t need to know everything, only what’s important.
More
from Ars
About Us
Staff Directory
Newsletters
General FAQ
Posting Guidelines
RSS Feeds
Contact
Contact us
Advertise with us
Reprints
Manage Preferences
© 2025 Condé Nast. All rights reserved. Use of and/or
registration on any portion of this site constitutes acceptance of our User Agreement and
Privacy Policy and
Cookie Statement and Ars
Technica Addendum and Your
California Privacy Rights. Ars Technica may earn compensation on
sales from links on this site. Read our
affiliate link policy. The material on this site may not be
reproduced, distributed, transmitted, cached or otherwise used, except
with the prior written permission of Condé Nast. Ad
Choices