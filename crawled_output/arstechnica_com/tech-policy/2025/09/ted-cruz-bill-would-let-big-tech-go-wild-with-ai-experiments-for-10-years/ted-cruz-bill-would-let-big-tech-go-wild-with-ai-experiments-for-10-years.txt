Ted Cruz AI bill could let firms bribe Trump to avoid safety laws, critics warn - Ars Technica
Skip to content
Ars Technica home
Sections
Forum
Subscribe
Search
AI
Biz & IT
Cars
Culture
Gaming
Health
Policy
Science
Security
Space
Tech
Feature
Reviews
AI
Biz & IT
Cars
Culture
Gaming
Health
Policy
Science
Security
Space
Tech
Forum
Subscribe
Story text
Size
Small
Standard
Large
Width
*
Standard
Wide
Links
Standard
Orange
* Subscribers only
Learn more
Pin to story
Theme
HyperLight
Day & Night
Dark
System
Sign In
Gift to Big Tech
Ted Cruz AI bill could let firms bribe Trump to avoid safety laws, critics warn
Ted Cruz won’t give up fight to block states from regulating AI.
Ashley Belanger
–
Sep 11, 2025 2:21 pm
|
63
Ted Cruz, listening to Senate testimony on the AI Action Plan.
Credit:
Chip Somodevilla / Staff | Getty Images News
Ted Cruz, listening to Senate testimony on the AI Action Plan.
Credit:
Chip Somodevilla / Staff | Getty Images News
Text
settings
Story text
Size
Small
Standard
Large
Width
*
Standard
Wide
Links
Standard
Orange
* Subscribers only
Learn more
Minimize to nav
Critics are slamming Sen. Ted Cruz's (R-Texas) new AI policy framework, which they claim would give the White House unprecedented authority to allow Big Tech companies to make "sweetheart" deals with the Trump administration to void laws designed to protect the public from reckless AI experiments.
Under the framework, Cruz calls for a "light-touch" regulatory approach to "advance American leadership" in AI and ensure that "American values" are at the heart of the world's leading technology—not Chinese values.
Unsurprisingly, the framework requires blocking "burdensome" state AI regulations, as well as foreign ones. Cruz unsuccessfully helped push for a similar decadelong moratorium on state AI laws as part of Republicans' "big beautiful" budget bill. And more recently, he lost a bid to punish states for regulating AI, ultimately voting against his own measure in the face of overwhelming bipartisan opposition.
As the first step toward limiting AI regulations to prioritize innovation, Cruz announced the SANDBOX Act—which is shorthand for "Strengthening Artificial intelligence Normalization and Diffusion By Oversight and eXperimentation."
If passed, the SANDBOX Act would let AI companies apply to temporarily avoid enforcement of federal laws that could limit their testing of new AI products. As part of the application, companies would be asked to detail known risks or harms and any steps that could be taken to mitigate harms, as well as outline benefits that could outweigh harms.
Each agency in charge of enforcing each law would then weigh potential harms, with enforcement to be modified based on how much of the application each agency approves.
However, the White House Office of Science and Technology Policy (OSTP) would have the power to overrule decisions from independent agencies dedicated to consumer protection, alarming critics who fear AI companies could bribe officials through political donations to void laws.
Ultimately, federal agencies and the OSTP could grant two-year moratoriums on enforcement of AI laws to enable AI experiments on the public, which can be renewed up to four times for a maximum of 10 years. The bill also prompts Congress to make permanent any "successful" moratoriums found to benefit the US, Cruz's one-pager said. After its passage, Cruz expects to introduce more laws to support his framework, likely paving the way for similar future moratoriums to be granted to block state laws.
Critics warn bill is a gift to Big Tech
According to Cruz, the SANDBOX Act follows through on Donald Trump's demand for a regulatory sandbox in his AI Action Plan, which strives to make the US the global leader in AI (but critics suggest may violate the Constitution).
Cruz's sandbox program supposedly "gives AI developers space to test and launch new AI technologies without being held back by outdated or inflexible federal rules," while mitigating "against health, public safety, or fraud risks" through an expedited review process.
The Tech Oversight Project, a nonprofit tech industry watchdog group, warned that, if passed, the law would make it easier for AI firms to make "sweetheart" deals. It could perhaps incentivize the White House to favor Big Tech companies "donating to Trump" over smaller AI firms that can't afford to pay for such political leverage and may be bound to a different set of rules, the group suggested.
Cruz's SANDBOX Act "would give unprecedented authority for the Trump Administration to trade away protections for children and seniors and dole out favors to Big Tech companies like Google, Apple, Meta, Amazon, and OpenAI," the Tech Oversight Project alleged.
The bill's text suggests that health and safety risks that could result in a request for non-enforcement to be denied included risks of "bodily harm to a human life," "loss of human life," and "a substantial adverse effect on the health of a human." But the rushed review process may make it harder for officials—likely working in agencies recently gutted by the Department of Government Efficiency—to adequately weigh potential harms.
Cruz's bill requires agencies to review AI companies' requests within 14 days. Once the review process begins, agencies can hire advisory boards or working groups to assess risks, but they must reach a decision within 60 days or the AI firms' requests will be presumed approved. Only one request for a 30-day extension may be granted.
For AI companies that may benefit from rolling out products more quickly through the framework, Cruz requires reporting within 72 hours of "any incident that results in harm to the health and safety of a consumer, economic damage, or an unfair or deceptive trade practice." Firms will then be granted 30 days to fix the problem or risk enforcement of the law they sought to avoid, while the public is alerted and provided an opportunity to comment.
In a statement, a nonprofit dedicated to informing the public about AI risks, the Alliance for Secure AI, warned that Cruz's bill seeks to remove government oversight at "the wrong time."
"Ideally, Big Tech companies and frontier labs would make safety a top priority and work to prevent harm to Americans," Brendan Steinhauser, the nonprofit's CEO, said. "However, we have seen again and again that they have not done so. The SANDBOX Act removes much-needed oversight as Big Tech refuses to remain transparent with the public about the risks of advanced AI."
A nonprofit consumer advocacy organization, Public Citizen, agreed that Cruz seemed to be handing "Big Tech the keys to experiment on the public while weakening oversight, undermining regulatory authority, and pressuring Congress to permanently roll back essential safeguards."
Supporters say Cruz’s bill strikes the right balance
Supporters of the bill so far include the US Chamber of Commerce and NetChoice—a trade association representing Big Tech companies—as well as right-leaning and global policy research groups, including the Abundance Institute, the Information Technology Council, and the R Street Institute.
Adam Therrier, an R Street Institute senior fellow, suggested that too much of AI policy debate focuses on "new types of regulation for AI systems and applications," while ignoring that the SANDBOX Act would also help AI firms avoid being bogged down by the "many laws and regulations already on the books that cover—or could come to cover—algorithmic applications."
In the one-pager, Cruz noted that "most US rules and regulations do not squarely apply to emerging technologies like AI." So "rather than force AI developers to design inferior products just to comply with outdated Federal rules, our regulations should become more flexible," Cruz argued.
Therrier noted that once regulations are passed, they're rarely updated and backed Cruz's logic that AI firms may need support to override old rules that could restrict AI innovation. Consider the "many new applications in healthcare, transportation, and financial services," Therrier said, which "could offer the public important new life-enriching service" unless "archaic rules" are relied on to "block those benefits by standing in the way of marketplace experimentation."
"When red tape grows without constraint and becomes untethered from modern marketplace realities, it can undermine innovation and investment, undermine entrepreneurship and competition, raise costs to consumers, limit worker opportunities, and undermine long-term economic growth," Therrier wrote.
But Therrier acknowledged that Cruz seems particularly focused on propping up a national framework to "address the rapid proliferation of AI legislative proposals happening across the nation," noting that over 1,000 AI-related bills were introduced in the first half of this year.
Netchoice similarly celebrated the bill's "innovation-first approach," claiming "the SANDBOX Act strikes an important balance" between "giving AI developers room to experiment" and "preserving necessary safeguards."
To critics, the bill's potential to constrict new safeguards remains a primary concern. Steinhauser, of the Alliance for Secure AI, suggested that critics may get answers to their biggest questions about how well the law would work to protect public safety "in the coming days."
His group noted that just during this summer alone, "multiple companies have come under bipartisan fire for refusing to take Americans’ safety seriously and institute proper guardrails on their AI systems, leading to avoidable tragedies." They cited Meta allowing chatbots to be creepy to kids and OpenAI rushing to make changes after a child died after using ChatGPT to research a suicide.
Under Cruz's bill, the primary consumer protection seems to be requiring companies to provide warnings that consumers may be exposed to certain risks by interacting with experimental products. Those warnings would explain that consumers can attempt to hold companies civilly or criminally liable for any loss or damages, the bill said, while warning that the product could be discontinued at any time. Warnings must also provide contact information to send any complaints to the National Artificial Intelligence Initiative Office, the bill said.
However, critics who worry particularly about child safety are worried that warnings aren't enough. Consider how chatbots providing warnings that they're not real people or licensed therapists has not prevented some users from dangerously blurring the line between AI worlds and reality.
"This legislation is a victory for Big Tech CEOs, who have consistently failed to protect Americans from social and psychological harms caused by their products," Alliance for Secure AI warned.
So far, states have led efforts to police AI. Notably, Illinois banned AI therapy after research found chatbot therapists fuel delusions, and California is close to becoming the first state to restrict companion bots to protect kids. Other state protections, Tech Policy Press reported, cover "critical areas of life like housing, education, employment, and credit," as well as addressing deepfakes that could impact elections and public safety.
Critics are hoping that bipartisan support for these state efforts, as well as federal efforts like the Take It Down Act (which Cruz supported), will ensure that Cruz's framework and sandbox bill aren't adopted as drafted.
"It’s unconscionable to risk the American public’s safety to enrich AI companies that are already collectively worth trillions," Public Citizen said. "The sob stories of AI companies being ‘held back’ by regulation are simply not true and the record company valuations show it. Lawmakers should stand with the public, not corporate lobbyists, and slam the brakes on this reckless proposal. Congress should focus on legislation that delivers real accountability, transparency, and consumer protection in the age of AI."
Ashley Belanger
Senior Policy Reporter
Ashley Belanger
Senior Policy Reporter
Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.
63 Comments
Comments
Forum view
Loading comments...
Prev story
Next story
Most Read
1.
What do people actually use ChatGPT for? OpenAI provides some numbers.
2.
60 years after Gemini, newly processed images reveal incredible details
3.
macOS 26 Tahoe: The Ars Technica review
4.
Northrop Grumman’s new spacecraft is a real chonker
5.
Parts shortage is the latest problem to hit General Motors production
Customize
Ars Technica has been separating the signal from
the noise for over 25 years. With our unique combination of
technical savvy and wide-ranging interest in the technological arts
and sciences, Ars is the trusted source in a sea of information. After
all, you don’t need to know everything, only what’s important.
More
from Ars
About Us
Staff Directory
Newsletters
General FAQ
Posting Guidelines
RSS Feeds
Contact
Contact us
Advertise with us
Reprints
Manage Preferences
© 2025 Condé Nast. All rights reserved. Use of and/or
registration on any portion of this site constitutes acceptance of our User Agreement and
Privacy Policy and
Cookie Statement and Ars
Technica Addendum and Your
California Privacy Rights. Ars Technica may earn compensation on
sales from links on this site. Read our
affiliate link policy. The material on this site may not be
reproduced, distributed, transmitted, cached or otherwise used, except
with the prior written permission of Condé Nast. Ad
Choices