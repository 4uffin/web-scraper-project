UpToDate Launches Gen AI For Clinical Decision Support - Newsweek
U.S.WorldScienceHealthLifeRankingsOpinionEntertainmentFact CheckMy TurnEducation
EventsSportsPodcastsBetter PlanetBetter WorkplacesVaultMightierAutosNewslettersUnconventionalVantageExpertsVoicesSubscribe
Login
√ó
Subscribe
LoginU.S.WorldScienceHealthLifeRankingsOpinionEntertainmentFact CheckMy TurnEducationEventsSportsPodcastsBetter PlanetBetter WorkplacesVaultMightierAutosNewslettersUnconventionalVantageExpertsVoices
Share
Copy Link ‚úì Link copied to clipboard!
Health Care
AI
Doctor
Research
Medicine
ChatGPT
UpToDate Launches Gen AI For Clinical Decision Support
Published Sep 24, 2025 at 8:00 AM EDT
Updated Sep 24, 2025 at 3:04 PM EDT
CLOSE X
By
Alexis Kayser is Newsweek's Healthcare Editor based in Chicago. Her focus is reporting on the operations and priorities of U.S. hospitals and health systems. She has extensively covered value-based care models, artificial intelligence, clinician burnout and Americans' trust in the health care industry. Alexis joined Newsweek in 2024 from Becker's Hospital Review. She is a graduate of Saint Louis University. You can get in touch with Alexis by emailing a.kayser@newsweek.com or by connecting with her on LinkedIn. Languages: English
Writers Page
Alexis Kayser
Healthcare Editor
Newsweek Is A Trust Project Member
FOLLOW
news article Based on facts, either observed and verified firsthand by the reporter, or reported and verified from knowledgeable sources.
Share
Copy Link
‚úì Link copied to clipboard!
Listen
Translate
English (Original)
Espa√±ol‰∏≠ÂõΩ‰∫∫Fran√ßaisDeutschPortuguese‡§π‡§ø‡§®‡•ç‡§¶‡•ÄNewsweek AI is in beta. Translations may contain inaccuracies‚Äîplease refer to the original content.
Read original
Speed: 0.5xSpeed: 1xSpeed: 1.5xSpeed: 2x
üéôÔ∏è Voice is AI-generated. Inconsistencies may occur.
‚úñ
UpToDate‚Äîthe popular clinical research and information database used by thousands of hospitals around the globe‚Äîhas officially tacked on an AI solution.As one family physician put it, who currently uses a competing tool: "This will be like dropping a bomb on [the competitor]."UpToDate Expert AI is a clinical decision support tool that leverages generative AI to answer medical professionals' questions, drawing on the platform's extensive suite of literature and input from more than 7,600 medical experts. The tool will be available starting in October for approximately 250,000 users in North America, with general availability to follow soon thereafter, Dr. Peter Bonis, chief medical officer of UpToDate's parent company Wolters Kluwer Health, told Newsweek in an exclusive interview."Over many, many years, we have done everything we can possibly do to be able to anticipate and answer [clinicians'] questions and then to answer them at or near the point of care with the best possible information we could, written by absolute experts in the field," Bonis said.
Wolters Kluwer is a professional information, software and services firm. Its health arm houses UpToDate, a popular clinical decision support software for medical professionals. Wolters Kluwer's global headquarters in Alphen aan den Rijn, South Holland,...
Wolters Kluwer is a professional information, software and services firm. Its health arm houses UpToDate, a popular clinical decision support software for medical professionals. Wolters Kluwer's global headquarters in Alphen aan den Rijn, South Holland, The Netherlands, are pictured above.
More
Wolters Kluwer
UpToDate's announcement bookends a busy summer in health care AI. Industry leaders like Epic, Microsoft, Doximity, athenahealth and Oracle have been rolling out new capabilities at a rapid clip.But many of the available tools are focused on reducing administrative burden by transcribing clinical visits, drafting notes and formulating appeal letters. Few have ventured into the realm of clinical decision support, which comes with higher stakes and trickier legal questions.This is an area that UpToDate is uniquely poised to tackle, Bonis said. More than 3 million clinicians have trusted the tool for over three decades and are already using it to find best practices for challenging, complex medical cases. Read more
Health care's tech motto? Move as fast as you can without breaking anything
How Doximity built an empire on "doctors and dorks"
Health care AI solved note-taking. Fixing the core business will be harder
Right now, patients don't have the ability to confirm whether their doctors' advice is correct, according to Bonis. The patient-provider relationship is built on a "tremendous amount of trust," he said, and researchers have been studying ways to validate physicians' recommendations for years."If you summarize that literature, it essentially says that about two out of three clinical encounters, so typical and primary care, will generate a question," Bonis said. "But before the availability of information resources like UpToDate, only 30 percent of those would ever get answered. And yet, if you answered all of them, you would change five to eight management decisions per day."Studies of UpToDate over the years found that when a care provider uses the software to look something up, they change what they do or say in some meaningful way, per Bonis."Realize how scary it is to think that you might be getting a piece of advice, and that a piece of information might completely change that piece of advice or modify it," he said. "That's the stakes."Those stakes are heightened by the availability of public large language models (LLMs), like ChatGPT and Gemini. Physicians are using these models as clinical decision support, although they are prone to hallucination and bias that can lead to false or incomplete recommendations. An October 2024 survey from Fierce Healthcare and the physician social network Sermo found that 76 percent of physicians use general-purpose LLMs to aid clinical decision-making.Wolters Kluwer Health looked at some of these popular LLMs in practice. Bonis declined to share names, but said that their examination revealed multiple errors that could cause harm to patients. One recommended carotid artery surgery for a patient who did not need it. Another recommended that an antidepressant could be stopped cold turkey, despite the medication having a well-known withdrawal reaction. Yet another said to avoid the influenza vaccine in a patient with an egg allergy, although the data demonstrates that vaccination would be safe."This isn't old," Bonis said. "This is new. This is still continuing today. These are tools out there that doctors could be using this moment to answer their questions."
General purpose LLMs like ChatGPT aren't designed for clinicians' use, but a recent survey found that up to 76 percent of physicians use them to support clinical decision-making.
General purpose LLMs like ChatGPT aren't designed for clinicians' use, but a recent survey found that up to 76 percent of physicians use them to support clinical decision-making.
Getty Images
The models' responses are inconsistent, he added: "We've also found problems with search reliability, and others documented this. You search using the exact same phrase twice, an hour apart, a day apart, and you get a different result. Or if you search slightly differently on the same concept, you get a different result."He believes that UpToDate Expert AI can reduce reliance on those general-purpose models, allowing clinicians to access support in a safer, more reliable way. UpToDate's AI model is closed off to the broader web, and only draws from peer-reviewed, expert-authored literature in the system's library‚Äîwhich eliminates the chance of hallucination, according to Bonis.Wolters Kluwer Health also gathered more than 7,600 medical experts from various specialties to address questions that came up in their areas, infusing the answers with the same clinical judgment and reasoning that they'd exercise in their own practices. Their work was supplemented by an internal staff of 55 deputy editor physicians, and external editors who are typically faculty professors at universities."They understand the intersection of evidence, real world patient care, the fact that there isn't a randomized study for everything, and they have judgment," Bonis said of the models' trainers. "How can we make that transparent and bring that to the surface in such a way that you're sharing that judgment and that way of thinking of things from really a world expert, so that everyone has access to it?"The first iteration of UpToDate Expert AI was tested in a laboratory setting for the past two years, allowing Wolters Kluwer Health to gather customer feedback and refine the technology. Several health care organizations had access to the model on a limited basis, with about five members from each being able to test it.That original has been "retired and replaced" with a more polished product, Bonis said, which will be rolled out to a few institutions with a limited number of users. Over the coming months, they'll extend capabilities to "several hundreds of thousands" of UpToDate users, starting in the United States before opening access internationally.UpToDate Expert AI still isn't perfect, Bonis said. The number one complaint from early testers has been latency. Wolters Kluwer declined to share averages for how long it takes the model to generate an answer. A spokesperson told Newsweek, "We don't have shareable benchmarks yet, but speed is a critical part of our development focus. We're focused on delivering fast responses, but never at the expense of clinical reliability."Users have also said that they'd like lighter text and more graphics."But in terms of accuracy, it's been pretty good, so we're encouraged by that," Bonis said.
Dr. Peter Bonis, chief medical officer at Wolters Kluwer Health, at Newsweek's Digital Health Care Forum on September 16.
Dr. Peter Bonis, chief medical officer at Wolters Kluwer Health, at Newsweek's Digital Health Care Forum on September 16.
Newsweek
Newsweek saw an exclusive demonstration of the tool. It describes "assumptions" it is making about the patient, in case any context is missing from the inquiry. Then, it populates an answer with backlinks to the clinical research so that the asker can follow the model's decision-making process.For example, the AI model was asked, "I have a patient whose mother had colon cancer at age 43. She is 27. When should I start colon cancer screening?"Its answer started by clarifying the assumption that the patient does not have a known high-risk hereditary syndrome for colon cancer, like Lynch Syndrome or familial adenomatous polyposis (FAP), which would increase the chance of incidence and may affect the recommendation. It also assumed that the family history was limited to a single, first-degree relative.It then listed its recommendation, backing all 52 steps of the reasoning process with links to the section in UpToDate that validates them.UpToDate Expert AI also had recommendations for more relational questions. Newsweek asked, "I am a pediatrician managing an infant whose parent is refusing the recommended vaccines. What should I do?"The model assumed that the refusal was not due to a medical contraindication, but due to caregiver hesitancy, and that the infant was otherwise healthy. It provided multiple suggestions for approaching the conversation with the caregiver, and recommended trying to compromise on a limited vaccine panel if the caregiver remained insistent.Clinical decision support tools are not meant to replace physicians' education and expertise, but to supplement them. In the United States, approximately four hundred thousand people die every year as a result of misdiagnosis. Ideally, AI could be used to check providers' instincts and pose ideas they didn't come to on their own.However, the real world is not an ideal one. While doctors think they can identify an error in an AI response, they're not always able to catch them."There's an issue of automaticity, which is what the FDA is very interested and concerned about, in that [the AI model] is so efficient in giving you a response that you don't engage in that response adequately to really think through it, and you take action without paying a due consideration," Bonis said.Plus, recent studies have indicated that reliance on AI models can reduce physicians' ability to make accurate clinical judgments in the absence of AI.When asked if he is concerned about AI deskilling physicians, Bonis reflected on his eighth-grade algebra teacher who refused to let the class use calculators "in case we were ever on a desert island." It seems silly, now, in a world where calculators are available on most mobile phones.Generative AI could become like calculators, he continued: a standard technology that we use without question, without worrying that it is detracting from our own capabilities. After all, calculators are more reliable than mental math.But Bonis does wonder about medical students and residents who are going to grow up with these tools, and may not be able to fully develop their own clinical reasoning."Medicine is a continual learning system," he said. "You have to keep up with your field. You have to be able to apply knowledge to patients directly. And if you're going to rely on tools, I think there's at least enough concern out there from what's been published that we should certainly keep an eye on it."Updated 9/24/25 at 3:04 p.m. ET: This article was updated for clarity.
Request Reprint & Licensing
Submit Correction
View Editorial & AI Guidelines
Top stories
Charlie Kirk's Widow, Erika, Speaks for First Time Since Assassination
Who Is Tyler Robinson? Charlie Kirk Shooting Suspect Identified
Utah Governor Spencer Cox Emerges as Voice of Reason After Kirk Killing
Republicans Pass Map Eliminating Seat Democrats Held for 76 Years About the writer
Alexis Kayser is Newsweek's Healthcare Editor based in Chicago. Her focus is reporting on the operations and priorities of U.S. hospitals and health systems. She has extensively covered value-based care models, artificial intelligence, clinician burnout and Americans' trust in the health care industry. Alexis joined Newsweek in 2024 from Becker's Hospital Review. She is a graduate of Saint Louis University. You can get in touch with Alexis by emailing a.kayser@newsweek.com or by connecting with her on LinkedIn. Languages: English
Writers Page
Alexis Kayser
FOLLOW
Alexis Kayser is Newsweek's Healthcare Editor based in Chicago. Her focus is reporting on the operations and priorities of U.S. hospitals and health systems. She has extensively covered value-based care models, artificial intelligence, clinician burnout and Americans' trust in the health care industry. Alexis joined Newsweek in 2024 from Becker's Hospital Review. She is a graduate of Saint Louis University. You can get in touch with Alexis by emailing a.kayser@newsweek.com or by connecting with her on LinkedIn. Languages: English
Alexis Kayser is Newsweek's Healthcare Editor based in Chicago. Her focus is reporting on the operations and priorities of U.S.
...
Read more
The Debate
How Can America Stop School Shootings? Newsweek Contributors Debate
By Newsweek Contributors
VS
Gabby Giffords: Americans Deserve Freedom From Gun Violence | Opinion
By Gabby Giffords
U.S.WorldScienceHealthRankingsOpinionEntertainmentFact CheckMy TurnEducationEventsSportsPodcastsBetter PlanetBetter WorkplacesVaultMightierAutosNewslettersUnconventionalVantageExpertsVoices
Trending
Israel at War Vladimir Putin Russia-Ukraine War Donald Trump
Subscriptions
Membership Monthly $4.99
Membership Yearly $49.00
Membership+Print Monthly $9.99
Membership+Print Yearly $99Newsletters in your inbox See allThe Bulletin (Daily)See SampleThe Gist of It (Daily)Geoscape (Twice a Week)The 1600 (Daily)Inside Trump Policy (Weekly)Newsweek AI (Weekly)Sports Daily (Daily)The Josh Hammer Report (Weekly)See SampleFor The Culture (Three Times a Week)See SampleDiscoveries (3 Times a Week)Like & Subscribe (Daily)Breaking News (As it Breaks)The Debate (Twice a Week)Pawsitively (Daily)Better Planet (Weekly)The Good Life (Weekly)Newsweek Pulse (2x3 Times a Month)
Sign up now
You can unsubscribe at any time. By signing up you are agreeing to our Terms of Service and Privacy Policy
In The Magazine
September 19
2025 Issue
Company
About UsMastheadDiversityAnnouncementsArchivePolicies and StandardsMission StatementLeadershipNewslettersPress Center
Editions:
U.S. EditionÊó•Êú¨PolskaRom√¢nia
Contact
AdvertiseCareersContact UsCorrections
Terms of Use
Cookie PolicyCopyrightPrivacy PolicyTerms & ConditionsTerms of Sale Privacy Settings
¬© 2025 NEWSWEEK DIGITAL LLC