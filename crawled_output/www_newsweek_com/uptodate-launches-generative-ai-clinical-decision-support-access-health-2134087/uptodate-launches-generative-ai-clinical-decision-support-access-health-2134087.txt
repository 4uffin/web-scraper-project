UpToDate Launches Gen AI For Clinical Decision Support - NewsweekNationNewsPoliticsTechFact CheckPersonal FinanceAutomotiveSportsBetter WorkplacesWorldRussia-UkraineMiddle EastChina And AsiaBetter PlanetAll World NewsLifestyleFamily & ParentingEntertainmentTravelPetsRelationshipsScienceHealthOpinionMy TurnAll OpinionRankingsHealthFinanceProductsEducationWorkplacesCorporate ResponsibilityAll RankingsConnectNewslettersFacebookInstagramYouTubeTikTokTwitter/XRedditAnnouncementsMoreUnconventionalEventsPodcastsVantageReaders ChoiceNewsweek.AISubscribeSign InNationNewsPoliticsTechFact CheckPersonal FinanceAutomotiveSportsBetter WorkplacesWorldRussia-UkraineMiddle EastChina And AsiaBetter PlanetAll World NewsLifestyleFamily & ParentingEntertainmentTravelPetsRelationshipsScienceHealthOpinionMy TurnAll OpinionRankingsHealthFinanceProductsEducationWorkplacesCorporate ResponsibilityAll RankingsConnectNewslettersFacebookInstagramYouTubeTikTokTwitter/XRedditAnnouncementsMoreUnconventionalEventsPodcastsVantageReaders ChoiceNewsweek.AI
Health CareAIDoctorResearchMedicineChatGPTNews ArticleUpToDate Launches Gen AI For Clinical Decision SupportPublishedSep 24, 2025 at 08:00 AM EDTupdatedSep 24, 2025 at 03:04 PM EDTBy Alexis KayserHealthcare EditorShareNewsweek is a Trust Project memberUpToDate—the popular clinical research and information database used by thousands of hospitals around the globe—has officially tacked on an AI solution.As one family physician put it, who currently uses a competing tool: "This will be like dropping a bomb on [the competitor]."UpToDate Expert AI is a clinical decision support tool that leverages generative AI to answer medical professionals' questions, drawing on the platform's extensive suite of literature and input from more than 7,600 medical experts. The tool will be available starting in October for approximately 250,000 users in North America, with general availability to follow soon thereafter, Dr. Peter Bonis, chief medical officer of UpToDate's parent company Wolters Kluwer Health, told Newsweek in an exclusive interview."Over many, many years, we have done everything we can possibly do to be able to anticipate and answer [clinicians'] questions and then to answer them at or near the point of care with the best possible information we could, written by absolute experts in the field," Bonis said....UpToDate's announcement bookends a busy summer in health care AI. Industry leaders like Epic, Microsoft, Doximity, athenahealth and Oracle have been rolling out new capabilities at a rapid clip.But many of the available tools are focused on reducing administrative burden by transcribing clinical visits, drafting notes and formulating appeal letters. Few have ventured into the realm of clinical decision support, which comes with higher stakes and trickier legal questions.This is an area that UpToDate is uniquely poised to tackle, Bonis said. More than 3 million clinicians have trusted the tool for over three decades and are already using it to find best practices for challenging, complex medical cases.Related StoriesHealth Care’s Tech Motto? Move As Fast As You Can Without Breaking Anything9 min. readHow Doximity Built an Empire On “Doctors and Dorks”9 min. readHealth Care AI Solved Note-Taking. Fixing the Core Business Will Be Harder9 min. readRight now, patients don't have the ability to confirm whether their doctors' advice is correct, according to Bonis. The patient-provider relationship is built on a "tremendous amount of trust," he said, and researchers have been studying ways to validate physicians' recommendations for years."If you summarize that literature, it essentially says that about two out of three clinical encounters, so typical and primary care, will generate a question," Bonis said. "But before the availability of information resources like UpToDate, only 30 percent of those would ever get answered. And yet, if you answered all of them, you would change five to eight management decisions per day."Studies of UpToDate over the years found that when a care provider uses the software to look something up, they change what they do or say in some meaningful way, per Bonis."Realize how scary it is to think that you might be getting a piece of advice, and that a piece of information might completely change that piece of advice or modify it," he said. "That's the stakes."Those stakes are heightened by the availability of public large language models (LLMs), like ChatGPT and Gemini. Physicians are using these models as clinical decision support, although they are prone to hallucination and bias that can lead to false or incomplete recommendations. An October 2024 survey from Fierce Healthcare and the physician social network Sermo found that 76 percent of physicians use general-purpose LLMs to aid clinical decision-making.Wolters Kluwer Health looked at some of these popular LLMs in practice. Bonis declined to share names, but said that their examination revealed multiple errors that could cause harm to patients. One recommended carotid artery surgery for a patient who did not need it. Another recommended that an antidepressant could be stopped cold turkey, despite the medication having a well-known withdrawal reaction. Yet another said to avoid the influenza vaccine in a patient with an egg allergy, although the data demonstrates that vaccination would be safe."This isn't old," Bonis said. "This is new. This is still continuing today. These are tools out there that doctors could be using this moment to answer their questions."...The models' responses are inconsistent, he added: "We've also found problems with search reliability, and others documented this. You search using the exact same phrase twice, an hour apart, a day apart, and you get a different result. Or if you search slightly differently on the same concept, you get a different result."He believes that UpToDate Expert AI can reduce reliance on those general-purpose models, allowing clinicians to access support in a safer, more reliable way. UpToDate's AI model is closed off to the broader web, and only draws from peer-reviewed, expert-authored literature in the system's library—which eliminates the chance of hallucination, according to Bonis.Wolters Kluwer Health also gathered more than 7,600 medical experts from various specialties to address questions that came up in their areas, infusing the answers with the same clinical judgment and reasoning that they'd exercise in their own practices. Their work was supplemented by an internal staff of 55 deputy editor physicians, and external editors who are typically faculty professors at universities."They understand the intersection of evidence, real world patient care, the fact that there isn't a randomized study for everything, and they have judgment," Bonis said of the models' trainers. "How can we make that transparent and bring that to the surface in such a way that you're sharing that judgment and that way of thinking of things from really a world expert, so that everyone has access to it?"The first iteration of UpToDate Expert AI was tested in a laboratory setting for the past two years, allowing Wolters Kluwer Health to gather customer feedback and refine the technology. Several health care organizations had access to the model on a limited basis, with about five members from each being able to test it.That original has been "retired and replaced" with a more polished product, Bonis said, which will be rolled out to a few institutions with a limited number of users. Over the coming months, they'll extend capabilities to "several hundreds of thousands" of UpToDate users, starting in the United States before opening access internationally.UpToDate Expert AI still isn't perfect, Bonis said. The number one complaint from early testers has been latency. Wolters Kluwer declined to share averages for how long it takes the model to generate an answer. A spokesperson told Newsweek, "We don't have shareable benchmarks yet, but speed is a critical part of our development focus. We're focused on delivering fast responses, but never at the expense of clinical reliability."Users have also said that they'd like lighter text and more graphics."But in terms of accuracy, it's been pretty good, so we're encouraged by that," Bonis said....Newsweek saw an exclusive demonstration of the tool. It describes "assumptions" it is making about the patient, in case any context is missing from the inquiry. Then, it populates an answer with backlinks to the clinical research so that the asker can follow the model's decision-making process.For example, the AI model was asked, "I have a patient whose mother had colon cancer at age 43. She is 27. When should I start colon cancer screening?"Its answer started by clarifying the assumption that the patient does not have a known high-risk hereditary syndrome for colon cancer, like Lynch Syndrome or familial adenomatous polyposis (FAP), which would increase the chance of incidence and may affect the recommendation. It also assumed that the family history was limited to a single, first-degree relative.It then listed its recommendation, backing all 52 steps of the reasoning process with links to the section in UpToDate that validates them.UpToDate Expert AI also had recommendations for more relational questions. Newsweek asked, "I am a pediatrician managing an infant whose parent is refusing the recommended vaccines. What should I do?"The model assumed that the refusal was not due to a medical contraindication, but due to caregiver hesitancy, and that the infant was otherwise healthy. It provided multiple suggestions for approaching the conversation with the caregiver, and recommended trying to compromise on a limited vaccine panel if the caregiver remained insistent.Clinical decision support tools are not meant to replace physicians' education and expertise, but to supplement them. In the United States, approximately four hundred thousand people die every year as a result of misdiagnosis. Ideally, AI could be used to check providers' instincts and pose ideas they didn't come to on their own.However, the real world is not an ideal one. While doctors think they can identify an error in an AI response, they're not always able to catch them."There's an issue of automaticity, which is what the FDA is very interested and concerned about, in that [the AI model] is so efficient in giving you a response that you don't engage in that response adequately to really think through it, and you take action without paying a due consideration," Bonis said.Plus, recent studies have indicated that reliance on AI models can reduce physicians' ability to make accurate clinical judgments in the absence of AI.When asked if he is concerned about AI deskilling physicians, Bonis reflected on his eighth-grade algebra teacher who refused to let the class use calculators "in case we were ever on a desert island." It seems silly, now, in a world where calculators are available on most mobile phones.Generative AI could become like calculators, he continued: a standard technology that we use without question, without worrying that it is detracting from our own capabilities. After all, calculators are more reliable than mental math.But Bonis does wonder about medical students and residents who are going to grow up with these tools, and may not be able to fully develop their own clinical reasoning."Medicine is a continual learning system," he said. "You have to keep up with your field. You have to be able to apply knowledge to patients directly. And if you're going to rely on tools, I think there's at least enough concern out there from what's been published that we should certainly keep an eye on it."Updated 9/24/25 at 3:04 p.m. ET: This article was updated for clarity.Request Reprint & LicensingSubmit CorrectionView Editorial & AI GuidelinesRecommended For YouRelated PodcastsTop StoriesWorldNATO Is At War with Russia Says Kremlin, As Drone Incursions Continue in Europe—Live Updates2 min. readNewsDonald Trump Lays Down Red Line for Israel4 min. readPoliticsTrump Warns ‘It’s Going to Get Worse’ After Dallas ICE Facility Shooting5 min. readNewsChuck Schumer Responds as Trump Admin Plans Mass Firings: What to Know4 min. readU.S.Pete Hegseth Summons Hundreds of US Military Officials to Quantico4 min. readPoliticsSupreme Court Gets New Warning Over Donald Trump Move6 min. readTrendingViralMan Finds Collectable in Thrift Store for $75, Then Learns Its True Value3 min. readSocial SecurityMap Shows States Where Retirees Can Live On Social Security Alone3 min. readHomelessnessVA Announces $84 Million Boost for Veterans3 min. readNational Weather ServiceWinter Weather Warning Issued As 8 Inches of Snow To Hit3 min. readNATORussian Bombers, Fighter Jets Intercepted Near Alaska1 min. readOpinionOpinionGrifters Desecrating Charlie Kirk’s Memory Could Implode MAGA | Opinion6 min. readOpinionIt’s OK To Feel Nothing On Charlie Kirk’s Killing. America Needs More Than That | Opinion5 min. readOpinionPresident Trump, Don’t Settle for Empty Promises on Reindustrialization | Opinion5 min. readOpinionCharlie Kirk’s Christianity Was the Christianity of the American Founding6 min. readOpinionWhy America Medicates Sadness | Opinion5 min. readTrending01Man Finds Collectable in Thrift Store for $75, Then Learns Its True Value3 min read02Map Shows States Where Retirees Can Live On Social Security Alone3 min read03VA Announces $84 Million Boost for Veterans3 min read04Winter Weather Warning Issued As 8 Inches of Snow To Hit3 min read05Russian Bombers, Fighter Jets Intercepted Near Alaska1 min readOpinionGrifters Desecrating Charlie Kirk’s Memory Could Implode MAGA | OpinionBy Josh HammerIt’s OK To Feel Nothing On Charlie Kirk’s Killing. America Needs More Than That | OpinionBy Stephen KentPresident Trump, Don’t Settle for Empty Promises on Reindustrialization | OpinionBy Nathan Picarsic and Emily de La BruyèreCharlie Kirk’s Christianity Was the Christianity of the American FoundingBy Josh HammerWhy America Medicates Sadness | OpinionBy Jonathan AlpertsectionsNationWorldLifestyleHealthOpinionRankingscompanyAbout UsMastheadCareersDiversity & InclusionMission StatementLeadershipeditionsU.S. Edition日本PolskaRomâniacontactAdvertiseCorrectionsAnnouncementsPress CenterContact Usterms of useCookie PolicyCopyrightPrivacy PolicyTerms & ConditionsTerms of SalePrivacy SettingssectionsNationWorldLifestyleHealthOpinionRankingscompanyAbout UsMastheadCareersDiversity & InclusionMission StatementLeadershipeditionsU.S. Edition日本PolskaRomâniacontactAdvertiseCorrectionsAnnouncementsPress CenterContact Usterms of useCookie PolicyCopyrightPrivacy PolicyTerms & ConditionsTerms of SalePrivacy Settings© 2025 Newsweek Digital LLC