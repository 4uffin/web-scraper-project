smolagents
Hugging Face
Models
Datasets
Spaces
Community
Docs
Enterprise
Pricing
Log In
Sign Up
smolagents documentation
smolagents
smolagents
🏡 View all docsAWS Trainium & InferentiaAccelerateArgillaAutoTrainBitsandbytesChat UIDataset viewerDatasetsDeploying on AWSDiffusersDistilabelEvaluateGradioHubHub Python LibraryHuggingface.jsInference Endpoints (dedicated)Inference ProvidersKernelsLeRobotLeaderboardsLightevalMicrosoft AzureOptimumPEFTSafetensorsSentence TransformersTRLTasksText Embeddings InferenceText Generation InferenceTokenizersTrackioTransformersTransformers.jssmolagentstimm
Search documentation
mainv1.22.0v1.21.2v1.20.0v1.19.0v1.18.0v1.17.0v1.16.1v1.15.0v1.14.0v1.13.0v1.12.0v1.11.0v1.10.0v1.9.2v1.8.1v1.7.0v1.6.0v1.5.1v1.4.1v1.3.0v1.2.2v1.1.0v0.1.3
ENHIKOZH
Get started
Introduction
Installation options
Guided tour
Tutorials
✨ Building good agents
📊 Inspect your agent runs using telemetry
🛠️ Tools - in-depth guide
🛡️ Secure code execution
📚 Manage your agent's memory
Conceptual guides
🤖 What are agents?
🤔 How do Multi-step agents work?
Examples
Self-correcting Text-to-SQL
Master your knowledge base with agentic RAG
Orchestrate a multi-agent system
Build a web browser agent using vision models
Using different models
Human-in-the-Loop: Customize agent plan interactively
Async Applications with Agents
Reference
Agent-related objects
Model-related objects
Tools
Tool-related objects
Built-in Tools
Join the Hugging Face community
and get access to the augmented documentation experience
Collaborate on models, datasets and Spaces
Faster examples with accelerated inference
Switch between documentation themes
Sign Up
to get started
smolagents
What is smolagents? smolagents is an open-source Python library designed to make it extremely easy to build and run agents using just a few lines of code. Key features of smolagents include: ✨ Simplicity: The logic for agents fits in ~thousand lines of code. We kept abstractions to their minimal shape above raw code! 🧑‍💻 First-class support for Code Agents: CodeAgent writes its actions in code (as opposed to “agents being used to write code”) to invoke tools or perform computations, enabling natural composability (function nesting, loops, conditionals). To make it secure, we support executing in sandboxed environment via E2B or via Docker. 📡 Common Tool-Calling Agent Support: In addition to CodeAgents, ToolCallingAgent supports usual JSON/text-based tool-calling for scenarios where that paradigm is preferred. 🤗 Hub integrations: Seamlessly share and load agents and tools to/from the Hub as Gradio Spaces. 🌐 Model-agnostic: Easily integrate any large language model (LLM), whether it’s hosted on the Hub via Inference providers, accessed via APIs such as OpenAI, Anthropic, or many others via LiteLLM integration, or run locally using Transformers or Ollama. Powering an agent with your preferred LLM is straightforward and flexible. 👁️ Modality-agnostic: Beyond text, agents can handle vision, video, and audio inputs, broadening the range of possible applications. Check out this tutorial for vision. 🛠️ Tool-agnostic: You can use tools from any MCP server, from LangChain, you can even use a Hub Space as a tool. 💻 CLI Tools: Comes with command-line utilities (smolagent, webagent) for quickly running agents without writing boilerplate code.
Quickstart
Get started with smolagents in just a few minutes! This guide will show you how to create and run your first agent.
Installation Install smolagents with pip:
Copied pip install 'smolagents[toolkit]'
# Includes default tools like web search
Create Your First Agent Here’s a minimal example to create and run an agent:
Copied from smolagents import CodeAgent, InferenceClientModel
# Initialize a model (using Hugging Face Inference API)
model = InferenceClientModel()
# Uses a default model
# Create an agent with no tools
agent = CodeAgent(tools=[], model=model)
# Run the agent with a task
result = agent.run("Calculate the sum of numbers from 1 to 10")
print(result) That’s it! Your agent will use Python code to solve the task and return the result.
Adding Tools Let’s make our agent more capable by adding some tools:
Copied from smolagents import CodeAgent, InferenceClientModel, DuckDuckGoSearchTool
model = InferenceClientModel()
agent = CodeAgent(
tools=[DuckDuckGoSearchTool()],
model=model,
)
# Now the agent can search the web!
result = agent.run("What is the current weather in Paris?")
print(result)
Using Different Models You can use various models with your agent:
Copied # Using a specific model from Hugging Face
model = InferenceClientModel(model_id="meta-llama/Llama-2-70b-chat-hf")
# Using OpenAI/Anthropic (requires 'smolagents[litellm]')
from smolagents import LiteLLMModel
model = LiteLLMModel(model_id="gpt-4")
# Using local models (requires 'smolagents[transformers]')
from smolagents import TransformersModel
model = TransformersModel(model_id="meta-llama/Llama-2-7b-chat-hf")
Next Steps Learn how to set up smolagents with various models and tools in the Installation Guide Check out the Guided Tour for more advanced features Learn about building custom tools Explore secure code execution See how to create multi-agent systems Guided tour Learn the basics and become familiar with using Agents. Start here if you are using Agents for the first time! How-to guides Practical guides to help you achieve a specific goal: create an agent to generate and test SQL queries! Conceptual guides High-level explanations for building a better understanding of important topics. Tutorials Horizontal tutorials that cover important aspects of building agents. < > Update on GitHub
Installation options→
smolagents
What is smolagents?
Quickstart
Installation
Create Your First Agent
Adding Tools
Using Different Models
Next Steps