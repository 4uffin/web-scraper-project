Microsoft claims a 'breakthrough' in AI chip coolingSign inAdvertisementAdvertisementAdvertisementTrending:DJI Osmo Nano reviewiPhone 17 review: Closer to ProiPhone 17 Pro and Pro Max reviewiOS 26: Is your iPhone is compatible?October Prime Day: Best early dealsAIMicrosoft claims a 'breakthrough' in AI chip coolingIt could be up to three times more effective than current methods.Will ShanklinContributing ReporterWill ShanklinContributing ReporterTue, September 23, 2025 at 7:31 PM UTC2 min readAdd Engadget on GoogleMicrosoftAI is an enormous energy drain, contributing to greenhouse gas emissions at a time when the planet desperately needs progress in the opposite direction. Although most of that comes from running GPUs, cooling them is another significant overhead. So, it's worth noting when a company of Microsoft's stature claims to have achieved a breakthrough in chip cooling.Microsoft's new system is based on microfluidics, a method long pursued but hard to implement. The company claims its approach could lead to three times better cooling than current methods.Many data centers rely on cold plates to prevent GPUs from overheating. Although effective to a degree, the plates are separated from the heat source by several layers of material, which limits their performance. "If you're still relying heavily on traditional cold plate technology [in five years], you're stuck," Microsoft program manager Sashi Majety is quoted as saying in the company's announcement.AdvertisementAdvertisementAdvertisementIn microfluidics, the coolant flows closer to the source. The liquid in Microsoft's prototype moves through thread-like channels etched onto the back of the chip. The company also used AI to more efficiently direct the coolant through those channels.MicrosoftAnother aspect separating this prototype from previous attempts is that it drew inspiration from Mother Nature. As you can see in the image above, the etchings resemble the veins in a leaf or a butterfly wing.Microsoft says the technique can reduce the maximum silicon temperature rise inside a GPU by 65 percent. (However, that number depends on the workload and chip type.) This would enable overclocking "without worrying about melting the chip down," Microsoft's Jim Kleewein said. It could allow the company to place servers closer together physically, reducing latency. It would also lead to "higher-quality" waste heat use.Although this sounds good for the environment in a general sense, Microsoft's announcement doesn't lean into that. The blog post primarily discusses the technique's potential for performance and efficiency gains. Green benefits are only alluded to briefly as "sustainability" and reduced grid stress. Let's hope that's only a case of a cynical observer overanalyzing framing. Our planet needs all the help it can get.AdvertisementAbout our adsAdvertisementAdvertisementSubscribe to our newsletter:The Morning After - A twice-weekly dose of the news you needBy subscribing, you are agreeing to Engadget's Terms andPrivacy Policy.SubscribeBy subscribing, you are agreeing to Engadget's Terms andPrivacy Policy.AboutEngadget mastheadAbout our adsAdvertiseLicensingFAQRSS feedSectionsReviewsGearGamingEntertainmentTomorrowBuying guidesVideoPodcastsDealsContributeComment guidelinesSupportBuying GuidesBest laptopThe best iPadBest Bluetooth speakerBest E Ink tabletsBest wireless earbudsBest power banksBest gaming handhelds ContributeComment guidelinesSupportBuying GuidesBest laptopThe best iPadBest Bluetooth speakerBest E Ink tabletsBest wireless earbudsBest power banksBest gaming handhelds Follow UsÂ© 2025 Yahoo. All rights reserved.About UsReprints and PermissionsTrademarksAdvertiseAbout Our AdsTerms and Privacy PolicyPrivacy Dashboard