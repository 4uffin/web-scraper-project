polymorphism - Unexpected caching behavior using polymorphic records in Haskell - Stack Overflow
Skip to main content
Stack Overflow
About
Products
For Teams
Stack Overflow for Teams
Where developers & technologists share private knowledge with coworkers
Advertising
Reach devs & technologists worldwide about your product, service or employer brand
Knowledge Solutions
Data licensing offering for businesses to build and improve AI tools and models
Labs
The future of collective knowledge sharing
About the company
Visit the blog
Loading…
current community
Stack Overflow
help
chat
Meta Stack Overflow
your communities
Sign up or log in to customize your list.
more stack exchange communities
company blog
Log in
Sign up
Home
Questions
AI Assist
Labs
Tags
Challenges
Chat
Articles
Users
Jobs
Companies
Collectives
Communities for your favorite technologies.
Explore all Collectives
Teams
Ask questions, find answers and collaborate at work with Stack Overflow for Teams.
Try Teams for free
Explore Teams
Teams
Ask questions, find answers and collaborate at work with Stack Overflow for Teams.
Explore Teams
Collectives™ on Stack Overflow
Find centralized, trusted content and collaborate around the technologies you use most.
Learn more about Collectives
Teams
Q&A for work
Connect and share knowledge within a single location that is structured and easy to search.
Learn more about Teams
Unexpected caching behavior using polymorphic records in Haskell
Ask Question
Asked
6 years, 8 months ago
Modified
6 years, 8 months ago
Viewed
173 times
8
I've run into some unexpected behavior using polymorphic records in Haskell, where some values are not cached when I expect them to be cached.
Here is a minimal example:
{-# LANGUAGE RankNTypes #-}
import Debug.Trace
-- Prints out two "hello"s
data Translation = Trans { m :: forall a . Floating a => a }
g :: Floating a => a -> a
g x = x + 1
f :: Floating a => a -> a
f x = trace "hello" $ x - 2.0
-- Only one "hello"
-- data Translation = Trans { m :: Float }
--
-- f :: Float -> Float
-- f x = trace "hello" $ x - 2.0
main :: IO ()
main = do
let trans = Trans { m = f 1.5 }
putStrLn $ show $ m trans
putStrLn $ show $ m trans
In the example, I thought if the value f 1.5 was computed and stored in the field m, on the next time it is accessed, it would not be computed again. However, it seems to be recomputed on every access to the record field, as shown by the fact that "hello" is printed twice.
On the other hand, if we remove the polymorphism from the field, the value is cached as expected, and "hello" is only printed once.
I suspect this is due to the interaction of typeclasses (being treated as records) preventing memoization. However, I don't fully understand why.
I realized that compiling with -O2 makes the problem go away, however, this behavior occurs in a much larger system where compiling with -O2 does not seem to have any effect, therefore I'd like to understand the root cause of the problem, so I can fix the performance issues in the larger system.
haskellpolymorphismrecord
Share
Improve this question
Follow
asked Jan 21, 2019 at 20:18
kyekye
45333 silver badges88 bronze badges
Add a comment
|
2 Answers
2
Sorted by:
Reset to default
Highest score (default)
Trending (recent votes count more)
Date modified (newest first)
Date created (oldest first)
6
Hold my beer.
{-# LANGUAGE RankNTypes #-}
{-# LANGUAGE GADTs #-}
{-# LANGUAGE ConstraintKinds #-}
import Debug.Trace
data Dict c where Dict :: c => Dict c
-- An isomorphism between explicit dictionary-passing style (Dict c -> a)
-- and typeclass constraints (c => a) exists:
from :: (c => a) -> (Dict c -> a)
from v Dict = v
to :: (Dict c -> a) -> (c => a)
to f = f Dict
data Translation = Trans { m :: forall a . Floating a => a }
f1, f2 :: Dict (Floating a) -> a -> a
f1 = trace "hello" $ \Dict x -> x - 2.0
f2 = \Dict -> trace "hello" $ \x -> x - 2.0
main = do
let trans1 = Trans { m = to (flip f1 1.5) }
trans2 = Trans { m = to (flip f2 1.5) }
putStrLn "trans1"
print (m trans1)
print (m trans1)
putStrLn "trans2"
print (m trans2)
print (m trans2)
Take a second to predict what this will output before you run it. Then go ask your GHC if she agrees with your guess.
Clear as mud?
The basic distinction you need to draw here is right here in this significantly simplified example:
> g = trace "a" $ \() -> trace "b" ()
> g ()
a
b
()
> g ()
b
()
There is a separate notion of caching a function and caching its output. The latter is, simply, never done in GHC (though see discussion of what's going on with your optimized version below). The former may sound dumb, but it in fact is not so dumb as you might think; you could imagine writing a function which is, say, id if the collatz conjecture is true and not otherwise. In such a situation, it makes complete sense to only test the collatz conjecture once, and then cache whether we should behave as id or not forever afterwards.
Once you understand this basic fact, the next leap you must believe is that in GHC, typeclass constraints are compiled to functions. (The arguments to the function are typeclass dictionaries telling how each of the typeclass' methods behave.) GHC itself manages constructing and passing these dictionaries around for you, and in most cases it's quite transparent to the user.
But the upshot of this compilation strategy is this: a polymorphic but typeclass-constrained type is a function even if it doesn't appear to have function arrows in it. That is,
f 1.5 :: Floating a => a
looks like a plain old value; but in fact it is a function which takes a Floating a dictionary and produces a value of type a. So any computations that go into computing the value a are redone afresh each time this function is applied (read: used at a specific monomorphic type) because, after all, the precise value chosen depends critically on how the typeclass' methods behave.
This leaves only the question of why optimizations changed things in your situation. There I believe what happened is called "specialization", in which the compiler will try to notice when polymorphic things get used at a statically-known monomorphic type and make a binding for that. It goes something like this:
-- starting point
main = do
let trans = \dict -> trace "hello" $ minus dict (fromRational dict (3%2)) (fromRational dict (2%1))
print (trans dictForDouble)
print (trans dictForDouble)
-- specialization
main = do
let trans = \dict -> trace "hello" $ minus dict (fromRational dict (3%2)) (fromRational dict (2%1))
let transForDouble = trans dictForDouble
print transForDouble
print transForDouble
-- inlining
main = do
let transForDouble = trace "hello" $ minus dictForDouble (fromRational dict (3%2)) (fromRational dictForDouble (2%1))
print transForDouble
print transForDouble
In this last one the function-ness is gone; it is "as if" GHC has cached the output of trans when applied to the dictionary dictForDouble. (If you compile with optimizations and -ddump-simpl you will see it goes even further, doing constant-propagation to turn the minus ... stuff into just D# -0.5##. Whew!)
Share
Improve this answer
Follow
edited Jan 21, 2019 at 22:47
answered Jan 21, 2019 at 21:40
Daniel WagnerDaniel Wagner
155k1010 gold badges231231 silver badges392392 bronze badges
Comments
Add a comment
1
{-# LANGUAGE RankNTypes #-}
import Debug.Trace
--Does not get cached
data Translation = Trans { m :: forall a. Floating a => a }
f :: Floating a => a -> a
f x = trace "f" $ x - 2.0
Since a is a rigid type variable bound by a type expected by the context
forall a. Floating a => a you would have to cache the context as well
--Does get cached
data Translation' = Trans' { m' :: Float }
f' :: Float -> Float
f' x = trace "f'" $ x - 2.0
Since this is a value of type Float it can be computed once and cached afterwards.
main :: IO ()
main = do
let
trans = Trans { m = f 1.5 }
trans' = Trans' { m' = f' 1.5}
putStrLn $ show $ (m trans :: Double)
putStrLn $ show $ (m trans :: Float)
-- ^ you can evaluate it with 2 different contexts
putStrLn $ show $ (m' trans' :: Float)
putStrLn $ show $ (m' trans' :: Float)
-- ^ context fixed
Note that the former one does not get cached whether compiler optimization is turned on or off.
When they are both Float and you turn on optimization the problem is gone.
If you compile the larger system with optimization and it is to inefficient on some metric I would suspect that the problem lies somewhere else.
Share
Improve this answer
Follow
edited Jan 21, 2019 at 22:27
answered Jan 21, 2019 at 21:53
stevesteve
28111 silver badge55 bronze badges
Comments
Add a comment
Your Answer
Thanks for contributing an answer to Stack Overflow!Please be sure to answer the question. Provide details and share your research!But avoid …Asking for help, clarification, or responding to other answers.Making statements based on opinion; back them up with references or personal experience.To learn more, see our tips on writing great answers.
Draft saved
Draft discarded
Sign up or log in
Sign up using Google
Sign up using Email and Password
Submit
Post as a guest
Name
Email
Required, but never shown
Post as a guest
Name
Email
Required, but never shown
Post Your Answer
Discard
By clicking “Post Your Answer”, you agree to our terms of service and acknowledge you have read our privacy policy.
Start asking to get answers
Find the answer to your question by asking.
Ask question
Explore related questions
haskellpolymorphismrecord
See similar questions with these tags.
The Overflow Blog
Stack Overflow is helping you learn to code with new resources
Off with your CMS’s head! Composability and security in headless CMS
Featured on Meta
Spevacus has joined us as a Community Manager
Introducing a new proactive anti-spam measure
Policy: Generative AI (e.g., ChatGPT) is banned
New and improved coding challenges
New comment UI experiment graduation
Linked
0
Integer is fast, but Integral a is slow
0
Confused output of `traceM` in recursive call on function monad
Related
4
Implementing a cache
5
Haskell polymorphic functions with records and class types
49
How can I use HaskellDB with polymorphic fields? (Problems with overlapping instances)
7
Laziness and polymorphic values
15
Why does adding a polymorphic type signature degrade performance?
2
Haskell Caching
6
Polymorphic types in records
4
Polymorphic variable used in different contexts haskell
8
reuse/memoization of global polymorphic (class) values in Haskell
3
Polymorphic functions in Record Types Haskell
Hot Network Questions
Movie with an alien in disguise as a human boy. Fights a bad alien
How to prevent paste from removing Data Validation (no macros), while allowing users to insert rows in Excel?
Can Slashing Grace be used with natural attacks?
Key change, from Ab major to E major
Did Jack Swigert really cover the LEM detachment switch with a paper note in Apollo 13?
Apparent contradiction in Lorentz's magnetic force and Ohm's law relation
`circledsteps`, but... `squaredsteps` and `triangledsteps`?
Why would you find "be clutch" useful or not and is there another slang/informal phrase with a similar meaning?
What does "your own" mean in "did it not remain your own?", Acts 5:4?
Why is it useful to have mem_top < mem_max?
What is a numerically practical and safe measure of dispersion of a data set?
How to cast rays from curve points?
help understanding quantifier rules for natural deduction
What spider is this. Found in Milwaukee WI
n white and n black balls, pairs of balls drawn one by one. Probability that each pair contains 1W & 1B.
How do I handle two apps for a single Firebase Project?
Find a linear function such that if f(0), f(1), f(2), ⋯ are indices of the elements of the list, the sum must equal to its slope
Linear rheostat - where lies a trick of a sliding contact with isolated wire?
What are the circumstances that would put an offender at risk of the death penalty in state court under Utah law?
Prospective new PI wants to chat with former PI who kicked me out. What to do?
In a Windows 10 system how can I clear the stored credentials used to access a network shared folder?
What is this circuit breaker on the outside of my house for?
Novel Two ships set out to explore the arctic. Disaster befalls them. There is a demon which appears to be a polar bear
How to completely remove the Firefox tabs' "tooltips", without affecting anything else?
more hot questions
Question feed
Subscribe to RSS
Question feed
To subscribe to this RSS feed, copy and paste this URL into your RSS reader.
lang-hs
Stack Overflow
Questions
Help
Chat
Products
Teams
Advertising
Talent
Company
About
Press
Work Here
Legal
Privacy Policy
Terms of Service
Contact Us
Your Privacy Choices
Cookie Policy
Stack Exchange Network
Technology
Culture & recreation
Life & arts
Science
Professional
Business
API
Data
Blog
Facebook
Twitter
LinkedIn
Instagram
Site design / logo © 2025 Stack Exchange Inc;
user contributions licensed under
CC BY-SA
.
rev 2025.9.22.34261