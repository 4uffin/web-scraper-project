Newest 'llama' Questions - Stack Overflow
Skip to main content
Stack Overflow
About
Products
For Teams
Stack Overflow for Teams
Where developers & technologists share private knowledge with coworkers
Advertising
Reach devs & technologists worldwide about your product, service or employer brand
Knowledge Solutions
Data licensing offering for businesses to build and improve AI tools and models
Labs
The future of collective knowledge sharing
About the company
Visit the blog
Loading…
current community
Stack Overflow
help
chat
Meta Stack Overflow
your communities
Sign up or log in to customize your list.
more stack exchange communities
company blog
Log in
Sign up
Home
Questions
AI Assist
Labs
Tags
Challenges
Chat
Articles
Users
Jobs
Companies
Collectives
Communities for your favorite technologies.
Explore all Collectives
Teams
Ask questions, find answers and collaborate at work with Stack Overflow for Teams.
Try Teams for free
Explore Teams
Teams
Ask questions, find answers and collaborate at work with Stack Overflow for Teams.
Explore Teams
Collectives™ on Stack Overflow
Find centralized, trusted content and collaborate around the technologies you use most.
Learn more about Collectives
Teams
Q&A for work
Connect and share knowledge within a single location that is structured and easy to search.
Learn more about Teams
401 questions
Newest
Active
Bountied
Unanswered
More
Bountied
0
Unanswered
Frequent
Score
Trending
Week
Month
Unanswered (my tags)
Filter
Filter by
No answers
No upvoted or accepted answers
No Staging Ground
Has bounty
Days old
Sorted by
Newest
Recent activity
Highest score
Most frequent
Bounty ending soon
Trending
Most activity
Tagged with
My watched tags
The following tags:
Apply filter
Cancel
0
votes
0
answers
62
views
pippy examples: torch._dynamo.exc.UserError: It looks like one of the outputs with type <class transformers.cache_utils.DynamicCache> is not supported
when the program starts to initialize pipeline object, a unexpected error was thrown:
[rank0]: Traceback (most recent call last):
[rank0]:
File "/root/anaconda3/envs/polar/lib/python3.12/site-...
pythonpytorchhuggingface-transformersllama
Aerith
1
asked 2 days ago
0
votes
0
answers
13
views
Running Ollama on local computer and prompting from jupyter notebook - does the model recall prior prompts like if it was the same chat?
I am doing some tests using Ollama on local computer, with Llama 3.2, which consists in prompting a task against a document.
I read that after having reached maximum context, I should restart the ...
large-language-modelllamaollamallama3
user305883
1,749
asked 2 days ago
0
votes
0
answers
45
views
The data type of the llava model uncontrollably changes to float32
I am using the llama-8b-llava model. I have made some modifications to the model, which are non-structural and do not introduce any parameters. During the model loading process, I used the torch....
huggingface-transformersllama
ILOT
23
asked Aug 29 at 13:26
1
vote
1
answer
72
views
Import "llama_index.llms.ollama" could not be resolved
I have the following imports for a python file thats meant to be a multi llm agent soon. I wanted to use llama_index and I found a nice video from Tech with Tim which explains everything very well. I ...
pythonpython-venvllamaollama
Joshie
23
asked Aug 13 at 15:07
1
vote
0
answers
87
views
Fine-tuned LLaMA 2–7B with QLoRA, but reloading fails: missing 4bit metadata. Likely saved after LoRA+resize. Need proper 4bit save method
I’ve been working on fine-tuning LLaMA 2–7B using QLoRA with bitsandbytes 4-bit quantization and ran into a weird issue. I did adaptive pretraining on Arabic data with a custom tokenizer (vocab size ~...
huggingface-transformersquantizationllamapeft
orchid Ali
11
asked Jun 26 at 17:50
1
vote
0
answers
146
views
llama-cpp-python installing for x86_64 instead of arm64
I am trying to set up local, high speed NLP but am failing to install the arm64 version of llama-cpp-python.
Even when I run
CMAKE_ARGS="-DLLAMA_METAL=on -DLLAMA_METAL_EMBED_LIBRARY=on" \
...
pythonllamallama-cpp-python
Dennis Losett
11
asked Jun 22 at 16:45
2
votes
1
answer
160
views
Llama_cookbook: why are labels not shifted for CausalLM?
I'm studying the llama_cookbok repo, in particular their finetuning example.
This example uses LlamaForCausalLM model and samsum_dataset (input: dialog, output: summary). Now, looking at how they ...
pythonlarge-language-modelllamaattention-modelfine-tuning
Dmitry
340
asked Jun 1 at 4:29
0
votes
0
answers
44
views
Using llama-index with the deployed LLM
I wanted to make a web app that uses llama-index to answer queries using RAG from specific documents. I have locally set up Llama3.2-1B-instruct llm and using that locally to create indexes of the ...
large-language-modelhuggingfacellamallama-indexrag
Utkarsh
1
asked May 29 at 11:17
0
votes
0
answers
90
views
Why `mul_mat` in ggml slower than llama.cpp?
I use the following command to compile an executable file for Android:
cmake \
-DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \
-DANDROID_ABI=arm64-v8a \
-...
c++openmplarge-language-modelinferencellama
XUHAO77
11
asked May 13 at 6:49
1
vote
0
answers
103
views
How to implement timeout and retry for long-running Hugging Face model inference in Python?
I'm working with a locally hosted Hugging Face transformers model (mistral-7b, llama2-13b, etc.), using the pipeline interface on a GPU server (A100).
Sometimes inference takes much longer than ...
pythonpipelinehuggingface-transformersllamamistral-ai
Swati
189
asked Apr 27 at 2:15
2
votes
1
answer
56
views
How to re-use attention in huggingface
I have a long chunk of text that I need to process using a transformer, I would then like to have users ask different questions about it (all questions are independent, they don't relate to each other)...
huggingface-transformerslarge-language-modelhuggingfacellama
Matt
45
asked Apr 25 at 20:08
0
votes
1
answer
164
views
No stopping token generated by Llama-3.2-1B-Instruct
I am experimenting with Llama-3.2-1B-Instruct for learning purposes. When I try to implement a simple re-write task with Hugging Face transformers, I get a weird result when the model does not ...
huggingface-transformerslarge-language-modelllama
user2101255
1
asked Apr 21 at 3:10
0
votes
1
answer
59
views
How to incorporate additional data in fine tuning LLM
My goal is to create a chat bot specialized in answering questions related to diabetes.
I am new to fine tuning and have a couple questions before I begin. My question is about the dataset format and ...
large-language-modelllamafine-tuning
Shlok Kothari
11
asked Mar 26 at 19:57
1
vote
0
answers
73
views
Microsoft.Extensions.AI responses output JSON when custom functions are used
I'm using Microsoft.Extensions.AI to run queries against numerous Ollama models that I have installed. I have added a custom functions (AIFunction type) by creating a ChatOptions instance and passing ...
artificial-intelligencellamaollamamicrosoft-extensions-ai
Dmitri Nesteruk
23.9k
asked Mar 17 at 6:48
0
votes
1
answer
164
views
Meta llama 3.2 3b model local download
I am installed the llamma3.2 model from meta directly and got it in this format
-a----
3/10/2025
3:22 PM
209 checklist.chk
-a----
3/10/2025
9:47 AM
6425585114 ...
pythonlarge-language-modelllama
Joe
23
asked Mar 13 at 7:21
15
30
50
per page
1
2
3
4
5
…
27
Next
The Overflow Blog
Democratizing your data access with AI agents
The history and future of software development (part 1)
Featured on Meta
Spevacus has joined us as a Community Manager
Introducing a new proactive anti-spam measure
New and improved coding challenges
New comment UI experiment graduation
Policy: Generative AI (e.g., ChatGPT) is banned
Hot Network Questions
Can a state execute an ICC arrest warrant in international waters?
Plotting functions without sampling artefacts
Change the font for the dagger symbol in math mode
In Justice Kagan's "Congress, as everyone agrees, prohibited each of those presidential removals." who exactly is "everyone"?
Separating trefoil knot on torus
Changing size of math environments
What is an aggravating factor and why is kinship considered one?
How to delete a file with a very long (and very strange) filename in Windows?
Smoothing a triangulated surface without changing its quasi-isometry class
How can blood fuel space travel?
How do trees drop their leaves?
Simplification of an analytically evaluated integral expressed in terms of elliptic integrals
What is the exact method of calculating a number needed to treat (NNT) in a meta-analysis?
How can an alien symbiote coexist with the immune system long-term?
How does a telepathic bond work if the bondee lacks language?
From honeycombs to a cube
Space Princess Space Tours: Black Holes merging - what would you visually see?
What is the exact meaning of olcAccess: {1}to dn.exact="" by * read
List of crowdsourced math projects actively seeking participants
How do I make the middle of the bill curve up?
What exactly makes something a "phased-out creature"
Is there a specific term to describe someone who is religious but does not necessarily believe everything that their religion teaches, and uses logic?
What does "my left a** cheek" mean?
Another Slitherlink Next Step
more hot questions
Newest llama questions feed
Subscribe to RSS
Newest llama questions feed
To subscribe to this RSS feed, copy and paste this URL into your RSS reader.
Stack Overflow
Questions
Help
Chat
Products
Teams
Advertising
Talent
Company
About
Press
Work Here
Legal
Privacy Policy
Terms of Service
Contact Us
Your Privacy Choices
Cookie Policy
Stack Exchange Network
Technology
Culture & recreation
Life & arts
Science
Professional
Business
API
Data
Blog
Facebook
Twitter
LinkedIn
Instagram
Site design / logo © 2025 Stack Exchange Inc;
user contributions licensed under
CC BY-SA
.
rev 2025.9.25.34480