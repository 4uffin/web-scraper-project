What are large language models (LLMs)? | Microsoft Azure
This is the Trace Id: 35a68352c9a21dde464ab7767eb15c98
Skip to main content
Microsoft
Azure
Azure
Azure
Home
Explore
Products
Popular
Popular
View all products (200+)
Azure AI Foundry
Azure AI Foundry Agent Service
Azure OpenAI in Foundry Models
Azure AI Content Safety
GitHub Copilot
Azure DevOps
Azure Kubernetes Service (AKS)
Azure Cosmos DB
Azure Database for PostgreSQL
Azure Arc​
AI + machine learning
AI + machine learning
Azure AI Foundry
Azure AI Foundry Agent Service
Azure OpenAI in Foundry Models
Azure AI Foundry Models
Azure AI Search
Azure AI Speech
Azure AI Content Understanding
Azure AI Content Safety
Azure AI Services
Azure Machine Learning
Databases + analytics
Databases + analytics
Azure Cosmos DB
Azure SQL
Azure Database for PostgreSQL
Azure Managed Redis
Microsoft Fabric
Azure Databricks
Azure Synapse Analytics
View all databases
Compute
Compute
Linux virtual machines in Azure
SQL Server on Azure Virtual Machines
Windows Server
Azure Functions
Azure Virtual Machine Scale Sets
Azure Spot Virtual Machines
Azure Container Apps
Azure Compute Fleet
Containers
Containers
Azure Kubernetes Service (AKS)
Azure App Service
Azure Functions
Azure Container Instances​
Azure Spring Apps
Azure Red Hat OpenShift
Azure Kubernetes Fleet Manager
Azure Container Apps
Azure Container Registry
App Configuration
Hybrid + multicloud
Hybrid + multicloud
Azure Arc​
Azure Local
Microsoft Defender for Cloud
Azure IoT Edge
Azure Monitor
Microsoft Sentinel
Azure Migrate
Solutions
Featured
Featured
View all solutions (40+)
Azure AI
Migrate to innovate in the era of AI
Build and modernize intelligent apps
Data analytics for AI
Azure AI Infrastructure
Adaptive cloud
Azure networking and network security
SAP on the Microsoft Cloud
Azure Databases
Azure Integration Services
AI
AI
Azure AI
Responsible AI with Azure
Azure AI Infrastructure
Build and modernize intelligent apps
Knowledge mining
Hugging Face on Azure
Machine learning operations (MLOps)
Application development
Application development
Build and modernize intelligent apps
Development and testing
DevOps
DevSecOps
Serverless computing
Application and Data Modernization
Low-code application development on Azure
Cloud migration and modernization
Cloud migration and modernization
Migration and modernization center
Migrate to innovate in the era of AI
Build and modernize intelligent apps​
.NET apps migration
Development and testing
SQL Server migration
Linux on Azure
SAP on the Microsoft Cloud
Oracle on Azure
Azure confidential computing
Hybrid Cloud and infrastructure
Hybrid Cloud and infrastructure
Hybrid and multicloud solutions
Backup and disaster recovery
High-performance computing (HPC)
Business-critical applications
Quantum computing
Resources
Resources
Reference architectures
Resources for accelerating growth
Azure Marketplace
Azure Essentials
Browse the Microsoft Business Solutions Hub
Azure innovate & Azure Migrate and Modernize
Microsoft Cloud Adoption Framework for Azure
Azure Well-Architected Framework
FinOps on Azure
Pricing
How to buy
How to buy
Azure pricing
Free Azure services
Azure account
Flexible purchase options
Azure benefits and incentives
Pricing tools and resources
Pricing tools and resources
Pricing calculator
Optimize your costs
FinOps on Azure
Partners
Find a partner
Find a partner
Azure Marketplace
Find a partner
Become a partner
Become a partner
Azure for Software Development Companies
Azure for Partners
Join ISV Success
Resources
Learning
Learning
Get started with Azure
Customer stories
Analyst reports, white papers, and e-books
Videos
Learn more about cloud computing
Technical resources
Technical resources
Documentation
Get the Azure mobile app
Developer resources
Quickstart templates
Resources for startups
Community
Community
Developer community
Students
Developer stories
What's new
What's new
Blog
Events and Webinars
Learn
Support
Contact Sales
Get started with Azure
Sign in
More
All Microsoft
Global
Microsoft 365
Teams
Copilot
Windows
Surface
Xbox
Deals
Small Business
Support
Software
Software
Windows Apps
AI
Outlook
OneDrive
Microsoft Teams
OneNote
Microsoft Edge
Moving from Skype to Teams
PCs & Devices
PCs & Devices
Computers
Shop Xbox
Accessories
VR & mixed reality
Certified Refurbished
Trade-in for cash
Entertainment
Entertainment
Xbox Game Pass Ultimate
PC Game Pass
Xbox games
PC games
Business
Business
Microsoft Cloud
Microsoft Security
Dynamics 365
Microsoft 365 for business
Microsoft Power Platform
Windows 365
Microsoft Industry
Small Business
Developer & IT
Developer & IT
Azure
Microsoft Developer
Microsoft Learn
Support for AI marketplace apps
Microsoft Tech Community
Azure Marketplace
AppSource
Visual Studio
Other
Other
Microsoft Rewards
Free downloads & security
Education
Licensing
Unlocked stories
View Sitemap
Search
Show search input
No results
Cancel
Resources
Cloud Terms
What are Large Language Models?
What are large language models (LLMs)?
Get an overview of how LLMs work—and explore how they are used to build AI-powered solutions.
Explore the Azure model catalog
Get started with Azure
What are LLMs?
What are LLMs?
How it works
Pros and cons
Use cases
What’s next
Resources
FAQ
READ TIME
10 min
LLM meaning
Large language models (LLMs) are advanced AI systems that understand and generate natural language, or human-like text, using the data they’ve been trained on through machine learning techniques. LLMs can automatically generate text-based content, which can be applied to a myriad of uses cases across industries, resulting in greater efficiencies and cost savings for organizations worldwide.
Key takeaways
LLMs are advanced AI systems that can understand and generate natural language.
LLMs rely on deep learning architectures and machine learning techniques to process and incorporate information from different data sources.
LLMs bring major benefits, such as language generation and translation, to a diverse set of fields.
Though they are groundbreaking, LLMs face challenges that may include computational requirements, ethical concerns, and limitations in understanding context.
Despite these challenges, organizations are already using the generative pretrained transformers (GPT) series and bidirectional encoder representations from transformers (BERT) for tasks such as content creation, chatbots, translation, and sentiment analysis.
How it works
How LLMs work
Brief history of LLMs
LLMs are a modern-day development, but the study of natural language processing (NLP) dates to 1950, when Alan Turing launched the Turing test to gauge intelligent behavior among machines. In the test, a human judge speaks to a computer using a set of questions—and must determine if they are speaking to a machine or a human. By the 1980s and 1990s, NLP shifted away from logic experiments toward a more data-driven approach. With their ability to predict which words in a sentence were likely to come next based on the words before them, statistical language models, such as n-grams, paved the way for a new era. By the early 2010s, newer neural networks expanded the capabilities of these language models even further, allowing them to move beyond determining the order of words toward a deeper understanding of the representation and meaning of words.
These new developments culminated in a breakthrough in 2018, when eight Google scientists penned and published “Attention is All You Need,” a landmark study on machine learning. Most notably, the paper introduced the transformer architecture, an innovative neural network framework that could manage and understand complex textual information with greater accuracy and scale. Transformers are now foundational to some of today’s most powerful LLMs, including the GPT series, as well as BERT.
Basic architecture
Today’s state-of-the-art LLMs use deep learning architectures like transformers and other deep neural network frameworks to process information from different data sources. Transformers are especially effective at handling sequential data, such as text, which allows them to understand and generate natural language for tasks such as language generation and translation.  Transformers consist of two primary components: encoders and decoders. These components often work together to process and generate sequences. The encoder takes raw textual data and turns that input into discrete elements that can be analyzed by the model. The decoder then processes that data through a series of layers to produce the final output, which may, for instance, consist of a generated sentence. Transformers can also consist of encoders or decoders only, depending on the type of model or task.
Training process
The training process for LLMs consists of three main stages: data collection, model training, and fine-tuning.  During the data collection phase, the model is exposed to large volumes of textual data from a wide variety of sources, including Internet resources, books, articles, and databases. The data is also cleaned, processed, standardized, and stored in a NoSQL database so that it can be used to train the model on language patterns, grammar, information, and context.
In the pre-training phase, the model starts to build an understanding of the language in the data. This is accomplished through large-scale, unsupervised tasks where the model learns to predict text based on its context. Some techniques include autoregressive modeling, where the model learns to predict the next word in a sequence, as well as masked language modeling, where the model fills in masked words to understand the context.
Lastly, during the fine-tuning phase, the model is further trained on a smaller, more task-specific dataset. This process refines the model's knowledge and enhances its performance for specific tasks, such as sentiment analysis or translation, so that it can be used for a variety of applications.
Key components
The transformer model breaks raw text down into smaller, basic units of text called tokens. Tokens may consist of words, parts of words, or even individual characters, depending on the use case. These tokens are then converted into dense numerical representations that capture order, semantic meaning, and context. These representations, called embeddings, are then passed through a stack of layers consisting of two sub-layers: self-attention and neural networks. While both layers assist in converting text into a form that the model can process effectively, the self-attention mechanism is a key component to the transformer architecture. The self-attention mechanism is what permits the model to home in on different parts of a text sequence and dynamically weigh the value of information relative to other tokens in the sequence, regardless of their position. This mechanism is also what gives LLMs the capacity to capture the intricate dependencies, relationships, and contextual nuances of written language.
Benefits, challenges
Benefits and challenges
Benefits
LLMs offer many benefits that have contributed to significant advancements in work and society.
Improved language generation and translation
Because LLMs can understand and capture the nuanced relationships between words, they excel at producing natural, human-like text, resulting in improved language generation. They can fluently and consistently generate creative, contextually appropriate responses, and they can do so in various formats, including novels. Since they can contextualize and find subtleties in meaning, LLMs that are trained on multilingual data can also perform highly accurate translations. Training a model on a specific set of languages can help them fine-tune their ability to handle idioms, expressions, and other complex linguistic features, resulting in translations that feel organic and fluent.
Applications in diverse fields
LLMs are versatile tools that have many applications across many fields, including healthcare, finance, and customer service.   In healthcare, LLMs can:  Analyze patient reports for possible conditions and provide preliminary diagnoses.
Generate patient notes and discharge summaries, in turn streamlining administrative tasks.
Suggest personalized treatment plans and medical care based on patient history.
In the finance sector, LLMs can: Identify unusual activity across financial data that may point to fraud.
Assess financial risks by analyzing market trends and financial reports.
Suggest personalized recommendations based on your unique financial history and goals.
In customer service, LLMs can: Drive automated customer support through conversational agents and chatbots.
Expand the scope of an organization’s service by providing customers with all-day support.
Help create and update documentation by generating content based on common questions.
Challenges
LLMs offer crucial benefits, but they also come with challenges to consider.
Computational and energy requirements
While LLMs are powerful, they require substantial amounts of computational resources, storage, and energy consumption to operate. During training, transformers scale with the length of the input sequence, so the longer the text, the more memory you’ll need. Not only are these demands expensive, but they also emit a significant amount of carbon into the environment. Cloud computing platforms can support the heavy computational load of LLMs by providing flexible, scalable infrastructure, making it more accessible for organizations to start developing their own models. Still, the environmental impact of LLMs pose a challenge and is indicative of a need for more energy-efficient models and techniques.
Ethical concerns (e.g., bias, misinformation)
LLMs are only as good as the data they are trained on. If there is discriminatory bias against certain groups in the training data, then the model will highlight these attitudes. Identifying and mitigating these biases so that the model remains fair is an ongoing task, one that requires frequent and consistent human monitoring. LLMs can also produce compelling but factually misleading information, resulting in the spread of misinformation, fake news, phishing emails, and other forms of harmful content. Content moderation guidelines can also vary across regions, which makes them difficult to navigate around. As a result, many organizations may find it challenging to build and maintain trust in their users when introducing LLMs to their business operations.
Limitations in understanding context and nuance
While LLMs excel at identifying patterns in language, they can still struggle with new or unknown contexts that require more nuanced understanding. As a result, LLMs trained on sensitive, proprietary data may accidentally generate or reveal confidential information from their training data.  Addressing this issue can pose a significant challenge, especially since the internal workings of LLMs often lack transparency. This can contribute to an overall lack of accountability, as well as issues around trust-building.
Use cases
Types and use cases
GPT series
First developed by OpenAI in 2018, the GPT series introduced the foundational concept of data collection, pretraining, and fine-tuning to LLMs. GPT-2, released in 2019, significantly scaled up the model’s capabilities and improved its ability to generate more contextually relevant language. GPT-3 advanced the model’s capacity for handling complex prompts and tasks. The latest iteration, GPT-4, was released in 2023 and provides even more accurate and nuanced responses to prompts—while also addressing some of the model’s previous challenges, including bias.  Today, GPT continues to push the boundaries of what’s possible in the field of natural language generation. Each model in the series builds upon the previous one, driving AI-powered innovation forward.
BERT and its variants
Developed by Google in 2018, BERT is a groundbreaking model that has set the standard for what’s possible with LLMs. Unlike the GPT series, which processes text in a unidirectional manner (from left-to-right or right-to-left), BERT takes on a bidirectional approach. A bidirectional model processes the context of each word from both directions simultaneously, which allows BERT to perform masked language modeling in addition to next-sentence predictions. Researchers have also contributed to further advancements in the field by fine-tuning BERT on tasks such as sentiment analysis, setting new benchmarks as a result.
Other notable models
Developed by Facebook AI in 2019, Robustly optimized BERT approach (RoBERTa) is a variant of the BERT model that expands on BERT's bidirectional transformer architecture by optimizing the pretraining process. RoBERTa is trained with a larger data set, and for longer. It also focuses solely on masked language modeling. This allows RoBERTa to demonstrate its robust ability to capture context and nuances.  Text-To-Text Transfer Transformer (T5), which was invented by Google Research, is another notable LLM. Like traditional models, T5 is built on the transformer architecture and uses encoders and decoders to process text during the pretraining phase. Unlike traditional models, T5 treats both the inputs and outputs as text strings, simplifying the architecture and streamlining the training process. T5 models are an adaptable general-purpose model that can handle a versatile range of tasks.
Content creation and summarization
LLMs can generate engaging, informative, and contextually appropriate content in a variety of styles and formats. When prompted, they can generate articles, reports, blog posts, emails, marketing copy, and even code snippets.    When it comes to summaries, LLMs stand out in their unique ability to distill large volumes of text into concise and accurate snapshots. They can present key points while still maintaining the original context and meaning of the original content. Researchers are already saving time and boosting productivity by using LLMs to summarize research papers, articles, presentations, and meeting notes.
Conversational agents and chatbots
Conversational agents and chatbots rely on the advanced natural language processing capabilities of LLMs to generate human-like interactions. They interpret user inputs and respond in a fluent, natural, and contextually relevant manner. Not only can they answer questions, but they can also engage in long and complex dialogue.  With the addition of chatbots and virtual assistants, businesses can now provide round-the-clock support to their customers, in turn expanding their service availability, improving response times, and increasing overall customer satisfaction.
Language translation and sentiment analysis
LLMs that are extensively trained on multilingual datasets produce highly accurate translations across various languages. Unlike traditional models, LLMs can capture the subtleties and complexities of language, such as idiomatic expressions, resulting in translations that are both fluent and contextually appropriate.  LLMs are also able to perform sentiment analysis, which analyzes the underlying emotional tone of a text. By processing and interpreting the subtleties of language, LLMs provide more precise and insightful sentiment evaluations. They can even detect more nuanced sentiments, such as sarcasm.
Personalized recommendations
LLMs can analyze user data, including user history and preferences, and generate personalized, tailored recommendations that reflect the user's interests and needs, in turn enhancing the overall user experience.  This capability is widely used across e-commerce, content streaming, and social media, where delivering tailored recommendations drives more meaningful interactions. LLMs can also be used as an educational tool by providing personalized learning experiences to students.
What's next
What’s next
As researchers continue to improve their understanding, efficiency, and scalability, LLMs are expected to become even more adept at handling complex language tasks. With the adoption of LLMs on the rise, more and more organizations will be experiencing streamlined automation, greater personalization, and better decision-making processes overall.  Researchers are continuing to explore new ways of addressing bias, an ongoing issue. These include debiasing algorithms that tackle bias during training, incorporating synthetic data that can rebalance datasets to reflect fairness, explainability tools to better understand model decisions, and detection benchmarks that help identify and quantify bias more precisely.  Multimodal models, which process text, image, audio, and video data, are also becoming more and more sophisticated. While LLMs process textual data by evaluating syntax and meaning, multimodal models analyze visual data through computer vision techniques, as well as audio data through temporal processing.Top of Form Multimodal models are enhancing today’s technologies while also paving the way for the innovations of tomorrow.
RESOURCES
Learn more about Azure AI
Resources
Student developer resources
Take advantage of learning materials and programs that will help you jump-start your career.
Learn more
Resources
Azure resources
Access all the Azure resources you need, including tutorials, white papers, and code samples.
Explore resources
Resources
Azure learning hub
Build your AI skills with training customized to your role or specific technologies.
Learn more
FAQ
Frequently Asked Questions
Expand all
Collapse all
01/
What does LLM stand for?
LLM stands for large language model.
02/
What is the difference between LLM and AI?
AI is a broad field that covers a wide range of applications beyond just language. It includes all technologies that aim to replicate human intelligence. As a specific type of AI model, LLMs are a subset of the broader AI landscape, one that focuses on processing and generating natural language text.
03/
What is the difference between NLP and LLM?
Natural language processing (NLP) refers to the overarching field focused on language processing, while large language models (LLMs) are a specific, advanced type of model within the field of NLP that uses deep learning techniques to handle language tasks.
04/
What is the difference between GPT and LLM?
Generative pre-trained transformer (GPT) refers to a specific series of large language models (LLMs) developed by OpenAI. They are a type of LLM, with a specific focus on language generation.
Get the Azure mobile app
Explore Azure
What is Azure?
Get started with Azure
Global infrastructure
Datacenter regions
Trust your cloud
Azure Essentials
Customer stories
Products and pricing
Products
Azure pricing
Free Azure services
Flexible purchase options
FinOps on Azure
Optimize your costs
Solutions and support
Solutions
Resources for accelerating growth
Solution architectures
Support
Azure demo and live Q&A
Partners
Azure Marketplace
Find a partner
Join ISV Success
Resources
Documentation
Blog
Developer resources
Students
Events and Webinars
Analyst reports, white papers, and e-books
Videos
Cloud computing
What is cloud computing?
What is multicloud?
What is machine learning?
What is deep learning?
What is AIaaS?
What are LLMs?
What are SLMs?
What is RAG?
English (United States)
Your Privacy Choices Opt-Out Icon
Your Privacy Choices
Your Privacy Choices Opt-Out Icon
Your Privacy Choices
Consumer Health Privacy
Sitemap
Contact Microsoft
Privacy
Manage cookies
Terms of use
Trademarks
Safety & eco
Recycling
About our ads
© Microsoft 2025