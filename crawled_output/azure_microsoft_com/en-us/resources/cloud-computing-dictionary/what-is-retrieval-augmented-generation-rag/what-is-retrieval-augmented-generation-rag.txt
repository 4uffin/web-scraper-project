What is RAG? | Microsoft Azure
This is the Trace Id: 54602c3e4d0e4facb551a8a21a15a740
Skip to main content
Microsoft
Azure
Azure
Azure
Home
Explore
Products
Popular
Popular
View all products (200+)
Azure AI Foundry
Azure AI Foundry Agent Service
Azure OpenAI in Foundry Models
Azure AI Content Safety
GitHub Copilot
Azure DevOps
Azure Kubernetes Service (AKS)
Azure Cosmos DB
Azure Database for PostgreSQL
Azure Arc​
AI + machine learning
AI + machine learning
Azure AI Foundry
Azure AI Foundry Observability
Azure AI Foundry Agent Service
Azure OpenAI in Foundry Models
Azure AI Foundry Models
Azure AI Search
Azure AI Speech
Azure AI Content Understanding
Azure AI Content Safety
Azure AI Services
Azure Machine Learning
Databases + analytics
Databases + analytics
Azure Cosmos DB
Azure SQL
Azure Database for PostgreSQL
Azure Managed Redis
Microsoft Fabric
Azure Databricks
Azure Synapse Analytics
View all databases
Compute
Compute
Linux virtual machines in Azure
SQL Server on Azure Virtual Machines
Windows Server
Azure Functions
Azure Virtual Machine Scale Sets
Azure Spot Virtual Machines
Azure Container Apps
Azure Compute Fleet
Containers
Containers
Azure Kubernetes Service (AKS)
Azure App Service
Azure Functions
Azure Container Instances​
Azure Spring Apps
Azure Red Hat OpenShift
Azure Kubernetes Fleet Manager
Azure Container Apps
Azure Container Registry
App Configuration
Hybrid + multicloud
Hybrid + multicloud
Azure Arc​
Azure Local
Microsoft Defender for Cloud
Azure IoT Edge
Azure Monitor
Microsoft Sentinel
Azure Migrate
Solutions
Featured
Featured
View all solutions (40+)
Azure AI
Azure cloud migration and modernization center
Build and modernize intelligent apps
Data analytics for AI
Azure AI Infrastructure
Adaptive cloud
Azure networking and network security
SAP on the Microsoft Cloud
Azure Databases
Azure Integration Services
AI
AI
Azure AI
Responsible AI with Azure
Azure AI Infrastructure
Build and modernize intelligent apps
Knowledge mining
Hugging Face on Azure
Machine learning operations (MLOps)
Application development
Application development
Build and modernize intelligent apps
Development and testing
DevOps
DevSecOps
Serverless computing
Application and Data Modernization
Low-code application development on Azure
Cloud migration and modernization
Cloud migration and modernization
Migration and modernization center
Migrate to innovate in the era of AI
Build and modernize intelligent apps​
.NET apps migration
Development and testing
SQL Server migration
Linux on Azure
SAP on the Microsoft Cloud
Oracle on Azure
Azure confidential computing
Hybrid Cloud and infrastructure
Hybrid Cloud and infrastructure
Hybrid and multicloud solutions
Backup and disaster recovery
High-performance computing (HPC)
Business-critical applications
Quantum computing
Resources
Resources
Reference architectures
Resources for accelerating growth
Azure Marketplace
Azure Essentials
Browse the Microsoft Business Solutions Hub
Azure innovate & Azure Migrate and Modernize
Microsoft Cloud Adoption Framework for Azure
Azure Well-Architected Framework
FinOps on Azure
Pricing
How to buy
How to buy
Azure pricing
Free Azure services
Azure account
Flexible purchase options
Azure benefits and incentives
Pricing tools and resources
Pricing tools and resources
Pricing calculator
Optimize your costs
FinOps on Azure
Partners
Software Development Companies
Microsoft Marketplace
Find a partner
Resources
Learning
Learning
Get started with Azure
Customer stories
Analyst reports, white papers, and e-books
Videos
Learn more about cloud computing
Technical resources
Technical resources
Documentation
Get the Azure mobile app
Developer resources
Quickstart templates
Resources for startups
Community
Community
Developer community
Students
Azure for partners
What's new
What's new
Blog
Events and Webinars
Learn
Support
Contact Sales
Get started with Azure
Sign in
More
All Microsoft
Global
Microsoft 365
Teams
Copilot
Windows
Surface
Xbox
Deals
Small Business
Support
Software
Software
Windows Apps
AI
Outlook
OneDrive
Microsoft Teams
OneNote
Microsoft Edge
Moving from Skype to Teams
PCs & Devices
PCs & Devices
Computers
Shop Xbox
Accessories
VR & mixed reality
Certified Refurbished
Trade-in for cash
Entertainment
Entertainment
Xbox Game Pass Ultimate
PC Game Pass
Xbox games
PC games
Business
Business
Microsoft Cloud
Microsoft Security
Dynamics 365
Microsoft 365 for business
Microsoft Power Platform
Windows 365
Microsoft Industry
Small Business
Developer & IT
Developer & IT
Azure
Microsoft Developer
Microsoft Learn
Support for AI marketplace apps
Microsoft Tech Community
Microsoft Marketplace
Marketplace Rewards
Visual Studio
Other
Other
Microsoft Rewards
Free downloads & security
Education
Licensing
Unlocked stories
View Sitemap
Search
Show search input
No results
Cancel
Resources
Cloud Terms
What is RAG?
What is retrieval-augmented generation (RAG)?
Learn how retrieval-augmented generation (RAG) technology improves the accuracy and relevance of responses generated by large language models (LLMs).
Build intelligent apps
Get started with Azure
About RAG
About RAG
Benefits
Use cases
Future of LLMs
Resources
FAQ
READ TIME
7 min
RAG boosts AI accuracy by integrating external knowledge, ensuring up-to-date, relevant responses
By enhancing cloud computing capabilities and influencing the advancement of AI, RAG helps improve the accuracy and relevance of AI-generated responses, making AI systems more reliable and effective across various applications.
Key takeaways
The history and evolution of RAG in AI reflects a broader trend towards more intelligent and context-aware systems that can effectively combine vast amounts of information with sophisticated generation capabilities.
RAG architecture enables AI systems to produce more informed and reliable content by grounding pre-trained generation in retrieved external knowledge.   The benefits of RAG make it a powerful technique for creating AI systems that are more accurate, reliable, and versatile, with broad applications across domains, industries and tasks.   Developers use RAG to build AI systems that can generate content grounded in accurate information, leading to more reliable, context-aware, and user-centric applications.
RAG systems combine retrieval and generation, making it a powerful tool for a wide range of applications, industries, and use cases.
As RAG models continue to advance, they’re expected to play a crucial role in various applications, from customer service to research and content creation.
RAG is set to play a crucial role in the future of LLMs by enhancing the integration of retrieval and generation processes.
About RAG
RAG: Mechanics, history, and impact
How RAG works
Retrieval-augmented generation (RAG) is an AI framework that combines two techniques; First, it retrieves relevant information from external sources, such as databases, documents, or the web. Once this information is gathered, it is used to inform and enhance the generation of responses. This approach capitalizes on the strengths of both retrieval and generation techniques, ensuring that the responses are accurate, relevant, and contextually enriched by the most up-to-date and specific information available. This dual capability allows RAG systems to produce more informed and nuanced outputs than purely generative models.
The history of RAG
RAG is rooted in the early systems of basic information retrieval. As generative AI technologies rapidly advanced and generative language models like GPT-2 and BERT emerged, the need for more accurate and relevant responses grew.   In 2020, RAG architecture was introduced, marking a significant advancement. By using machine learning to combine retriever and generator modules—integrating the internal knowledge base of the LLM with external sources of knowledge—RAGs were able to produce more accurate, up-to-date, coherent, and contextually accurate text.   With deep learning at their core, RAG models can be trained end-to-end, enabling outputs that optimize responses, improving the quality of generated content as the model learns to retrieve the most reliable and contextually useful information.
The importance of RAG to AI
RAG plays a crucial role in advancing the capabilities of AI, reflecting a trend towards more intelligent and context-aware systems that can effectively combine vast amounts of information with sophisticated generation capabilities. Here are key reasons why RAG is foundational to AI:
Enhanced accuracy: By integrating external knowledge sources, RAG significantly improves the accuracy and relevance of responses generated by LLMs.
Contextual relevance: RAG allows AI systems to generate responses that are more contextually appropriate by retrieving specific information related to the request.
Cost-effectiveness: Implementing RAG is more efficient than continuously retraining LLMs with new data.
Transparency: By providing sources for the information used in responses, RAG enhances credibility and trust.   Versatility: RAG can be applied across various sectors, like healthcare, education, and financial sectors, and for purposes such as customer service, research, and content creation.
Improved experience: By delivering more accurate and relevant responses, RAG technology leads to more satisfying and productive interactions for users.
RAG architecture
The architecture of RAG systems is a combination of two main modules plus a fusing mechanism that work together to produce accurate and contextually relevant outputs. RAG modules can be trained end-to-end, allowing the algorithm to optimize retrieval and generation jointly, resulting in a more informed and reliable result.
Here’s how RAG architecture works:
The retriever module searches through a large data set to find the most relevant pieces of information based on the query.
After retrieval, the generator module uses the retrieved information as additional context to generate a coherent and relevant response. Typically, generator modules are a pre-trained language model like generative pre-trained transformer (GPT) or bidirectional and auto-regressive transformers (BART) that has been fine-tuned to generate text based on the input and the retrieved information.
The fusion mechanism ensures that the information retrieved is effectively combined in the generative process. This interaction between the modules enables RAG systems to produce more informed and reliable content by grounding generation in retrieved knowledge.
Benefits
The benefits of RAG
Powerful architecture to improve AI
Developers use RAG architecture to create AI systems that are more accurate, reliable, and versatile, with broad applications across various industries and tasks. The benefits of RAG are:     Improved accuracy, relevance, and contextual precision: By retrieving relevant documents or data, RAG ensures that the generated output is grounded in factual and pertinent information, improving the overall accuracy and relevance of responses.
Reduced hallucinations through fact-based generation: RAG reduces the likelihood of hallucinations—generating plausible but incorrect information—basing the generative model’s output on actual retrieved content, leading to more trustworthy results.
Enhanced performance in open-domain tasks with broad knowledge access: RAG excels in open-domain question answering and similar tasks by efficiently retrieving information from vast and diverse sources, enabling it to handle a wide range of topics with depth and breadth.
Scalability and capacity to handle large knowledge bases: RAG can efficiently search and retrieve relevant information from massive datasets, making it scalable and suitable for applications requiring extensive knowledge access. NoSQL databases allow RAG models to leverage vast amounts of data for generating contextually enriched responses.
Customization and domain-specific applications: RAG models are adaptable and can be fine-tuned for specific domains, allowing developers to create specialized AI systems tailored to particular industries or tasks, such as legal advice, medical diagnostics, or financial analysis.
Interactive and adaptive learning: Through user-centric adaptation, RAG systems can learn from user interactions, retrieving more relevant information over time and adapting their responses to better meet user needs, improving user experience and engagement.
Versatility and multi-modal integration: RAG can be extended to work with multi-modal data (text, images, structured data), enhancing the richness and diversity of the information used in generation and broadening the applications of the model.
Informed writing for efficient content creation: RAG provides a powerful tool by retrieving relevant facts and references, ensuring that generated content is not only creative but also accurate and well-informed.
Use cases
Types of RAG systems
Versatility across applications
Retrieval-augmented generation is an adaptive, versatile AI architecture with a wide range of use cases across domains and industries. Here are  key applications of RAG:   Open-domain question answering (ODQA)  Use case: RAG is highly effective in ODQA systems, where users can ask questions on virtually any topic. Example: Customer support chatbots use RAG to provide accurate answers by retrieving information from large knowledge bases or FAQs.
Domain-specific specialized queries  Use case: For the legal industry, RAG can assist in analyzing and generating summaries of case law, precedents, and statues by retrieving relevant documents. Example: A legal assistant tool retrieves and summarizes documents for specific purposes.
Content summarization Use case: RAG can assist in generating high-quality content, like virtual assistant meeting notes, or summaries of articles, reports, or blog posts, by retrieving relevant information and integrating it into the generated text. Example: A journalist uses RAG to generate summaries of recent news articles by pulling in key details from various sources.
Personalized recommendations Use case: RAG can enhance recommendation systems by retrieving user-specific information and generating personalized suggestions. Example: An e-commerce platform uses RAG to recommend products based on a user's browsing history and preferences, offering explanations generated from relevant product reviews or descriptions.
Complex scenario analysis and content creation  Use case: A hybrid RAG model can be used to generate and synthesize detailed reports or analyses by retrieving relevant data, documents, or news from multiple complex sources. Example: A financial analysis tool generates investment projections, analyses, or reports by retrieving and summarizing recent market trends, historical financial data, stock performance, expert commentary, and economic indicators.
Research information and synthesis Use Case: Researchers can use RAG to retrieve and synthesize information from academic papers, reports, or databases, facilitating reviews and research projects. Example: An academic tool generates summaries of relevant research papers by pulling in key findings from various studies.
Multi-lingual and cross-lingual applications Use Case: RAG can be deployed in multi-lingual environments to retrieve information in different languages and generate cross-lingual content. Example: A translation tool translates text while also retrieving culturally relevant information to ensure the translation is contextually appropriate.
Future of LLMs
RAG will power tomorrow’s AI
Boosting precision in AI output
Retrieval-augmented generation is set to play a crucial role in the future of LLMs by enhancing the integration of retrieval and generation processes. Expected advancements in this area will lead to more seamless and sophisticated fusion of these components, enabling LLMs to deliver highly accurate and contextually relevant outputs across a broader range of applications and industries.
As RAG continues to evolve, we can anticipate its adoption in new domains such as personalized education, where it can tailor learning experiences based on individual needs, and advanced research tools, offering precise and comprehensive information retrieval for complex inquiries.
Addressing current limitations, such as improving retrieval accuracy and reducing biases, will be key to maximizing the potential of RAG systems. Future iterations of RAG are likely to feature more interactive and context-aware systems, enhancing user experiences by dynamically adapting to user inputs.
Additionally, the development of multimodal RAG models, which use computer vision to integrate text, images, and other data types, will expand and open even more possibilities, making LLMs more versatile and powerful than ever.
RESOURCES
Build with Azure AI Services
Get started
Previous Slide
Next Slide
Azure resources
Tour the Azure resource center
Watch how-to videos, view white papers and analyst reports, explore training and events, and get case studies, code samples, and solution architectures.
Learn about Azure
Microsoft Learn
Explore the AI learning hub
Build your AI skills with self-paced tutorials, virtual training events, and in-person courses designed for your specific role.
Start learning
Student developers
Jumpstart your career in tech
Achieve more with tools and programs just for students. Get access to videos, tutorials, free tools, and community programs.
Explore student resources
Back to RELATED PRODUCTS section
FAQ
Frequently asked questions
Expand all
Collapse all
01/
What is RAG in AI?
Retrieval-augmented generation (RAG) is an AI technique that combines a retrieval model with a generative model. It retrieves related information from a database or document set and uses it to generate more accurate and contextually relevant responses. This approach enhances the quality of AI-generated text by grounding it in real-world data, making it particularly useful for tasks like answering questions, summarizing, and creating content.
02/
What does retrieval-augmented generation do?
RAG improves AI-generated content by incorporating external data. It retrieves relevant information from a database and then uses that data to generate more accurate and context-aware responses. This process ensures that the AI system’s output is better informed and more reliable.
03/
What is the difference between RAG and LLM?
RAG combines a large language model (LLM) with a retrieval mechanism. While an LLM generates text based on pre-trained data, RAG enhances this by retrieving relevant information from external sources in real time, improving accuracy and relevance. Essentially, LLM relies on learned patterns, while RAG actively pulls in up-to-date information to inform its responses.
Get the Azure mobile app
Explore Azure
What is Azure?
Get started with Azure
Global infrastructure
Datacenter regions
Trust your cloud
Azure Essentials
Customer stories
Products and pricing
Products
Azure pricing
Free Azure services
Flexible purchase options
FinOps on Azure
Optimize your costs
Solutions and support
Solutions
Resources for accelerating growth
Solution architectures
Support
Azure demo and live Q&A
Partners
Software Development Companies
Microsoft Marketplace
Find a partner
Resources
Documentation
Blog
Developer resources
Students
Events and Webinars
Analyst reports, white papers, and e-books
Videos
Cloud computing
What is cloud computing?
What is multicloud?
What is machine learning?
What is deep learning?
What is AIaaS?
What are LLMs?
What are SLMs?
What is RAG?
English (United States)
Your Privacy Choices Opt-Out Icon
Your Privacy Choices
Your Privacy Choices Opt-Out Icon
Your Privacy Choices
Consumer Health Privacy
Sitemap
Contact Microsoft
Privacy
Manage cookies
Terms of use
Trademarks
Safety & eco
Recycling
About our ads
© Microsoft 2025
AI-powered assistant
Created with Copilot Studio
AI-powered assistant Created with Copilot Studio
Can we help you?
AI-powered assistant is available 24x7.
Chat now
No thanks