Nvidia's deal with Intel has far reaching implications, and most of them aren't good
Menu
Sign in now
Close
News
PC Hardware
Submenu
CPU
GPU
Storage
Monitors
Keyboards & Mice
Software
Submenu
Productivity
Other Software
Operating Systems
Submenu
Windows
Linux
macOS
Devices
Submenu
Single-Board Computers
Laptops
Gaming Handheld
Prebuilt PC
Home
Submenu
Networking
Smart Home
Gaming
Submenu
Game Reviews
Sign in
Newsletter
Menu
Follow
Followed
Like
Threads
2
More Action
Summary
Generate a summary of this story
Sign in now
Switch 2
RTX 5060
Windows 11
Gaming
Forums
Close
Nvidia's deal with Intel has far reaching implications, and most of them aren't good
By
Adam Conway
Published 7 days ago
I’m Adam Conway, an Irish technology fanatic with a BSc in Computer Science and I'm XDA’s Lead Technical Editor. My Bachelor’s thesis was conducted on the viability of benchmarking the non-functional elements of Android apps and smartphones such as performance, and I’ve been working in the tech industry in some way or another since 2017.
In my spare time, you’ll probably find me playing Counter-Strike or VALORANT, and you can reach out to me at adam@xda-developers.com, on Twitter as @AdamConwayIE, on Instagram as adamc.99, or u/AdamConwayIE on Reddit.
Sign in to your XDA account
Summary
Generate a summary of this story
follow
Follow
followed
Followed
Like
Like
Thread
2
Log in
Here is a fact-based summary of the story contents:
Try something different:
Show me the facts
Explain it like I’m 5
Give me a lighthearted recap
Nvidia's surprise partnership with Intel, sealed by a $5 billion investment, has raised several eyebrows across the tech industry. Subject to regulatory approval, the world's leading GPU maker is taking, roughly, a 4% stake in one of the world's biggest CPU companies, and what's more, both companies intend to jointly build multiple generations of chips for both consumer machines and data centers. On the surface, it sounds interesting; fusing Nvidia's graphics chops with Intel's CPUs sounds like some powerful hardware in the making, but to be honest, it's just kind of worrying.
What did Intel and Nvidia agree on?
Intel will be tightly coupled with Nvidia
Before looking into the implications, we'll first look into the deal itself. Nvidia is investing $5 billion into Intel's common stock, valued at $23.28 per share. It offers Intel some much needed cash while giving Nvidia influence over Intel and at a discounted rate. Before the news broke, Intel's stock was valued at $25.01 from the previous day's close. It's not just a soft collaboration, though. As a core component of the partnership, Intel will both design and manufacture x86 CPUs that make use of Nvidia's NVLink interconnect for connecting Intel CPUs and Nvidia GPUs, facilitating usage in AI-centric data centers. For consumers, things get very interesting: Intel has said that it will develop x86-based SoCs that integrate Nvidia's RTX GPU chiplets. In other words, Intel will design SoCs that use Nvidia's integrated graphics for the x86 consumer market. Understandably, leadership of both companies have come across incredibly pleased. And why wouldn't they be? A single chip package combining an Intel processor and an Nvidia GPU (connected via NVLink) could do wonders when it comes to AI performance, in both data centers and in consumer-grade hardware. The fact that it's subject to regulatory approval is important, though, because there are a lot of potential implications of this deal.
Intel's GPUs have a rocky road ahead
Though apparently there will still be "GPU offerings"
In the last couple of years, Intel re-entered the discrete GPU market (if you count the AGP-only i740 released in 1998 as being the first entry, anyway) with its Arc series after two decades of integrated graphics. It originally positioned itself as a third-player alongside Nvidia and AMD, but by effectively out-sourcing its graphics to Nvidia, where's the incentive to continue investing in its GPUs? Intel might not outright abandon its GPU strategy, but whatever heavy investment was being made is unlikely to continue to the same degree. Think about it: much of Intel's graphics capabilities come from its work in the integrated graphics market over the last few years. Looking to the Intel Arc B580, for example, you'll see that it packs 20 Xe2 cores and 12 GB of VRAM. However, Lunar Lake featured the same architecture for its integrated graphics, packing eight Xe2 cores. Of course, there's a big difference between integrated graphics and dedicated graphics, but the relationship is there. Now, with that knowledge, read the press release again. Specifically this part:
Intel will build and offer to the market x86 system-on-chips (SOCs) that integrate NVIDIA RTX GPU chiplets.
If those x86 SoCs include RTX GPU chiplets, it's clear that Intel's integrated graphics are getting chopped, or at the very least, will be found in fewer Intel chips. After all, Nvidia has experience with getting RTX cores into an integrated chip anyway, such as in the case of the Nintendo Switch 2's T239 SoC. The overall plan here essentially swaps out Intel's GPU for an Nvidia one, a call-back to the Kaby Lake-G days where Intel included an AMD RX Vega GPU for integrated graphics. Not only does packing Nvidia's RTX chiplets here mean a big boost to graphics performance, it suddenly makes Intel competitive with AMD in the gaming handheld market. For consumers, this could mean fewer options in the graphics market, especially when it comes to dedicated GPUs. AMD and Nvidia were the titans duking it out for a long time, though recent generations saw Nvidia leap ahead with the best of AMD merely going toe to toe with the RTX 4080. Intel didn't offer the best performance, but it certainly showed promise. The Arc A770 received a lot of praise for its price to performance ratio, and it's even capable of running some local AI workloads. To Intel's credit, the company has made it clear in a statement to PC World that its GPUs will continue in some form:
We’re not discussing specific roadmaps at this time, but the collaboration is complementary to Intel’s roadmap and Intel will continue to have GPU product offerings
With that being said, "Intel will continue to have GPU product offerings" is a fairly vague statement, and it seems from the outside looking in that not even Intel knows what's going to happen next. Many leaks over the past few months have pointed to Intel preparing a launch for the Arc B770, and even if that still materializes later this year, what happens to the next generation of Celestial cards? All of this is to say that if Intel bows out of the GPU race as a result of the Nvidia deal, then Nvidia's dominance only grows. Intel was a tiny, tiny percentage of the market, but if it had managed to make serious strides within a generation or two, that would have chipped away at Nvidia while potentially acting as a downward force to bring prices down. Plus, if Intel does continue to release dedicated GPUs, it's a bit strange to be in direct competition with someone who owns a percentage of your company. The conflict of interest alone leaves a lot more questions than answers.
Nvidia suddenly gained a say in x86 chips, so what happens to Arm?
Nvidia also claims to be committed to Arm, still
Credit: Source: Nvidia
Nvidia's computational foray has always taken place in the world of Arm, such as its Tegra chips which powered tablets, the Nvidia Shield, and the Nintendo Switch. Its Grace CPU can also be found in servers, and Project DIGITS saw the NVIDIA Grace Blackwell GB10 combine its Arm-based Grace CPU with Blackwell computational cores for graphics and local inference. Nvidia even tried to buy Arm a couple of years ago, with the deal falling through thanks to legal scrutiny and regulatory pushback. Nvidia's focus on Arm wasn't just because it liked Arm; in fact, very few companies have an x86 license. Right now, for PCs, only Intel, AMD, and Chinese-based Zhaoxin hold licenses that allow for producing processors using the x86 architecture. This is thanks to the complicated shared ownership that both AMD and Intel have over it, with the two companies wrapped up in a cross-licensing agreement of many different patents. Technically speaking, the 1999 verison of x86 could be reverse engineered and reimplemented, but the extensions, compiler, and IP blocks to accelerate those extensions would still prevent anything meaningful from being produced by someone without a license. What can Nvidia do? It could try to acquire a license to x86, but even if Intel wanted to, AMD would need to agree to give a big competitor access to it as well. Instead, Nvidia went to Intel, essentially piggybacking off of Intel's license to the architecture to produce chips in the x86 ecosystem. Many data center workloads and high-end computers still favor x86 over Arm, and this is, realistically, the only way that Nvidia can get its graphics integrated into x86 SoCs.
Credit: Source: YouTube
Think about Nvidia's position before the deal: everyone knows that Nvidia's GPUs are the best of the best, but for a tight GPU-CPU coupling, the best Nvidia could offer was its Arm-based designs, or rely on AMD and Intel CPUs while relying on connectivity over standard interfaces or NVLink for inter-GPU communication. Now, Nvidia can get the best of both worlds, by offering x86 options built to its specifications. What this means for Arm is unclear, and Nvidia CEO Jensen Huang stated in a joint webcast that this partnership doesn't affect any of that. However, Nvidia's long-rumored N1X SoC was said to be Arm-based and targeted at Windows on Arm machines, and renowned Apple analyst Ming-chi Kuo said the following, per a machine translation:
For Nvidia, developing its own Windows-on-ARM processors is highly uncertain; for Intel, rapidly becoming competitive in the GPU space is very difficult. By combining strengths (CPU + GPU), the two companies are expected to generate strong synergies and advantages in the PC ecosystem.
Does that mean N1X faces a risk of being canned? The truth is that we don't know, but what we do know is that x86 has become a big part of Nvidia's future, even if Nvidia remains committed to its Arm roadmap. Deals like this don't crop up overnight, but given that the company has a direct say in some x86 chips which it never had before, Nvidia certainly has less of an incentive to champion Arm in certain segments. For example, would Nvidia still push a consumer Arm CPU to challenge x86 PCs in the future, or will it instead funnel those efforts into this Intel partnership?
Credit: Source: Intel
Finally, when it comes to the fabrication process, things are a bit murky there, too. Intel has historically used its own fabrication facilities, though has outsourced much of its recent offerings to TSMC. Intel's upcoming Panther Lake is fabricated on the company's new Intel 18A process, but there have reportedly been roadblocks when it comes to yield. Yield refers to the percentage of chips that are actually usable from the fabrication process, and is a process that tends to improve over time. We have no details on what the fabrication process will look like for these chips, but we know that Intel's stumbles have been well-documented over the years. Given that Intel CEO, Lip-Bu Tan, said "Intel’s leading data center and client computing platforms, combined with our process technology, manufacturing and advanced packaging capabilities, will complement NVIDIA’s AI and accelerated computing leadership," it's hard to glean any specific information aside from a general acknowledgment that Intel can produce the chips. What we do know is that orders at fabrication facilities are often placed a year or more in advance, and given TSMC's technological prowess, it's likely that we'll still see these companies using TSMC for quite a while into the future yet. As well, given that we're talking about chiplets, it's possible for Nvidia to produce its RTX GPUs at TSMC, Intel to produce other parts of the chip in its own fabs, then bring the two together for packaging.
AMD is the real loser here
AMD stands to lose out in data centers and gaming handhelds
If there’s a clear loser in this development, it's AMD, the one company that competes with both Intel (in CPUs) and Nvidia (in GPUs). AMD now faces a scenario where its two biggest rivals are joining forces, coordinating their strengths in ways that could complete oust AMD from key markets. AMD has been doing phenomenal work in the consumer CPU space over the last few years, but its been doing really well in the enterprise space, too. Its data-center offerings actually outsold Intel for the first time ever in 2025's Q2, though a third of AMD's revenue in this area comes from its Instinct MI300X GPUs. Still, EPYC has been gaining ground for a while, thanks to its impressive power efficiency and better performance. In the consumer space, AMD is going to face real trouble. Its APUs have been incredibly competitive; so much so that the company has basically owned the gaming handheld space over the past couple of years. Intel's attempt went rather poorly at the start (though got better as time went on), but an Intel CPU with an Nvidia GPU? AMD suddenly looks significantly less appealing, especially given that its first-mover advantage and graphical prowess when compared to Intel will likely evaporate immediately. As for AMD's growth in the data center segment, both Intel and Nvidia are clearly taking aim there, too. While the excitement for consumers undoubtedly rests on what an "x86 RTX SoC" can bring to the table, an Intel CPU with an Nvidia GPU for high-performance computing can directly compete with AMD's own EPYC and Instinct combination. NVLink support between CPU and GPU is particularly interesting here, as AMD CPUs more loosely interface with Nvidia GPUs. Nvidia is playing a strong hand here; by propping up Intel (which it clearly doesn't see as a threat), AMD struggles as a result. Plus, if cloud vendors can buy an Nvidia HGX box that comes with custom Intel CPUs built-in, they might be less inclined to buy AMD CPUs for Nvidia GPU clusters. For consumers and the industry, reduced competition is rarely good news. AMD has been the underdog in a lot of ways, forcing Intel to lower CPU prices and forcing Nvidia to keep GPU prices somewhat in check, though the latter was more in the mid-2010s rather than in the last couple of years. If AMD's ability to compete diminishes, say its CPU gains stall because Intel's products improve thanks to Nvidia, and its GPU sales suffer against an Nvidia that faces no Intel threat, the end result could be higher prices or slower innovation. We've seen this scenario before. When AMD nearly went bankrupt in the mid-2010s, Intel's CPU advances stagnated for years due to lack of competition. This Nvidia and Intel alliance could risk a similar dynamic occurring in GPUs or even AI accelerators, with AMD's future suddenly carrying a giant question mark.
What happens to UA Link?
The open-standard alternative to NVLink
Intel's collaboration with Nvidia centers on NVLink, Nvidia's proprietary high-bandwidth interconnect. This is what will glue Intel CPUs to Nvidia GPU chiplets at high speed, especially in those data-center custom chips. However, what some have overlooked is that Intel had been working on an open alternative to NVLink, dubbed UA Link. UA Link, or Ultra Accelerator Link, is a standard supported by 75 other companies such as Google, Broadcom, AMD, and more. What it's meant to achieve is very similar to what Nvidia does achieve with NVLink. It's designed as an open-standard for CPU-to-accelerator connectivity, and was spearheaded by AMD atop its Infinity Fabric technology. It's essentially a vendor-agnostic way for CPUs, GPUs, and other accelerators to talk to each other at high speed. But with Intel pivoting to NVLink for its future designs, what happens to UA Link? In the short term, Intel will probably continue to support UA Link for products already in the pipeline, as existing customers won't be abandoned overnight. With that said, why would Intel push an open interconnect standard that could help AMD or others, when it can use Nvidia's solution exclusively in its own chips? This causes fragmentation and potentially kills an open standard in its tracks, and while NVLink previously allowed for the interconnectivity of Nvidia GPUs, you could still pair it with an AMD EPYC CPU. Now, though, the direct link to Intel's CPU can lead to vendor lock-in, as Nvidia's GPUs for data centers may perform at their best when paired with Intel's NVLink-supporting CPUs in the future. In contrast, had UA Link succeeded, a data center could mix and match CPU and accelerator vendors with a common interconnect. Now, though, we could see a market split with Intel and NVLink on one side, and UA Link on the other. And since Nvidia's GPUs are still the best for data centers, high-performance computing, and AI, companies have no reason to leave that ecosystem and instead have reason to switch to Intel CPUs because of that increased integration thanks to NVLink.
We still need to see how it plays out
Regulatory approval may come with several stipulations
Credit: Source: Intel
At the end of the day, Nvidia and Intel's partnership represents a potentially major shift for the industry. Sure, on paper, combining Intel's CPUs and Nvidia's GPUs could deliver some of the most compelling consumer and enterprise hardware we've ever seen. But beneath all of that lies something more sinister: competition gets weaker, and open standards are put at risk. Plus, one of the few companies still somewhat successfully pushing against Nvidia's dominance and very successfully pushing against Intel's may end up finding itself sidelined. For consumers, all of this could mean fewer choices and even higher prices. It could mean innovation slows down again. And it could be the death knell for what was once an exciting open standard. The real winners are obvious: Nvidia gets a way into x86, Intel gets much-needed cash and additional relevance, while uniquely positioning itself to compete in gaming handhelds and data-center offerings with Nvidia's computational prowess. Right now, the deal is subject to regulatory approval. I imagine that there will be some pushback from other companies in the space, but I personally find it unlikely that there will be much pushback from the current U.S. administration. The U.S. has a vested interest in Intel's success, and with the U.S. government recently taking a 10% stake in Intel, this further serves to benefit its investment. That's not say the deal won't face any roadblocks, but I suspect that this is a seismic shift which, in the long-run, likely won't favor us consumers.
GPU
Nvidia
Follow
Followed
Like
Share
Facebook
X
LinkedIn
Reddit
Flipboard
Copy link
Email
Close
Thread
2
Sign in to your XDA account
We want to hear from you! Share your opinions in the thread below and remember to keep it respectful.
Reply / Post
Images
Attachment(s)
Please respect our community guidelines. No links, inappropriate language, or spam.
Your comment has not been saved
Send confirmation email
Sort by:
Popular
Oldest
Newest
Bradford
Bradford
Bradford
#LR962577
Member since 2025-06-16
0
Threads
4
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
I worked for AMD and Intel in Silicon Valley back when wafers were much smaller: 3" - 6". Both companies have undergone significant changes since I left Intel in 2010, so my observations are largely those of an outsider. Intel has been struggling lately, and the US Gov't invested in it to help it survive and to not become a casualty in the technology space. NVidia, Apple, and AMD all depend on TSMC for production.
NVDA and INTC partnering appears to be a good move. I do not think the risk of reduced innovation or higher prices (which are both debatable) outweighs the potential loss of semiconductor manufacturing capabilities. AMD may hit a speed bump, but they have always recovered in the past, so I think the AMD/Intel rivalry will continue to be strong. Intel leadership has a lot of work ahead of them, but the synergy in the deal looks impressive.
2025-09-20 13:11:09
Upvote
Downvote
Reply
Copy
Johann7
Johann7
Johann7
#EA213744
Member since 2024-12-07
0
Threads
30
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
A consumer boycott of closed standards might be the only solution here. Tech journalist like you all can help by not hyping fractional performance advantages as significant and focusing on value over peak performance - including in the value calculation the opportunity cost foreclosed by closed standards compared to open ones.
2025-09-21 20:09:59
Upvote
Downvote
Reply
Copy
Terms
Privacy
Feedback
Recommended
Sep 18, 2025
4 reasons I keep coming back to Obsidian
Sep 17, 2025
These are gaming's most iconic NPCs who stole the spotlight
Sep 18, 2025
This beloved roguelike with 98% positive reviews is just over $6 on Steam, its lowest price ever
Sep 18, 2025
4 ways NotebookLM actually helps me stop procrastinating
Today's best deals
This niche space sandbox game with 96% positive reviews is at its lowest price ever on Steam
16 minutes ago
This retro-inspired mechanical keyboard is all vibes and now just $44
4 hours ago
This rare discount makes the AMD Ryzen 7 9800X3D the ultimate CPU for your next gaming PC build
6 hours ago
See More
Trending Now
I swapped Trello for Focalboard on my NAS, and it's so much better
Microsoft aims for SteamOS's crown as it reveals everything to expect from its handheld console debut
5 problems you didn't know a CMOS reset could fix
Join Our Team
Our Audience
About Us
Press & Events
Contact Us
Follow Us
Advertising
Careers
Terms
Privacy
Policies
XDA is part of the
Valnet Publishing Group
Copyright © 2025 Valnet Inc.