This self-hosted Wikipedia is wrong about everything, and it's hilarious
Menu
Sign in now
Close
News
PC Hardware
Submenu
CPU
GPU
Storage
Monitors
Keyboards & Mice
Software
Submenu
Productivity
Other Software
Operating Systems
Submenu
Windows
Linux
macOS
Devices
Submenu
Single-Board Computers
Laptops
Gaming Handheld
Prebuilt PC
Home
Submenu
Networking
Smart Home
Gaming
Submenu
Game Reviews
Sign in
Newsletter
Menu
Follow
Followed
Like
Threads
5
More Action
Summary
Generate a summary of this story
Sign in now
Switch 2
RTX 5060
Windows 11
Gaming
Forums
Close
This self-hosted Wikipedia is wrong about everything, and it's hilarious
By
Joe Rice-Jones
Published Sep 5, 2025
Maker, meme-r, and unabashed geek, Joe has been writing about technology since starting his career in 2018 at KnowTechie. He's covered everything from Apple to apps and crowdfunding and loves getting to the bottom of complicated topics. In that time, he's also written for SlashGear and numerous corporate clients before finding his home at XDA in the spring of 2023.
He was the kid who took apart every toy to see how it worked, even if it didn't exactly go back together afterward. That's given him a solid background for explaining how complex systems work together, and he promises he's gotten better at the putting things back together stage since then.
Sign in to your XDA account
Summary
Generate a summary of this story
follow
Follow
followed
Followed
Like
Like
Thread
5
Log in
Here is a fact-based summary of the story contents:
Try something different:
Show me the facts
Explain it like I’m 5
Give me a lighthearted recap
Generally, the stack of apps that the average self-host enthusiast has going will aim to reduce cloud dependency and those monthly subscription fees that add up all too quickly. Or you might be running local LLMs to keep your queries and training models local and private, or any number of other, ostensibly useful tasks. But who says everything has to be for productivity, or even for performing tasks like
serving video files over your home network? Where's the sense of whimsy in that, or in reams of YAML files to create Docker swarms or
set everything back up with Ansible when your home lab breaks down for the sixth time this week? While sometimes doing the task is fun, sometimes the end result is fun too, and this wonderful wiki that hallucinates most of its content is hours of fun.
Wait, do we actually want this Wiki to hallucinate?
Yes, because it's jolly good fun
Sometimes wikis feel like they are droning on forever, but most have a hard stop because they rely on the contributions of human writers to add, fact-check, and revise the content. That's a good thing, believe me, because it would be boring if everything were already written down and known, and there was nothing left to discover.
Endless wiki plays with knowledge as a fluid construct by throwing the rule book out in a "vibe coded experiment in hallucination."
Endless wiki plays with knowledge as a fluid construct by throwing the rule book out in a "vibe coded experiment in hallucination." Yes, that's right. It's LLM-created code, running in a Docker container, connected to a local LLM that is absolutely, positively, 100% flying by the seat of its virtual pants and making it all up on the spot. It's the type of willful misinformation and silicon psychosis that you were warned about when Generative AI was starting out, harnessed for amusingly disinformational educational use. There are no guardrails, other than those that the model had to begin with, only a tenuous grasp on reality, and you can create the new page of piffle by selecting any text to make it the new title of the next article. And yes, it's endless, only constrained by the length of your attention span. I've got it running on a mini PC running Proxmox, with ample speedy storage thanks to six Crucial P310 NVMe drives to store the LLM models on for generating gobbledegook and balderdash. Anyone with Docker knowledge will have it up and running in minutes, but I did notice the automated installation didn't actually download the Ollama LLM model, so I had to hop into a local terminal window and download it before it would generate fake wiki pages.
Endless Wiki
See at Github
Expand
Collapse
Okay, how endless is the Endless Wiki
How deep is a hole? It's pretty deep, man
Ever wondered just how much misinformation an LLM could spew when given full rein? When asked about XDA Developers, it cranked out a wiki page with a different founding year each time (where none were the actual founding year), and a successive parade of founders who didn't have any bearing on the reality of our humble start as a forum based around the O2 XDA. But it's not just our site, oh no. This LLM of lies will confidently write wiki pages almost faster than I can type in new prompts, and with any highlighted section of a given wiki page, start the process over again, and again, and again. It's like the kid in your class at school who would convincingly ramble on about things they knew nothing about, but nobody else knew quite enough to tell them that they were wrong, or to shut up, or that their breath would be better spent trying to topple the maple tree outside the window.
I'm not sure that we need more misinformation
But I love the creative energy here, and it shows a lot about AI in the process
To be fair, local LLMs like Ollama are handy tools for many computing tasks, like enabling Home Assistant to respond to voice commands. Large language models are absolutely neat to play around with, and they bring power to image recognition, text-to-speech (or transcriptions), or vibe coding things, like the earlier abomination of a Large Lying Language Model with associated wiki. But for all the potential they have, there still isn't a killer use case. Companies are absolutely trying to shoehorn AI into everything, even if it doesn't need it. I'm sure we're heading toward a saturation point where things will somewhat reverse, and an actual good reason to install LLMs emerges. Maybe that will be simple things like a better smart thermostat, or perhaps it will genuinely change the world, and we'll only think about the days before AI like they were forever ago. My point is they're a tool, and all the hype can't make them a better or worse tool. That's not separate from the water and power usage issues, or the potential data privacy ones, but you could say similar things about many other tools across the ages. Maybe they'll die off like Beanie Babies or the Cabbage Patch Kids, and hopefully we'll be around to see that.
I grew up on absurdist comedy, and I absolutely love the Endless Wiki
Until then, I absolutely love the Endless Wiki and its confident confidence trick of not saying a lot in many, many pages. It's a fantastic waste of an afternoon, and I'm going to go see what other confidently wrong answers it gives to things I know well.
Software and Services
Home Lab
Self-Hosting
Follow
Followed
Like
Share
Facebook
X
LinkedIn
Reddit
Flipboard
Copy link
Email
Close
Thread
5
Sign in to your XDA account
We want to hear from you! Share your opinions in the thread below and remember to keep it respectful.
Reply / Post
Images
Attachment(s)
Please respect our community guidelines. No links, inappropriate language, or spam.
Your comment has not been saved
Send confirmation email
Sort by:
Popular
Oldest
Newest
Brett
Brett
Brett
#FX214529
Member since 2025-09-10
0
Threads
1
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
Gemini, ChatGPT, and other non-local LLMs are still wrong about a great many things, and it's pretty far from hilarious. Because that garbage is at the top of my search feed now.
2025-09-10 08:56:38
Upvote
1
Downvote
Reply
Copy
John
John
John
#PF274467
Member since 2025-08-11
0
Threads
5
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
Why'd you ever end up picking qwen 2.5 as your model? There are lost of better options available, such as llama... You didn't even use the newest version of qwen (which is 3).I'm not saying that you did things badly; no, not at all! It's just that things could be improved :)
2025-09-08 21:20:01
Upvote
Downvote
Reply
3
Copy
pu239
pu239
pu239
#OE603413
Member since 2024-09-20
0
Threads
49
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
Qwen2.5 is one of the most "malleable" models, like the Llama 3 family. Maybe they just had it downloaded lol.
2025-09-07 10:15:18
Upvote
1
Downvote
Reply
Copy
pu239
pu239
pu239
#OE603413
Member since 2024-09-20
0
Threads
49
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
gpt-oss is terrible though, much better off using a random 7b model than their 20b
2025-09-07 10:16:39
Upvote
Downvote
Reply
Copy
Zoran
Zoran
Zoran
#RF505478
Member since 2025-02-19
0
Threads
22
Posts
Following
0
Stories
0
Topics
0
Authors
0
Users
Follow
Followed
0
Followers
View
Maybe there are better models, but gtp-oss:20b surely isn't one of them. At least in non-english languages, it's purely horrible. I thought the more "b" the better, until I tried gpt-oss. Qwen3 wipes the floor with it. It's not even a competition. Out of the 20-ish b category, mistral-small is the best I have tried
2025-09-08 14:32:04
Upvote
Downvote
Reply
Copy
Terms
Privacy
Feedback
Recommended
Sep 9, 2025
The most alive and immersive open-world maps ever created
Sep 9, 2025
3 surprising things you can repurpose laptop batteries for
Sep 10, 2025
5 projects you can do for much cheaper with an ESP32 than a Raspberry Pi
Sep 9, 2025
6 lightweight tools I install before anything else on a new PC
More from our brands
What is a Home lab, and why tech enthusiasts should build one
How I Use Copilot in Word to Instantly Simplify Complex Text
I Swapped Multitasking for “Monotasking”—and It Changed My Brain
I ditched Windows Search for this free app and it’s amazing
How I run a local LLM on my Raspberry Pi
I Tried the Most Dangerous Writing App—It Deleted My Work When I Paused
I tried running AI on my old GTX 1070 and it actually worked
Today's best deals
This retro-inspired mechanical keyboard is all vibes and now just $44
52 minutes ago
This rare discount makes the AMD Ryzen 7 9800X3D the ultimate CPU for your next gaming PC build
3 hours ago
This legendary triple-A FPS series is currently $10 for six games on Steam
20 hours ago
See More
Trending Now
I don't code, but VSCode is still my favorite app
3 reasons why Obsidian seems intimidating, and why you shouldn't worry
4 problems with Borderlands 3 that Borderlands 4 fixes
Join Our Team
Our Audience
About Us
Press & Events
Contact Us
Follow Us
Advertising
Careers
Terms
Privacy
Policies
XDA is part of the
Valnet Publishing Group
Copyright © 2025 Valnet Inc.