Is it fair to fear AI? - DEV Community
Forem Feed
Follow new Subforems to improve your feed
DEV Community
Follow
A space to discuss and keep up software development and manage your software career
Gamers Forem
Follow
An inclusive community for gaming enthusiasts
Future
Follow
News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.
Music Forem
Follow
From composing and gigging to gear, hot music takes, and everything in between.
DUMB DEV Community
Follow
Memes and software development shitposting
Vibe Coding Forem
Follow
Discussing AI software development, and showing off what we're building.
Popcorn Movies and TV
Follow
Movie and TV enthusiasm, criticism and everything in-between.
Design Community
Follow
Web design, graphic design and everything in-between
Maker Forem
Follow
A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.
Scale Forem
Follow
For engineers building software at scale. We discuss architecture, cloud-native, and SRE—the hard-won lessons you can't just Google
Forem Core
Follow
Discussing the core forem open source software project — features, bugs, performance, self-hosting.
Security Forem
Follow
Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike
Crypto Forem
Follow
A collaborative community for all things Crypto—from Bitcoin to protocol development and DeFi to NFTs and market analysis.
Open Forem
Follow
A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here
Dropdown menu
Dropdown menu
Skip to content
Navigation menu
Search
Powered by Algolia
Search
Log in
Create account
DEV Community
Close
Add reaction
Like
Unicorn
Exploding Head
Raised Hands
Fire
Jump to Comments
Save
Boost
More...
Moderate
Copy link
Copy link
Copied to Clipboard
Share to X
Share to LinkedIn
Share to Facebook
Share to Mastodon
Report Abuse
Mariana Caldas
for Web Dev Path
Posted on Sep 12
Is it fair to fear AI?
#ai
#ethics
#society
Every great invention has carried both wonder and fear. The printing press spread knowledge but also propaganda. The internet connected the world but also created new ways to exploit and divide it.
AI sits in that same lineage. It sparks fascination with the promise of medical breakthroughs, climate solutions, and new forms of creativity. At the same time, it raises alarms about misinformation, job loss, and the possibility of systems we can’t fully control.
The big difference now is scale.
When the printing press emerged, adoption took centuries. Electricity spread over decades. Even the internet, though fast, rolled out unevenly. Because of globalization and digital infrastructure, a breakthrough in one lab today can impact millions tomorrow. That speed and reach make both the risks and opportunities harder to contain or ignore.
Both reactions, fear and excitement, are justified. Fear acts as a compass pointing to where risks lie, while excitement is the energy that drives discovery. In this article, we will reflect on why the real work is learning how to carry both at once and to design AI with engines that move us forward and brakes that keep us safe.
Reasoning the fear
“AI fear is a response to speed and scope colliding in ways humanity hasn’t faced before.”
AI fears aren’t abstract; they’re grounded in what people already see. Algorithms already shape who gets hired, who receives loans, and how information spreads. In the past, the consequences of new technologies were often limited by geography. A printing error might mislead a city; an electrical fault might black out a neighborhood. With AI, a flaw can propagate globally in seconds, replicated across platforms and industries before anyone notices.
This scale amplifies existing worries:
The feeling of losing control when decisions are made by systems that most people don’t fully understand.
The concentration of influence when only a few actors hold the keys to the most advanced models.
The unease of watching machines step into not just repetitive labor, but creative and professional spaces that shape identity and purpose.
The erosion of trust as misinformation spreads faster than fact-checks can keep up.
And finally, the existential unease that even low-probability risks matter when the reach is this vast.
Balancing excitement with caution
If fear is amplified by speed and scale, so is excitement. The very qualities that make AI risky—its ability to learn, adapt, and spread quickly—are also what make it powerful. A system that can connect patterns across domains doesn’t just disrupt jobs; it can accelerate cures, design new materials, and help stabilize fragile ecosystems.
The temptation is to either sprint forward blindly or freeze in panic. But history shows us that progress paired with restraint is what creates lasting value. Electricity didn’t become transformative until we invented standards and safety codes. The internet didn’t become usable until we learned to build protocols and firewalls. With AI, the “brakes” we design now will decide whether its engines move us toward collective progress or collective harm.
That balance requires a mindset shift: building for resilience, not just speed. It’s not enough to launch faster models. We need oversight that can keep pace, transparency that makes the invisible visible, and social systems flexible enough to absorb disruption without breaking.
The skills and brakes we’ll need
“Together, these skills and breaks form the toolkit for resilience. Without them, engines run unchecked. With them, we have a chance to shape where we’re headed.”
Unlike past inventions, AI doesn’t give us decades to adjust. Its scale forces us to build engines and brakes at the same time, and that means different kinds of expertise working together from day one.
Technical builders are the ones who can turn “black boxes” into something interpretable. The brake here is interpretability, which means code and tools that let humans question the machine before acting.
A practical scenario: The engine can be represented by an AI model that detects patterns in scans that a human eye would miss, offering earlier diagnoses and potentially saving lives. But the brake matters just as much: every AI-generated recommendation must still pass through medical professionals who can weigh context, ethics, and patient history. Without it, one flawed update could spread misdiagnoses worldwide overnight.
Lawyers and ethicists turn abstract values into enforceable standards. The brake here is accountability: clear rules that force organizations to explain and defend automated decisions, just as we expect food or medicine to meet safety codes.
A practical scenario: In hiring, the engine is an AI system that can screen thousands of resumes in hours. But without accountability, that same system can quietly filter out women or minorities at scale. Audit trails and appeals are the brakes that keep bias from being locked into code.
Economists and labor experts keep disruption visible. The brake here is preparation—retraining programs, transition funds, and new models of social support designed before jobs vanish, not after.
A practical scenario: The engine could be AI tools producing marketing copy or legal briefs in seconds. But that efficiency could hollow out industries overnight. Preparation through reskilling initiatives and income transition programs can soften the shock and help workers adapt instead of collapsing into unemployment.
Psychologists and sociologists map the invisible shifts in trust and identity. The brake here is awareness, which means guidelines and education that help people navigate blurred boundaries.
A practical scenario: The engine is a chatbot designed to reduce loneliness. For some, it works. For others, it deepens dependency, blurring the line between authentic human connection and simulation. Awareness campaigns and mental health frameworks act as brakes, ensuring tools meant to support don’t quietly harm.
Communicators—teachers, journalists, artists—make the invisible visible. The brake here is translation, turning technical complexity into language and imagery that people can understand and respond to.
A practical scenario: The engine is AI-powered predictive policing, pitched as a tool for safety. Without translation, communities may never see the biases embedded in the data. By surfacing those biases in clear language, communicators create the space for public debate and resistance.
And everyday citizens are not just passive recipients of AI; they’re the first to notice when something is off. These lived experiences are brakes too that alert the rest of us before harms become systemic.
A practical scenario: The engine is an AI scheduling system rolled out across a retail chain. It boosts efficiency but leaves workers struggling with unpredictable hours. Employees themselves—sharing experiences with unions, co-workers, or the public—will apply the brake by forcing accountability and adjustments.
Fear as compass, excitement as fuel
And in the midst of uncertainty, I invite you to start seeing fear and excitement not as opposites, but as partners. I also invite you to imagine a future where this balance works: doctors supported, not replaced, by transparent diagnostic tools; workers retrained before industries collapse; children learning with AI tutors but guided by teachers who keep curiosity alive; climate models open and accountable, driving collective action instead of private gain. That’s what engines and brakes together can look like.
If humanity gets this right, AI could become a partner that amplifies our better side and helps us protect the beauty of the world we share.
What do you think?
Do you feel more fear or more excitement about AI right now? And how do you think society can adapt to its increasingly global and fast-moving scale?
Please drop your thoughts in the comments. I’d love to hear your perspective!
Talk soon, and take care.
Top comments (0)
Subscribe
Personal
Trusted User
Create template
Templates let you quickly answer FAQs or store snippets for re-use.
Submit
Preview
Dismiss
Code of Conduct
•
Report abuse
Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink.
Hide child comments as well
Confirm
For further actions, you may consider blocking this person and/or reporting abuse
Web Dev Path
Follow
Get involved!
Web Dev Path portal
More from Web Dev Path
Why AI struggles with "no" and what that teaches us about ourselves
#ai
#chatgpt
#llm
💎 DEV Diamond Sponsors
Thank you to our Diamond Sponsors for supporting the DEV Community
Google AI is the official AI Model and Platform Partner of DEV
Neon is the official database partner of DEV
Algolia is the official search partner of DEV
DEV Community — A space to discuss and keep up software development and manage your software career
Home
DEV++
Reading List
Podcasts
Videos
Tags
DEV Education Tracks
DEV Challenges
DEV Help
Advertise on DEV
DEV Showcase
About
Contact
Free Postgres Database
Software comparisons
Forem Shop
Code of Conduct
Privacy Policy
Terms of Use
Built on Forem — the open source software that powers DEV and other inclusive communities.
Made with love and Ruby on Rails. DEV Community © 2016 - 2025.
We're a place where coders share, stay up-to-date and grow their careers.
Log in
Create account