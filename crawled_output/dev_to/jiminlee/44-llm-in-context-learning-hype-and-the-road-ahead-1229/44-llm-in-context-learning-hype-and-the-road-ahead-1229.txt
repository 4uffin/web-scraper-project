(3/3) LLM: In-Context Learning, Hype, and the Road Ahead - DEV Community
Forem Feed
Follow new Subforems to improve your feed
DEV Community
Follow
A space to discuss and keep up software development and manage your software career
Gamers Forem
Follow
An inclusive community for gaming enthusiasts
Future
Follow
News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.
Music Forem
Follow
From composing and gigging to gear, hot music takes, and everything in between.
DUMB DEV Community
Follow
Memes and software development shitposting
Vibe Coding Forem
Follow
Discussing AI software development, and showing off what we're building.
Popcorn Movies and TV
Follow
Movie and TV enthusiasm, criticism and everything in-between.
Design Community
Follow
Web design, graphic design and everything in-between
Maker Forem
Follow
A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.
Scale Forem
Follow
For engineers building software at scale. We discuss architecture, cloud-native, and SRE‚Äîthe hard-won lessons you can't just Google
Forem Core
Follow
Discussing the core forem open source software project ‚Äî features, bugs, performance, self-hosting.
Security Forem
Follow
Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike
Open Forem
Follow
A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here
Crypto Forem
Follow
A collaborative community for all things Crypto‚Äîfrom Bitcoin to protocol development and DeFi to NFTs and market analysis.
Dropdown menu
Dropdown menu
Skip to content
Navigation menu
Search
Powered by Algolia
Search
Log in
Create account
DEV Community
Close
Add reaction
Like
Unicorn
Exploding Head
Raised Hands
Fire
Jump to Comments
Save
Boost
More...
Moderate
Copy link
Copy link
Copied to Clipboard
Share to X
Share to LinkedIn
Share to Facebook
Share to Mastodon
Report Abuse
Jimin Lee
Posted on Sep 13
‚Ä¢ Edited on Sep 14
(3/3) LLM: In-Context Learning, Hype, and the Road Ahead
#llm
#machinelearning
LLM (9 Part Series)
1
(1/3) LLM: How LLMs Became the Bedrock of Modern AI
2
(2/3) LLM: Data, Transformers, and Relentless Compute
...
5 more parts...
3
(3/3) LLM: In-Context Learning, Hype, and the Road Ahead
4
From Word Predictor to Thinking Partner: The Rise of Thinking Models
5
Understanding Mixture of Experts (MoE)
6
From Full Fine-Tuning to LoRA
7
RAG Explained
8
Understanding Context Window Size in LLMs
9
On-Device LLM
üìå Note: This article was originally written in April 2023. Even though I‚Äôve updated parts of it, some parts may feel a bit dated by today‚Äôs standards. However, most of the key ideas about LLMs remain just as relevant today.
So‚Ä¶ Are LLMs ‚ÄúFoundation Models‚Äù?
Short answer: kind of, yes‚Äîbut with caveats.
Long answer: let‚Äôs walk through why a model trained to predict the next token can still feel like a general-purpose engine for NLP tasks.
Quick recap: what a Language Model actually does
Collect a massive amount of text.
Show it to a language model.
Train it to predict the next token (word/subword).
Feed the model‚Äôs own output back into the input (auto-regressive) to generate long sequences.
In other words, a Language Model predicts the next token; stretched out over many steps, it writes. Now, does making that model large turn it into an NLP foundation model‚Äîa base you can adapt to many downstream tasks? A strict yes/no is tough, but in practice: LLMs do a surprisingly good job today and are the closest thing we have so far. Better approaches may come; for now, LLMs are the front-runners.
Why can ‚Äújust next-token prediction‚Äù look like general intelligence?
Two big reasons.
1) The breadth of data
A student who has read widely writes better than one who hasn‚Äôt. Same for LLMs: while ‚Äúknowledge‚Äù in a philosophical sense is debatable, training across diverse, large-scale text exposes the model to patterns, facts, styles, and structures from many domains. That breadth makes next-token prediction look powerful across tasks.
Think of it this way: someone who‚Äôs read a mountain of detective novels can mimic the genre well‚Äîeven if they‚Äôve never solved a case.
2) The power of Transformers
It‚Äôs not just the data. Transformers learn statistical relationships across tokens efficiently. They don‚Äôt build an explicit knowledge graph with named entities and edges, but self-attention lets the model connect distant parts of text and maintain coherence over long spans. Multi-head self-attention is why an LLM can hold a thread instead of getting lost mid-paragraph. (Unlike some blog posts that shall remain unnamed‚Ä¶)
If LLMs are a kind of foundation, how do we use them?
Fine-tuning
Assume the LLM already ‚Äúknows‚Äù general language. You then fine-tune it on your task (sentiment, NER, classification, etc.) with labeled data.
Another way to view it: use the LLM as an initialization rather than starting from random weights. Starting near a good solution can converge faster and more reliably.
Reality check: As models grew, full fine-tuning became slow and expensive. That‚Äôs why we often reach for the next thing‚Ä¶
In-Context Learning (ICL): zero-shot & few-shot
Instead of changing the model, change the input at inference time.
Zero-shot: ‚ÄúWhat‚Äôs the capital of South Korea?‚Äù
Few-shot: Provide patterns first:
USA -> Washington, D.C.
Japan -> Tokyo
China -> Beijing
South Korea -> ?
The model isn‚Äôt ‚Äúanswering a question‚Äù so much as continuing the pattern in the text you gave it. With strong base models, few-shot‚Äîand often zero-shot‚Äîare already useful without retraining.
Fine-tuning can still win on accuracy for some tasks. But for many practical cases, ICL gives you ‚Äògood enough‚Äô without training cost.
Prompt Engineering
LLMs are pattern completers. So how you phrase the input matters.
Worse: What‚Äôs the capital of South Korea?
Better: You‚Äôre a system that answers world-capital questions concisely.
Question: What is the capital of South Korea?
Answer:
The second prompt supplies role, format, and intent, which biases the completion toward what you want.
Conversational LLMs
Base LMs aren‚Äôt chatbots. But they act like one if:
1) They see lots of dialog data during pre-training or fine-tuning, and
2) We wrap user input with a dialog-style prompt before sending it to the model.
How is context maintained? We keep a running transcript:
User: What‚Äôs the capital of South Korea?
Assistant: Seoul.
User: And Japan?
The model gets the whole history (up to the context window, measured in tokens), then continues it. That‚Äôs it‚Äîno magic, just careful prompt construction and truncation when the history gets too long.
Steering with RLHF
Left alone, a base LM will happily produce anything it thinks ‚Äúfits‚Äù the next-token distribution‚Äîincluding unsafe or unhelpful text. Enter Reinforcement Learning with Human Feedback (RLHF): humans rank model responses; a reward model learns those preferences; the LM is optimized to produce safer, more helpful, more ‚Äúon-policy‚Äù outputs.
Important: RLHF doesn‚Äôt grant new raw capabilities; it steers behavior. Sometimes raw benchmark scores even dip slightly while helpfulness/safety improve.
Challenges we shouldn‚Äôt hand-wave away
Concentration of power
Data access is improving (especially for English), but compute is the new bottleneck. Training frontier models requires huge GPU clusters and budgets, which risks consolidation among a few players. Open weights, shared preference datasets, and efficient training methods can help‚Äîbut it‚Äôs an ongoing tension.
Carbon footprint
Training and serving LLMs consume significant energy. Estimates for a single large run can be hundreds of tons of CO‚ÇÇ-equivalent. The field is working on efficiency (better hardware, algorithms, and scheduling) and reporting emissions more transparently, but this is a real externality.
Hallucinations
LLMs will invent details when the next-token distribution ‚Äúleans that way.‚Äù The prose looks confident, which makes fact-checking hard. Mitigations include:
Retrieval-augmented generation (RAG) to ground answers in external sources,
Better prompts and system rules,
Task-specific fine-tuning or adapters,
Structured output and verification steps.
Open questions
Do LLMs ‚Äúreason‚Äù?
One camp: LLMs just do massive pattern matching.
Another: human reasoning might itself be pattern completion over experience.
Truth likely sits between: techniques like chain-of-thought, tool use, and self-consistency push LLMs to perform surprisingly well on reasoning-like tasks‚Äîyet they still fail in distinctly non-human ways.
Arthur C. Clarke had a line for this: ‚ÄúAny sufficiently advanced technology is indistinguishable from magic.‚Äù We‚Äôre somewhere along that curve‚Äîimpressive, but not magic.
Will LLMs replace doctors or lawyers?
Passing an exam ‚â† practicing the profession. Real-world work involves clients, tools, procedures, accountability, and context. Today‚Äôs LLMs won‚Äôt replace entire professions, but they already automate slices of knowledge work (drafting, summarizing, retrieval, brainstorming). The trajectory points toward AI-augmented professionals, not wholesale replacement‚Äîat least for now.
Bottom line
Are LLMs the foundation model for NLP? Today, they‚Äôre the best we‚Äôve got.
Are they perfect? No.
Can we adapt them to many tasks? Absolutely‚Äîand that‚Äôs why they feel foundational.
LLM (9 Part Series)
1
(1/3) LLM: How LLMs Became the Bedrock of Modern AI
2
(2/3) LLM: Data, Transformers, and Relentless Compute
...
5 more parts...
3
(3/3) LLM: In-Context Learning, Hype, and the Road Ahead
4
From Word Predictor to Thinking Partner: The Rise of Thinking Models
5
Understanding Mixture of Experts (MoE)
6
From Full Fine-Tuning to LoRA
7
RAG Explained
8
Understanding Context Window Size in LLMs
9
On-Device LLM
Top comments (0)
Subscribe
Personal
Trusted User
Create template
Templates let you quickly answer FAQs or store snippets for re-use.
Submit
Preview
Dismiss
Code of Conduct
‚Ä¢
Report abuse
Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink.
Hide child comments as well
Confirm
For further actions, you may consider blocking this person and/or reporting abuse
Jimin Lee
Follow
My name is Jimin.
Joined
Sep 13, 2025
More from Jimin Lee
On-Device LLM
#llm
#machinelearning
#nlp
#ondeviceai
Understanding Context Window Size in LLMs
#llm
#machinelearning
RAG Explained
#llm
#machinelearning
#rag
üíé DEV Diamond Sponsors
Thank you to our Diamond Sponsors for supporting the DEV Community
Google AI is the official AI Model and Platform Partner of DEV
Neon is the official database partner of DEV
Algolia is the official search partner of DEV
DEV Community ‚Äî A space to discuss and keep up software development and manage your software career
P√°gina Inicial
DEV++
Welcome Thread
Podcasts
Videos
Tags
DEV Education Tracks
DEV Challenges
DEV Help
Advertise on DEV
DEV Showcase
Sobre
Contato
Free Postgres Database
Software comparisons
Forem Shop
C√≥digo de Conduta
Pol√≠tica de Privacidade
Termos de Uso
Built on Forem ‚Äî the open source software that powers DEV and other inclusive communities.
Made with love and Ruby on Rails. DEV Community ¬© 2016 - 2025.
We're a place where coders share, stay up-to-date and grow their careers.
Log in
Create account