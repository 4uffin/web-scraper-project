Introducing db2lake: A Lightweight and Powerful ETL Framework for Node.js - DEV Community
Forem Feed
Follow new Subforems to improve your feed
DEV Community
Follow
A space to discuss and keep up software development and manage your software career
Gamers Forem
Follow
An inclusive community for gaming enthusiasts
Future
Follow
News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.
Music Forem
Follow
From composing and gigging to gear, hot music takes, and everything in between.
DUMB DEV Community
Follow
Memes and software development shitposting
Vibe Coding Forem
Follow
Discussing AI software development, and showing off what we're building.
Popcorn Movies and TV
Follow
Movie and TV enthusiasm, criticism and everything in-between.
Design Community
Follow
Web design, graphic design and everything in-between
Maker Forem
Follow
A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.
Scale Forem
Follow
For engineers building software at scale. We discuss architecture, cloud-native, and SRE—the hard-won lessons you can't just Google
Forem Core
Follow
Discussing the core forem open source software project — features, bugs, performance, self-hosting.
Security Forem
Follow
Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike
Open Forem
Follow
A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here
Crypto Forem
Follow
A collaborative community for all things Crypto—from Bitcoin to protocol development and DeFi to NFTs and market analysis.
Dropdown menu
Dropdown menu
Skip to content
Navigation menu
Search
Powered by Algolia
Search
Log in
Create account
DEV Community
Close
Add reaction
Like
Unicorn
Exploding Head
Raised Hands
Fire
Jump to Comments
Save
Boost
More...
Moderate
Copy link
Copy link
Copied to Clipboard
Share to X
Share to LinkedIn
Share to Facebook
Share to Mastodon
Report Abuse
Bahador Raghibizadeh
Posted on Sep 13
Introducing db2lake: A Lightweight and Powerful ETL Framework for Node.js
#ai
#node
#opensource
#datascience
Transferring data from operational databases to data lakes or warehouses is a critical need in the modern data landscape. Traditional ETL (Extract, Transform, Load) tools are often complex or rely on costly cloud infrastructure, making them overkill for small to medium-sized projects. db2lake is an open-source Node.js-based framework that simplifies this process with a lightweight, flexible, and intuitive API. It not only handles data extraction and loading but also supports transformation and integration with various architectures like webhooks and database triggers. In this article, we introduce db2lake, its available drivers, the transformer capability, suggested architectures, testing with Vitest, and a comparison with competitors.
Why db2lake? Key Benefits
db2lake is designed for developers who want to implement ETL quickly without the complexity of enterprise tools:
Lightweight and Fast: The core package (@db2lake/core) is minimal and uses streaming and batch processing for high performance.
TypeScript-Native: Strong typing reduces errors and enhances the development experience.
Free and Open-Source: Licensed under MIT, suitable for personal, startup, and commercial projects.
Node.js Integration: Seamlessly fits into the JavaScript ecosystem, no new languages required.
With db2lake, you can transfer data from PostgreSQL to Redshift in just a few lines of code!
Installation and Quick Start
Install via npm:
npm install @db2lake/core @db2lake/driver-mysql @db2lake/driver-bigquery
Enter fullscreen mode
Exit fullscreen mode
Simple example:
import { Pipeline, ITransformer, ILogger } from '@db2lake/core';
import { MySQLSourceDriver } from '@db2lake/driver-mysql';
import { BigQueryDestinationDriver } from '@db2lake/driver-bigquery';
// --- Configure drivers (fill with your credentials) ---
const mysqlConfig = {
query: 'SELECT * FROM orders WHERE order_id > ? LIMIT 50',
params: [0],
cursorField: 'order_id',
cursorParamsIndex: 0,
connectionUri: 'mysql://user:password@localhost:3306/shopdb'
};
const bigqueryConfig = {
bigQueryOptions: {
keyFilename: './service-account.json',
projectId: 'my-project-id'
},
dataset: 'my_dataset',
table: 'users',
batchSize: 1000,
// Optional: use streaming for real-time inserts
writeOptions: {
sourceFormat: 'NEWLINE_DELIMITED_JSON'
}
};
// --- Transformer: adapt source row shape to destination schema ---
const transformer: ITransformer<any, any> = (rows) => rows.map(r => ({
id: r.id,
fullName: `${r.name}`,
createdAt: r.created_at instanceof Date ? r.created_at.toISOString() : r.created_at
}));
// --- Logger ---
const logger: ILogger = (level, message, data) => {
const ts = new Date().toISOString();
console.log(`${ts} [${level.toUpperCase()}] ${message}`);
if (data) console.debug(data);
};
async function main() {
const source = new MySQLSourceDriver(mysqlConfig);
const dest = new BigQueryDestinationDriver(bigqueryConfig);
const pipeline = new Pipeline(source, dest, transformer, logger);
try {
await pipeline.run();
console.log('Pipeline finished', pipeline.getMetrics());
} catch (err) {
console.error('Pipeline error', err);
}
}
main().catch(err => { console.error(err); process.exit(1); });
Enter fullscreen mode
Exit fullscreen mode
Available Drivers
db2lake uses a modular design: the core (@db2lake/core) and separate drivers for sources and destinations. Available drivers:
Sources:
PostgreSQL (@db2lake/driver-postgres): Supports complex queries, incremental loads, and Supabase integration.
MySQL (@db2lake/driver-mysql): Fast streaming with mysql2/promise.
Oracle (@db2lake/driver-oracle): For legacy systems.
Firestore (@db2lake/driver-firestore): For NoSQL databases.
Destinations:
BigQuery (@db2lake/driver-bigquery): Batch inserts for analytics.
Databricks (@db2lake/driver-databricks): Loads to Delta Lake tables.
Redshift (@db2lake/driver-redshift): Upsert and bulk loads for AWS.
Snowflake (@db2lake/driver-snowflake): Supported only as a destination.
Developers can contribute new drivers via the project’s GitHub repository.
Transformer Capability: Smart Data Processing
db2lake supports data transformation (the T in ETL) through the ITransformer interface, allowing you to modify data before loading, such as mapping fields or adding calculations.
Example:
// --- Transformer: adapt source row shape to destination schema ---
const transformer: ITransformer<any, any> = (rows) => rows.map(r => ({
id: r.id,
fullName: `${r.name}`,
createdAt: r.created_at instanceof Date ? r.created_at.toISOString() : r.created_at
}));
Enter fullscreen mode
Exit fullscreen mode
Transformers can be async and integrate with tools like Lodash, making db2lake a complete ETL solution.
Suggested Architectures: How to Deploy db2lake
db2lake is flexible and works in various architectures, depending on project needs:
1. Scheduled Cronjob (For Periodic ETL)
Why? Simple for weekly/daily transfers of new data using cursors.
Implementation:
const cron = require('node-cron');
cron.schedule('0 2 * * 0', runETL);
// Every Sunday at 2 AM
Enter fullscreen mode
Exit fullscreen mode
Benefits: No real-time overhead; ideal for startups.
2. Event-Driven with Webhook (For Real-Time)
Why? Perfect for databases like Supabase that support webhooks for table changes.
Implementation:
const express = require('express');
const app = express();
app.use(express.json());
app.post('/webhook', async (req, res) => {
if (req.body.type === 'INSERT') {
await runETL();
}
res.send('OK');
});
app.listen(3000);
Enter fullscreen mode
Exit fullscreen mode
3. Database Trigger Functions (For Internal Automation)
Why? Minimal latency with database triggers (e.g., PostgreSQL pg_notify).
Implementation: SQL trigger sending signals to a Node.js server.
PostgreSQL Example:
CREATE FUNCTION notify_change() RETURNS trigger AS $$
BEGIN
PERFORM pg_notify('data_change', row_to_json(NEW)::text);
RETURN NEW;
END;
$$ LANGUAGE plpgsql;
CREATE TRIGGER table_change AFTER INSERT OR UPDATE ON your_table
FOR EACH ROW EXECUTE PROCEDURE notify_change();
Enter fullscreen mode
Exit fullscreen mode
Cursors in all architectures prevent duplicate transfers. For scaling, use Docker or PM2.
Testing with Vitest: Ensuring Quality
To ensure db2lake’s reliability, unit and integration tests are run before each release using Vitest, chosen for its speed and TypeScript integration. Check the GitHub repository for test details.
Comparison with Competitors
db2lake stands out with its simplicity and Node.js focus:
db2lake excels for developers seeking simplicity and control.
Advanced Tips and Future
Security: Use Snyk for vulnerability scanning and add a security badge to README.
Monitoring: Integrate with Winston for logging.
Future: New drivers (e.g., MongoDB), serverless support (Vercel), and UI dashboard.
Contribute: Join the project on GitHub!
Conclusion
db2lake is a lightweight, powerful ETL framework for transferring data to data lakes and warehouses (like Snowflake as a destination). With TypeScript support, transformers, flexible architectures, and Vitest testing, it’s an excellent choice for Node.js developers. Get started with: npm install @db2lake/core and send your data to the lake!
Links
Github
npm
Author: Based on information up to September 2025
Top comments (0)
Subscribe
Personal
Trusted User
Create template
Templates let you quickly answer FAQs or store snippets for re-use.
Submit
Preview
Dismiss
Code of Conduct
•
Report abuse
Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink.
Hide child comments as well
Confirm
For further actions, you may consider blocking this person and/or reporting abuse
Bahador Raghibizadeh
Follow
Joined
May 29, 2025
More from Bahador Raghibizadeh
express-access: Elegant Role-Based Access Control for Express.js
#node
#webdev
#javascript
#opensource
💎 DEV Diamond Sponsors
Thank you to our Diamond Sponsors for supporting the DEV Community
Google AI is the official AI Model and Platform Partner of DEV
Neon is the official database partner of DEV
Algolia is the official search partner of DEV
DEV Community — A space to discuss and keep up software development and manage your software career
Home
DEV++
Welcome Thread
Reading List
Podcasts
Videos
Tags
DEV Education Tracks
DEV Challenges
DEV Help
Advertise on DEV
DEV Showcase
About
Contact
Free Postgres Database
Software comparisons
Forem Shop
Code of Conduct
Privacy Policy
Terms of Use
Built on Forem — the open source software that powers DEV and other inclusive communities.
Made with love and Ruby on Rails. DEV Community © 2016 - 2025.
We're a place where coders share, stay up-to-date and grow their careers.
Log in
Create account