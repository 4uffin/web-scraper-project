Moe - DEV Community
Forem Feed
Follow new Subforems to improve your feed
DEV Community
Follow
A space to discuss and keep up software development and manage your software career
Gamers Forem
Follow
An inclusive community for gaming enthusiasts
Future
Follow
News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.
Music Forem
Follow
From composing and gigging to gear, hot music takes, and everything in between.
DUMB DEV Community
Follow
Memes and software development shitposting
Vibe Coding Forem
Follow
Discussing AI software development, and showing off what we're building.
Popcorn Movies and TV
Follow
Movie and TV enthusiasm, criticism and everything in-between.
Design Community
Follow
Web design, graphic design and everything in-between
Maker Forem
Follow
A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.
Scale Forem
Follow
For engineers building software at scale. We discuss architecture, cloud-native, and SREâ€”the hard-won lessons you can't just Google
Forem Core
Follow
Discussing the core forem open source software project â€” features, bugs, performance, self-hosting.
Security Forem
Follow
Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike
Open Forem
Follow
A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here
Crypto Forem
Follow
A collaborative community for all things Cryptoâ€”from Bitcoin to protocol development and DeFi to NFTs and market analysis.
Dropdown menu
Dropdown menu
Skip to content
Navigation menu
Search
Powered by Algolia
Search
Log in
Create account
DEV Community
Close
#
moe
Follow
Hide
Create Post
4 Posts Published
Posts
Left menu
ðŸ‘‹ Sign in for the ability to sort posts by relevant, latest, or top.
Right menu
Understanding Mixture of Experts (MoE)
Jimin Lee
Jimin Lee
Jimin Lee
Follow
Sep 20
Understanding Mixture of Experts (MoE)
#llm
#machinelearning
#nlp
#moe
4Â reactions
Comments
AddÂ Comment
5 min read
ðŸš€ LLMs are getting huge. But do we need all that firepower all the time?
Aleksei Aleinikov
Aleksei Aleinikov
Aleksei Aleinikov
Follow
Apr 11
ðŸš€ LLMs are getting huge. But do we need all that firepower all the time?
#ai
#llm
#machinelearning
#moe
1Â reaction
Comments
AddÂ Comment
1 min read
A Slightly Technical Deep Dive into DeepSeek R1
Abhishek Gautam
Abhishek Gautam
Abhishek Gautam
Follow
Jan 30
A Slightly Technical Deep Dive into DeepSeek R1
#deepseek
#ai
#opensource
#moe
3Â reactions
Comments
AddÂ Comment
3 min read
DBRX, Grok, Mixtral: Mixture-of-Experts is a trending architecture for LLMs
AI/ML API
AI/ML API
AI/ML API
Follow
Apr 11 '24
DBRX, Grok, Mixtral: Mixture-of-Experts is a trending architecture for LLMs
#llm
#moe
#ai
Comments
AddÂ Comment
7 min read
loading...
trending guides/resources
Understanding Mixture of Experts (MoE)
ðŸ’Ž DEV Diamond Sponsors
Thank you to our Diamond Sponsors for supporting the DEV Community
Google AI is the official AI Model and Platform Partner of DEV
Neon is the official database partner of DEV
Algolia is the official search partner of DEV
DEV Community â€” A space to discuss and keep up software development and manage your software career
Home
DEV++
Welcome Thread
Podcasts
Videos
Tags
DEV Education Tracks
DEV Challenges
DEV Help
Advertise on DEV
DEV Showcase
About
Contact
Forem Shop
Code of Conduct
Privacy Policy
Terms of Use
Built on Forem â€” the open source software that powers DEV and other inclusive communities.
Made with love and Ruby on Rails. DEV Community Â© 2016 - 2025.
We're a place where coders share, stay up-to-date and grow their careers.
Log in
Create account