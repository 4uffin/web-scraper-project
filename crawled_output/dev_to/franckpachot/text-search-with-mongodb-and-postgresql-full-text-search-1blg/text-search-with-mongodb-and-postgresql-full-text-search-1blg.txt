Text Search with MongoDB (BM25 TF-IDF) and PostgreSQL - DEV Community
Forem Feed
Follow new Subforems to improve your feed
DEV Community
Follow
A space to discuss and keep up software development and manage your software career
Gamers Forem
Follow
An inclusive community for gaming enthusiasts
Future
Follow
News and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.
Music Forem
Follow
From composing and gigging to gear, hot music takes, and everything in between.
DUMB DEV Community
Follow
Memes and software development shitposting
Vibe Coding Forem
Follow
Discussing AI software development, and showing off what we're building.
Popcorn Movies and TV
Follow
Movie and TV enthusiasm, criticism and everything in-between.
Design Community
Follow
Web design, graphic design and everything in-between
Maker Forem
Follow
A community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.
Scale Forem
Follow
For engineers building software at scale. We discuss architecture, cloud-native, and SRE‚Äîthe hard-won lessons you can't just Google
Forem Core
Follow
Discussing the core forem open source software project ‚Äî features, bugs, performance, self-hosting.
Security Forem
Follow
Your central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike
Crypto Forem
Follow
A collaborative community for all things Crypto‚Äîfrom Bitcoin to protocol development and DeFi to NFTs and market analysis.
Open Forem
Follow
A general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here
Dropdown menu
Dropdown menu
Skip to content
Navigation menu
Search
Powered by Algolia
Search
Log in
Create account
DEV Community
Close
Add reaction
Like
Unicorn
Exploding Head
Raised Hands
Fire
Jump to Comments
Save
Boost
More...
Moderate
Copy link
Copy link
Copied to Clipboard
Share to X
Share to LinkedIn
Share to Facebook
Share to Mastodon
Report Abuse
Franck Pachot
Posted on Sep 19
Text Search with MongoDB (BM25 TF-IDF) and PostgreSQL
#database
#mongodb
#postgres
#elasticsearch
MongoDB Search Indexes provide full‚Äëtext search capabilities directly within MongoDB, allowing complex queries to be run without copying data to a separate search system. Initially deployed in Atlas, MongoDB‚Äôs managed service, Search Indexes are now also part of the community edition. This post compares the default full‚Äëtext search behaviour between MongoDB and PostgreSQL, using a simple example to illustrate the ranking algorithm.
Setup: a small dataset
I‚Äôve inserted nine small documents, each consisting of different fruits, using emojis to make it more visual. The üçé and üçè emojis represent our primary search terms. They appear at varying frequencies in documents of different lengths.
db.articles.deleteMany({});
db.articles.insertMany([
{ description : "üçè üçå üçä" },
// short, 1 üçè
{ description : "üçé üçå üçä" },
// short, 1 üçé
{ description : "üçé üçå üçä üçé" },
// larger, 2 üçé
{ description : "üçé üçå üçä üçä üçä" },
// larger, 1 üçé
{ description : "üçé üçå üçä üå¥ ü´ê üçà üçá üå∞" },
// large, 1 üçé
{ description : "üçé üçé üçé üçé üçé üçé" },
// large, 6 üçé
{ description : "üçé üçå" },
// very short, 1 üçé
{ description : "üçå üçä üå¥ ü´ê üçà üçá üå∞ üçé" },
// large, 1 üçé
{ description : "üçé üçé üçå üçå üçå" },
// shorter, 2 üçé
]);
Enter fullscreen mode
Exit fullscreen mode
To enable dynamic indexing, I created a MongoDB Search Index without specifying any particular field names:
db.articles.createSearchIndex("default",
{ mappings: { dynamic: true } }
);
Enter fullscreen mode
Exit fullscreen mode
I created the equivalent on PostgreSQL:
DROP TABLE IF EXISTS articles;
CREATE TABLE articles (
id BIGSERIAL PRIMARY KEY,
description TEXT
);
INSERT INTO articles(description) VALUES
('üçè üçå üçä'),
('üçé üçå üçä'),
('üçé üçå üçä üçé'),
('üçé üçå üçä üçä üçä'),
('üçé üçå üçä üå¥ ü´ê üçà üçá üå∞'),
('üçé üçé üçé üçé üçé üçé'),
('üçé üçå'),
('üçå üçä üå¥ ü´ê üçà üçá üå∞ üçé'),
('üçé üçé üçå üçå üçå');
Enter fullscreen mode
Exit fullscreen mode
Since text search needs multiple index entries for each row, I set up a GIN (Generalized Inverted Index) and use tsvector to extract and index the relevant tokens.
CREATE INDEX articles_fts_idx
ON articles USING GIN (to_tsvector('simple', description))
;
Enter fullscreen mode
Exit fullscreen mode
MongoDB Text Search (Lucene BM25):
I use my custom search index to find articles containing either üçé or üçè in their descriptions. The results are sorted by relevance score and displayed as follows:
db.articles.aggregate([
{ $search: { text: { query: ["üçé", "üçè"], path: "description" }, index: "default" } },
{ $project: { _id: 0, score: { $meta: "searchScore" }, description: 1 } },
{ $sort: { score: -1 } }
]).forEach( i=> print(i.score.toFixed(3).padStart(5, " "),i.description) )
Enter fullscreen mode
Exit fullscreen mode
Here are the results, presented in order of best to worst match:
1.024 üçè üçå üçä
0.132 üçé üçé üçé üçé üçé üçé
0.107 üçé üçå üçä üçé
0.101 üçé üçé üçå üçå üçå
0.097 üçé üçå
0.088 üçé üçå üçä
0.073 üçé üçå üçä üçä üçä
0.059 üçé üçå üçä üå¥ ü´ê üçà üçá üå∞
0.059 üçå üçä üå¥ ü´ê üçà üçá üå∞ üçé
Enter fullscreen mode
Exit fullscreen mode
All documents were retrieved by this search since each contains a red or green apple. However, they are assigned different scores:
Multiple appearances boost the score: When a document contains the search term more than once, its ranking increases compared to those with only a single appearance. That's why documents featuring several üçé are ranked higher than those containing only one.
Rarity outweighs quantity: When a term like üçé appears in every document, it has less impact than a rare term, such as üçè. Therefore, even if üçè only appears once, the document containing it ranks higher than others with multiple üçé. In this model, rarity carries more weight than mere frequency.
Diminishing returns on term frequency: Each extra occurrence of a term adds less to the relevance score. For instance, increasing üçé from one to six times (from üçé üçå to üçé üçé üçé üçé üçé üçé) boosts the score, but not by a factor of six. The effect of term repetition diminishes as the count rises.
Document length matters: A term that appears only once is scored higher in a short document than in a long one. That's why üçé üçå ranks higher than üçé üçå üçä, which itself ranks higher than üçé üçå üçä üçä üçä.
MongoDB Atlas Search indexes are powered by Lucene‚Äôs BM25 algorithm, a refinement of the classic TF‚ÄëIDF model:
Term Frequency (TF): More occurrences of a term in a document increase its relevance score, but with diminishing returns.
Inverse Document Frequency (IDF): Terms that appear in fewer documents receive higher weighting.
Length Normalization: Matches in shorter documents contribute more to relevance than the same matches in longer documents.
To demonstrate the impact of IDF, I added several documents that do not contain any of the apples I'm searching for.
const fruits = [ "üçê","üçä","üçã","üçå","üçâ","üçá","üçì","ü´ê",
"ü•ù","ü•≠","üçç","ü••","üçà","üçÖ","ü•ë","üçÜ",
"üçã","üçê","üçì","üçá","üçà","ü•≠","üçç","üçë",
"ü•ù","ü´ê","üçå","üçâ","ü••","ü•ë","ü••","üçç" ];
function randomFruitSentence(min=3, max=8) {
const len = Math.floor(Math.random() * (max - min + 1)) + min;
return Array.from({length: len}, () => fruits[Math.floor(Math.random()*fruits.length)]).join(" ");
}
db.articles.insertMany(
Array.from({length: 500}, () => ({ description: randomFruitSentence() }))
);
db.articles.aggregate([
{ $search: { text: { query: ["üçé", "üçè"], path: "description" }, index: "default" } },
{ $project: { _id: 0, score: { $meta: "searchScore" }, description: 1 } },
{ $sort: { score: -1 } }
]).forEach( i=> print(i.score.toFixed(3).padStart(5, " "),i.description) )
3.365 üçé üçé üçé üçé üçé üçé
3.238 üçè üçå üçä
2.760 üçé üçå üçä üçé
2.613 üçé üçé üçå üçå üçå
2.506 üçé üçå
2.274 üçé üçå üçä
1.919 üçé üçå üçä üçä üçä
1.554 üçé üçå üçä üå¥ ü´ê üçà üçá üå∞
1.554 üçå üçä üå¥ ü´ê üçà üçá üå∞ üçé
Enter fullscreen mode
Exit fullscreen mode
Although the result set is unchanged, the score has increased and the frequency gap between üçé and üçè has narrowed. As a result, üçé üçé üçé üçé üçé üçé now ranks higher than üçè üçå üçä, since the inverse document frequency (IDF) of üçè does not fully offset its term frequency (TF) within a single document. Crucially, changes made in other documents can influence the score of any given document, unlike in traditional indexes where changes in one document do not impact others' index entries.
PostgreSQL Text Search (TF only):
Here is the result in PostgreSQL:
SELECT ts_rank_cd(
to_tsvector('simple', description)
,
to_tsquery('simple', 'üçé | üçè')
) AS score, description
FROM articles
WHERE
to_tsvector('simple', description)
@@
to_tsquery('simple', 'üçé | üçè')
ORDER BY score DESC;
Enter fullscreen mode
Exit fullscreen mode
It retrieves the same documents, but with many having the same score, even with different patterns:
score |
description
-------+-------------------------
0.6 | üçé üçé üçé üçé üçé üçé
0.2 | üçé üçå üçä üçé
0.2 | üçé üçé üçå üçå üçå
0.1 | üçè üçå üçä
0.1 | üçé üçå
0.1 | üçå üçä üå¥ ü´ê üçà üçá üå∞ üçé
0.1 | üçé üçå üçä üå¥ ü´ê üçà üçá üå∞
0.1 | üçé üçå üçä
0.1 | üçé üçå üçä üçä üçä
(9 rows)
Enter fullscreen mode
Exit fullscreen mode
With PostgreSQL text search, only the term frequency (TF) matters, and is a direct multiplicator of the score: 6 apples ranks 3x higher than two, and 6x than one.
There's some possible normalization available with additiona flags:
SELECT ts_rank_cd(
to_tsvector('simple', description),
to_tsquery('simple', 'üçé | üçè')
,
0 -- (the default) ignores the document length
|
1 -- divides the rank by 1 + the logarithm of the document length
--
|
2 -- divides the rank by the document length
--
|
4 -- divides the rank by the mean harmonic distance between extents (this is implemented only by ts_rank_cd)
|
8 -- divides the rank by the number of unique words in document
--
| 16 -- divides the rank by 1 + the logarithm of the number of unique words in document
--
| 32 -- divides the rank by itself + 1
) AS score,
description
FROM articles
WHERE to_tsvector('simple', description) @@ to_tsquery('simple', 'üçé | üçè')
ORDER BY score DESC
;
score
|
description
-------------+-------------------------
0.308339 | üçé üçé üçé üçé üçé üçé
0.055811062 | üçé üçé üçå üçå üçå
0.04551196 | üçé üçå
0.04142233 | üçé üçå üçä üçé
0.024044918 | üçè üçå üçä
0.024044918 | üçé üçå üçä
0.018603688 | üçé üçå üçä üçä üçä
0.005688995 | üçé üçå üçä üå¥ ü´ê üçà üçá üå∞
0.005688995 | üçå üçä üå¥ ü´ê üçà üçá üå∞ üçé
(9 rows)
Enter fullscreen mode
Exit fullscreen mode
This penalizes longer documents and those with more unique terms. Still, it doesn't consider other documents like IDF.
PostgreSQL Full Text Search scoring with ts_rank_cd is based on term frequency and proximity. It does not compute inverse document frequency, so scores do not change as the corpus changes. Normalization flags can penalize long documents or those with many unique terms, but they are length-based adjustments, not true IDF, like we have in TF‚ÄëIDF or BM25‚Äëstyle search engine.
ParadeDB with pg_search (Tantivy BM25)
PostgreSQL popularity is not only due to its features but also its extensibility and ecosystem. The pg_search extension adds functions and operators that use BM25 indexes (Tantivy, a Rust-based search library inspired by Lucene). It is easy to test with ParadeDB:
docker run --rm -it paradedb/paradedb bash
POSTGRES_PASSWORD=x docker-entrypoint.sh postgres &
psql -U postgres
Enter fullscreen mode
Exit fullscreen mode
The extension is installed in version 0.18.4:
postgres=# \dx
List of installed extensions
Name
| Version |
Schema
|
Description
------------------------+---------+------------+------------------------------------------------------------
fuzzystrmatch
| 1.2
| public
| determine similarities and distance between strings
pg_cron
| 1.6
| pg_catalog | Job scheduler for PostgreSQL
pg_ivm
| 1.9
| pg_catalog | incremental view maintenance on PostgreSQL
pg_search
| 0.18.4
| paradedb
| pg_search: Full text search for PostgreSQL using BM25
plpgsql
| 1.0
| pg_catalog | PL/pgSQL procedural language
postgis
| 3.6.0
| public
| PostGIS geometry and geography spatial types and functions
postgis_tiger_geocoder | 3.6.0
| tiger
| PostGIS tiger geocoder and reverse geocoder
postgis_topology
| 3.6.0
| topology
| PostGIS topology spatial types and functions
vector
| 0.8.0
| public
| vector data type and ivfflat and hnsw access methods
(9 rows)
Enter fullscreen mode
Exit fullscreen mode
I created and inserted the same as I did above on PostgreSQL and created the BM25 index:
CREATE INDEX search_idx ON articles
USING bm25 (id, description)
WITH (key_field='id')
;
Enter fullscreen mode
Exit fullscreen mode
We can query using the @@@ operator and rank with paradedb.score(id). Unlike PostgreSQL‚Äôs built‚Äëin @@, which uses query‚Äëlocal statistics, @@@ computes scores using global IDF and Lucene‚Äôs BM25 length normalization ‚Äî so adding unrelated documents can still change the scores.
SELECT description, paradedb.score(id) AS score
FROM articles
WHERE description @@@ 'üçé' OR description @@@ 'üçè'
ORDER BY score DESC, description;
description | score
-------------+-------
(0 rows)
Enter fullscreen mode
Exit fullscreen mode
The result is empty. Using emoji as terms can lead to inconsistent tokenization results, so I replaced them with text labels instead:
UPDATE articles SET description
= replace(description, 'üçé', 'Gala');
UPDATE articles SET description
= replace(description, 'üçè', 'Granny Smith');
UPDATE articles SET description
= replace(description, 'üçä', 'Orange');
Enter fullscreen mode
Exit fullscreen mode
This time, the scoring is more precise and takes into account the term frequency within the document (TF), the term‚Äôs rarity across the entire indexed corpus (IDF), along with a length normalization factor to prevent longer documents from having an unfair advantage:
SELECT description, paradedb.score(id) AS score
FROM articles
WHERE description @@@ 'Gala' OR description @@@ 'Granny Smith'
ORDER BY score DESC, description;
description
|
score
-------------------------------+------------
Granny Smith üçå Orange
|
3.1043208
Gala Gala Gala Gala Gala Gala | 0.79529095
Gala Gala üçå üçå üçå
|
0.7512194
Gala üçå
| 0.69356775
Gala üçå Orange Gala
| 0.63589364
Gala üçå Orange
|
0.5195716
Gala üçå Orange üå¥ ü´ê üçà üçá
|
0.5195716
üçå Orange üå¥ ü´ê üçà üçá
Gala |
0.5195716
Gala üçå Orange Orange Orange
| 0.34597924
(9 rows)
Enter fullscreen mode
Exit fullscreen mode
It looks very similar to the MongoDB result. Lucene may give a slight edge to terms that appear more frequently (üçé üçå üçä üçé), even if the document length penalty is higher. Tantivy might apply length normalization in a slightly different way, so the shorter (üçé üçå) gets a bigger boost.
Here is the execution plan in ParadeDB:
EXPLAIN(ANALYZE, BUFFERS, VERBOSE)
SELECT description, paradedb.score(id) AS score
FROM articles
WHERE description @@@ 'Gala' OR description @@@ 'Granny Smith'
ORDER BY score DESC, description
;
Gather Merge
(cost=1010.06..1010.68 rows=5 width=31) (actual time=5.893..8.237 rows=8 loops=1)
Output: description, (score(id))
Workers Planned: 2
Workers Launched: 2
Buffers: shared hit=333
->
Sort
(cost=10.04..10.05 rows=3 width=31) (actual time=0.529..0.540 rows=3 loops=3)
Output: description, (score(id))
Sort Key: (score(articles.id)) DESC, articles.description
Sort Method: quicksort
Memory: 25kB
Buffers: shared hit=306
Worker 0:
actual time=0.548..0.558 rows=0 loops=1
Sort Method: quicksort
Memory: 25kB
Buffers: shared hit=64
Worker 1:
actual time=0.596..0.607 rows=0 loops=1
Sort Method: quicksort
Memory: 25kB
Buffers: shared hit=64
->
Parallel Custom Scan (ParadeDB Scan) on public.articles
(cost=10.00..10.02 rows=3 width=31) (actual time=0.367..0.444 rows=3 loops=3)
Output: description, score(id)
Table: articles
Index: search_idx
Segment Count: 5
Heap Fetches: 8
Virtual Tuples: 0
Invisible Tuples: 0
Parallel Workers: {"-1":{"query_count":0,"claimed_segments":[{"id":"a17b19a2","deleted_docs":0,"max_doc":9},{"id":"3fa71653","deleted_docs":6,"max_doc":6},{"id":"3c243f8e","deleted_docs":1,"max_doc":1},{"id":"badbcd7e","deleted_docs":8,"max_doc":8},{"id":"add79d5d","deleted_docs":9,"max_doc":9}]}}
Exec Method: NormalScanExecState
Scores: true
Tantivy Query: {"boolean":{"should":[{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"Gala","lenient":null,"conjunction_mode":null}}}},{"with_index":{"query":{"parse_with_field":{"field":"description","query_string":"Granny Smith","lenient":null,"conjunction_mode":null}}}}]}}
Buffers: shared hit=216
Worker 0:
actual time=0.431..0.441 rows=0 loops=1
Buffers: shared hit=19
Worker 1:
actual time=0.447..0.457 rows=0 loops=1
Buffers: shared hit=19
Enter fullscreen mode
Exit fullscreen mode
This PostgreSQL plan shows ParadeDB executing a parallel full-text search with Tantivy. The Parallel Custom Scan node issues a BM25 query (Gala OR "Granny Smith") to the segmented Tantivy index. Each worker searches its segments, scores, fetches matching descriptions, and sorts locally. The Gather Merge then combines these into a single ranked list. Since search and scoring are done within Tantivy across CPU cores and results are fetched from shared memory, the query is quick and efficient.
In the execution plan, the Tantivy query closely resembles a MongoDB search query. Specifically, "boolean" in Tantivy is equivalent to "compound" in MongoDB, "should" matches "should", "parse_with_field.field" is similar to "path".
PostgreSQL‚Äôs built-in search only provides basic, local term frequency scoring. To get a full-featured text search that can be used in an application's search boxes, it can be extended with third-party tools like ParadeDB's pg_search.
Conclusion
Relevance scoring in text search can differ widely between systems because each uses its own ranking algorithms and analyzers. To better visualize my results in these tests, I used emojis and opted for the simplest definitions. I selected PostgreSQL's to_tsvector('simple') configuration to prevent language-specific processing, while for MongoDB Atlas Search, I used the default dynamic mapping.
MongoDB Atlas Search (and now in MongoDB Community Edition) uses Lucene‚Äôs BM25 algorithm, combining:
Term Frequency (TF): Frequent terms in a document boost scores, but with diminishing returns
Inverse Document Frequency (IDF): Rare terms across the corpus get higher weight
Length normalization: Matches in shorter documents are weighted more than the same matches in longer ones
PostgreSQL‚Äôs full-text search (ts_rank_cd()) evaluates only term frequency and position, overlooking other metrics like IDF. For more advanced features such as BM25, extensions like ParadeDB‚Äôs pg_search are needed, which require extra configuration and are not always available on managed platforms. PostgreSQL offers a modular approach, allowing extensions to add advanced ranking algorithms, such as BM25. MongoDB provides built‚Äëin BM25‚Äëbased full‚Äëtext search in both Atlas and the Community Edition.
Top comments (0)
Subscribe
Personal
Trusted User
Create template
Templates let you quickly answer FAQs or store snippets for re-use.
Submit
Preview
Dismiss
Code of Conduct
‚Ä¢
Report abuse
Are you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's permalink.
Hide child comments as well
Confirm
For further actions, you may consider blocking this person and/or reporting abuse
Franck Pachot
Follow
ü•ë Developer Advocate at üçÉ¬†MongoDB, üî∂¬†AWS Data Hero, üêò¬†PostgreSQL fan,‚ñù‚ñû¬†YugabyteDB expert, üÖæÔ∏è¬†Oracle Certified Master, and üíö¬†loving all databases üõ¢Ô∏è
Location
Lausanne, Switzerland
Education
Master MIAGE, Universit√© Paris-Sud, France
Work
Developer Advocate at MongoDB
Joined
Nov 12, 2018
More from Franck Pachot
Combine Two JSON Collections with Nested Arrays: MongoDB and PostgreSQL Aggregations
#mongodb
#postgres
#sql
#json
MongoDB Multikey Indexes and Index Bound Optimization
#database
#mongodb
#performance
MongoDB Internals: How Collections and Indexes Are Stored in WiredTiger
#mongodb
#database
#wiredtiger
#internals
üíé DEV Diamond Sponsors
Thank you to our Diamond Sponsors for supporting the DEV Community
Google AI is the official AI Model and Platform Partner of DEV
Neon is the official database partner of DEV
Algolia is the official search partner of DEV
DEV Community ‚Äî A space to discuss and keep up software development and manage your software career
Home
DEV++
Reading List
Podcasts
Videos
Tags
DEV Education Tracks
DEV Challenges
DEV Help
Advertise on DEV
DEV Showcase
About
Contact
Free Postgres Database
Software comparisons
Forem Shop
Code of Conduct
Privacy Policy
Terms of Use
Built on Forem ‚Äî the open source software that powers DEV and other inclusive communities.
Made with love and Ruby on Rails. DEV Community ¬© 2016 - 2025.
We're a place where coders share, stay up-to-date and grow their careers.
Log in
Create account