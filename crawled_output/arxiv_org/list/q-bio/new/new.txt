Quantitative Biology
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
q-bio
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Quantitative Biology
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Tuesday, 23 September 2025
Total of 55 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 31 of 31 entries)
[1]
arXiv:2509.16229
[pdf, other]
Title:
Low-Cost Shield MicroBCI to Measure EEG with STM32
Ildar Rakhmatulin
Subjects:
Neurons and Cognition (q-bio.NC)
The article introduces an accessible pathway into neuroscience using the MicroBCI device, which leverages the STM32 Nucleo-55RG development board as the core platform. MicroBCI enables the STM32 board to function as a brain-computer interface, capable of recording EEG, EMG, and ECG signals across 8 channels. Over the past decade, the rapid growth of artificial intelligence has transformed many fields, including neurobiology. The application of machine learning methods has created opportunities for the practical use of EEG signals in diverse technological domains. This growing interest has fueled the popularity of affordable brain-computer interface systems that utilize non-invasive electrodes for EEG acquisition. The MicroBCI device demonstrates reliable noise performance and accuracy for applied research and prototyping. Furthermore, it effectively detects alpha brain waves, confirming its ability to capture key neurological signals.
[2]
arXiv:2509.16232
[pdf, other]
Title:
Emotions are Recognized Patterns of Cognitive Activities
Yue Jin (Nokia Bell Labs France)
Comments:
10 pages, 7 figures
Subjects:
Neurons and Cognition (q-bio.NC); Human-Computer Interaction (cs.HC)
Emotions play a crucial role in human life. The research community has proposed many theories on emotions without reaching much consensus. The situation is similar for emotions in cognitive architectures and autonomous agents. I propose in this paper that emotions are recognized patterns of cognitive activities. These activities are responses of an agent to the deviations between the targets of its goals and the performances of its actions. Emotions still arise even if these activities are purely logical. I map the patterns of cognitive activities to emotions. I show the link between emotions and attention and the impacts of the parameterized functions in the cognitive architecture on the computing of emotions. My proposition bridges different theories on emotions and advances the building of consensus.
[3]
arXiv:2509.16238
[pdf, html, other]
Title:
Evolvable Graph Diffusion Optimal Transport with Pattern-Specific Alignment for Brain Connectome Modeling
Xiaoqi Sheng, Jiawen Liu, Jiaming Liang, Yiheng Zhang, Hongmin Cai
Subjects:
Neurons and Cognition (q-bio.NC); Graphics (cs.GR)
Network analysis of human brain connectivity indicates that individual differences in cognitive abilities arise from neurobiological mechanisms inherent in structural and functional brain networks. Existing studies routinely treat structural connectivity (SC) as optimal or fixed topological scaffolds for functional connectivity (FC), often overlooking higher-order dependencies between brain regions and limiting the modeling of complex cognitive processes. Besides, the distinct spatial organizations of SC and FC complicate direct integration, as naive alignment may distort intrinsic nonlinear patterns of brain connectivity. In this study, we propose a novel framework called Evolvable Graph Diffusion Optimal Transport with Pattern-Specific Alignment (EDT-PA), designed to identify disease-specific connectome patterns and classify brain disorders. To accurately model high-order structural dependencies, EDT-PA incorporates a spectrum of evolvable modeling blocks to dynamically capture high-order dependencies across brain regions. Additionally, a Pattern-Specific Alignment mechanism employs optimal transport to align structural and functional representations in a geometry-aware manner. By incorporating a Kolmogorov-Arnold network for flexible node aggregation, EDT-PA is capable of modeling complex nonlinear interactions among brain regions for downstream classification. Extensive evaluations on the REST-meta-MDD and ADNI datasets demonstrate that EDT-PA outperforms state-of-the-art methods, offering a more effective framework for revealing structure-function misalignments and disorder-specific subnetworks in brain disorders. The project of this work is released via this link.
[4]
arXiv:2509.16250
[pdf, other]
Title:
A study on Deep Convolutional Neural Networks, transfer learning, and Mnet model for Cervical Cancer Detection
Saifuddin Sagor, Md Taimur Ahad, Faruk Ahmed, Rokonozzaman Ayon, Sanzida Parvin
Subjects:
Tissues and Organs (q-bio.TO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
Early and accurate detection through Pap smear analysis is critical to improving patient outcomes and reducing mortality of Cervical cancer. State-of-the-art (SOTA) Convolutional Neural Networks (CNNs) require substantial computational resources, extended training time, and large datasets. In this study, a lightweight CNN model, S-Net (Simple Net), is developed specifically for cervical cancer detection and classification using Pap smear images to address these limitations. Alongside S-Net, six SOTA CNNs were evaluated using transfer learning, including multi-path (DenseNet201, ResNet152), depth-based (Serasnet152), width-based multi-connection (Xception), depth-wise separable convolutions (MobileNetV2), and spatial exploitation-based (VGG19). All models, including S-Net, achieved comparable accuracy, with S-Net reaching 99.99%. However, S-Net significantly outperforms the SOTA CNNs in terms of computational efficiency and inference time, making it a more practical choice for real-time and resource-constrained applications. A major limitation in CNN-based medical diagnosis remains the lack of transparency in the decision-making process. To address this, Explainable AI (XAI) techniques, such as SHAP, LIME, and Grad-CAM, were employed to visualize and interpret the key image regions influencing model predictions. The novelty of this study lies in the development of a highly accurate yet computationally lightweight model (S-Net) caPable of rapid inference while maintaining interpretability through XAI integration. Furthermore, this work analyzes the behavior of SOTA CNNs, investigates the effects of negative transfer learning on Pap smear images, and examines pixel intensity patterns in correctly and incorrectly classified samples.
[5]
arXiv:2509.16251
[pdf, other]
Title:
R-Net: A Reliable and Resource-Efficient CNN for Colorectal Cancer Detection with XAI Integration
Rokonozzaman Ayon, Md Taimur Ahad, Bo Song, Yan Li
Subjects:
Tissues and Organs (q-bio.TO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
State-of-the-art (SOTA) Convolutional Neural Networks (CNNs) are criticized for their extensive computational power, long training times, and large datasets. To overcome this limitation, we propose a reasonable network (R-Net), a lightweight CNN only to detect and classify colorectal cancer (CRC) using the Enteroscope Biopsy Histopathological Hematoxylin and Eosin Image Dataset (EBHI). Furthermore, six SOTA CNNs, including Multipath-based CNNs (DenseNet121, ResNet50), Depth-based CNNs (InceptionV3), width-based multi-connection CNNs (Xception), depth-wise separable convolutions (MobileNetV2), spatial exploitation-based CNNs (VGG16), Transfer learning, and two ensemble models are also tested on the same dataset. The ensemble models are a multipath-depth-width combination (DenseNet121-InceptionV3-Xception) and a multipath-depth-spatial combination (ResNet18-InceptionV3-VGG16). However, the proposed R-Net lightweight achieved 99.37% accuracy, outperforming MobileNet (95.83%) and ResNet50 (96.94%). Most importantly, to understand the decision-making of R-Net, Explainable AI such as SHAP, LIME, and Grad-CAM are integrated to visualize which parts of the EBHI image contribute to the detection and classification process of R-Net. The main novelty of this research lies in building a reliable, lightweight CNN R-Net that requires fewer computing resources yet maintains strong prediction results. SOTA CNNs, transfer learning, and ensemble models also extend our knowledge on CRC classification and detection. XAI functionality and the impact of pixel intensity on correct and incorrect classification images are also some novelties in CRC detection and classification.
[6]
arXiv:2509.16253
[pdf, other]
Title:
Quantum-like representation of neuronal networks' activity: modeling "mental entanglement"
Andrei Khrennikov, Makiko Yamada
Subjects:
Neurons and Cognition (q-bio.NC); Quantum Physics (quant-ph)
Quantum-like modeling (QLM) - quantum theory applications outside of physics - are intensively developed with applications in biology, cognition, psychology, and decision-making. For cognition, QLM should be distinguished from quantum reductionist models in the spirit of Hameroff and Penrose and well as Umezawa and Vitiello. QLM is not concerned with just quantum physical processes in the brain but also QL information processing by macroscopic neuronal structures. Although QLM of cognition and decision-making has seen some success, it suffers from a knowledge gap that exists between oscillatory neuronal network functioning in the brain and QL behavioral patterns. Recently, steps toward closing this gap have been taken using the generalized probability theory and prequantum classical statistical field theory (PCSFT) - a random field model beyond the complex Hilbert space formalism. PCSFT is used to move from the classical ``oscillatory cognition'' of the neuronal networks to QLM for this http URL. In this study, we addressed the most difficult problem within this construction: QLM for entanglement generation by classical networks, i.e., mental entanglement. We started with the observational approach to entanglement based on operator algebras describing local observables and bringing into being the tensor product structure in the space of QL states. Moreover, we applied the standard states entanglement approach: entanglement generation by spatially separated networks in the brain. Finally, we discussed possible future experiments on mental entanglement detection using the EEG/MEG technique.
[7]
arXiv:2509.16254
[pdf, html, other]
Title:
Imaging Modalities-Based Classification for Lung Cancer Detection
Sajim Ahmed, Muhammad Zain Chaudhary, Muhammad Zohaib Chaudhary, Mahmoud Abbass, Ahmed Sherif, Mohammad Mahbubur Rahman Khan Mamun
Comments:
Accepted at ICMI 2025
Subjects:
Tissues and Organs (q-bio.TO); Artificial Intelligence (cs.AI)
Lung cancer continues to be the predominant cause of cancer-related mortality globally. This review analyzes various approaches, including advanced image processing methods, focusing on their efficacy in interpreting CT scans, chest radiographs, and biological markers. Notably, we identify critical gaps in the previous surveys, including the need for robust models that can generalize across diverse populations and imaging modalities. This comprehensive synthesis aims to serve as a foundational resource for researchers and clinicians, guiding future efforts toward more accurate and efficient lung cancer detection. Key findings reveal that 3D CNN architectures integrated with CT scans achieve the most superior performances, yet challenges such as high false positives, dataset variability, and computational complexity persist across modalities.
[8]
arXiv:2509.16255
[pdf, other]
Title:
RootletSeg: Deep learning method for spinal rootlets segmentation across MRI contrasts
Katerina Krejci, Jiri Chmelik, Sandrine Bédard, Falk Eippert, Ulrike Horn, Virginie Callot, Julien Cohen-Adad, Jan Valosek
Comments:
26 pages, 6 figures, 4 tables
Subjects:
Tissues and Organs (q-bio.TO); Image and Video Processing (eess.IV); Medical Physics (physics.med-ph)
Purpose: To develop a deep learning method for the automatic segmentation of spinal nerve rootlets on various MRI scans. Material and Methods: This retrospective study included MRI scans from two open-access and one private dataset, consisting of 3D isotropic 3T TSE T2-weighted (T2w) and 7T MP2RAGE (T1-weighted [T1w] INV1 and INV2, and UNIT1) MRI scans. A deep learning model, RootletSeg, was developed to segment C2-T1 dorsal and ventral spinal rootlets. Training was performed on 76 scans and testing on 17 scans. The Dice score was used to compare the model performance with an existing open-source method. Spinal levels derived from RootletSeg segmentations were compared with vertebral levels defined by intervertebral discs using Bland-Altman analysis. Results: The RootletSeg model developed on 93 MRI scans from 50 healthy adults (mean age, 28.70 years $\pm$ 6.53 [SD]; 28 [56%] males, 22 [44%] females) achieved a mean $\pm$ SD Dice score of 0.67 $\pm$ 0.09 for T1w-INV2, 0.65 $\pm$ 0.11 for UNIT1, 0.64 $\pm$ 0.08 for T2w, and 0.62 $\pm$ 0.10 for T1w-INV1 contrasts. Spinal-vertebral level correspondence showed a progressively increasing rostrocaudal shift, with Bland-Altman bias ranging from 0.00 to 8.15 mm (median difference between level midpoints). Conclusion: RootletSeg accurately segmented C2-T1 spinal rootlets across MRI contrasts, enabling the determination of spinal levels directly from MRI scans. The method is open-source and can be used for a variety of downstream analyses, including lesion classification, neuromodulation therapy, and functional MRI group analysis.
[9]
arXiv:2509.16284
[pdf, other]
Title:
Temporally staggered cropping co-benefits beneficial insects and pest control globally
Adrija Datta (Department of Earth Sciences, Indian Institute of Technology, Gandhinagar, Gujarat, India), Subramanian Sankaranarayanan (Department of Biological Sciences and Engineering, Indian Institute of Technology, Gandhinagar, Gujarat, India), Udit Bhatia (Department of Computer Science and Engineering, Indian Institute of Technology, Gandhinagar, Gujarat, India, Department of Civil Engineering, Indian Institute of Technology, Gandhinagar, Gujarat, India)
Subjects:
Populations and Evolution (q-bio.PE)
Reconciling increasing food production with biodiversity conservation is critical yet challenging, particularly given global declines in beneficial insects driven by monoculture intensification. Intercropping, the simultaneous or sequential cultivation of multiple crops, has been proposed as a viable strategy to enhance beneficial insect services and suppress pests, yet global evidence regarding optimal spatiotemporal intercropping configurations remains fragmented. Here, we synthesize results from 7,584 field experiments spanning six continents and 22 Koppen climate regions, evaluating effects of spatial (row, strip, mixed, agroforestry) and temporal (additive, replacement, relay) intercropping configuations on beneficial insect (predators, parasitoids, pollinators) abundance and pest suppression using the Management Efficiency Ratio (MER; log ratio of abundance in intercropping versus monoculture). Relay intercropping, characterized by temporally staggered planting, emerged as the universally optimal temporal configuration, substantially increasing predator (MER = 0.473) and parasitoid populations (MER = 0.512) and effectively suppressing pests (MER = -0.611) globally. At regional scales, identical spatiotemporal configurations simultaneously optimized beneficial insect predator abundance and pest suppression in 57% of regions, while other regions required distinct, insect-specific approaches. Our findings highlight relay intercropping as a globally generalizable solution, but underscore regional variation that calls for targeted policies to simultaneously secure food production and biodiversity conservation.
[10]
arXiv:2509.16301
[pdf, html, other]
Title:
TF-DWGNet: A Directed Weighted Graph Neural Network with Tensor Fusion for Multi-Omics Cancer Subtype Classification
Tiantian Yang, Zhiqian Chen
Comments:
9 pages, 4 figures, 4 tables
Subjects:
Quantitative Methods (q-bio.QM); Machine Learning (cs.LG)
Integration and analysis of multi-omics data provide valuable insights for cancer subtype classification. However, such data are inherently heterogeneous, high-dimensional, and exhibit complex intra- and inter-modality dependencies. Recent advances in graph neural networks (GNNs) offer powerful tools for modeling such structure. Yet, most existing methods rely on prior knowledge or predefined similarity networks to construct graphs, which are often undirected or unweighted, failing to capture the directionality and strength of biological interactions. Interpretability at both the modality and feature levels also remains limited. To address these challenges, we propose TF-DWGNet, a novel Graph Neural Network framework that combines tree-based Directed Weighted graph construction with Tensor Fusion for multiclass cancer subtype classification. TF-DWGNet introduces two key innovations: a supervised tree-based approach for constructing directed, weighted graphs tailored to each omics modality, and a tensor fusion mechanism that captures unimodal, bimodal, and trimodal interactions using low-rank decomposition for efficiency. TF-DWGNet enables modality-specific representation learning, joint embedding fusion, and interpretable subtype prediction. Experiments on real-world cancer datasets show that TF-DWGNet consistently outperforms state-of-the-art baselines across multiple metrics and statistical tests. Moreover, it provides biologically meaningful insights by ranking influential features and modalities. These results highlight TF-DWGNet's potential for effective and interpretable multi-omics integration in cancer research.
[11]
arXiv:2509.16328
[pdf, html, other]
Title:
The Role of High-Performance GPU Resources in Large Language Model Based Radiology Imaging Diagnosis
Jyun-Ping Kao
Subjects:
Tissues and Organs (q-bio.TO)
Large-language models (LLMs) are rapidly being applied to radiology, enabling automated image interpretation and report generation tasks. Their deployment in clinical practice requires both high diagnostic accuracy and low inference latency, which in turn demands powerful hardware. High-performance graphical processing units (GPUs) provide the necessary compute and memory throughput to run large LLMs on imaging data. We review modern GPU architectures (e.g. NVIDIA A100/H100, AMD Instinct MI250X/MI300) and key performance metrics of floating-point throughput, memory bandwidth, VRAM capacity. We show how these hardware capabilities affect radiology tasks: for example, generating reports or detecting findings on CheXpert and MIMIC-CXR images is computationally intensive and benefits from GPU parallelism and tensor-core acceleration. Empirical studies indicate that using appropriate GPU resources can reduce inference time and improve throughput. We discuss practical challenges including privacy, deployment, cost, power and optimization strategies: mixed-precision, quantization, compression, and multi-GPU scaling. Finally, we anticipate that next-generation features (8-bit tensor cores, enhanced interconnect) will further enable on-premise and federated radiology AI. Advancing GPU infrastructure is essential for safe, efficient LLM-based radiology diagnostics.
[12]
arXiv:2509.16385
[pdf, html, other]
Title:
Parameter variability can produce heavy tails in a model for the spatial distribution of settling organisms
Luis F. Gordillo, Priscilla E. Greenwood
Subjects:
Populations and Evolution (q-bio.PE); Applications (stat.AP)
We show that a simple mechanistic model of spatial dispersal for settling organisms, subject to parameter variability, can generate heavy-tailed radial probability density functions. The movement of organisms in the model consists of a two-dimensional diffusion that ceases after a random time, where the parameters that characterize each of these stages have been randomized. Our findings show that these minimal assumptions can yield heavy-tailed dispersal patterns, providing a simplified framework that increases the understanding of long-distance dispersal events in movement ecology.
[13]
arXiv:2509.16405
[pdf, html, other]
Title:
Ordered Leaf Attachment (OLA) Vectors can Identify Reticulation Events even in Multifurcated Trees
Alexey Markin, Tavis K. Anderson
Comments:
18 pages, 4 figures
Subjects:
Populations and Evolution (q-bio.PE); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)
Recently, a new vector encoding, Ordered Leaf Attachment (OLA), was introduced that represents $n$-leaf phylogenetic trees as $n-1$ length integer vectors by recording the placement location of each leaf. Both encoding and decoding of trees run in linear time and depend on a fixed ordering of the leaves. Here, we investigate the connection between OLA vectors and the maximum acyclic agreement forest (MAAF) problem. A MAAF represents an optimal breakdown of $k$ trees into reticulation-free subtrees, with the roots of these subtrees representing reticulation events. We introduce a corrected OLA distance index over OLA vectors of $k$ trees, which is easily computable in linear time. We prove that the corrected OLA distance corresponds to the size of a MAAF, given an optimal leaf ordering that minimizes that distance. Additionally, a MAAF can be easily reconstructed from optimal OLA vectors. We expand these results to multifurcated trees: we introduce an $O(kn \cdot m\log m)$ algorithm that optimally resolves a set of multifurcated trees given a leaf-ordering, where $m$ is the size of a largest multifurcation, and show that trees resolved via this algorithm also minimize the size of a MAAF. These results suggest a new approach to fast computation of phylogenetic networks and identification of reticulation events via random permutations of leaves. Additionally, in the case of microbial evolution, a natural ordering of leaves is often given by the sample collection date, which means that under mild assumptions, reticulation events can be identified in polynomial time on such datasets.
[14]
arXiv:2509.16486
[pdf, html, other]
Title:
Comment on "mbtransfer: Microbiome intervention analysis using transfer functions and mirror statistics": Implementation errors, theoretical misapplication, and methodological flaws
Travis E. Gibson
Comments:
10 pages, 2 figures. Comment on arXiv:2306.06364, with the published version in PLOS Computational Biology as doi:https://doi.org/10.1371/journal.pcbi.1012196
Subjects:
Quantitative Methods (q-bio.QM)
There are a number of errors in "mbtransfer: Microbiome intervention analysis using transfer functions and mirror statistics" PLOS Comp Bio (2024) spanning multiple aspects of the paper. The wrong inputs were provided to comparator methods for model training, when forecasting one method was provided initial conditions in the wrong units, and performance metrics were calculated without proper unit conversion. The false discovery rate and power analysis conclusions provided in the text are not supported by theory or the empirical testing that was performed within the paper. The paper also has data leakage issues, equations are written down incorrectly, and incorrect definitions/terminology are used.
[15]
arXiv:2509.16571
[pdf, other]
Title:
Enhancing Antimicrobial Molecule Prediction via Dynamic Routing Capsule Networks and Multi-Source Molecular Embeddings
R. He
Subjects:
Quantitative Methods (q-bio.QM)
Antibiotics are a vital class of drugs closely associated with the prevention and treatment of bacterial infections. Accurate prediction of molecular antimicrobial activity remains a key challenge in the pursuit of novel antibiotic candidates. However, laboratory-based antimicrobial compounds identification is costly, time-consuming, and prone to rediscovering known antibiotics, highlighting the urgent need for efficient and accurate computational models. Recent advances in machine learning (ML) and deep learning (DL) have significantly enhanced the ability to explore chemical space and identify potential antimicrobial compounds. In this study, we particularly emphasize deep learning models and employ five chemistry language models tailored for chemical data to encode small molecules. Our model incorporates a unique capsule network architecture and introduces innovations in loss function selection and feature processing modules, demonstrating superior performance in predicting inhibitory activities against Escherichia coli and Acinetobacter baumannii. We conducted a series of ablation studies to elucidate the contributions of network design and input features. Case studies validated the usability and effectiveness of our this http URL facilitate accessibility, we developed an intuitive web portal to disseminate this novel tool. Our results indicate that the proposed approach offers improved predictive accuracy and enhanced interpretability, underscoring the potential of interpretable artificial intelligence methods in accelerating antibiotic discovery and addressing the urgent challenge of antimicrobial resistance.
[16]
arXiv:2509.16661
[pdf, other]
Title:
Cycling and tensed cells interpenetrated by non-cycling and compressed cells form a critical epithelial reticulum
Liav Daraf, Yael Lavi, Areej Saleem, Daniel Sevilla Sanchez, Yuri Feldman, Lior Atia
Comments:
Supplementary video links are available on the video description pages
Subjects:
Cell Behavior (q-bio.CB); Soft Condensed Matter (cond-mat.soft); Adaptation and Self-Organizing Systems (nlin.AO); Biological Physics (physics.bio-ph); Tissues and Organs (q-bio.TO)
With the completion of development and wound repair, as the epithelium approaches homeostasis, cell proliferation is reduced to a minimum. In parallel, cellular motion transitions from a migratory unjammed state to a quiescent jammed state. This quiescent state is commonly regarded as devoid of large-scale regional variations in cell-cycle re-entry and cellular mechanics. To the contrary, here we report that during late maturation there arises a heretofore unanticipated epithelial reticulum that is supracellular and spans multiple scales of length. This reticulum evolves dynamically and comprises two interpenetrating networks: large regions of cycling and mechanically tensed cells, embedded with islands of non-cycling and mechanically compressed cells. The islands of compressed cells emerge and grow in cell numbers, with gradual jamming and with reduced cellular rearrangements. We show how island growth is both reversible, by provoking unjamming, and detainable, by cell cycle arrest treatment. Moreover, the distribution of island sizes was found to conform to a power-law, thus leading us to employ a computational model of percolating critical networks. Together, the observations indicate that the newly discovered epithelial reticulum self-organizes close to but just shy of criticality - thus avoiding mergers of compressed cell islands. This quasi-criticality reframes epithelial homeostasis as a dynamic regional balance of forces and proliferation.
[17]
arXiv:2509.16687
[pdf, html, other]
Title:
Modeling the Effects of Over and Under Doses Antibiotic Treatment to Bacterial Resistance in Presence of Immune System
Uzzwal Kumar Mallick, Jobayer Ahmed, Khan Anik Islam, Pulak Kundu
Subjects:
Populations and Evolution (q-bio.PE)
Antibiotic resistance presents a growing global health threat by diminishing the effectiveness of treatments and allowing once-manageable bacterial infections to persist. This study develops and analyzes an optimization-based mathematical model to investigate the impact of varying antibiotic dosages on bacterial resistance, incorporating the role of the immune system. Additionally, to capture the effects of over and underdosing, a floor function is newly introduced into the model as a switch function. The model is examined both analytically and numerically. As part of the analytical solution, the validity of the model through the existence and uniqueness theorem, stability at the equilibrium points, and characteristics of equilibrium points in relation to state variables have been investigated. Numerical simulations, performed using the Runge Kutta 4th order method, reveal that while antibiotics effectively reduce sensitive bacteria, they simultaneously increase resistant strains and suppress immune cell levels. The results also demonstrate that underdosing antibiotics increases the risk of resistance through bacterial mutation, while overdosing weakens the immune system by disrupting beneficial microbes. These findings emphasize that improper dosing whether below or above the prescribed level can accelerate the development of antibiotic resistance, underscoring the need for carefully regulated treatment strategies that preserve both antimicrobial effectiveness and immune system integrity.
[18]
arXiv:2509.16877
[pdf, html, other]
Title:
A review of topological data analysis and topological deep learning in molecular sciences
JunJie Wee, Jian Jiang
Subjects:
Biomolecules (q-bio.BM)
Topological Data Analysis (TDA) has emerged as a powerful framework for extracting robust, multiscale, and interpretable features from complex molecular data for artificial intelligence (AI) modeling and topological deep learning (TDL). This review provides a comprehensive overview of the development, methodologies, and applications of TDA in molecular sciences. We trace the evolution of TDA from early qualitative tools to advanced quantitative and predictive models, highlighting innovations such as persistent homology, persistent Laplacians, and topological machine learning. The paper explores TDA's transformative impact across diverse domains, including biomolecular stability, protein-ligand interactions, drug discovery, materials science, and viral evolution. Special attention is given to recent advances in integrating TDA with machine learning and AI, enabling breakthroughs in protein engineering, solubility and toxicity prediction, and the discovery of novel materials and therapeutics. We also discuss the limitations of current TDA approaches and outline future directions, including the integration of TDA with advanced AI models and the development of new topological invariants. This review aims to serve as a foundational reference for researchers seeking to harness the power of topology in molecular science.
[19]
arXiv:2509.16908
[pdf, html, other]
Title:
Discrete Heat Kernels on Simplicial Complexes and Its Application to Functional Brain Networks
Sixtus Dakurah
Subjects:
Quantitative Methods (q-bio.QM); Neurons and Cognition (q-bio.NC)
Networks constitute fundamental organizational structures across biological systems, although conventional graph-theoretic analyses capture exclusively pairwise interactions, thereby omitting the intricate higher-order relationships that characterize network complexity. This work proposes a unified framework for heat kernel smoothing on simplicial complexes, extending classical signal processing methodologies from vertices and edges to cycles and higher-dimensional structures. Through Hodge Laplacian, a discrete heat kernel on a finite simplicial complex $\mathcal{K}$ is constructed to smooth signals on $k$-simplices via the boundary operator $\partial_k$. Computationally efficient sparse algorithms for constructing boundary operators are developed to implement linear diffusion processes on $k$-simplices. The methodology generalizes heat kernel smoothing to $k$-simplices, utilizing boundary structure to localize topological features while maintaining homological invariance. Simulation studies demonstrate qualitative signal enhancement across vertex and edge domains following diffusion processes. Application to parcellated human brain functional connectivity networks reveals that simplex-space smoothing attenuates spurious connections while amplifying coherent anatomical architectures, establishing practical significance for computational neuroscience applications.
[20]
arXiv:2509.16973
[pdf, html, other]
Title:
Deep Learning Inductive Biases for fMRI Time Series Classification during Resting-state and Movie-watching
Behdad Khodabandehloo, Reza Rajimehr
Subjects:
Neurons and Cognition (q-bio.NC); Machine Learning (cs.LG)
Deep learning has advanced fMRI analysis, yet it remains unclear which architectural inductive biases are most effective at capturing functional patterns in human brain activity. This issue is particularly important in small-sample settings, as most datasets fall into this category. We compare models with three major inductive biases in deep learning including convolutional neural networks (CNNs), long short-term memory networks (LSTMs), and Transformers for the task of biological sex classification. These models are evaluated within a unified pipeline using parcellated multivariate fMRI time series from the Human Connectome Project (HCP) 7-Tesla cohort, which includes four resting-state runs and four movie-watching task runs. We assess performance on Whole-brain, subcortex, and 12 functional networks. CNNs consistently achieved the highest discrimination for sex classification in both resting-state and movie-watching, while LSTM and Transformer models underperformed. Network-resolved analyses indicated that the Whole-brain, Default Mode, Cingulo-Opercular, Dorsal Attention, and Frontoparietal networks were the most discriminative. These results were largely similar between resting-state and movie-watching. Our findings indicate that, at this dataset size, discriminative information is carried by local spatial patterns and inter-regional dependencies, favoring convolutional inductive bias. Our study provides insights for selecting deep learning architectures for fMRI time series classification.
[21]
arXiv:2509.17138
[pdf, html, other]
Title:
Analyzing Memory Effects in Large Language Models through the lens of Cognitive Psychology
Zhaoyang Cao, Lael Schooler, Reza Zafarani
Subjects:
Neurons and Cognition (q-bio.NC)
Memory, a fundamental component of human cognition, exhibits adaptive yet fallible characteristics as illustrated by Schacter's memory "sins".These cognitive phenomena have been studied extensively in psychology and neuroscience, but the extent to which artificial systems, specifically Large Language Models (LLMs), emulate these cognitive phenomena remains underexplored. This study uses human memory research as a lens for understanding LLMs and systematically investigates human memory effects in state-of-the-art LLMs using paradigms drawn from psychological research. We evaluate seven key memory phenomena, comparing human behavior to LLM performance. Both people and models remember less when overloaded with information (list length effect) and remember better with repeated exposure (list strength effect). They also show similar difficulties when retrieving overlapping information, where storing too many similar facts leads to confusion (fan effect). Like humans, LLMs are susceptible to falsely "remembering" words that were never shown but are related to others (false memories), and they can apply prior learning to new, related situations (cross-domain generalization). However, LLMs differ in two key ways: they are less influenced by the order in which information is presented (positional bias) and more robust when processing random or meaningless material (nonsense effect). These results reveal both alignments and divergences in how LLMs and humans reconstruct memory. The findings help clarify how memory-like behavior in LLMs echoes core features of human cognition, while also highlighting the architectural differences that lead to distinct patterns of error and success.
[22]
arXiv:2509.17174
[pdf, html, other]
Title:
Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks
Kijung Yoon
Comments:
To appear in NeurIPS 2025
Subjects:
Neurons and Cognition (q-bio.NC); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
Inferring synaptic connectivity from neural population activity is a fundamental challenge in computational neuroscience, complicated by partial observability and mismatches between inference models and true circuit dynamics. In this study, we propose a graph-based neural inference model that simultaneously predicts neural activity and infers latent connectivity by modeling neurons as interacting nodes in a graph. The architecture features two distinct modules: one for learning structural connectivity and another for predicting future spiking activity via a graph neural network (GNN). Our model accommodates unobserved neurons through auxiliary nodes, allowing for inference in partially observed circuits. We evaluate this approach using synthetic data from ring attractor networks and real spike recordings from head direction cells in mice. Across a wide range of conditions, including varying recurrent connectivity, external inputs, and incomplete observations, our model consistently outperforms standard baselines, resolving spurious correlations more effectively and recovering accurate weight profiles. When applied to real data, the inferred connectivity aligns with theoretical predictions of continuous attractor models. These results highlight the potential of GNN-based models to infer latent neural circuitry through self-supervised structure learning, while leveraging the spike prediction task to flexibly link connectivity and dynamics across both simulated and biological neural systems.
[23]
arXiv:2509.17224
[pdf, html, other]
Title:
AI-based Methods for Simulating, Sampling, and Predicting Protein Ensembles
Bowen Jing, Bonnie Berger, Tommi Jaakkola
Subjects:
Biomolecules (q-bio.BM); Machine Learning (cs.LG); Biological Physics (physics.bio-ph)
Advances in deep learning have opened an era of abundant and accurate predicted protein structures; however, similar progress in protein ensembles has remained elusive. This review highlights several recent research directions towards AI-based predictions of protein ensembles, including coarse-grained force fields, generative models, multiple sequence alignment perturbation methods, and modeling of ensemble descriptors. An emphasis is placed on realistic assessments of the technological maturity of current methods, the strengths and weaknesses of broad families of techniques, and promising machine learning frameworks at an early stage of development. We advocate for "closing the loop" between model training, simulation, and inference to overcome challenges in training data availability and to enable the next generation of models.
[24]
arXiv:2509.17260
[pdf, other]
Title:
A tutorial on electrogastrography using low-cost hardware and open-source software
Evgeniya Anisimova, Sameer N.B. Alladin, Styliani Tsamaz, Edwin S. Dalmaijer
Subjects:
Neurons and Cognition (q-bio.NC)
Electrogastrography is the recording of changes in electric potential caused by the stomach's pacemaker region, typically through several cutaneous sensors placed on the abdomen. It is a worthwhile technique in medical and psychological research, but also relatively niche. Here we present a tutorial on the acquisition and analysis of the human electrogastrogram. Because dedicated equipment and software can be prohibitively expensive, we demonstrate how data can be acquired using a low-cost OpenBCI Ganglion amplifier. We also present a processing pipeline that minimises attrition, which is particularly helpful for low-cost equipment but also applicable to top-of-the-line hardware. Our approach comprises outlier rejection, frequency filtering, movement filtering, and noise reduction using independent component analysis. Where traditional approaches include a subjective step in which only one channel is manually selected for further analysis, our pipeline recomposes the electrogastrogram from all recorded channels after automatic rejection of nuisance components. The main benefits of this approach are reduced attrition, retention of data from all recorded channels, and reduced influence of researcher bias. In addition to our tutorial on the method, we offer a proof-of-principle in which our approach leads to reduced data rejection compared to established methods. We aimed to describe each step in sufficient detail to be implemented in any programming language. In addition, we made an open-source Python package freely available for ease of use.
[25]
arXiv:2509.17280
[pdf, other]
Title:
From Prediction to Understanding: Will AI Foundation Models Transform Brain Science?
Thomas Serre, Ellie Pavlick
Subjects:
Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI)
Generative pretraining (the "GPT" in ChatGPT) enables language models to learn from vast amounts of internet text without human supervision. This approach has driven breakthroughs across AI by allowing deep neural networks to learn from massive, unstructured datasets. We use the term foundation models to refer to large pretrained systems that can be adapted to a wide range of tasks within and across domains, and these models are increasingly applied beyond language to the brain sciences. These models achieve strong predictive accuracy, raising hopes that they might illuminate computational principles. But predictive success alone does not guarantee scientific understanding. Here, we outline how foundation models can be productively integrated into the brain sciences, highlighting both their promise and their limitations. The central challenge is to move from prediction to explanation: linking model computations to mechanisms underlying neural activity and cognition.
[26]
arXiv:2509.17448
[pdf, other]
Title:
Monitoring Nitric Oxide in Trigeminal Neuralgia Rats with a Cerium Single-Atom Nanozyme Electrochemical Biosensor
Kangling Tian, Fuhua Li, Ran Chen, Shihong Chen, Wenbin Wei, Yihang Shen, Muzi Xu, Chunxian Guo, Luigi G. Occhipinti, Hong Bin Yang, Fangxin Hu
Subjects:
Biomolecules (q-bio.BM); Materials Science (cond-mat.mtrl-sci); Medical Physics (physics.med-ph)
Trigeminal neuralgia (TN) is the most common neuropathic disorder; however, its pathogenesis remains unclear. A prevailing theory suggests that nitric oxide (NO) may induce nerve compression and irritation via vascular dilation, thereby being responsible for the condition, making real-time detection of generated NO critical. However, traditional evaluations of NO rely on indirect colorimetric or chemiluminescence techniques, which offer limited sensitivity and spatial resolution for its real-time assessment in biological environments. Herein, we reported the development of a highly sensitive NO electrochemical biosensor based cerium single-atom nanozyme (Ce1-CN) with ultrawide linear range from 1.08 nM to 143.9 {\mu}M, and ultralow detection limit of 0.36 nM, which enables efficient and real-time evaluation of NO in TN rats. In-situ attenuated total reflection surface-enhanced infrared spectroscopy combined with density functional theory calculations revealed the high-performance biosensing mechanism, whereby the Ce centers in Ce1-CN nanoenzymes adsorb NO and subsequently react with OH- to form *HNO2. Results demonstrated that NO concentration was associated with TN onset. Following carbamazepine treatment, NO production from nerves decreased, accompanied by an alleviation of pain. These findings indicate that the biosensor serves as a valuable tool for investigating the pathogenesis of TN and guiding subsequent therapeutic strategies.
[27]
arXiv:2509.17594
[pdf, html, other]
Title:
A Sensitivity Analysis Methodology For Rule-Based Stochastic Chemical Systems
Erika M. Herrera Machado, Jakob L. Andersen, Rolf Fagerberg, Daniel Merkle
Subjects:
Quantitative Methods (q-bio.QM); Molecular Networks (q-bio.MN)
In this study, we introduce a sensitivity analysis methodology for stochastic systems in chemistry, where dynamics are often governed by random processes. Our approach is based on gradient estimation via finite differences, averaging simulation outcomes, and analyzing variability under intrinsic noise. We characterize gradient uncertainty as an angular range within which all plausible gradient directions are expected to lie. This uncertainty measure adaptively guides the number of simulations performed for each nominal-perturbation pair of points in order to minimize unnecessary computations while maintaining robustness.
Systematically exploring a range of parameter values across the parameter space, rather than focusing on a single value, allows us to identify not only sensitive parameters but also regions of parameter space associated with different levels of sensitivity. These results are visualized through vector field plots to offer an intuitive representation of local sensitivity across parameter space. Additionally, global sensitivity coefficients are computed to capture overall trends.
Flexibility regarding the choice of output observable measures is another key feature of our method: while traditional sensitivity analyses often focus on species concentrations, our framework allows for the definition of a large range of problem-specific observables. This makes it broadly applicable in diverse chemical and biochemical scenarios. We demonstrate our approach on two systems: classical Michaelis-Menten kinetics and a rule-based model of the formose reaction, using the cheminformatics software MØD for Gillespie-based stochastic simulations.
[28]
arXiv:2509.17854
[pdf, other]
Title:
Magnetically Guided Endothelial BioBots: A Next-Generation Strategy for Treating Complex Cerebral Aneurysms
Duong Le (Department of Biomedical Engineering, University of Massachusetts Amherst, Amherst, MA)
Comments:
18 pages, 2 figures, 1 table. Review/Technical Report. Currently under journal peer review
Subjects:
Tissues and Organs (q-bio.TO)
Cerebral aneurysms affect three to five percent of the population, and rupture remains a major cause of stroke-related death and disability. Current therapies, surgical clipping, endovascular coiling, and flow diversion, have improved outcomes but each carries limitations. Clipping is invasive and often unsuitable for deep or posterior lesions. Coiling is prone to recurrence from compaction or incomplete occlusion, particularly in wide-neck or fusiform aneurysms. Flow diverters offer improved durability but rely on rigid metallic scaffolds that may malappose in tortuous vessels, compromise branch arteries, delay endothelialization, and necessitate long-term dual antiplatelet therapy. These shortcomings highlight a gap in current management: devices primarily provide mechanical occlusion but fail to conform to complex geometries or reliably promote rapid, complete endothelialization. As a result, aneurysm necks may remain exposed to persistent flow, delayed healing, and thrombosis.
To address this, we propose magnetically guided endothelial BioBots as a next-generation therapeutic strategy. BioBots are biodegradable hydrogel carriers embedded with magnetic nanoparticles and coated with primed endothelial progenitor cells. Delivered through microcatheters and guided by external electromagnetic fields, they can assemble across aneurysm defects. Once localized, they form a conformal, geometry-adaptive endothelial patch that provides immediate antithrombotic protection and, as the hydrogel degrades, leaves behind a stable, functional endothelial lining. By integrating microrobotic navigation with regenerative vascular biology, BioBots may overcome the central limitations of current devices and enable safer, more durable treatment for complex aneurysms.
[29]
arXiv:2509.17913
[pdf, html, other]
Title:
Effective decoupling of mutations and the resulting loss of biodiversity caused by environmental change
Ruixi Huang, David Waxman
Comments:
83 pages consisting of manuscript (31 pages) and SI (52 pages) in a single document
Subjects:
Populations and Evolution (q-bio.PE); Biological Physics (physics.bio-ph)
Many biological populations exhibit diversity in their strategy for survival and reproduction in a given environment, and microbes are an example. We explore the fate of different strategies under sustained environmental change by considering a mathematical model for a large population of asexual organisms. Fitness is a bimodal function of a quantitative trait, with two local optima, separated by a local minimum, i.e., a mixture of stabilising and disruptive selection. The optima represent two locally `best' trait values. We consider regimes where, when the environment is unchanging, the equilibrium distribution of the trait is bimodal. A bimodal trait distribution generally requires, for its existence, mutational coupling between the two peaks, and it indicates two coexisting clones with distinct survival and reproduction strategies. When subject to persistent environmental change, the population adapts by utilising mutations that allow it to track the changing environment. The faster the rate of change of the environment, the larger the effect of the mutations that are utilised. Under persistent environmental change, the distribution of trait values takes two different forms. At low rates of change, the distribution remains bimodal. At higher rates, the distribution becomes unimodal. This loss of a clone/biodiversity is driven by a novel mechanism where environmental change decouples a class of mutations.
[30]
arXiv:2509.18050
[pdf, other]
Title:
Why we need all the organisms: an exploration of the Monarch knowledge graph to aid mechanism discovery
Katherina Cortes, Daniel Korn, Sarah Gehrke, Kevin Schaper, Corey Cox, Patrick Golden, Aaron Odell, Bryan Laraway, Madan Krishnamurthy, Justin Reese, Harry Caufield, Sierra Moxon, Ellen Elias, Christopher J Mungall, Melissa Haendel
Subjects:
Quantitative Methods (q-bio.QM)
Research done using model organisms has been fundamental to the biological understanding of human genes, diseases and phenotypes. Model organisms provide tractable systems for experiments to enhance understanding of biological mechanisms conserved across the evolutionary tree. Decades of model organism research has generated vast amounts of data; however, this data is split across many domains, organisms, and biological fields of research. Knowledge graphs (KGs) are a computational way to aggregate and compile disparate information in a parsable format. By unifying data across studies, organisms and time points, KG researchers can create novel targeted hypotheses. Here we demonstrate how model organisms are connected to humans and other organisms through genes, diseases and phenotypes allowing for a broader understanding of genetic biology than just one organism alone can provide. Utilizing resources such as the Monarch KG is a great way to reduce redundant experiments and find directions previously unexplored.
[31]
arXiv:2509.18065
[pdf, html, other]
Title:
Mathematical modelling of nutrient-dependent biofilm growth on medical implants
Parna Mandal, Nigel J. Mottram, Sean McGinty
Subjects:
Populations and Evolution (q-bio.PE)
Biofilm infections on medical implants are difficult to eradicate because insufficient nutrient availability promotes antibiotic-tolerant persister cells that survive treatment and reseed growth. Existing mathematical models usually omit nutrient-dependent phenotypic switching between proliferative and persister states. Without this mechanism, models cannot capture how environmental conditions control the balance between active growth and dormancy, which is central to biofilm persistence. We present a continuum model that couples nutrient transport with the dynamics of proliferative bacteria, persisters, dead cells, and extracellular polymeric substances. The switching rates between proliferative and persister phenotypes depend on local nutrient concentration through two thresholds, enabling adaptation across nutrient-poor, intermediate, and nutrient-rich regimes. Simulations show that nutrient limitation produces a high and sustained proportion of persister cells even when biomass is reduced, whereas nutrient-rich conditions support reversion to proliferative growth and lead to greater biomass. The model also predicts that persister populations peak at times that vary with nutrient availability, and these peaks coincide with turning points in biofilm growth, identifying critical intervention windows. By directly linking nutrient availability to phenotypic switching, our model reveals mechanisms of biofilm persistence that earlier models could not capture, and it points toward strategies that target nutrient-driven adaptation as a means to improve the control of implant-associated infections.
Cross submissions (showing 9 of 9 entries)
[32]
arXiv:2509.16629
(cross-list from cs.LG)
[pdf, html, other]
Title:
Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features
Kaichen Xu, Yihang Du, Mianpeng Liu, Zimu Yu, Xiaobo Sun
Comments:
Accepted by NeurIPS 2025
Subjects:
Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
Positional encoding is essential for supplementing transformer with positional information of tokens. Existing positional encoding methods demand predefined token/feature order, rendering them unsuitable for real-world data with non-sequential yet causally-related features. To address this limitation, we propose CAPE, a novel method that identifies underlying causal structure over non-sequential features as a weighted directed acyclic graph (DAG) using generalized structural equation modeling. The DAG is then embedded in hyperbolic space where its geometric structure is well-preserved using a hyperboloid model-based approach that effectively captures two important causal graph properties (causal strength & causal specificity). This step yields causality-aware positional encodings for the features, which are converted into their rotary form for integrating with transformer's self-attention mechanism. Theoretical analysis reveals that CAPE-generated rotary positional encodings possess three valuable properties for enhanced self-attention, including causal distance-induced attenuation, causal generality-induced attenuation, and robustness to positional disturbances. We evaluate CAPE over both synthetic and real-word datasets, empirically demonstrating its theoretical properties and effectiveness in enhancing transformer for data with non-sequential features. Our code is available at this https URL.
[33]
arXiv:2509.16803
(cross-list from stat.AP)
[pdf, html, other]
Title:
Efficient Brain Network Estimation with Sparse ICA in Non-Human Primate Neuroimaging
Qiang Li, Liang Ma, Masoud Seraji, Shujian Yu, Yun Wang, Jingyu Liu, Vince D. Calhoun
Comments:
Submitted to ICASSP 2026
Subjects:
Applications (stat.AP); Neurons and Cognition (q-bio.NC)
Independent component analysis (ICA) is widely used to separate mixed signals and recover statistically independent components. However, in non-human primate neuroimaging studies, most ICA-recovered spatial maps are often dense. To extract the most relevant brain activation patterns, post-hoc thresholding is typically applied-though this approach is often imprecise and arbitrary. To address this limitation, we employed the Sparse ICA method, which enforces both sparsity and statistical independence, allowing it to extract the most relevant activation maps without requiring additional post-processing. Simulation experiments demonstrate that Sparse ICA performs competitively against 11 classical linear ICA methods. We further applied Sparse ICA to real non-human primate neuroimaging data, identifying several independent component networks spanning different brain networks. These spatial maps revealed clearly defined activation areas, providing further evidence that Sparse ICA is effective and reliable in practical applications.
[34]
arXiv:2509.16859
(cross-list from cs.AI)
[pdf, other]
Title:
The Principles of Human-like Conscious Machine
Fangfang Li, Xiaojie Zhang
Subjects:
Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)
Determining whether another system, biological or artificial, possesses phenomenal consciousness has long been a central challenge in consciousness studies. This attribution problem has become especially pressing with the rise of large language models and other advanced AI systems, where debates about "AI consciousness" implicitly rely on some criterion for deciding whether a given system is conscious. In this paper, we propose a substrate-independent, logically rigorous, and counterfeit-resistant sufficiency criterion for phenomenal consciousness. We argue that any machine satisfying this criterion should be regarded as conscious with at least the same level of confidence with which we attribute consciousness to other humans. Building on this criterion, we develop a formal framework and specify a set of operational principles that guide the design of systems capable of meeting the sufficiency condition. We further argue that machines engineered according to this framework can, in principle, realize phenomenal consciousness. As an initial validation, we show that humans themselves can be viewed as machines that satisfy this framework and its principles. If correct, this proposal carries significant implications for philosophy, cognitive science, and artificial intelligence. It offers an explanation for why certain qualia, such as the experience of red, are in principle irreducible to physical description, while simultaneously providing a general reinterpretation of human information processing. Moreover, it suggests a path toward a new paradigm of AI beyond current statistics-based approaches, potentially guiding the construction of genuinely human-like AI.
[35]
arXiv:2509.17147
(cross-list from nlin.AO)
[pdf, html, other]
Title:
A game played by tandem-running ants: Hint of procedural rationality
Joy Das Bairagya, Udipta Chakraborti, Sumana Annagiri, Sagar Chakraborty
Subjects:
Adaptation and Self-Organizing Systems (nlin.AO); Theoretical Economics (econ.TH); Biological Physics (physics.bio-ph); Populations and Evolution (q-bio.PE)
Navigation through narrow passages during colony relocation by the tandem-running ants, $\textit{Diacamma}$ $\textit{indicum}$, is a tour de force of biological traffic coordination. Even on one-lane paths, the ants tactfully manage a bidirectional flow: Informed individuals (termed leaders) guide nest-mates (termed followers) from a suboptimal nest to a new optimal nest, and then return to recruit additional followers. We propose that encounters between the ants moving in opposite directions can be modelled within the framework of game theory leading to an understanding of the mechanism behind observed behaviours. Our experiments reveal that, upon encountering a tandem pair (a leader and its follower) on a narrow path, the returning leader reverses her direction and proceeds toward the new nest again as if she becomes the leader guiding a follower. This observed behaviour is consistent with game-theoretic predictions, provided the assumption of perfect rationality is relaxed in favour of bounded rationality -- specifically, procedural rationality. In other words, the experimental outcomes are consistent with sampling equilibrium but not with Nash equilibrium. Our work, which strives to induct the essence of behavioural game theory into the world of ants, is first ever report of realizing sampling equilibrium in scenarios not involving human players.
[36]
arXiv:2509.17305
(cross-list from cs.CE)
[pdf, html, other]
Title:
Rational Multi-Modal Transformers for TCR-pMHC Prediction
Jiarui Li, Zixiang Yin, Zhengming Ding, Samuel J. Landry, Ramgopal R. Mettu
Comments:
The 16th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB 2025)
Subjects:
Computational Engineering, Finance, and Science (cs.CE); Quantitative Methods (q-bio.QM)
T cell receptor (TCR) recognition of peptide-MHC (pMHC) complexes is fundamental to adaptive immunity and central to the development of T cell-based immunotherapies. While transformer-based models have shown promise in predicting TCR-pMHC interactions, most lack a systematic and explainable approach to architecture design. We present an approach that uses a new post-hoc explainability method to inform the construction of a novel encoder-decoder transformer model. By identifying the most informative combinations of TCR and epitope sequence inputs, we optimize cross-attention strategies, incorporate auxiliary training objectives, and introduce a novel early-stopping criterion based on explanation quality. Our framework achieves state-of-the-art predictive performance while simultaneously improving explainability, robustness, and generalization. This work establishes a principled, explanation-driven strategy for modeling TCR-pMHC binding and offers mechanistic insights into sequence-level binding behavior through the lens of deep learning.
[37]
arXiv:2509.17422
(cross-list from physics.bio-ph)
[pdf, html, other]
Title:
Adaptive mechanical proofreading toward faithful clonal selection
Qing Xu, Shenshen Wang
Comments:
13 pages, 7 figures
Subjects:
Biological Physics (physics.bio-ph); Cell Behavior (q-bio.CB); Populations and Evolution (q-bio.PE)
To ensure faithful information transmission, cells utilize nonequilibrium drives to reduce errors. Kinetic proofreading is a classic mechanism known to sharpen ligand discrimination by T lymphocytes. It remains an open question whether the adaptive immune system relies solely on kinetic proofreading to boost fidelity. Here, we suggest an alternative: an enhanced form of mechanical proofreading (MPR) in which adaptive force exertion via dynamic cell-cell contact allows faithful selection of high-affinity B lymphocytes. Using a minimal model validated with experiment, we show that adaptive MPR, characterized by mechanical feedback between force generation and contact formation, enables robust discrimination of receptor quality regardless of ligand quantity. Although MPR generically balances the tradeoffs between speed and fidelity, a negative scaling of contact duration with ligand abundance indicates the presence of feedback. Due to its ability to modulate interactions of distinct ligands that share load at membrane contacts, adaptive MPR can be harnessed to mitigate autoimmunity or enhance multivalent vaccines. Overall, this work suggests a generalization of the proofreading mechanism to encompass cellular designs that act across scales to enable competing functionalities.
[38]
arXiv:2509.17891
(cross-list from physics.med-ph)
[pdf, other]
Title:
Quantitative and Computational Radiobiology for Precision Radiopharmaceutical Therapies
Tahir Yusufaly, Hamid Abdollahi, Babak Saboury, Arman Rahmim
Subjects:
Medical Physics (physics.med-ph); Quantitative Methods (q-bio.QM)
This article reviews the evolving field of radiobiology, emphasizing the need for advanced multiscale, mechanistic models to optimize radiopharmaceutical therapies (RPT). While the traditional linear-quadratic (LQ) model underpins external beam radiation therapy (EBRT), RPT's unique biological and spatial complexities demand new approaches. First-principles simulations of DNA damage, repair, and multicellular responses are crucial for understanding therapeutic efficacy and toxicity. The integration of these models into personalized, digital twin frameworks promises transformative clinical applications, but progress depends on deep mechanistic insights, experimental validation, and balancing model complexity with practicality for clinical use.
[39]
arXiv:2509.17924
(cross-list from cs.LG)
[pdf, html, other]
Title:
Medical priority fusion: achieving dual optimization of sensitivity and interpretability in nipt anomaly detection
Xiuqi Ge, Zhibo Yao, Yaosong Du
Comments:
24 pages, 47 figures, publish to BIBM
Subjects:
Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)
Clinical machine learning faces a critical dilemma in high-stakes medical applications: algorithms achieving optimal diagnostic performance typically sacrifice the interpretability essential for physician decision-making, while interpretable methods compromise sensitivity in complex scenarios. This paradox becomes particularly acute in non-invasive prenatal testing (NIPT), where missed chromosomal abnormalities carry profound clinical consequences yet regulatory frameworks mandate explainable AI systems. We introduce Medical Priority Fusion (MPF), a constrained multi-objective optimization framework that resolves this fundamental trade-off by systematically integrating Naive Bayes probabilistic reasoning with Decision Tree rule-based logic through mathematically-principled weighted fusion under explicit medical constraints. Rigorous validation on 1,687 real-world NIPT samples characterized by extreme class imbalance (43.4:1 normal-to-abnormal ratio) employed stratified 5-fold cross-validation with comprehensive ablation studies and statistical hypothesis testing using McNemar's paired comparisons. MPF achieved simultaneous optimization of dual objectives: 89.3% sensitivity (95% CI: 83.9-94.7%) with 80% interpretability score, significantly outperforming individual algorithms (McNemar's test, p < 0.001). The optimal fusion configuration achieved Grade A clinical deployment criteria with large effect size (d = 1.24), establishing the first clinically-deployable solution that maintains both diagnostic accuracy and decision transparency essential for prenatal care. This work demonstrates that medical-constrained algorithm fusion can resolve the interpretability-performance trade-off, providing a mathematical framework for developing high-stakes medical decision support systems that meet both clinical efficacy and explainability requirements.
[40]
arXiv:2509.17948
(cross-list from physics.soc-ph)
[pdf, html, other]
Title:
Social influence on complex networks as a perturbation to individual behavior
Dhruv Mittal, Flávio L. Pinheiro, Vítor V. Vasconcelos
Subjects:
Physics and Society (physics.soc-ph); Populations and Evolution (q-bio.PE)
Cooperation is fundamental to the functioning of biological and social systems in both human and animal populations, with the structure of interactions playing a crucial role. Previous studies have used networks to describe interactions and explore the evolution of cooperation, but with limited transposability to social settings due to biologically relevant assumptions. Exogenous processes -- that affect the individual and are not derived from social interactions -- even if unbiased, have a role in supporting cooperation over defection, and this role has been largely overlooked in the context of network-based interactions. Here, we show that selection can favor either cooperation or defection depending on the frequency of exogenous, even if neutral, processes in any population structure. Our framework allows for deriving analytically the conditions for favoring a specific behavior in any network structure strongly affected by non-social environments (frequent exogenous forcing, FEF), which contrasts with previous computationally prohibitive methods. Our results demonstrate that the requirements for favoring cooperation under FEF do not match those in the rare-mutation limit, establishing that underlying neutral processes can be considered a mechanism for cooperation. We reveal that, under FEF, populations are less cooperative, and network heterogeneity can provide an advantage only if targeting specific network properties, clarifying seemingly contradictory experimental results and evolutionary predictions. While focused on cooperation, our assumptions generalize to any decision-making process involving a choice between alternative options. Our framework is particularly applicable to non-homogeneous human populations, offering a new perspective on cooperation science in the context of cultural evolution, where neutral and biased processes within structured interactions are abundant.
Replacement submissions (showing 15 of 15 entries)
[41]
arXiv:2501.03247
(replaced)
[pdf, html, other]
Title:
A sub-Riemannian model of neural states in the primary motor cortex
Caterina Mazzetti, Jawad Ali, Alessandro Sarti, Giovanna Citti
Subjects:
Neurons and Cognition (q-bio.NC)
We develop a neurogeometric model for the arm area of motor cortex, which encodes complex motor primitives, ranging from simple movement features like movement direction, to short hand trajectories, termed fragments, and ultimately to more complex patterns known as neural states (Georgopoulos, Hatsopoulos, Kadmon-Harpaz et al). Based on the sub-riemannian framework introduced in 2023, we model the space of fragments as a set of short curves defined by kinematic parameters. We then introduce a geometric kernel that serves as a model for cortical connectivity and use it in a differential equation to describe cortical activity. By applying a grouping algorithm to this cortical activity model, we successfully recover the neural states observed in Kadmon-Harpaz et al, which were based on measured cortical activity. This confirms that the choice of kinematic variables and the distance metric used here are sufficient to explain the phenomena of neural state formation. The modularity of our model reflects the brain's hierarchical structure, where initial groupings in the kinematic space $\mathcal{M}$ lead to more abstract representations. This approach mimics how the brain processes stimuli at different scales, extracting both local and global properties.
[42]
arXiv:2501.12069
(replaced)
[pdf, other]
Title:
Tikhonov-Fenichel Reductions and their Application to a Novel Modelling Approach for Mutualism
Johannes Apelt, Volkmar Liebscher
Comments:
55 pages, 8 figures, 2 tables
Journal-ref:
Theoretical Population Biology, Volume 166, December 2025, Pages 16-35
Subjects:
Populations and Evolution (q-bio.PE)
When formulating a model there is a trade-off between model complexity and (biological) realism. In the present paper we demonstrate how model reduction from a precise mechanistic "super model" to simpler conceptual models using Tikhonov--Fenichel reductions, an algebraic approach to singular perturbation theory, can mitigate this problem. Compared to traditional methods for time scale separations (Tikhonov's theorem, quasi-steady state assumption), Tikhonov--Fenichel reductions have the advantage that we can compute a reduction directly for a separation of rates into slow and fast ones instead of a separation of components of the system. Moreover, we can find all such eductions algorithmically. In this work we use Tikhonov--Fenichel reductions to analyse a mutualism model tailored towards lichens with an explicit description of the interaction. We find: (1) the implicit description of the interaction given in the reductions by interaction terms (functional responses) varies depending on the scenario, (2) there is a tendency for the Mycobiont, an obligate mutualist, to always benefit from the interaction while it can be detrimental for the photobiont, a facultative mutualist, depending on the parameters, (3) our model is capable of describing the shift from mutualism to parasitism, (4) via numerical analyis, that our model experiences bistability with multiple stable fixed points in the interior of the first orthant. To analyse the reductions we formalize and discuss a mathematical criterion that categorizes two-species interactions. Throughout the paper we focus on the relation between the mathematics behind Tikhonov--Fenichel reductions and their biological interpretation.
[43]
arXiv:2505.14429
(replaced)
[pdf, html, other]
Title:
Compositional amortized inference for large-scale hierarchical Bayesian models
Jonas Arruda, Vikas Pandey, Catherine Sherry, Margarida Barroso, Xavier Intes, Jan Hasenauer, Stefan T. Radev
Subjects:
Quantitative Methods (q-bio.QM)
Amortized Bayesian inference (ABI) has emerged as a powerful simulation-based approach for estimating complex mechanistic models, offering fast posterior sampling via generative neural networks. However, extending ABI to hierarchical models, a cornerstone of modern Bayesian analysis, remains a major challenge due to the need to simulate massive data sets and estimate thousands of parameters. In this work, we build on compositional score matching (CSM), a divide-and-conquer strategy for Bayesian updating using diffusion models. To address existing stability issues of CSM in dealing with large data sets, we couple adaptive solvers with a novel, error-damping compositional estimator. Our estimator remains stable even with hundreds of thousands of data points and parameters. We validate our approach on a controlled toy example, a high-dimensional autoregressive model, and a real-world advanced microscopy application involving over 750,000 parameters.
[44]
arXiv:2506.08599
(replaced)
[pdf, html, other]
Title:
Geometric Hyperscanning of Affect under Active Inference
Nicolas Hinrichs, Mahault Albarracin, Dimitris Bolis, Yuyue Jiang, Leonardo Christov-Moore, Leonhard Schilbach
Comments:
12 pages excl. references, 2 figures, and 2 appendixes. Accepted at the 6th International Workshop on Active Inference
Subjects:
Neurons and Cognition (q-bio.NC)
Second-person neuroscience holds social cognition as embodied meaning co-regulation through reciprocal interaction, modeled here as coupled active inference with affect emerging as inference over identity-relevant surprise. Each agent maintains a self-model that tracks violations in its predictive coherence while recursively modeling the other. Valence is computed from self-model prediction error, weighted by self-relevance, and modulated by prior affective states and by what we term temporal aiming, which captures affective appraisal over time. This accommodates shifts in the self-other boundary, allowing affect to emerge at individual and dyadic levels. We propose a novel method termed geometric hyperscanning, based on the Forman-Ricci curvature, to empirically operationalize these processes: it tracks topological reconfigurations in inter-brain networks, with its entro-py serving as a proxy for affective phase transitions such as rupture, co-regulation, and re-attunement.
[45]
arXiv:2506.12986
(replaced)
[pdf, html, other]
Title:
Improving spliced alignment by modeling splice sites with deep learning
Siying Yang, Neng Huang, Heng Li
Subjects:
Genomics (q-bio.GN)
Motivation: Spliced alignment refers to the alignment of messenger RNA (mRNA) or protein sequences to eukaryotic genomes. It plays a critical role in gene annotation and the study of gene functions. Accurate spliced alignment demands sophisticated modeling of splice sites, but current aligners use simple models, which may affect their accuracy given dissimilar sequences.
Results: We implemented minisplice to learn splice signals with a one-dimensional convolutional neural network (1D-CNN) and trained a model with 7,026 parameters for vertebrate and insect genomes. It captures conserved splice signals across phyla and reveals GC-rich introns specific to mammals and birds. We used this model to estimate the empirical splicing probability for every GT and AG in genomes, and modified minimap2 and miniprot to leverage pre-computed splicing probability during alignment. Evaluation on human long-read RNA-seq data and cross-species protein datasets showed our method greatly improves the junction accuracy especially for noisy long RNA-seq reads and proteins of distant homology.
Availability and implementation: this https URL
[46]
arXiv:2508.06835
(replaced)
[pdf, other]
Title:
Expand or better manage protected areas: a framework for minimizing extinction risk when threats are concentrated near edges
Brendan G Dillon, Hugh P Possingham, Matthew H Holden
Journal-ref:
Biological Conservation, 311, 111469 (2025)
Subjects:
Populations and Evolution (q-bio.PE)
Several international agreements have called for the rapid expansion of protected areas to halt biodiversity declines. However, recent research has shown that expanding protected areas may be less cost-effective than redirecting resources towards threat management in existing reserves. These findings often assume that threats are homogeneously distributed in the landscape. In some cases, threats are more concentrated near the edge of protected areas. As protected areas expand, core habitat in the centre expands more rapidly than its edge, potentially creating a refuge from threats. In this paper, we present a framework linking protected area expansion and threat management to extinction risk, via their impact on population carrying capacity and growth rate within core and edge habitats. We demonstrate the framework using a simple population model where individuals are uniformly distributed in a circular protected area threatened by poachers who penetrate the protected area to a fixed distance. We parameterise the model for Peter's Duiker (Cephalophus callipygus) harvested for food in the dense undergrowth of African forests using snares. Expanding protected areas can reduce extinction risk more effectively compared to an equivalent investment in snare removal for larger protected areas that already sustain core unhunted habitat. Our results demonstrate the importance of protected area expansion in buffering susceptible populations from fixed hunting pressure restricted to protected area edges. However, for cases where threats, wildlife, and managers respond to each other strategically in space, the relative importance of expansion versus increased management remains a significant open problem.
[47]
arXiv:2509.01426
(replaced)
[pdf, html, other]
Title:
DCA: Graph-Guided Deep Embedding Clustering for Brain Atlases
Mo Wang, Kaining Peng, Jingsheng Tang, Hongkai Wen, Quanying Liu
Comments:
Accepted as a poster at NeurIPS 2025 with scores 5554
Subjects:
Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
Brain atlases are essential for reducing the dimensionality of neuroimaging data and enabling interpretable analysis. However, most existing atlases are predefined, group-level templates with limited flexibility and resolution. We present Deep Cluster Atlas (DCA), a graph-guided deep embedding clustering framework for generating individualized, voxel-wise brain parcellations. DCA combines a pretrained autoencoder with spatially regularized deep clustering to produce functionally coherent and spatially contiguous regions. Our method supports flexible control over resolution and anatomical scope, and generalizes to arbitrary brain structures. We further introduce a standardized benchmarking platform for atlas evaluation, using multiple large-scale fMRI datasets. Across multiple datasets and scales, DCA outperforms state-of-the-art atlases, improving functional homogeneity by 98.8% and silhouette coefficient by 29%, and achieves superior performance in downstream tasks such as autism diagnosis and cognitive decoding. We also observe that a fine-tuned pretrained model achieves superior results on the corresponding task. Codes and models are available at this https URL .
[48]
arXiv:2509.06991
(replaced)
[pdf, html, other]
Title:
Towards deep-learning based detection and quantification of intestinal metaplasia on digitized gastric biopsies: a multi-expert comparative study
Fabian Cano, Mauricio Caviedes, Andres Siabatto, Jesus Villarreal, Jose Quijano, Álvaro Bedoya-Urresta, Marino Coral Bedoya, Yomaira Yepez Caicedo, Angel Cruz-Roa, Fabio A. González, Satish E. Viswanath, Eduardo Romero
Comments:
15 pages, 6 figures
Subjects:
Tissues and Organs (q-bio.TO); Computational Engineering, Finance, and Science (cs.CE)
Current gastric cancer (GCa) risk systems are prone to errors since they evaluate a visual estimation of intestinal metaplasia percentages in histopathology images of gastric mucosa to assign a risk. This study presents an automated method to detect and quantify intestinal metaplasia using deep convolutional neural networks as well as a comparative analysis with visual estimations of three experienced pathologists. Gastric samples were collected from two different cohorts: 149 asymptomatic volunteers from a region with a high prevalence of GCa in Colombia and 56 patients from a tertiary hospital. Deep learning models were trained to classify intestinal metaplasia, and predictions were used to estimate the percentage of intestinal metaplasia and assign the OLGIM risk score. Results were compared with independent blinded metaplastic assessments performed by three experienced pathologists. The best-performing deep learning architecture classified intestinal metaplasia with F1-Score of 0.80 +- 0.01 and AUC of 0.91 +- 0.01. Among pathologists, inter-observer agreement by a Fleiss's Kappa score ranged from 0.20 to 0.48. In comparison, agreement between the pathologists and the best-performing model ranged from 0.12 to 0.35. Deep learning models show potential to reliably detect and quantify the percentage of intestinal metaplasia, achieving high classification performance. Visual estimation of intestinal metaplasia remains highly dependent on individual expertise, resulting in inter-observer variability. Deep learning models provide consistent estimates that could help reduce this subjectivity in risk stratification.
[49]
arXiv:2509.10554
(replaced)
[pdf, html, other]
Title:
MAE-SAM2: Mask Autoencoder-Enhanced SAM2 for Clinical Retinal Vascular Leakage Segmentation
Xin Xing, Irmak Karaca, Samira Badrloo, Quan Dong Nguyen, Mahadevan Subramaniam
Subjects:
Tissues and Organs (q-bio.TO); Image and Video Processing (eess.IV)
We propose MAE-SAM2, a novel foundation model for retinal vascular leakage segmentation on fluorescein angiography images. Due to the small size and dense distribution of the leakage areas, along with the limited availability of labeled clinical data, this presents a significant challenge for segmentation tasks. Our approach integrates a Self-Supervised learning (SSL) strategy, Masked Autoencoder (MAE), with SAM2. In our implementation, we explore different loss functions and conclude a task-specific combined loss. Extensive experiments and ablation studies demonstrate that MAE-SAM2 outperforms several state-of-the-art models, achieving the highest Dice score and Intersection-over-Union (IoU). Compared to the original SAM2, our model achieves a $5\%$ performance improvement, highlighting the promise of foundation models with self-supervised pretraining in clinical imaging tasks.
[50]
arXiv:2008.08983
(replaced)
[pdf, other]
Title:
Randomness in appendage coordination facilitates strenuous ground self-righting
Qihan Xuan, Chen Li
Journal-ref:
Bioinspiration & Biomimetics, 15 (6), 65004 (2020)
Subjects:
Biological Physics (physics.bio-ph); Systems and Control (eess.SY); Quantitative Methods (q-bio.QM)
Randomness is common in biological and artificial systems, resulting either from stochasticity of the environment or noise in organisms or devices themselves. In locomotor control, randomness is typically considered a nuisance. For example, during dynamic walking, randomness in stochastic terrain leads to metastable dynamics, which must be mitigated to stabilize the system around limit cycles. Here, we studied whether randomness in motion is beneficial for strenuous locomotor tasks. Our study used robotic simulation modeling of strenuous, leg-assisted, winged ground self-righting observed in cockroaches, in which unusually large randomness in wing and leg motions is present. We developed a simplified simulation robot capable of generating similar self-righting behavior and varied the randomness level in wing-leg coordination. During each wing opening attempt, the more randomness added to the time delay between wing opening and leg swinging, the more likely it was for the naive robot (which did not know what coordination is best) to self-right within a finite time. Wing-leg coordination, measured by the phase between wing and leg oscillations, had a crucial impact on self-righting outcome. Without randomness, periodic wing and leg oscillations often limited the system to visit a few bad phases, leading to failure to escape from the metastable state. With randomness, the system explored phases thoroughly and had a better chance of encountering good phases to self-right. Our study complements previous work by demonstrating that randomness helps destabilize locomotor systems from being trapped in undesired metastable states, a situation common in strenuous locomotion.
[51]
arXiv:2401.08064
(replaced)
[pdf, other]
Title:
A mechanistic model of trust based on neural information processing
Scott E. Allen, René F. Kizilcec, A. David Redish
Subjects:
General Economics (econ.GN); Human-Computer Interaction (cs.HC); Neurons and Cognition (q-bio.NC)
Trust is central to human social interactions, manifesting in actions that make one vulnerable to another. We argue that trust will thus depend on the decision-making processes that arise in neural systems. Building on advances in the cognitive neuroscience of decision making, we propose a mechanistic model of trust arising from multiple parallel systems that perform distinct, complementary information processing. Because each system learns via different mechanisms, trust can be created (or destroyed) in multiple ways. This systems-level taxonomy of information representations provides a principled basis for differentiating forms of trust, linking them to specific learning processes, and generating testable predictions about their expression in behavior. By situating trust within a broader theory of neural decision systems, our account unifies diverse findings across psychology, neuroscience, and the social sciences, and offers a foundation for explaining how humans develop, maintain, and repair trust in a complex social world.
[52]
arXiv:2503.09076
(replaced)
[pdf, html, other]
Title:
Bounding the SNPR distance between two tree-child networks using generalised agreement forests
Steven Kelk, Simone Linz, Charles Semple
Journal-ref:
The Electronic Journal of Combinatorics, 32, P3.46, 2025
Subjects:
Combinatorics (math.CO); Populations and Evolution (q-bio.PE)
Agreement forests continue to play a central role in the comparison of phylogenetic trees since their introduction more than 25 years ago. More specifically, they are used to characterise several distances that are based on tree rearrangement operations and related quantifiers of dissimilarity between phylogenetic trees. In addition, the concept of agreement forests continues to underlie most advancements in the development of algorithms that exactly compute the aforementioned measures. In this paper, we introduce agreement digraphs, a concept that generalises agreement forests for two phylogenetic trees to two phylogenetic networks. Analogous to the way in which agreement forests compute the subtree prune and regraft distance between two phylogenetic trees but inherently more complex, we then use agreement digraphs to bound the subnet prune and regraft distance between two tree-child networks from above and below and show that our bounds are tight.
[53]
arXiv:2504.03699
(replaced)
[pdf, html, other]
Title:
Enhancing Clinical Decision-Making: Integrating Multi-Agent Systems with Ethical AI Governance
Ying-Jung Chen, Ahmad Albarqawi, Chi-Sheng Chen
Subjects:
Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Quantitative Methods (q-bio.QM)
Recent advances in the data-driven medicine approach, which integrates ethically managed and explainable artificial intelligence into clinical decision support systems (CDSS), are critical to ensure reliable and effective patient care. This paper focuses on comparing novel agent system designs that use modular agents to analyze laboratory results, vital signs, and clinical context, and to predict and validate results. We implement our agent system with the eICU database, including running lab analysis, vitals-only interpreters, and contextual reasoners agents first, then sharing the memory into the integration agent, prediction agent, transparency agent, and a validation agent. Our results suggest that the multi-agent system (MAS) performed better than the single-agent system (SAS) with mortality prediction accuracy (59\%, 56\%) and the mean error for length of stay (LOS)(4.37 days, 5.82 days), respectively. However, the transparency score for the SAS (86.21) is slightly better than the transparency score for MAS (85.5). Finally, this study suggests that our agent-based framework not only improves process transparency and prediction accuracy but also strengthens trustworthy AI-assisted decision support in an intensive care setting.
[54]
arXiv:2505.09584
(replaced)
[pdf, html, other]
Title:
Tropical Fermat-Weber Points over Spaces of $M$-Ultrametrics
Shelby Cox, John Sabol, Roan Talbut, Ruriko Yoshida
Subjects:
Combinatorics (math.CO); Populations and Evolution (q-bio.PE)
We extend reconstruction methods for phylogenetic trees to ultrametrics of arbitrary matroids and study the stability of these data analysis methods in the combinatorial spirit of Andreas Dress. In particular, we generalize Atteson's work on the safety radius of phylogenetic reconstruction methods, as well as Gascuel and Steel's work on the stochastic safety radius, to arbitrary matroids. We also show that although the tropical Fermat-Weber points of an $M$-ultrametric sample are generally not contained in the space of $M$-ultrametrics, the intersection between the Fermat-Weber set and the space of $M$-ultrametrics is non-empty.
[55]
arXiv:2505.19144
(replaced)
[pdf, html, other]
Title:
DPASyn: Mechanism-Aware Drug Synergy Prediction via Dual Attention and Precision-Aware Quantization
Yuxuan Nie, Yutong Song, Jinjie Yang, Yupeng Song, Yujue Zhou, Hong Peng
Subjects:
Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
Drug combinations are essential in cancer therapy, leveraging synergistic drug-drug interactions (DDI) to enhance efficacy and combat resistance. However, the vast combinatorial space makes experimental screening impractical, and existing computational models struggle to capture the complex, bidirectional nature of DDIs, often relying on independent drug encoding or simplistic fusion strategies that miss fine-grained inter-molecular dynamics. Moreover, state-of-the-art graph-based approaches suffer from high computational costs, limiting scalability for real-world drug discovery. To address this, we propose DPASyn, a novel drug synergy prediction framework featuring a dual-attention mechanism and Precision-Aware Quantization (PAQ). The dual-attention architecture jointly models intra-drug structures and inter-drug interactions via shared projections and cross-drug attention, enabling fine-grained, biologically plausible synergy modeling. While this enhanced expressiveness brings increased computational resource consumption, our proposed PAQ strategy complements it by dynamically optimizing numerical precision during training based on feature sensitivity-reducing memory usage by 40% and accelerating training threefold without sacrificing accuracy. With LayerNorm-stabilized residual connections for training stability, DPASyn outperforms seven state-of-the-art methods on the O'Neil dataset (13,243 combinations) and supports full-batch processing of up to 256 graphs on a single GPU, setting a new standard for efficient and expressive drug synergy prediction.
Total of 55 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack