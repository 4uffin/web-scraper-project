Quantitative Biology
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
q-bio
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Quantitative Biology
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Friday, 26 September 2025
Total of 21 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 5 of 5 entries)
[1]
arXiv:2509.20402
[pdf, other]
Title:
cAItomorph: Transformer-Based Hematological Malignancy Prediction from Peripheral Blood Smears in a Real-Word Cohort
Muhammed Furkan Dasdelen, Ivan Kukuljan, Peter Lienemann, Ario Sadafi, Matthias Hehr, Karsten Spiekermann, Christian Pohlkamp, Carsten Marr
Comments:
23 pages, 11 figures
Subjects:
Quantitative Methods (q-bio.QM)
Peripheral blood smears remain a cornerstone in the diagnosis of hematological neoplasms, offering rapid and valuable insights that inform subsequent diagnostic steps. However, since neoplastic transformations typically arise in the bone marrow, they may not manifest as detectable aberrations in peripheral blood, presenting a diagnostic challenge. In this paper, we introduce cAItomorph, an explainable transformer-based AI model, trained to classify hematological malignancies based on peripheral blood cytomorphology. Our data comprises peripheral blood single-cell images from 6115 patients with diagnoses confirmed by cytomorphology, cytogenetics, molecular genetics, and immunophenotyping from bone marrow samples, and 495 healthy controls, categorized into 22 detailed and 7 coarse classes. cAItomorph leverages the DinoBloom hematology foundation model and aggregates image encodings via a transformer-based architecture into a single vector. It achieves an overall accuracy of 68$\pm$1% (mean$\pm$s.d., 5-fold cross-validation) in 7-disease classification, with F1 scores of 74$\pm$2% for acute leukemia, 75$\pm$3% for myeloproliferative neoplasms and 82$\pm$3% for no malignancy cases. The overall accuracy increases to 84$\pm$1% in top-2 predictions. By analyzing multi-head attentions, we demonstrate clinically relevant cell-level attentions and pixel-level heatmaps. Moreover, our model's calibrated prediction probabilities reduced the false discovery rate from 13.8% to 12% without missing any acute leukemia cases, thereby decreasing the number of unnecessary bone marrow aspirations. Our code, test data, and model weights are publicly available to ensure reproducibility. This study highlights the potential of AI-assisted diagnostics in hematological malignancies, illustrating how models trained on real-world data could enhance diagnostic accuracy and reduce invasive procedures.
[2]
arXiv:2509.20538
[pdf, other]
Title:
Pattern Formation in Agent-Based and PDE Models for Evolutionary Games with Payoff-Driven Motion
Tianyong Yao, Chenning Xu, Daniel B. Cooney
Comments:
56 pages, 15 figures, equal contribution from TY and CX
Subjects:
Populations and Evolution (q-bio.PE); Pattern Formation and Solitons (nlin.PS)
Spatial structure can play an important role in the evolution of cooperative behavior and the achievement of collective success of a population. In this paper, we explore the role of random and directed motion on spatial pattern formation and the payoff achieved by populations in both stochastic and deterministic models of spatial populations who engage in social interactions following a hawk-dove game. For the case of purely diffusive motion, both a stochastic spatial model and a partial differential equation model show that Turing patterns can emerge when hawks have a greater movement rate than doves, and in both models hawks and doves see an increase in population size and average payoff as hawk mobility increases. For the case of the payoff-driven motion, the stochastic model shows an overall decrease in population size and average payoff, but the PDE model displays more subtle behavior in this setting and will depend on the relative diffusivities of the two strategies. The PDE model also displays a biologically infeasible short-wave instability in the case of payoff-driven motion and equal diffusivities, indicating that we need to be careful about the mathematical properties of PDE models with payoff-driven directed motion and indicating potential use for nonlocal PDE models for spatial patterns in evolutionary games with directed motion.
[3]
arXiv:2509.21132
[pdf, other]
Title:
Detecting disease progression from animal movement using hidden Markov models
Dongmin Kim, Théo Michelot, Katherine Mertes, Jared A. Stabach, John Fieberg
Subjects:
Quantitative Methods (q-bio.QM); Applications (stat.AP)
Understanding disease dynamics is crucial for managing wildlife populations and assessing spillover risk to domestic animals and humans, but infection data on free-ranging animals are difficult to obtain. Because pathogen and parasite infections can alter host movement, infection status may be inferred from animal trajectories. We present a hidden Markov model (HMM) framework that links observed movement behaviors to unobserved infection states, consistent with epidemiological compartmental models (e.g., susceptible, infected, recovered, dead). Using movement data from 84 reintroduced scimitar-horned oryx (Oryx dammah), 38 confirmed dead in the field and 6 sampled for disease testing, we demonstrate how HMMs can incorporate epidemiological structure through (1) constrained transition probabilities (e.g., to preclude or allow recovery), (2) covariate effects on transmission, and (3) hierarchically structured HMMs (HHMMs) for multi-scale transitions. Comparing veterinary diagnostic reports with model outputs, we found that HMMs with epidemiological constraints successfully identified infection-associated reductions in movement, whereas unconstrained models failed to capture disease progression. Simulations further showed that constrained HMMs accurately classified susceptible, infected, and recovered states. By illustrating flexible formulations and a workflow for model selection, we provide a transferable approach for detecting infection from movement data. This framework can enhance wildlife disease surveillance, guide population management, and improve understanding of disease dynamics.
[4]
arXiv:2509.21206
[pdf, html, other]
Title:
Data-driven Neural Networks for Windkessel Parameter Calibration
Benedikt Hoock, Tobias Köppl
Comments:
32 pages, 15 figures, for associated git see this https URL, submitted to International Journal for Numerical Methods in Biomedical Engineering
Subjects:
Tissues and Organs (q-bio.TO); Machine Learning (cs.LG); Numerical Analysis (math.NA); Optimization and Control (math.OC); Quantitative Methods (q-bio.QM)
In this work, we propose a novel method for calibrating Windkessel (WK) parameters in a dimensionally reduced 1D-0D coupled blood flow model. To this end, we design a data-driven neural network (NN)trained on simulated blood pressures in the left brachial artery. Once trained, the NN emulates the pressure pulse waves across the entire simulated domain, i.e., over time, space and varying WK parameters, with negligible error and computational effort. To calibrate the WK parameters on a measured pulse wave, the NN is extended by dummy neurons and retrained only on these. The main objective of this work is to assess the effectiveness of the method in various scenarios -- particularly, when the exact measurement location is unknown or the data are affected by noise.
[5]
arXiv:2509.21277
[pdf, html, other]
Title:
More than a feeling: Expressive style influences cortical speech tracking in subjective cognitive decline
Matthew King-Hang Ma, Manson Cheuk-Man Fong, Yun Feng, Cloris Pui-Hang Li, William Shiyuan Wang
Comments:
©2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
Subjects:
Neurons and Cognition (q-bio.NC)
Subjective cognitive decline (SCD) approximately doubles the risk of progressing to MCI and dementia. The present study investigates how one's subjective concerns of his/her own cognition are manifested in the neural dynamics during speech perception. EEG was collected from 56 Cantonese, cognitively normal older adults (aged 60 - 70) while they listened to stimuli of four expressive styles that varied in prosody: scrambled, descriptive, dialogue, and exciting. Using encoding models to predict EEG signals from acoustic, segmentation, and phonotactic features, we found that greater subjective concern was associated with weaker cortical tracking of (1) higher-level linguistic features but not acoustic features and (2) less engaging stimuli (scrambled and descriptive styles) but not prosodically rich stimuli. Overall, our results suggest that early signs of cognitive impairment can be revealed from speech perception via cortical tracking, especially while listening to prosodically flat speech.
Cross submissions (showing 8 of 8 entries)
[6]
arXiv:2509.20542
(cross-list from cs.CE)
[pdf, html, other]
Title:
A Hierarchical Adaptive Diffusion Model for Flexible Protein-Protein Docking
Rujie Yin, Yang Shen
Subjects:
Computational Engineering, Finance, and Science (cs.CE); Biomolecules (q-bio.BM)
Structural prediction of protein-protein interactions is important to understand the molecular basis of cellular interactions, but it still faces major challenges when significant conformational changes are present. We propose a generative framework of hierarchical adaptive diffusion to improve accuracy and efficiency in such cases. It is hierarchical in separating global inter-protein rigid-body motions and local intra-protein flexibility in diffusion processes, and the distinct local and global noise schedules are designed to mimic the induced-fit effect. It is adaptive in conditioning the local flexibility schedule on predicted levels of conformational change, allowing faster flexing for larger anticipated conformational changes. Furthermore, it couples the local and global diffusion processes through a common score and confidence network with sequence, evolution, structure, and dynamics features as inputs, and maintains rotational or translational invariance or equivariance in outputs. It builds on our newly curated DIPS-AF dataset of nearly 39,000 examples for pre-training. Experiments on the independent docking benchmark dataset DB5.5 show that our model outperforms an AlphaFold2-like iterative transformer (GeoDock) and a diffusion model (DiffDock-PP) in both rigid and flexible cases, with larger improvements in more flexible cases. Ablation studies prove the importance of adaptive schedules, dynamics features, and pre-training. Additional analyses and case studies reveal remaining gaps in sampling, scoring, and conformational resolution.
[7]
arXiv:2509.20693
(cross-list from cs.LG)
[pdf, html, other]
Title:
Learning to Align Molecules and Proteins: A Geometry-Aware Approach to Binding Affinity
Mohammadsaleh Refahi, Bahrad A. Sokhansanj, James R. Brown, Gail Rosen
Comments:
10pages,2 figures
Subjects:
Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Molecular Networks (q-bio.MN)
Accurate prediction of drug-target binding affinity can accelerate drug discovery by prioritizing promising compounds before costly wet-lab screening. While deep learning has advanced this task, most models fuse ligand and protein representations via simple concatenation and lack explicit geometric regularization, resulting in poor generalization across chemical space and time. We introduce FIRM-DTI, a lightweight framework that conditions molecular embeddings on protein embeddings through a feature-wise linear modulation (FiLM) layer and enforces metric structure with a triplet loss. An RBF regression head operating on embedding distances yields smooth, interpretable affinity predictions. Despite its modest size, FIRM-DTI achieves state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark, as demonstrated by an extensive ablation study and out-of-domain evaluation. Our results underscore the value of conditioning and metric learning for robust drug-target affinity prediction.
[8]
arXiv:2509.20702
(cross-list from stat.AP)
[pdf, html, other]
Title:
Incorporating LLM Embeddings for Variation Across the Human Genome
Hongqian Niu, Jordan Bryan, Xihao Li, Didong Li
Subjects:
Applications (stat.AP); Artificial Intelligence (cs.AI); Genomics (q-bio.GN)
Recent advances in large language model (LLM) embeddings have enabled powerful representations for biological data, but most applications to date focus only on gene-level information. We present one of the first systematic frameworks to generate variant-level embeddings across the entire human genome. Using curated annotations from FAVOR, ClinVar, and the GWAS Catalog, we constructed semantic text descriptions for 8.9 billion possible variants and generated embeddings at three scales: 1.5 million HapMap3+MEGA variants, ~90 million imputed UK Biobank variants, and ~9 billion all possible variants. Embeddings were produced with both OpenAI's text-embedding-3-large and the open-source Qwen3-Embedding-0.6B models. Baseline experiments demonstrate high predictive accuracy for variant properties, validating the embeddings as structured representations of genomic variation. We outline two downstream applications: embedding-informed hypothesis testing by extending the Frequentist And Bayesian framework to genome-wide association studies, and embedding-augmented genetic risk prediction that enhances standard polygenic risk scores. These resources, publicly available on Hugging Face, provide a foundation for advancing large-scale genomic discovery and precision medicine.
[9]
arXiv:2509.20719
(cross-list from cs.LG)
[pdf, html, other]
Title:
A Genetic Algorithm for Navigating Synthesizable Molecular Spaces
Alston Lo, Connor W. Coley, Wojciech Matusik
Subjects:
Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)
Inspired by the effectiveness of genetic algorithms and the importance of synthesizability in molecular design, we present SynGA, a simple genetic algorithm that operates directly over synthesis routes. Our method features custom crossover and mutation operators that explicitly constrain it to synthesizable molecular space. By modifying the fitness function, we demonstrate the effectiveness of SynGA on a variety of design tasks, including synthesizable analog search and sample-efficient property optimization, for both 2D and 3D objectives. Furthermore, by coupling SynGA with a machine learning-based filter that focuses the building block set, we boost SynGA to state-of-the-art performance. For property optimization, this manifests as a model-based variant SynGBO, which employs SynGA and block filtering in the inner loop of Bayesian optimization. Since SynGA is lightweight and enforces synthesizability by construction, our hope is that SynGA can not only serve as a strong standalone baseline but also as a versatile module that can be incorporated into larger synthesis-aware workflows in the future.
[10]
arXiv:2509.20850
(cross-list from stat.AP)
[pdf, html, other]
Title:
Detecting gene-environment interactions to guide personalized intervention: boosting distributional regression for polygenic scores
Qiong Wu, Hannah Klinkhammer, Kiran Kunwar, Christian Staerk, Carlo Maj, Andreas Mayr
Comments:
18 pages with 8 figures
Subjects:
Applications (stat.AP); Genomics (q-bio.GN); Quantitative Methods (q-bio.QM); Computation (stat.CO)
Polygenic risk scores can be used to model the individual genetic liability for human traits. Current methods primarily focus on modeling the mean of a phenotype neglecting the variance. However, genetic variants associated with phenotypic variance can provide important insights to gene-environment interaction studies. To overcome this, we propose snpboostlss, a cyclical gradient boosting algorithm for a Gaussian location-scale model to jointly derive sparse polygenic models for both the mean and the variance of a quantitative phenotype. To improve computational efficiency on high-dimensional and large-scale genotype data (large n and large p), we only consider a batch of most relevant variants in each boosting step. We investigate the effect of statins therapy (the environmental factor) on low-density lipoprotein in the UK Biobank cohort using the new snpboostlss algorithm. We are able to verify the interaction between statins usage and the polygenic risk scores for phenotypic variance in both cross sectional and longitudinal analyses. Particularly, following the spirit of target trial emulation, we observe that the treatment effect of statins is more substantial in people with higher polygenic risk scores for phenotypic variance, indicating gene-environment interaction. When applying to body mass index, the newly constructed polygenic risk scores for variance show significant interaction with physical activity and sedentary behavior. Therefore, the polygenic risk scores for phenotypic variance derived by snpboostlss have potential to identify individuals that could benefit more from environmental changes (e.g. medical intervention and lifestyle changes).
[11]
arXiv:2509.20916
(cross-list from cs.CL)
[pdf, html, other]
Title:
Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density
Krishna Aggarwal
Comments:
7 pages, 4 figures (Figure 2 has 3 sub-divisions)
Subjects:
Computation and Language (cs.CL); Neurons and Cognition (q-bio.NC)
This study examines whether sentence-level memory load in comprehension is better explained by linear proximity between syntactically related words or by the structural density of the intervening material. Building on locality-based accounts and cross-linguistic evidence for dependency length minimization, the work advances Intervener Complexity-the number of intervening heads between a head and its dependent-as a structurally grounded lens that refines linear distance measures. Using harmonized dependency treebanks and a mixed-effects framework across multiple languages, the analysis jointly evaluates sentence length, dependency length, and Intervener Complexity as predictors of the Memory-load measure. Studies in Psycholinguistics have reported the contributions of feature interference and misbinding to memory load during processing. For this study, I operationalized sentence-level memory load as the linear sum of feature misbinding and feature interference for tractability; current evidence does not establish that their cognitive contributions combine additively. All three factors are positively associated with memory load, with sentence length exerting the broadest influence and Intervener Complexity offering explanatory power beyond linear distance. Conceptually, the findings reconcile linear and hierarchical perspectives on locality by treating dependency length as an important surface signature while identifying intervening heads as a more proximate indicator of integration and maintenance demands. Methodologically, the study illustrates how UD-based graph measures and cross-linguistic mixed-effects modelling can disentangle linear and structural contributions to processing efficiency, providing a principled path for evaluating competing theories of memory load in sentence comprehension.
[12]
arXiv:2509.21191
(cross-list from stat.AP)
[pdf, html, other]
Title:
Not All Accuracy Is Equal: Prioritizing Diversity in Infectious Disease Forecasting
Carson Dudley, Marisa Eisenberg
Comments:
5 pages, 2 figures
Subjects:
Applications (stat.AP); Quantitative Methods (q-bio.QM)
Ensemble forecasts have become a cornerstone of large-scale disease response, underpinning decision making at agencies such as the US Centers for Disease Control and Prevention (CDC). Their growing use reflects the goal of combining multiple models to improve accuracy and stability versus using a single model. However, recent experience shows these benefits are not guaranteed. During the COVID-19 pandemic, the CDC's multi-model forecasting ensemble outperformed the best single model by only 1%, and CDC flu forecasting ensembles have often ranked below multiple individual models.
This raises a key question: why are ensembles underperforming? We posit that a central reason is that both model developers and ensemble builders typically focus on stand-alone accuracy. Models are fit to minimize their own forecasting error, and ensembles are often weighted according to those same scores. However, most epidemic forecasts are built from a small set of approaches and trained on the same surveillance data, leading to highly correlated errors. This redundancy limits the benefit of ensembling and may explain why large ensembles sometimes deliver only marginal gains.
To realize the potential of ensembles, both modelers and ensemblers should prioritize models that contribute complementary information rather than replicating existing approaches. Ensembles built with this principle in mind move beyond size for its own sake toward true diversity, producing forecasts that are more robust and more valuable for epidemic preparedness and response.
[13]
arXiv:2509.21239
(cross-list from cs.CV)
[pdf, html, other]
Title:
SlideMamba: Entropy-Based Adaptive Fusion of GNN and Mamba for Enhanced Representation Learning in Digital Pathology
Shakib Khan, Fariba Dambandkhameneh, Nazim Shaikh, Yao Nie, Raghavan Venugopal, Xiao Li
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)
Advances in computational pathology increasingly rely on extracting meaningful representations from Whole Slide Images (WSIs) to support various clinical and biological tasks. In this study, we propose a generalizable deep learning framework that integrates the Mamba architecture with Graph Neural Networks (GNNs) for enhanced WSI analysis. Our method is designed to capture both local spatial relationships and long-range contextual dependencies, offering a flexible architecture for digital pathology analysis. Mamba modules excels in capturing long-range global dependencies, while GNNs emphasize fine-grained short-range spatial interactions. To effectively combine these complementary signals, we introduce an adaptive fusion strategy that uses an entropy-based confidence weighting mechanism. This approach dynamically balances contributions from both branches by assigning higher weight to the branch with more confident (lower-entropy) predictions, depending on the contextual importance of local versus global information for different downstream tasks. We demonstrate the utility of our approach on a representative task: predicting gene fusion and mutation status from WSIs. Our framework, SlideMamba, achieves an area under the precision recall curve (PRAUC) of 0.751 \pm 0.05, outperforming MIL (0.491 \pm 0.042), Trans-MIL (0.39 \pm 0.017), Mamba-only (0.664 \pm 0.063), GNN-only (0.748 \pm 0.091), and a prior similar work GAT-Mamba (0.703 \pm 0.075). SlideMamba also achieves competitive results across ROC AUC (0.738 \pm 0.055), sensitivity (0.662 \pm 0.083), and specificity (0.725 \pm 0.094). These results highlight the strength of the integrated architecture, enhanced by the proposed entropy-based adaptive fusion strategy, and suggest promising potential for application of spatially-resolved predictive modeling tasks in computational pathology.
Replacement submissions (showing 8 of 8 entries)
[14]
arXiv:2503.02781
(replaced)
[pdf, html, other]
Title:
Multimodal AI predicts clinical outcomes of drug combinations from preclinical data
Yepeng Huang, Xiaorui Su, Varun Ullanat, Intae Moon, Ivy Liang, Lindsay Clegg, Damilola Olabode, Ruthie Johnson, Nicholas Ho, Megan Gibbs, Megan Gibbs, Alexander Gusev, Bino John, Marinka Zitnik
Subjects:
Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
Predicting clinical outcomes from preclinical data is essential for identifying safe and effective drug combinations, reducing late-stage clinical failures, and accelerating the development of precision therapies. Current AI models rely on structural or target-based features but fail to incorporate the multimodal data necessary for accurate, clinically relevant predictions. Here, we introduce Madrigal, a multimodal AI model that learns from structural, pathway, cell viability, and transcriptomic data to predict drug-combination effects across 953 clinical outcomes and 21,842 compounds, including combinations of approved drugs and novel compounds in development. Madrigal uses an attention bottleneck module to unify preclinical drug data modalities while handling missing data during training and inference, a major challenge in multimodal learning. It outperforms single-modality methods and state-of-the-art models in predicting adverse drug interactions, and ablations show both modality alignment and multimodality are necessary. It captures transporter-mediated interactions and aligns with head-to-head clinical trial differences for neutropenia, anemia, alopecia, and hypoglycemia. In type 2 diabetes and MASH, Madrigal supports polypharmacy decisions and prioritizes resmetirom among safer candidates. Extending to personalization, Madrigal improves patient-level adverse-event prediction in a longitudinal EHR cohort and an independent oncology cohort, and predicts ex vivo efficacy in primary acute myeloid leukemia samples and patient-derived xenograft models. Madrigal links preclinical multimodal readouts to safety risks of drug combinations and offers a generalizable foundation for safer combination design.
[15]
arXiv:2505.17914
(replaced)
[pdf, html, other]
Title:
Flexible MOF Generation with Torsion-Aware Flow Matching
Nayoung Kim, Seongsu Kim, Sungsoo Ahn
Comments:
24 pages, 9 figures
Journal-ref:
Neural Information Processing Systems (NeurIPS) 2025
Subjects:
Biomolecules (q-bio.BM); Machine Learning (cs.LG)
Designing metal-organic frameworks (MOFs) with novel chemistries is a longstanding challenge due to their large combinatorial space and complex 3D arrangements of the building blocks. While recent deep generative models have enabled scalable MOF generation, they assume (1) a fixed set of building blocks and (2) known local 3D coordinates of building blocks. However, this limits their ability to (1) design novel MOFs and (2) generate the structure using novel building blocks. We propose a two-stage MOF generation framework that overcomes these limitations by modeling both chemical and geometric degrees of freedom. First, we train an SMILES-based autoregressive model to generate metal and organic building blocks, paired with a cheminformatics toolkit for 3D structure initialization. Second, we introduce a flow matching model that predicts translations, rotations, and torsional angles to assemble the blocks into valid 3D frameworks. Our experiments demonstrate improved reconstruction accuracy, the generation of valid, novel, and unique MOFs, and the ability to create novel building blocks. Our code is available at this https URL.
[16]
arXiv:2507.16080
(replaced)
[pdf, html, other]
Title:
Interpretable Embeddings of Speech Enhance and Explain Brain Encoding Performance of Audio Models
Riki Shimizu, Richard J. Antonello, Chandan Singh, Nima Mesgarani
Comments:
19 pages, 5 figures
Subjects:
Neurons and Cognition (q-bio.NC); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Speech foundation models (SFMs) are increasingly hailed as powerful computational models of human speech perception. However, since their representations are inherently black-box, it remains unclear what drives their alignment with brain responses. To remedy this, we built linear encoding models from six interpretable feature families: mel-spectrogram, Gabor filter bank features, speech presence, phonetic, syntactic, and semantic features, and contextualized embeddings from three state-of-the-art SFMs (Whisper, HuBERT, WavLM), quantifying electrocorticography (ECoG) response variance shared between feature classes. Variance-partitioning analyses revealed several key insights: First, the SFMs' alignment with the brain can be mostly explained by their ability to learn and encode simple interpretable speech features. Second, SFMs exhibit a systematic trade-off between encoding of brain-relevant low-level and high-level features across layers. Finally, our results show that SFMs learn brain-relevant semantics which cannot be explained by lower-level speech features, with this capacity increasing with model size and context length. Together, our findings suggest a principled approach to build more interpretable, accurate, and efficient encoding models of the brain by augmenting SFM embeddings with interpretable features.
[17]
arXiv:2509.02196
(replaced)
[pdf, html, other]
Title:
Beyond Ensembles: Simulating All-Atom Protein Dynamics in a Learned Latent Space
Aditya Sengar, Jiying Zhang, Pierre Vandergheynst, Patrick Barth
Subjects:
Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI)
Simulating the long-timescale dynamics of biomolecules is a central challenge in computational science. While enhanced sampling methods can accelerate these simulations, they rely on pre-defined collective variables that are often difficult to identify. A recent generative model, LD-FPG, demonstrated that this problem could be bypassed by learning to sample the static equilibrium ensemble as all-atom deformations from a reference structure, establishing a powerful method for all-atom ensemble generation. However, while this approach successfully captures a system's probable conformations, it does not model the temporal evolution between them. We introduce the Graph Latent Dynamics Propagator (GLDP), a modular component for simulating dynamics within the learned latent space of LD-FPG. We then compare three classes of propagators: (i) score-guided Langevin dynamics, (ii) Koopman-based linear operators, and (iii) autoregressive neural networks. Within a unified encoder-propagator-decoder framework, we evaluate long-horizon stability, backbone and side-chain ensemble fidelity, and functional free-energy landscapes. Autoregressive neural networks deliver the most robust long rollouts; score-guided Langevin best recovers side-chain thermodynamics when the score is well learned; and Koopman provides an interpretable, lightweight baseline that tends to damp fluctuations. These results clarify the trade-offs among propagators and offer practical guidance for latent-space simulators of all-atom protein dynamics.
[18]
arXiv:2509.16328
(replaced)
[pdf, html, other]
Title:
The Role of High-Performance GPU Resources in Large Language Model Based Radiology Imaging Diagnosis
Jyun-Ping Kao
Subjects:
Tissues and Organs (q-bio.TO)
Large-language models (LLMs) are rapidly being applied to radiology, enabling automated image interpretation and report generation tasks. Their deployment in clinical practice requires both high diagnostic accuracy and low inference latency, which in turn demands powerful hardware. High-performance graphical processing units (GPUs) provide the necessary compute and memory throughput to run large LLMs on imaging data. We review modern GPU architectures (e.g. NVIDIA A100/H100, AMD Instinct MI250X/MI300) and key performance metrics of floating-point throughput, memory bandwidth, VRAM capacity. We show how these hardware capabilities affect radiology tasks: for example, generating reports or detecting findings on CheXpert and MIMIC-CXR images is computationally intensive and benefits from GPU parallelism and tensor-core acceleration. Empirical studies indicate that using appropriate GPU resources can reduce inference time and improve throughput. We discuss practical challenges including privacy, deployment, cost, power and optimization strategies: mixed-precision, quantization, compression, and multi-GPU scaling. Finally, we anticipate that next-generation features (8-bit tensor cores, enhanced interconnect) will further enable on-premise and federated radiology AI. Advancing GPU infrastructure is essential for safe, efficient LLM-based radiology diagnostics.
[19]
arXiv:2502.01360
(replaced)
[pdf, html, other]
Title:
A Quotient Homology Theory of Representation in Neural Networks
Kosio Beshkov
Subjects:
Machine Learning (cs.LG); Algebraic Topology (math.AT); Neurons and Cognition (q-bio.NC)
Previous research has proven that the set of maps implemented by neural networks with a ReLU activation function is identical to the set of piecewise linear continuous maps. Furthermore, such networks induce a hyperplane arrangement splitting the input domain of the network into convex polyhedra $G_J$ over which a network $\Phi$ operates in an affine manner.
In this work, we leverage these properties to define an equivalence class $\sim_\Phi$ on top of an input dataset, which can be split into two sets related to the local rank of $\Phi_J$ and the intersections $\cap \text{Im}\Phi_{J_i}$. We refer to the latter as the \textit{overlap decomposition} $\mathcal{O}_\Phi$ and prove that if the intersections between each polyhedron and an input manifold are convex, the homology groups of neural representations are isomorphic to quotient homology groups $H_k(\Phi(\mathcal{M})) \simeq H_k(\mathcal{M}/\mathcal{O}_\Phi)$. This lets us intrinsically calculate the Betti numbers of neural representations without the choice of an external metric. We develop methods to numerically compute the overlap decomposition through linear programming and a union-find algorithm.
Using this framework, we perform several experiments on toy datasets showing that, compared to standard persistent homology, our overlap homology-based computation of Betti numbers tracks purely topological rather than geometric features. Finally, we study the evolution of the overlap decomposition during training on several classification problems while varying network width and depth and discuss some shortcomings of our method.
[20]
arXiv:2507.01046
(replaced)
[pdf, html, other]
Title:
A Compartmental Model for Epidemiology with Human Behavior and Stochastic Effects
Christian Parkinson, Weinan Wang
Comments:
31 pages, 7 figures
Subjects:
Dynamical Systems (math.DS); Populations and Evolution (q-bio.PE)
We propose a compartmental model for epidemiology wherein the population is split into groups with either comply or refuse to comply with protocols designed to slow the spread of a disease. Parallel to the disease spread, we assume that noncompliance with protocols spreads as a social contagion. We begin by deriving the reproductive ratio for a deterministic version of the model, and use this to fully characterize the local stability of disease free equilibrium points. We then append the deterministic model with stochastic effects, specifically assuming that the transmission rate of the disease and the transmission rate of the social contagion are uncertain. We prove global existence and nonnegativity for our stochastic model. Then using suitably constructed stochastic Lyapunov functions, we analyze the behavior of the stochastic system with respect to certain disease free states. We demonstrate all of our results with numerical simulations.
[21]
arXiv:2508.16509
(replaced)
[pdf, html, other]
Title:
ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks
Manuel Reinhardt, Gašper Tkačik, Pieter Rein ten Wolde
Comments:
9 pages, 2 figures
Subjects:
Biological Physics (physics.bio-ph); Statistical Mechanics (cond-mat.stat-mech); Information Theory (cs.IT); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)
The ability to quantify information transmission is crucial for the analysis and design of natural and engineered systems. The information transmission rate is the fundamental measure for systems with time-varying signals, yet computing it is extremely challenging. In particular, the rate cannot be obtained directly from experimental time-series data without approximations, because of the high dimensionality of the signal trajectory space. Path Weight Sampling (PWS) is a computational technique that makes it possible to obtain the information rate exactly for any stochastic system. However, it requires a mathematical model of the system of interest, be it described by a master equation or a set of differential equations. Here, we present a technique that employs Machine Learning (ML) to develop a generative model from experimental time-series data, which is then combined with PWS to obtain the information rate. We demonstrate the accuracy of this technique, called ML-PWS, by comparing its results on synthetic time-series data generated from a non-linear model against ground-truth results obtained by applying PWS directly to the same model. We illustrate the utility of ML-PWS by applying it to neuronal time-series data.
Total of 21 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack