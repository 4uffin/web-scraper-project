Economics
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
econ
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Economics
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Monday, 22 September 2025
Total of 26 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 12 of 12 entries)
[1]
arXiv:2509.15247
[pdf, html, other]
Title:
Demand, and consumer surplus in the payday-loan market: Evidence from British Columbia
Tim Zhang, Amity Quinn
Subjects:
General Economics (econ.GN)
This study examines how interest rate caps affect the demand for payday loans, using aggregate data from British Columbia (2012--2019) during which the province's maximum fee was reduced from \$23 to \$17 and then to \$15 per \$100 borrowed. Estimating a linear demand function via OLS, we find that lowering interest rate caps significantly increases loan demand. We estimate that the \$8 decrease, from \$23 to \$15 per \$100, raised annual consumer surplus by roughly \$28.6 million (2012 CAD). A further reduction to \$14, starting in January 2025, would add another \$3.9 million per year. These results suggest that stricter interest rate caps can yield substantial consumer welfare gains.
[2]
arXiv:2509.15265
[pdf, html, other]
Title:
AI and jobs. A review of theory, estimates, and evidence
R. Maria del Rio-Chanona, Ekkehard Ernst, Rossana Merola, Daniel Samaan, Ole Teutloff
Subjects:
General Economics (econ.GN)
Generative AI is altering work processes, task composition, and organizational design, yet its effects on employment and the macroeconomy remain unresolved. In this review, we synthesize theory and empirical evidence at three levels. First, we trace the evolution from aggregate production frameworks to task- and expertise-based models. Second, we quantitatively review and compare (ex-ante) AI exposure measures of occupations from multiple studies and find convergence towards high-wage jobs. Third, we assemble ex-post evidence of AI's impact on employment from randomized controlled trials (RCTs), field experiments, and digital trace data (e.g., online labor platforms, software repositories), complemented by partial coverage of surveys. Across the reviewed studies, productivity gains are sizable but context-dependent: on the order of 20 to 60 percent in controlled RCTs, and 15 to 30 percent in field experiments. Novice workers tend to benefit more from LLMs in simple tasks. Across complex tasks, evidence is mixed on whether low or high-skilled workers benefit more. Digital trace data show substitution between humans and machines in writing and translation alongside rising demand for AI, with mild evidence of declining demand for novice workers. A more substantial decrease in demand for novice jobs across AI complementary work emerges from recent studies using surveys, platform payment records, or administrative data. Research gaps include the focus on simple tasks in experiments, the limited diversity of LLMs studied, and technology-centric AI exposure measures that overlook adoption dynamics and whether exposure translates into substitution, productivity gains, erode or increase expertise.
[3]
arXiv:2509.15284
[pdf, html, other]
Title:
A moderate share of V2G outperforms large-scale smart charging of electric vehicles and benefits other consumers
Adeline Guéret, Carlos Gaete-Morales, Wolf-Peter Schill
Subjects:
General Economics (econ.GN)
While battery electric vehicles (BEVs) play a key role for decarbonizing the transport sector, their impact on the power sector heavily depends on their charging strategies. Here we systematically analyze various combinations between inflexible, smart and bidirectional (or vehicle-to-grid, V2G) charging of 15 million electric cars in Germany. Using a capacity expansion model, we find that even a moderate share of bidirectional charging below 30% leads to lower system costs than a fully smartly charging BEV fleet. At a V2G share of 50%, costs are even lower than in a system without any BEVs. This means that the flexibility effect of half of the BEV fleet charging bidirectionally outweighs the demand effect of the whole BEV fleet. We show how costs savings are driven by the ability of V2G to serve demand, especially during hours with high residual load. We also explore the distributional effects of respective electricity price changes. While V2G car owners internalize a substantial share of overall cost savings, the benefits increasingly spill over to other electricity consumers as the share of bidirectional charging grows. We conclude that policymakers should focus on enabling a moderate fleet share of V2G rather than on enabling every car to charge smartly.
[4]
arXiv:2509.15326
[pdf, other]
Title:
Efficient and Accessible Discrete Choice Experiments: The DCEtool Package for R
Daniel Pérez-Troncoso
Comments:
13 pages, 6 figures, R package in CRAN: this https URL
Subjects:
Econometrics (econ.EM)
Discrete Choice Experiments (DCEs) are widely used to elicit preferences for products or services by analyzing choices among alternatives described by their attributes. The quality of the insights obtained from a DCE heavily depends on the properties of its experimental design. While early DCEs often relied on linear criteria such as orthogonality, these approaches were later found to be inappropriate for discrete choice models, which are inherently non-linear. As a result, statistically efficient design methods, based on minimizing the D-error to reduce parameter variance, have become the standard. Although such methods are implemented in several commercial tools, researchers seeking free and accessible solutions often face limitations. This paper presents DCEtool, an R package with a Shiny-based graphical interface designed to support both novice and experienced users in constructing, decoding, and analyzing statistically efficient DCE designs. DCEtool facilitates the implementation of serial DCEs, offers flexible design settings, and enables rapid estimation of discrete choice models. By making advanced design techniques more accessible, DCEtool contributes to the broader adoption of rigorous experimental practices in choice modelling.
[5]
arXiv:2509.15343
[pdf, other]
Title:
Poverty and Perceptions of Electoral Integrity in the U.S
Douglas Cumming, Sofia Johan, Ikenna Uzuegbunam
Comments:
35 pages, 6 tables, 4 figures
Subjects:
General Economics (econ.GN)
We propose two opposing forces that impact the relation between electoral integrity and poverty. On the one hand, it is more costly to provide electoral integrity in states where there is more poverty due to transaction costs and opportunity costs. On the other hand, extreme levels of poverty attract media scrutiny and greater external monitoring of electoral integrity, giving rise to more demand for electoral integrity. Taken together, we expect electoral integrity to be a U-shaped function of poverty. We also hypothesize that electoral integrity will vary depending on the strength of state electoral laws. Expert-level survey data on electoral integrity from the 2016 U.S. Presidential election and the 2018 U.S. congressional election, in combination with U.S. state-level data on poverty are strongly consistent with these predictions.
[6]
arXiv:2509.15401
[pdf, html, other]
Title:
Inference on the Distribution of Individual Treatment Effects in Nonseparable Triangular Models
Jun Ma, Vadim Marmer, Zhengfei Yu
Subjects:
Econometrics (econ.EM); Methodology (stat.ME)
In this paper, we develop inference methods for the distribution of heterogeneous individual treatment effects (ITEs) in the nonseparable triangular model with a binary endogenous treatment and a binary instrument of Vuong and Xu (2017) and Feng, Vuong, and Xu (2019). We focus on the estimation of the cumulative distribution function (CDF) of the ITE, which can be used to address a wide range of practically important questions such as inference on the proportion of individuals with positive ITEs, the quantiles of the distribution of ITEs, and the interquartile range as a measure of the spread of the ITEs, as well as comparison of the ITE distributions across sub-populations. Moreover, our CDF-based approach can deliver more precise results than density-based approach previously considered in the literature. We establish weak convergence to tight Gaussian processes for the empirical CDF and quantile function computed from nonparametric ITE estimates of Feng, Vuong, and Xu (2019). Using those results, we develop bootstrap-based nonparametric inferential methods, including uniform confidence bands for the CDF and quantile function of the ITE distribution.
[7]
arXiv:2509.15454
[pdf, html, other]
Title:
Fact-Finding in Social Networks
Boris Ginzburg
Subjects:
Theoretical Economics (econ.TH)
This paper models voters who invest effort to determine whether a particular claim relevant to their voting choices is correct. If a voter succeeds in determining whether the claim is correct, this information is shared via a social network. I show that increased connectivity makes voters more informed about basic facts, but less informed about complicated issues. At the same time, polarization makes voters less informed overall.
[8]
arXiv:2509.15510
[pdf, html, other]
Title:
The (Short-Term) Effects of Large Language Models on Unemployment and Earnings
Danqing Chen, Carina Kane, Austin Kozlowski, Nadav Kunievsky, James A. Evans
Subjects:
General Economics (econ.GN); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)
Large Language Models have spread rapidly since the release of ChatGPT in late 2022, accompanied by claims of major productivity gains but also concerns about job displacement. This paper examines the short-run labor market effects of LLM adoption by comparing earnings and unemployment across occupations with differing levels of exposure to these technologies. Using a Synthetic Difference in Differences approach, we estimate the impact of LLM exposure on earnings and unemployment. Our findings show that workers in highly exposed occupations experienced earnings increases following ChatGPT's introduction, while unemployment rates remained unchanged. These results suggest that initial labor market adjustments to LLMs operate primarily through earnings rather than worker reallocation.
[9]
arXiv:2509.15885
[pdf, other]
Title:
The Impact of AI Adoption on Retail Across Countries and Industries
Yunqi Liu
Comments:
9 pages, 7 figures, 4 tables, conference paper, accepted at ICEMGD 2025
Subjects:
General Economics (econ.GN); Computers and Society (cs.CY)
This study investigates the impact of artificial intelligence (AI) adoption on job loss rates using the Global AI Content Impact Dataset (2020--2025). The panel comprises 200 industry-country-year observations across Australia, China, France, Japan, and the United Kingdom in ten industries. A three-stage ordinary least squares (OLS) framework is applied. First, a full-sample regression finds no significant linear association between AI adoption rate and job loss rate ($\beta \approx -0.0026$, $p = 0.949$). Second, industry-specific regressions identify the marketing and retail sectors as closest to significance. Third, interaction-term models quantify marginal effects in those two sectors, revealing a significant retail interaction effect ($-0.138$, $p < 0.05$), showing that higher AI adoption is linked to lower job loss in retail. These findings extend empirical evidence on AI's labor market impact, emphasize AI's productivity-enhancing role in retail, and support targeted policy measures such as intelligent replenishment systems and cashierless checkout implementations.
[10]
arXiv:2509.16067
[pdf, html, other]
Title:
Misspecified learning and evolutionary stability
Kevin He, Jonathan Libgober
Comments:
This material was previously part of a larger paper titled "Evolutionarily Stable (Mis)specifications: Theory and Applications," which split into two smaller papers: "Misspecified Learning and Evolutionary Stability" and "Higher-Order Beliefs and (Mis)learning from Prices.". arXiv admin note: text overlap with arXiv:2012.15007
Journal-ref:
Journal of Economic Theory 230:106082, 2025
Subjects:
Theoretical Economics (econ.TH); Computer Science and Game Theory (cs.GT)
We extend the indirect evolutionary approach to the selection of (possibly misspecified) models. Agents with different models match in pairs to play a stage game, where models define feasible beliefs about game parameters and about others' strategies. In equilibrium, each agent adopts the feasible belief that best fits their data and plays optimally given their beliefs. We define the stability of the resident model by comparing its equilibrium payoff with that of the entrant model, and provide conditions under which the correctly specified resident model can only be destabilized by misspecified entrant models that contain multiple feasible beliefs (that is, entrant models that permit inference). We also show that entrants may do well in their matches against the residents only when the entrant population is large, due to the endogeneity of misspecified beliefs. Applications include the selection of demand-elasticity misperception in Cournot duopoly and the emergence of analogy-based reasoning in centipede games.
[11]
arXiv:2509.16115
[pdf, other]
Title:
KRED: Korea Research Economic Database for Macroeconomic Research
Changryong Baek, Seunghyun Moon, Seunghyeon Lee
Subjects:
Econometrics (econ.EM); Applications (stat.AP)
We introduce KRED (Korea Research Economic Database), a new FRED MD style macroeconomic dataset for South Korea. KRED is constructed by aggregating 88 key monthly time series from multiple official sources (e.g., Bank of Korea ECOS, Statistics Korea KOSIS) into a unified, publicly available database. The dataset is aligned with the FRED MD format, enabling standardized transformations and direct comparability; an Appendix maps each Korean series to its FRED MD counterpart. Using a balanced panel of 80 series from 2009 to 2024, we extract four principal components via PCA that explain approximately 40% of the total variance. These four factors have intuitive economic interpretations, capturing monetary conditions, labor market activity, real output, and housing demand, analogous to diffusion indexes summarizing broad economic movements. Notably, the factor based diffusion indexes derived from KRED clearly trace major macroeconomic fluctuations over the sample period such as the 2020 COVID 19 recession. Our results demonstrate that KRED's factor structure can effectively condense complex economic information into a few informative indexes, yielding new insights into South Korea's business cycles and co movements.
[12]
arXiv:2509.16125
[pdf, html, other]
Title:
Who Pays, Who Benefits? Producer-Insurer Games in Life-Saving Medicines
Delia Coculescu, Maximilian Janisch, Thomas Lehéricy
Comments:
40 pages
Subjects:
Theoretical Economics (econ.TH)
Pharmaceutical markets for life-saving therapies combine monopoly power with insurance coverage. We build a tractable sequential game in which a patent-holder chooses the drug price, a profit-maximising insurer sets its premium, and a population of heterogeneous agents decide whether to insure and, conditional on diagnosis, whether to purchase treatment. Two sufficient statistics - subjective illness probability and reservation price - capture heterogeneity and nest risk-aversion and liquidity-constraint motives within a unified framework. We prove existence of subgame-perfect Nash equilibria and show that entry of an insurer strictly raises producer profits but may raise or lower both drug prices and treatment uptake, depending on the joint distribution of the population statistics. Numerical experiments calibrated to flexible parametric families illustrate non-monotone comparative statics and quantify conditions under which insurance reduces access. Our results provide benchmarks for evaluating price negotiations, price caps, and subsidy schemes in high-cost drug markets.
Cross submissions (showing 8 of 8 entries)
[13]
arXiv:1506.02084
(cross-list from math.ST)
[pdf, other]
Title:
Exact P-values for Network Interference
Susan Athey, Dean Eckles, Guido Imbens
Comments:
40 pages
Subjects:
Statistics Theory (math.ST); Econometrics (econ.EM); Methodology (stat.ME)
We study the calculation of exact p-values for a large class of non-sharp null hypotheses about treatment effects in a setting with data from experiments involving members of a single connected network. The class includes null hypotheses that limit the effect of one unit's treatment status on another according to the distance between units; for example, the hypothesis might specify that the treatment status of immediate neighbors has no effect, or that units more than two edges away have no effect. We also consider hypotheses concerning the validity of sparsification of a network (for example based on the strength of ties) and hypotheses restricting heterogeneity in peer effects (so that, for example, only the number or fraction treated among neighboring units matters). Our general approach is to define an artificial experiment, such that the null hypothesis that was not sharp for the original experiment is sharp for the artificial experiment, and such that the randomization analysis for the artificial experiment is validated by the design of the original experiment.
[14]
arXiv:1812.09970
(cross-list from stat.ME)
[pdf, other]
Title:
Synthetic Difference in Differences
Dmitry Arkhangelsky, Susan Athey, David A. Hirshberg, Guido W. Imbens, Stefan Wager
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
We present a new estimator for causal effects with panel data that builds on insights behind the widely used difference in differences and synthetic control methods. Relative to these methods we find, both theoretically and empirically, that this "synthetic difference in differences" estimator has desirable robustness properties, and that it performs well in settings where the conventional estimators are commonly used in practice. We study the asymptotic behavior of the estimator when the systematic part of the outcome model includes latent unit factors interacted with latent time factors, and we present conditions for consistency and asymptotic normality.
[15]
arXiv:2106.02029
(cross-list from stat.ML)
[pdf, other]
Title:
Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits
Ruohan Zhan, Vitor Hadad, David A. Hirshberg, Susan Athey
Subjects:
Machine Learning (stat.ML); Machine Learning (cs.LG); Econometrics (econ.EM); Methodology (stat.ME)
It has become increasingly common for data to be collected adaptively, for example using contextual bandits. Historical data of this type can be used to evaluate other treatment assignment policies to guide future innovation or experiments. However, policy evaluation is challenging if the target policy differs from the one used to collect data, and popular estimators, including doubly robust (DR) estimators, can be plagued by bias, excessive variance, or both. In particular, when the pattern of treatment assignment in the collected data looks little like the pattern generated by the policy to be evaluated, the importance weights used in DR estimators explode, leading to excessive variance.
In this paper, we improve the DR estimator by adaptively weighting observations to control its variance. We show that a t-statistic based on our improved estimator is asymptotically normal under certain conditions, allowing us to form confidence intervals and test hypotheses. Using synthetic data and public benchmarks, we provide empirical evidence for our estimator's improved accuracy and inferential properties relative to existing alternatives.
[16]
arXiv:2306.11979
(cross-list from stat.ME)
[pdf, html, other]
Title:
Qini Curves for Multi-Armed Treatment Rules
Erik Sverdrup, Han Wu, Susan Athey, Stefan Wager
Comments:
Forthcoming in the Journal of Computational and Graphical Statistics
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
Qini curves have emerged as an attractive and popular approach for evaluating the benefit of data-driven targeting rules for treatment allocation. We propose a generalization of the Qini curve to multiple costly treatment arms, that quantifies the value of optimally selecting among both units and treatment arms at different budget levels. We develop an efficient algorithm for computing these curves and propose bootstrap-based confidence intervals that are exact in large samples for any point on the curve. These confidence intervals can be used to conduct hypothesis tests comparing the value of treatment targeting using an optimal combination of arms with using just a subset of arms, or with a non-targeting assignment rule ignoring covariates, at different budget levels. We demonstrate the statistical performance in a simulation experiment and an application to treatment targeting for election turnout.
[17]
arXiv:2508.21536
(cross-list from stat.ME)
[pdf, other]
Title:
Triply Robust Panel Estimators
Susan Athey, Guido Imbens, Zhaonan Qu, Davide Viviano
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
This paper studies estimation of causal effects in a panel data setting. We introduce a new estimator, the Triply RObust Panel (TROP) estimator, that combines (i) a flexible model for the potential outcomes based on a low-rank factor structure on top of a two-way-fixed effect specification, with (ii) unit weights intended to upweight units similar to the treated units and (iii) time weights intended to upweight time periods close to the treated time periods. We study the performance of the estimator in a set of simulations designed to closely match several commonly studied real data sets. We find that there is substantial variation in the performance of the estimators across the settings considered. The proposed estimator outperforms two-way-fixed-effect/difference-in-differences, synthetic control, matrix completion and synthetic-difference-in-differences estimators. We investigate what features of the data generating process lead to this performance, and assess the relative importance of the three components of the proposed estimator. We have two recommendations. Our preferred strategy is that researchers use simulations closely matched to the data they are interested in, along the lines discussed in this paper, to investigate which estimators work well in their particular setting. A simpler approach is to use more robust estimators such as synthetic difference-in-differences or the new triply robust panel estimator which we find to substantially outperform two-way fixed effect estimators in many empirically relevant settings.
[18]
arXiv:2509.15594
(cross-list from stat.ME)
[pdf, html, other]
Title:
Beyond the Average: Distributional Causal Inference under Imperfect Compliance
Undral Byambadalai, Tomu Hirata, Tatsushi Oka, Shota Yasui
Comments:
arXiv admin note: text overlap with arXiv:2506.05945
Subjects:
Methodology (stat.ME); Econometrics (econ.EM); Statistics Theory (math.ST); Applications (stat.AP); Machine Learning (stat.ML)
We study the estimation of distributional treatment effects in randomized experiments with imperfect compliance. When participants do not adhere to their assigned treatments, we leverage treatment assignment as an instrumental variable to identify the local distributional treatment effect-the difference in outcome distributions between treatment and control groups for the subpopulation of compliers. We propose a regression-adjusted estimator based on a distribution regression framework with Neyman-orthogonal moment conditions, enabling robustness and flexibility with high-dimensional covariates. Our approach accommodates continuous, discrete, and mixed discrete-continuous outcomes, and applies under a broad class of covariate-adaptive randomization schemes, including stratified block designs and simple random sampling. We derive the estimator's asymptotic distribution and show that it achieves the semiparametric efficiency bound. Simulation results demonstrate favorable finite-sample performance, and we demonstrate the method's practical relevance in an application to the Oregon Health Insurance Experiment.
[19]
arXiv:2509.15898
(cross-list from math.PR)
[pdf, html, other]
Title:
Regularity properties of distributions of correspondences without countable generation: applications to large games
Motoki Otsuka
Subjects:
Probability (math.PR); Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH); Optimization and Control (math.OC)
We show that each of the regularity properties of regular conditional distributions of correspondences (convexity, closedness, compactness, and preservation of closed graphs) is equivalent to the condition of nowhere equivalence. This result does not require any countable-generation assumptions. As an application, we establish the existence of a pure-strategy equilibrium for large games with general trait spaces. The trait space may be an arbitrary measurable space. As a corollary, we obtain the existence of a pure-strategy equilibrium in semi-anonymous settings in which payoffs depend, in addition to agents' own actions, on the joint distribution over the space of agents and actions.
[20]
arXiv:2509.16052
(cross-list from cs.CR)
[pdf, html, other]
Title:
How Exclusive are Ethereum Transactions? Evidence from non-winning blocks
Vabuk Pahari, Andrea Canidio
Comments:
arXiv admin note: text overlap with arXiv:2506.04940
Subjects:
Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); General Economics (econ.GN)
We analyze 15,097 blocks proposed for inclusion in Ethereum's blockchain over an 8-minute window on December 3, 2024, during which 38 blocks were added to the chain. We classify transactions as exclusive -- present only in blocks from a single builder -- or private -- absent from the public mempool but included in blocks from multiple builders. We find that exclusive transactions account for 84% of the total fees paid by transactions in winning blocks. Furthermore, we show that exclusivity cannot be fully explained by exclusive relationships between senders and builders: about 7% of all exclusive transactions included on-chain, by value, come from senders who route exclusively to a single builder. Analyzing transaction logs shows that some exclusive transactions are duplicates or variations of the same strategy, but even accounting for that, the share of the total fees paid by transactions in winning blocks is at least 77.2%. Taken together, our findings highlight that exclusive transactions are the dominant source of builder revenues.
Replacement submissions (showing 6 of 6 entries)
[21]
arXiv:2203.11820
(replaced)
[pdf, html, other]
Title:
Dealing with Logs and Zeros in Regression Models
David Benatia, Christophe Bellégo, Louis Pape
Subjects:
Econometrics (econ.EM); Methodology (stat.ME)
The log transformation is widely used in linear regression, mainly because coefficients are interpretable as proportional effects. Yet this practice has fundamental limitations, most notably that the log is undefined at zero, creating an identification problem. We propose a new estimator, iterated OLS (iOLS), which targets the normalized average treatment effect, preserving the percentage-change interpretation while addressing these limitations. Our procedure is the theoretically justified analogue of the ad-hoc log(1+Y) transformation and delivers a consistent and asymptotically normal estimator of the parameters of the exponential conditional mean model. iOLS is computationally efficient, globally convergent, and free of the incidental-parameter bias, while extending naturally to endogenous regressors through iterated 2SLS. We illustrate the methods with simulations and revisit three influential publications.
[22]
arXiv:2403.15220
(replaced)
[pdf, html, other]
Title:
Modelling with Sensitive Variables
Felix Chan, Laszlo Matyas, Agoston Reguly
Comments:
31 pages, 2 tables, 2 figures
Subjects:
Econometrics (econ.EM); Methodology (stat.ME)
The paper deals with models in which the dependent variable, some explanatory variables, or both represent sensitive data. We introduce a novel discretization method that preserves data privacy when working with such variables. A multiple discretization method is proposed that utilizes information from the different discretization schemes. We show convergence in distribution for the unobserved variable and derive the asymptotic properties of the OLS estimator for linear models. Monte Carlo simulation experiments presented support our theoretical findings. Finally, we contrast our method with a differential privacy method to estimate the Australian gender wage gap.
[23]
arXiv:2501.16120
(replaced)
[pdf, html, other]
Title:
Copyright and Competition: Estimating Supply and Demand with Unstructured Data
Sukjin Han, Kyungho Lee
Subjects:
Econometrics (econ.EM); Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)
We study the competitive and welfare effects of copyright in creative industries in the face of cost-reducing technologies such as generative artificial intelligence. Creative products often feature unstructured attributes (e.g., images and text) that are complex and high-dimensional. To address this challenge, we study a stylized design product -- fonts -- using data from the world's largest font marketplace. We construct neural network embeddings to quantify unstructured attributes and measure visual similarity in a manner consistent with human perception. Spatial regression and event-study analyses demonstrate that competition is local in the visual characteristics space. Building on this evidence, we develop a structural model of supply and demand that incorporates embeddings and captures product positioning under copyright-based similarity constraints. Our estimates reveal consumers' heterogeneous design preferences and producers' cost-effective mimicry advantages. Counterfactual analyses show that copyright protection can raise consumer welfare by encouraging product relocation, and that the optimal policy depends on the interaction between copyright and cost-reducing technologies.
[24]
arXiv:2502.08440
(replaced)
[pdf, html, other]
Title:
Scenario Analysis with Multivariate Bayesian Machine Learning Models
Michael Pfarrhofer, Anna Stelzer
Comments:
Keywords: conditional forecast, generalized impulse response function, Bayesian additive regression trees, nonlinearities, structural inference; JEL: C32, C53, E44
Subjects:
Econometrics (econ.EM); Applications (stat.AP)
We present an econometric framework that adapts tools for scenario analysis, such as variants of conditional forecasts and generalized impulse responses, for use with dynamic nonparametric models. The proposed algorithms are based on predictive simulation and sequential Monte Carlo methods. Their utility is demonstrated with three applications: (1) conditional forecasts based on stress test scenarios, measuring (2) macroeconomic risk under varying financial stress, and estimating the (3) asymmetric effects of financial shocks in the US and their international spillovers. Our empirical results indicate the importance of nonlinearities and asymmetries in relationships between macroeconomic and financial variables.
[25]
arXiv:2505.05275
(replaced)
[pdf, html, other]
Title:
How General Are Measures of Choice Consistency? Evidence from Experimental and Scanner Data
Mingshi Chen, Tracy Xiao Liu, You Shan, Shu Wang, Songfa Zhong, Yanju Zhou
Subjects:
General Economics (econ.GN)
Choice consistency with utility maximization, as a key assumption in economics, has been extensively used to evaluate decision quality of individuals and to predict real-world outcomes across different contexts. Here we investigate the generalizability of consistency measures derived from budgetary decisions in the lab-in-the-field experiment and purchasing decisions using supermarket scanner data. In the first study, we observe a lack of correlation between consistency scores derived from risky decisions in the experiment and those from supermarket food purchasing decisions. In the second study, we observe moderate correlations between experimental tasks and low to moderate correlations across purchasing categories and over time periods within the supermarket. Moreover, consistency in the two settings exhibits distinct predictive validity in predicting consumer behavior. These results suggest that choice consistency, as a measure of decision quality, may be better characterized as a multidimensional skill set rather than a single-dimensional ability.
[26]
arXiv:2506.10480
(replaced)
[pdf, html, other]
Title:
Getting Explicit Instruction Right
Richard Holden, Fabio I. Martinenghi
Subjects:
General Economics (econ.GN)
There has been substantial public debate about the potentially deleterious effects of the long-run move to ``inquiry-based learning'' in which students are placed at the center of an educational journey and arrive at their own understanding of what is being taught. There have been numerous calls for a return to ``direct'' or ``explicit'' instruction. This paper focuses on identifying the causal effect of correctly implementing explicit instruction on student performance in standardized tests. We utilise a unique setting in Australia\textemdash a country in which all students in grades 3, 5, 7, and 9 undergo annual basic skills tests (``NAPLAN''). We use a synthetic control approach to study the effect of introducing Explicit Instruction in Charlestown South Public School\textemdash a median-performing school\textemdash on Year-3 and Year-5 NAPLAN scores in Reading and Numeracy. Importantly, this is achieved via peer modelling, with Charlestown teaching staff sitting-in during the classes of a high-performing explicit-instruction school. We find that the performance gains are substantial and persistent. JEL: I20, I21. Keywords: Education, Explicit Instruction, Pedagogy.
Total of 26 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack