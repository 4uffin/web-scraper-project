Economics
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
econ
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Economics
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Thursday, 25 September 2025
Total of 21 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 9 of 9 entries)
[1]
arXiv:2509.19413
[pdf, other]
Title:
Research and development as a driver of innovation and economic growth; case of developing economies
Ayusha Fayyaz, Zoltan Bartha
Journal-ref:
Journal of Social and Economic Development, 2025
Subjects:
General Economics (econ.GN)
The goal of this research is to uncover the channels through which research and development (R&D) impacts economic growth in developing countries. The study employed nine variables from three broader categories in the World Economic Forum database, each covering 32 countries from the lower-middle-income group for the year 2019. The theoretical framework is based on the R&D ecosystem, which includes components such as Institutions, Human capital, Capital market, R&D, and Innovation. Each of these components can contribute to the economic development of the country. Using Structural Equation Modelling (SEM), we build a path diagram to visualize and confirm a potential relationship between the components. R&D features had a positive impact on innovation (regression weight estimate: +0.34, p = 0.001), as did capital market institutions (regression weight estimate: +0.12, p = 0.007), but neither had a significant impact on growth. According to the Schumpeterian institutional interpretation, R&D and innovation efforts may not lead to sustained growth in middle-income countries. We find no significant connection between innovation performance and economic growth. This suggests that while R&D and capital markets may contribute to innovation through entrepreneurship, this contribution is not impactful enough to drive economic growth in developing countries. Our findings provide further evidence of the middle-income trap.
[2]
arXiv:2509.19416
[pdf, other]
Title:
Changes in varieties of capitalism within the OECD between 2010 and 2020
Zoltan Bartha
Journal-ref:
International Journal of Public Policy, 2024
Subjects:
General Economics (econ.GN)
This study aims to reveal different varieties of capitalism and to uncover new patterns of development that emerged between 2010 and 2020. A hybrid model is applied that quantifies three pillars of development (Future - F, Outside - O, Inside - I) using supply-side and demand-side indicators that measure norms, institutions, and policies. Investigating 34 OECD members, this study describes five varieties of capitalism: traditional, dualistic, government-led, open market-based, and human capital-based models. It is suggested that the most significant cut-off point in the development of OECD economies in this period was along the green growth dimension, where European countries with a tradition in coordinated markets outperform the rest. Using Israel and Estonia as an example, it is also suggested that institutional and policy changes that enhance the quality of governance and make coordination more effective are the way out of the middle-income trap.
[3]
arXiv:2509.19556
[pdf, html, other]
Title:
Gender and Agricultural Commercialization in Sub-Saharan Africa: Evidence from Three Panel Surveys
Wei Li, Kashi Kafle, Anna Josephson
Subjects:
General Economics (econ.GN)
Agricultural commercialization is often promoted as a key driver of development in Sub-Saharan Africa, yet its benefits may not extend equally to all farmers. Using longitudinal household data from the LSMS-ISA and a two-way Mundlak fixed effects estimator, we examine the relationship between farmers' gender and agricultural commercialization in Ethiopia, Nigeria, and Tanzania. In Ethiopia and Nigeria, women-headed households and those with a higher share of women-managed land face substantial disadvantages in market engagement, particularly in households oriented towards self-consumption. Interestingly, in both countries, women-headed households that do engage in sales are more likely to sell to market buyers and less likely to sell to individual buyers compared to men-headed households. In contrast, in Tanzania, the negative associations between gender and commercialization are weaker and less robust across outcomes. Overall, these findings demonstrate that gender gaps in commercialization are highly context-specific rather than universal, highlighting the need for country-tailored policies that address the institutional and market constraints faced by women farmers.
[4]
arXiv:2509.19591
[pdf, html, other]
Title:
An Analysis of Monetary Policy Evidence and Theory through Meta-Analyses
Ricardo Alonzo Fernandez Salguero
Subjects:
Theoretical Economics (econ.TH)
This paper offers a synthesis of the empirical literature on the effects of monetary policy. Using the findings from an extensive collection of meta-analyses, it evaluates the effectiveness of conventional and unconventional monetary policy instruments on key macroeconomic variables such as output, inflation, capital flows, and the exchange rate. The aggregated evidence reveals a systematic gap between the effects reported in primary studies and the actual magnitude of these effects, once corrected for publication bias and methodological heterogeneity. The findings suggest that, while monetary policy is a relevant tool, its power to modulate the business cycle has been consistently overestimated in the literature. Contextual factors - such as the degree of financial development, the exchange rate regime, central bank independence, and crisis conditions - that modulate the transmission of monetary policy are identified. In particular, it is found that publication bias systematically favors statistically significant results consistent with predominant theory, which artificially inflates the perception of effectiveness. By correcting these distortions, a picture of monetary policy emerges with more modest, uncertain effects and considerable lags, which has profound implications for macroeconomic theory and the practice of economic policy.
[5]
arXiv:2509.19823
[pdf, other]
Title:
A Simple Characterization of Qualified Majority Voting Rules
Héctor Hermida-Rivera
Subjects:
Theoretical Economics (econ.TH)
This note characterizes every qualified majority voting rule with a quota $q$ strictly greater than half of the voter set in environments with just two alternatives through anonymity, responsiveness, and $q$-neutrality. Crucially, the latter imposes independence of the labels of the alternatives only for all preference profiles in which some alternative is strictly top-ranked by at least $q$ voters. Thus, this note generalizes May's (1952, Theorem, p.~682) well-known axiomatic characterization of the simple majority voting rule to qualified majority voting rules with a quota $q$ strictly greater than half of the voter set. In doing so, it shows that these qualified majority voting rules are precisely distinguished by their "degree" of neutrality.
[6]
arXiv:2509.19911
[pdf, other]
Title:
Decomposing Co-Movements in Matrix-Valued Time Series: A Pseudo-Structural Reduced-Rank Approach
Alain Hecq, Ivan Ricardo, Ines Wilms
Subjects:
Econometrics (econ.EM)
We propose a pseudo-structural framework for analyzing contemporaneous co-movements in reduced-rank matrix autoregressive (RRMAR) models. Unlike conventional vector-autoregressive (VAR) models that would discard the matrix structure, our formulation preserves it, enabling a decomposition of co-movements into three interpretable components: row-specific, column-specific, and joint (row-column) interactions across the matrix-valued time series. Our estimator admits standard asymptotic inference and we propose a BIC-type criterion for the joint selection of the reduced ranks and the autoregressive lag order. We validate the method's finite-sample performance in terms of estimation accuracy, coverage and rank selection in simulation experiments, including cases of rank misspecification. We illustrate the method's practical usefelness in identifying co-movement structures in two empirical applications: U.S. state-level coincident and leading indicators, and cross-country macroeconomic indicators.
[7]
arXiv:2509.19945
[pdf, html, other]
Title:
Identification and Estimation of Seller Risk Aversion in Ascending Auctions
Nathalie Gimenes, Tonghui Qi, Sorawoot Srisuma
Subjects:
Econometrics (econ.EM)
How sellers choose reserve prices is central to auction theory, and the optimal reserve price depends on the seller's risk attitude. Numerous studies have found that observed reserve prices lie below the optimal level implied by risk-neutral sellers, while the theoretical literature suggests that risk-averse sellers can rationalize these empirical findings. In this paper, we develop an econometric model of ascending auctions with a risk-averse seller under independent private values. We provide primitive conditions for the identification of the Arrow-Pratt measures of risk aversion and an estimator for these measures that is consistent and converges in distribution to a normal distribution at the parametric rate under standard regularity conditions. A Monte Carlo study demonstrates good finite-sample performance of the estimator, and we illustrate the approach using data from foreclosure real estate auctions in São Paulo.
[8]
arXiv:2509.20000
[pdf, other]
Title:
Business Cycles explained by Instability
Galiya Klinkova, Michael Grabinski
Subjects:
Theoretical Economics (econ.TH)
Business cycles (a periodic change of e.g. GDP over five to ten years) exist, but a proper explanation for it is still lacking. Here we extend the well-known NAIRU (non-accelerating inflation rate of unemployment) model, resulting in a set of differ-ential equations. However, the solution is marginal stable. Therefore we find a nat-ural sinusoidal oscillation of inflation and unemployment just as observed in busi-ness cycles. When speculation is present, the instability becomes more severe. So we present for the first time a mathematical explanation for business cycles. The steering of central banks by setting interest rates to keep inflation stable and low needs an overhaul. One has to distinguish between real monetary instability and the one caused naturally by business cycles.
[9]
arXiv:2509.20203
[pdf, other]
Title:
Healthy diets are affordable but often displaced by other foods in Indonesia
Leah Costlow, Rachel Gilbert, William A. Masters, Flaminia Ortenzi, Ty Beal, Ashish Deo, Widya Sutiyo, Sutamara Noor, Wendy Gonzalez
Subjects:
General Economics (econ.GN)
New methods for modeling least-cost diets that meet nutritional requirements for health have emerged as important tools for informing nutrition policy and programming around the world. This study develops a three-step approach using cost of healthy diet to inform targeted nutrition programming in Indonesia. We combine detailed retail prices and household survey data from Indonesia to describe how reported consumption and expenditure patterns across all levels of household income diverge from least cost healthy diets using items from nearby markets. In this analysis, we examine regional price variations, identify households with insufficient income for healthy diets, and analyze the nutrient adequacy of reported consumption patterns. We find that household food spending was sufficient to meet national dietary guidelines using the least expensive locally available items for over 98% of Indonesians, but almost all households consume substantial quantities of discretionary foods and mixed dishes while consuming too little energy from fruits, vegetables, and legumes, nuts, and seeds. Households with higher incomes have higher nutrient adequacy and are closer to meeting local dietary guidelines, but still fall short of recommendations. These findings shed new light on how actual food demand differs from least-cost healthy diets, due to factors other than affordability, such as taste, convenience, and aspirations shaped by marketing and other sociocultural influences.
Cross submissions (showing 1 of 1 entries)
[10]
arXiv:2509.20194
(cross-list from stat.ME)
[pdf, other]
Title:
Identification and Semiparametric Estimation of Conditional Means from Aggregate Data
Cory McCartan, Shiro Kuriwaki
Comments:
24 pages, plus references and appendices
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
We introduce a new method for estimating the mean of an outcome variable within groups when researchers only observe the average of the outcome and group indicators across a set of aggregation units, such as geographical areas. Existing methods for this problem, also known as ecological inference, implicitly make strong assumptions about the aggregation process. We first formalize weaker conditions for identification, which motivates estimators that can efficiently control for many covariates. We propose a debiased machine learning estimator that is based on nuisance functions restricted to a partially linear form. Our estimator also admits a semiparametric sensitivity analysis for violations of the key identifying assumption, as well as asymptotically valid confidence intervals for local, unit-level estimates under additional assumptions. Simulations and validation on real-world data where ground truth is available demonstrate the advantages of our approach over existing methods. Open-source software is available which implements the proposed methods.
Replacement submissions (showing 11 of 11 entries)
[11]
arXiv:2211.11915
(replaced)
[pdf, html, other]
Title:
A Misuse of Specification Tests
Naoya Sueishi
Subjects:
Econometrics (econ.EM)
Empirical researchers often perform model specification tests, such as Hausman tests and overidentifying restrictions tests, to assess the validity of estimators rather than that of models. This paper examines the effectiveness of such specification pretests in detecting invalid estimators. We analyze the local asymptotic properties of test statistics and estimators and show that locally unbiased specification tests cannot determine whether asymptotically efficient estimators are asymptotically biased. In particular, an estimator may remain valid even when the null hypothesis of correct model specification is false, and it may be invalid even when the null hypothesis is true. The main message of the paper is that correct model specification and valid estimation are distinct issues: correct specification is neither necessary nor sufficient for asymptotically unbiased estimation.
[12]
arXiv:2403.15220
(replaced)
[pdf, html, other]
Title:
Modelling with Sensitive Variables
Felix Chan, Laszlo Matyas, Agoston Reguly
Comments:
31 pages, 2 tables, 2 figures
Subjects:
Econometrics (econ.EM); Methodology (stat.ME)
The paper deals with models in which the dependent variable, some explanatory variables, or both represent sensitive data. We introduce a novel discretization method that preserves data privacy when working with such variables. A multiple discretization method is proposed that utilizes information from the different discretization schemes. We show convergence in distribution for the unobserved variable and derive the asymptotic properties of the OLS estimator for linear models. Monte Carlo simulation experiments presented support our theoretical findings. Finally, we contrast our method with a differential privacy method to estimate the Australian gender wage gap.
[13]
arXiv:2405.17787
(replaced)
[pdf, other]
Title:
Dyadic Regression with Sample Selection
Kensuke Sakamoto
Subjects:
Econometrics (econ.EM)
This paper addresses the sample selection problem in panel dyadic regression analysis. Dyadic data often include many zeros in the main outcomes due to the underlying network formation process. This not only contaminates popular estimators used in practice but also complicates the inference due to the dyadic dependence structure. We extend Kyriazidou (1997)'s approach to dyadic data and characterize the asymptotic distribution of our proposed estimator. The convergence rates are $\sqrt{n}$ or $\sqrt{n^{2}h_{n}}$, depending on the degeneracy of the Hájek projection part of the estimator, where $n$ is the number of nodes and $h_{n}$ is a bandwidth. We propose a bias-corrected confidence interval and a variance estimator that adapts to the degeneracy. A Monte Carlo simulation shows the good finite sample performance of our estimator and highlights the importance of bias correction in both asymptotic regimes when the fraction of zeros in outcomes varies. We illustrate our procedure using data from Moretti and Wilson (2017)'s paper on migration.
[14]
arXiv:2407.00890
(replaced)
[pdf, html, other]
Title:
Macroeconomic Forecasting with Large Language Models
Andrea Carriero, Davide Pettenuzzo, Shubhranshu Shekhar
Subjects:
Econometrics (econ.EM); Computation and Language (cs.CL); Machine Learning (cs.LG)
This paper presents a comparative analysis evaluating the accuracy of Large Language Models (LLMs) against traditional macro time series forecasting approaches. In recent times, LLMs have surged in popularity for forecasting due to their ability to capture intricate patterns in data and quickly adapt across very different domains. However, their effectiveness in forecasting macroeconomic time series data compared to conventional methods remains an area of interest. To address this, we conduct a rigorous evaluation of LLMs against traditional macro forecasting methods, using as common ground the FRED-MD database. Our findings provide valuable insights into the strengths and limitations of LLMs in forecasting macroeconomic time series, shedding light on their applicability in real-world scenarios
[15]
arXiv:2410.05504
(replaced)
[pdf, html, other]
Title:
Persuasion with Ambiguous Communication
Xiaoyu Cheng, Peter Klibanoff, Sujoy Mukerji, Ludovic Renou
Subjects:
Theoretical Economics (econ.TH)
We explore whether ambiguous communication can be beneficial to the sender in a persuasion problem, when the receiver (and possibly the sender) is ambiguity averse. Our analysis highlights the necessity of using a collection of experiments that form a splitting of an obedient experiment. Some experiments in the collection must be Pareto-ranked in that both players agree on their payoff ranking. If an optimal Bayesian persuasion experiment can be split in this way, then any not-too-ambiguity-averse sender as well as the receiver benefit. There are no benefits when the receiver has only two actions.
[16]
arXiv:2503.04476
(replaced)
[pdf, other]
Title:
Optimizing Economic Complexity
Viktor Stojkoski, César A. Hidalgo
Subjects:
General Economics (econ.GN)
Efforts to apply economic complexity to identify diversification opportunities often rely on diagrams comparing the relatedness and complexity or products, technologies, or industries. Yer, the use of these diagrams is not based on empirical or theoretidal evidence supporting some notion of optimality. Here, we introduce an optimization-based framework that identifies diversification opportunities by minimizing a cost function capturing the constraints imposed by an economy's pattern of specialization. We show that the resulting portfolios often differ from those implied by relatedness-complexity diagrams, providing a target-oriented optimization layer to the economic complexity toolkit.
[17]
arXiv:2504.21156
(replaced)
[pdf, html, other]
Title:
Publication Design with Incentives in Mind
Ravi Jagadeesan, Davide Viviano
Subjects:
Econometrics (econ.EM); Theoretical Economics (econ.TH); Statistics Theory (math.ST)
The publication process both determines which research receives the most attention, and influences the supply of research through its impact on researchers' private incentives. We introduce a framework to study optimal publication decisions when researchers can choose (i) whether or how to conduct a study and (ii) whether or how to manipulate the research findings (e.g., via selective reporting or data manipulation). When manipulation is not possible, but research entails substantial private costs for the researchers, it may be optimal to incentivize cheaper research designs even if they are less accurate. When manipulation is possible, it is optimal to publish some manipulated results, as well as results that would have not received attention in the absence of manipulability. Even if it is possible to deter manipulation, such as by requiring pre-registered experiments instead of (potentially manipulable) observational studies, it is suboptimal to do so when experiments entail high research costs. We illustrate the implications of our model in an application to medical studies.
[18]
arXiv:2507.09419
(replaced)
[pdf, html, other]
Title:
Comrades and Cause: Peer Influence on West Point Cadets' Civil War Allegiances
Yuchen Guo, Matthew O. Jackson, Ruixue Jia
Subjects:
General Economics (econ.GN)
Do social networks and peer influence shape major life decisions in highly polarized settings? We explore this question by examining how peers influenced the allegiances of West Point cadets during the American Civil War. Leveraging quasi-random variations in the proportion of cadets from Free States, we analyze how these differences affected cadets' decisions about which army to join. We have four main findings. First, there was a strong and significant peer effect: a higher proportion of classmates from Free States significantly increased the likelihood that cadets from Slave States joined the Union Army. Second, the peer effect interacted with geography and economic circumstances: almost all cadets from Free States joined the Union Army (if they decided to join the war), and most cadets from Slave States that had more than a third of their population in slavery joined the Confederacy. The cadets who were most highly influenced were from Slave States that had less than a third of their population in slavery. Third, we analyze how cadets' decisions affected their military rank and career outcomes. Fourth, we show that having served together in the Mexican-American war increased the peer influence, providing additional evidence that peer interaction was influential.
[19]
arXiv:2509.05760
(replaced)
[pdf, html, other]
Title:
Rethinking Beta: A Causal Take on CAPM
Naftali Cohen
Subjects:
Theoretical Economics (econ.TH); Pricing of Securities (q-fin.PR); Statistical Finance (q-fin.ST); Applications (stat.AP)
The CAPM regression is typically interpreted as if the market return contemporaneously \emph{causes} individual returns, motivating beta-neutral portfolios and factor attribution. For realized equity returns, however, this interpretation is inconsistent: a same-period arrow $R_{m,t} \to R_{i,t}$ conflicts with the fact that $R_m$ is itself a value-weighted aggregate of its constituents, unless $R_m$ is lagged or leave-one-out -- the ``aggregator contradiction.'' We formalize CAPM as a structural causal model and analyze the admissible three-node graphs linking an external driver $Z$, the market $R_m$, and an asset $R_i$. The empirically plausible baseline is a \emph{fork}, $Z \to \{R_m, R_i\}$, not $R_m \to R_i$. In this setting, OLS beta reflects not a causal transmission, but an attenuated proxy for how well $R_m$ captures the underlying driver $Z$. Consequently, ``beta-neutral'' portfolios can remain exposed to macro or sectoral shocks, and hedging on $R_m$ can import index-specific noise. Using stylized models and large-cap U.S.\ equity data, we show that contemporaneous betas act like proxies rather than mechanisms; any genuine market-to-stock channel, if at all, appears only at a lag and with modest economic significance. The practical message is clear: CAPM should be read as associational. Risk management and attribution should shift from fixed factor menus to explicitly declared causal paths, with ``alpha'' reserved for what remains invariant once those causal paths are explicitly blocked.
[20]
arXiv:2309.08808
(replaced)
[pdf, other]
Title:
Adaptive Neyman Allocation
Jinglong Zhao
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
In the experimental design literature, Neyman allocation refers to the practice of allocating units into treated and control groups, potentially in unequal numbers proportional to their respective standard deviations, with the objective of minimizing the variance of the treatment effect estimator. This widely recognized approach increases statistical power in scenarios where the treated and control groups have different standard deviations, as is often the case in social experiments, clinical trials, marketing research, and online A/B testing. However, Neyman allocation cannot be implemented unless the standard deviations are known in advance. Fortunately, the multi-stage nature of the aforementioned applications allows the use of earlier stage observations to estimate the standard deviations, which further guide allocation decisions in later stages. In this paper, we introduce a competitive analysis framework to study this multi-stage experimental design problem. We propose a simple adaptive Neyman allocation algorithm, which almost matches the information-theoretic limit of conducting experiments. We provide theory for estimation and inference using data collected from our adaptive Neyman allocation algorithm. We demonstrate the effectiveness of our adaptive Neyman allocation algorithm using both online A/B testing data from a social media site and synthetic data.
[21]
arXiv:2504.19018
(replaced)
[pdf, html, other]
Title:
Finite-Sample Properties of Generalized Ridge Estimators in Nonlinear Models
Masamune Iwasawa
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
This paper addresses the longstanding challenge of analyzing the mean squared error (MSE) of ridge-type estimators in nonlinear models, including duration, Poisson, and multinomial choice models, where theoretical results have been scarce. Using a finite-sample approximation technique from the econometrics literature, we derive new results showing that the generalized ridge maximum likelihood estimator (MLE) with a sufficiently small penalty achieves lower finite-sample MSE for both estimation and prediction than the conventional MLE, regardless of whether the hypotheses incorporated in the penalty are valid. A key theoretical contribution is to demonstrate that generalized ridge estimators generate a variance-bias trade-off in the first-order MSE of nonlinear likelihood-based models -- a feature absent for the conventional MLE -- which enables ridge-type estimators to attain smaller MSE when the penalty is properly selected. Extensive simulations and an empirical application to the estimation of marginal mean and quantile treatment effects further confirm the superior performance and practical relevance of the proposed method.
Total of 21 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack