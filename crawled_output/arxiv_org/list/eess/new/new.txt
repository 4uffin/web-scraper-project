Electrical Engineering and Systems Science
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
eess
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Electrical Engineering and Systems Science
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Monday, 22 September 2025
Total of 155 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 53 of 53 entries)
[1]
arXiv:2509.15261
[pdf, html, other]
Title:
Pre-training Autoencoder for Acoustic Event Classification via Blinky
Xiaoyang Liu, Yuma Kinoshita
Comments:
Accepted to APSIPA ASC 2025. 6 pages, 1 figures
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
In the acoustic event classification (AEC) framework that employs Blinkies, audio signals are converted into LED light emissions and subsequently captured by a single video camera. However, the 30 fps optical transmission channel conveys only about 0.2% of the normal audio bandwidth and is highly susceptible to noise. We propose a novel sound-to-light conversion method that leverages the encoder of a pre-trained autoencoder (AE) to distill compact, discriminative features from the recorded audio. To pre-train the AE, we adopt a noise-robust learning strategy in which artificial noise is injected into the encoder's latent representations during training, thereby enhancing the model's robustness against channel noise. The encoder architecture is specifically designed for the memory footprint of contemporary edge devices such as the Raspberry Pi 4. In a simulation experiment on the ESC-50 dataset under a stringent 15 Hz bandwidth constraint, the proposed method achieved higher macro-F1 scores than conventional sound-to-light conversion approaches.
[2]
arXiv:2509.15344
[pdf, html, other]
Title:
Modeling Adaptive Tracking of Predictable Stimuli in Electric Fish
Yu Yang, Andreas Oliveira, Louis L. Whitcomb, Felipe Pait, Mario Sznaier, Noah J. Cowan
Comments:
Submitted for joint consideration to the IEEE Control Systems Letters and American Control Conference 2026
Subjects:
Systems and Control (eess.SY); Neurons and Cognition (q-bio.NC)
The weakly electric fish \emph{Eigenmannia virescens} naturally swims back and forth to stay within a moving refuge, tracking its motion using visual and electrosensory feedback. Previous experiments show that when the refuge oscillates as a low-frequency sinusoid (below about 0.5 Hz), the tracking is nearly perfect, but phase lag increases and gain decreases at higher frequencies. Here, we model this nonlinear behavior as an adaptive internal model principle (IMP) system. Specifically, an adaptive state estimator identifies the \emph{a priori} unknown frequency, and feeds this parameter estimate into a closed-loop IMP-based system built around a lightly damped harmonic oscillator. We prove that the closed-loop tracking error of the IMP-based system, where the online adaptive frequency estimate is used as a surrogate for the unknown frequency, converges exponentially to that of an ideal control system with perfect information about the stimulus. Simulations further show that our model reproduces the fish refuge tracking Bode plot across a wide frequency range. These results establish the theoretical validity of combining the IMP with an adaptive identification process and provide a basic framework in adaptive sensorimotor control.
[3]
arXiv:2509.15354
[pdf, html, other]
Title:
Risk-Aware Congestion Management with Capacity Limitation Contracts and Redispatch
Bart van der Holst, Phuong Nguyen, Johan Morren, Koen Kok
Subjects:
Systems and Control (eess.SY)
This paper presents the coordination of two congestion management instruments - capacity limitation contracts (CLCs) and redispatch contracts (RCs) - as a risk-aware resource allocation problem. We propose that the advantages and drawbacks of these instruments can be represented as operational risk profiles and can be balanced through coordination. To this end, we develop a chance-constrained two-stage stochastic mixed-integer program for a system operator procuring flexibility from an aggregator managing a fleet of electric vehicles (EVs). The model captures uncertainty in EV charging and redispatch market conditions, using real order book data from the Dutch redispatch market (GOPACS).
Results indicate that combining CLCs and RCs is generally the most cost-effective approach to mitigate risks associated with each instrument, but the optimal mix depends on fleet size and RC activation timing. Large uncertainty about EV loading increases RC activation intraday to correct for forecasting errors at the earlier CLC stage. For large fleet sizes (e.g. 25.000) the optimal policy limits redispatch due to market liquidity risks in the immature redispatch market. This risk increases for later redispatch activation due to shrinking trading windows for redispatch products. These findings highlight how various sources of uncertainty can impact the optimal trade-off between congestion management instruments.
[4]
arXiv:2509.15363
[pdf, html, other]
Title:
Recent Advancements in Microscopy Image Enhancement using Deep Learning: A Survey
Debasish Dutta, Neeharika Sonowal, Risheraj Barauh, Deepjyoti Chetia, Sanjib Kr Kalita
Comments:
7 pages, 3 figures and 1 table. 2024 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI). IEEE, 2024
Subjects:
Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
Microscopy image enhancement plays a pivotal role in understanding the details of biological cells and materials at microscopic scales. In recent years, there has been a significant rise in the advancement of microscopy image enhancement, specifically with the help of deep learning methods. This survey paper aims to provide a snapshot of this rapidly growing state-of-the-art method, focusing on its evolution, applications, challenges, and future directions. The core discussions take place around the key domains of microscopy image enhancement of super-resolution, reconstruction, and denoising, with each domain explored in terms of its current trends and their practical utility of deep learning.
[5]
arXiv:2509.15422
[pdf, html, other]
Title:
Analysis Plug-and-Play Methods for Imaging Inverse Problems
Edward P. Chandler, Shirin Shoushtari, Brendt Wohlberg, Ulugbek S. Kamilov
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Plug-and-Play Priors (PnP) is a popular framework for solving imaging inverse problems by integrating learned priors in the form of denoisers trained to remove Gaussian noise from images. In standard PnP methods, the denoiser is applied directly in the image domain, serving as an implicit prior on natural images. This paper considers an alternative analysis formulation of PnP, in which the prior is imposed on a transformed representation of the image, such as its gradient. Specifically, we train a Gaussian denoiser to operate in the gradient domain, rather than on the image itself. Conceptually, this is an extension of total variation (TV) regularization to learned TV regularization. To incorporate this gradient-domain prior in image reconstruction algorithms, we develop two analysis PnP algorithms based on half-quadratic splitting (APnP-HQS) and the alternating direction method of multipliers (APnP-ADMM). We evaluate our approach on image deblurring and super-resolution, demonstrating that the analysis formulation achieves performance comparable to image-domain PnP algorithms.
[6]
arXiv:2509.15473
[pdf, html, other]
Title:
Breathing and Semantic Pause Detection and Exertion-Level Classification in Post-Exercise Speech
Yuyu Wang, Wuyue Xia, Huaxiu Yao, Jingping Nie
Comments:
6 pages, 3rd ACM International Workshop on Intelligent Acoustic Systems and Applications (IASA 25)
Subjects:
Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD)
Post-exercise speech contains rich physiological and linguistic cues, often marked by semantic pauses, breathing pauses, and combined breathing-semantic pauses. Detecting these events enables assessment of recovery rate, lung function, and exertion-related abnormalities. However, existing works on identifying and distinguishing different types of pauses in this context are limited. In this work, building on a recently released dataset with synchronized audio and respiration signals, we provide systematic annotations of pause types. Using these annotations, we systematically conduct exploratory breathing and semantic pause detection and exertion-level classification across deep learning models (GRU, 1D CNN-LSTM, AlexNet, VGG16), acoustic features (MFCC, MFB), and layer-stratified Wav2Vec2 representations. We evaluate three setups-single feature, feature fusion, and a two-stage detection-classification cascade-under both classification and regression formulations. Results show per-type detection accuracy up to 89$\%$ for semantic, 55$\%$ for breathing, 86$\%$ for combined pauses, and 73$\%$overall, while exertion-level classification achieves 90.5$\%$ accuracy, outperformin prior work.
[7]
arXiv:2509.15475
[pdf, html, other]
Title:
(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation
Lioz Berman, Sharon Gannot, Tom Tirer
Comments:
Code can be found at this https URL
Subjects:
Signal Processing (eess.SP); Machine Learning (cs.LG); Machine Learning (stat.ML)
We consider the problem of estimating the directions of arrival (DOAs) of multiple sources from a single snapshot of an antenna array, a task with many practical applications. In such settings, the classical Bartlett beamformer is commonly used, as maximum likelihood estimation becomes impractical when the number of sources is unknown or large, and spectral methods based on the sample covariance are not applicable due to the lack of multiple snapshots. However, the accuracy and resolution of the Bartlett beamformer are fundamentally limited by the array aperture. In this paper, we propose a deep learning technique, comprising a novel architecture and training strategy, for generating a high-resolution spatial spectrum from a single snapshot. Specifically, we train a deep neural network that takes the measurements and a hypothesis angle as input and learns to output a score consistent with the capabilities of a much wider array. At inference time, a heatmap can be produced by scanning an arbitrary set of angles. We demonstrate the advantages of our trained model, named (SP)$^2$-Net, over the Bartlett beamformer and sparsity-based DOA estimation methods.
[8]
arXiv:2509.15516
[pdf, html, other]
Title:
State-of-the-Art Dysarthric Speech Recognition with MetaICL for on-the-fly Personalization
Dhruuv Agarwal, Harry Zhang, Yang Yu, Quan Wang
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
Personalizing Automatic Speech Recognition (ASR) for dysarthric speech is crucial but challenging due to training and storing of individual user adapters. We propose a hybrid meta-training method for a single model, excelling in zero-shot and few-shot on-the-fly personalization via in-context learning (ICL). Measuring Word Error Rate (WER) on state-of-the-art subsets, the model achieves 13.9% WER on Euphonia which surpasses speaker-independent baselines (17.5% WER) and rivals user-specific personalized models. On SAP Test 1, its 5.3% WER significantly bests the 8% from even personalized adapters. We also demonstrate the importance of example curation, where an oracle text-similarity method shows 5 curated examples can achieve performance similar to 19 randomly selected ones, highlighting a key area for future efficiency gains. Finally, we conduct data ablations to measure the data efficiency of this approach. This work presents a practical, scalable, and personalized solution.
[9]
arXiv:2509.15523
[pdf, html, other]
Title:
AFT: An Exemplar-Free Class Incremental Learning Method for Environmental Sound Classification
Xinyi Chen, Xi Chen, Zhenyu Weng, Yang Xiao
Comments:
Submitted to ICASSP 2026
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
As sounds carry rich information, environmental sound classification (ESC) is crucial for numerous applications such as rare wild animals detection. However, our world constantly changes, asking ESC models to adapt to new sounds periodically. The major challenge here is catastrophic forgetting, where models lose the ability to recognize old sounds when learning new ones. Many methods address this using replay-based continual learning. This could be impractical in scenarios such as data privacy concerns. Exemplar-free methods are commonly used but can distort old features, leading to worse performance. To overcome such limitations, we propose an Acoustic Feature Transformation (AFT) technique that aligns the temporal features of old classes to the new space, including a selectively compressed feature space. AFT mitigates the forgetting of old knowledge without retaining past data. We conducted experiments on two datasets, showing consistent improvements over baseline models with accuracy gains of 3.7\% to 3.9\%.
[10]
arXiv:2509.15564
[pdf, html, other]
Title:
CSIT-Free Downlink Transmission for mmWave MU-MISO Systems in High-Mobility Scenario
Jeongjae Lee, Wonseok Choi, Songnam Hong
Comments:
Submitted to IEEE Conference
Subjects:
Signal Processing (eess.SP)
This paper investigates the downlink (DL) transmission in millimeter-wave (mmWave) multi-user multiple-input single-output (MU-MISO) systems especially focusing on a high speed mobile scenario. To complete the DL transmission within an extremely short channel coherence time, we propose a novel DL transmission framework that eliminates the need for channel state information at the transmitter (CSIT), of which acquisition process requires a substantial overhead, instead fully exploiting the given channel coherence time. Harnessing the characteristic of mmWave channel and uniquely designed CSIT-free unitary precoding, we propose a symbol detection method along with the simultaneous CSI at the receiver (CSIR) and Doppler shift estimation method to completely cancel the interferences while achieving a full combining gain. Via simulations, we demonstrate the effectiveness of the proposed method comparing with the existing baselines.
[11]
arXiv:2509.15595
[pdf, html, other]
Title:
Prostate Capsule Segmentation from Micro-Ultrasound Images using Adaptive Focal Loss
Kaniz Fatema, Vaibhav Thakur, Emad A. Mohammed
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Micro-ultrasound (micro-US) is a promising imaging technique for cancer detection and computer-assisted visualization. This study investigates prostate capsule segmentation using deep learning techniques from micro-US images, addressing the challenges posed by the ambiguous boundaries of the prostate capsule. Existing methods often struggle in such cases, motivating the development of a tailored approach. This study introduces an adaptive focal loss function that dynamically emphasizes both hard and easy regions, taking into account their respective difficulty levels and annotation variability. The proposed methodology has two primary strategies: integrating a standard focal loss function as a baseline to design an adaptive focal loss function for proper prostate capsule segmentation. The focal loss baseline provides a robust foundation, incorporating class balancing and focusing on examples that are difficult to classify. The adaptive focal loss offers additional flexibility, addressing the fuzzy region of the prostate capsule and annotation variability by dilating the hard regions identified through discrepancies between expert and non-expert annotations. The proposed method dynamically adjusts the segmentation model's weights better to identify the fuzzy regions of the prostate capsule. The proposed adaptive focal loss function demonstrates superior performance, achieving a mean dice coefficient (DSC) of 0.940 and a mean Hausdorff distance (HD) of 1.949 mm in the testing dataset. These results highlight the effectiveness of integrating advanced loss functions and adaptive techniques into deep learning models. This enhances the accuracy of prostate capsule segmentation in micro-US images, offering the potential to improve clinical decision-making in prostate cancer diagnosis and treatment planning.
[12]
arXiv:2509.15599
[pdf, html, other]
Title:
MAGENTA: Magnitude and Geometry-ENhanced Training Approach for Robust Long-Tailed Sound Event Localization and Detection
Jun-Wei Yeow, Ee-Leng Tan, Santi Peksi, Woon-Seng Gan
Comments:
This work has been submitted to IEEE ICASSP 2026 for possible publication
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
Deep learning-based Sound Event Localization and Detection (SELD) systems degrade significantly on real-world, long-tailed datasets. Standard regression losses bias learning toward frequent classes, causing rare events to be systematically under-recognized. To address this challenge, we introduce MAGENTA (Magnitude And Geometry-ENhanced Training Approach), a unified loss function that counteracts this bias within a physically interpretable vector space. MAGENTA geometrically decomposes the regression error into radial and angular components, enabling targeted, rarity-aware penalties and strengthened directional modeling. Empirically, MAGENTA substantially improves SELD performance on imbalanced real-world data, providing a principled foundation for a new class of geometry-aware SELD objectives. Code is available at: this https URL
[13]
arXiv:2509.15601
[pdf, html, other]
Title:
Twisting Signals for Joint Radar-Communications: An OAM Vortex Beam Approach
Wanghan Lv, Kumar Vijay Mishra, Jinsong Hu
Comments:
13 pages, 12 figures, 1 table
Subjects:
Signal Processing (eess.SP); Applied Physics (physics.app-ph)
Orbital angular momentum (OAM) technology has attracted much research interest in recent years because of its characteristic helical phase front twisting around the propagation axis and natural orthogonality among different OAM states to encode more degrees of freedom than classical planar beams. Leveraging upon these features, OAM technique has been applied to wireless communication systems to enhance spectral efficiency and radar systems to distinguish spatial targets without beam scanning. Leveraging upon these unique properties, we propose an OAM-based millimeter-wave joint radar-communications (JRC) system comprising a bi-static automotive radar and vehicle-to-vehicle (V2V) communications. Different from existing uniform circular array (UCA) based OAM systems where each element is an isotropic antenna, an OAM spatial modulation scheme utilizing a uniform linear array (ULA) is adopted with each element being a traveling-wave antenna, producing multiple Laguerre-Gaussian (LG) vortex beams simultaneously. Specifically, we first build a novel bi-static automotive OAM-JRC model that embeds communication messages in a radar signal, following which a target position and velocity parameters estimation algorithm is designed with only radar frames. Then, an OAM-based mode-division multiplexing (MDM) strategy between radar and JRC frames is presented to ensure the JRC parameters identifiability and recovery. Furthermore, we analyze the performance of the JRC system through deriving recovery guarantees and Cramér-Rao lower bound (CRLB) of radar target parameters and evaluating the bit error rate (BER) of communication, respectively. Our numerical experiments validate the effectiveness of the proposed OAM-based JRC system and parameter estimation method.
[14]
arXiv:2509.15603
[pdf, html, other]
Title:
Blind Source Separation of Radar Signals in Time Domain Using Deep Learning
Sven Hinderer
Journal-ref:
2022 23rd International Radar Symposium (IRS)
Subjects:
Signal Processing (eess.SP); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Identification and further analysis of radar emitters in a contested environment requires detection and separation of incoming signals. If they arrive from the same direction and at similar frequencies, deinterleaving them remains challenging. A solution to overcome this limitation becomes increasingly important with the advancement of emitter capabilities. We propose treating the problem as blind source separation in time domain and apply supervisedly trained neural networks to extract the underlying signals from the received mixture. This allows us to handle highly overlapping and also continuous wave (CW) signals from both radar and communication emitters. We make use of advancements in the field of audio source separation and extend a current state-of-the-art model with the objective of deinterleaving arbitrary radio frequency (RF) signals. Results show, that our approach is capable of separating two unknown waveforms in a given frequency band with a single channel receiver.
[15]
arXiv:2509.15627
[pdf, html, other]
Title:
Wireless Sensing with Movable Intelligent Surface
Ziyuan Zheng, Qingqing Wu, Yanze Zhu, Wen Chen, Ying Gao, Honghao Wang
Comments:
13 pages, 11 figures, submitted to an IEEE Journal for possible publications
Subjects:
Signal Processing (eess.SP)
Future wireless networks are envisioned to deliver not only gigabit communications but also ubiquitous sensing. Reconfigurable intelligent surfaces (RISs) have emerged to reshape radio propagation, recently showing considerable promise for wireless sensing. Still, their per-element electronic tuning incurs prohibitive hardware cost and power consumption. Motivated by the concept of fluid antenna system (FAS), this paper introduces a low-cost movable intelligent surface (MIS) for wireless sensing, which replaces element-wise electronic phase tuning with panel-wise mechanical reconfiguration. The MIS stacks a large fixed and a smaller movable pre-phased metasurface layers, whose differential position shifts synthesize distinct composite phase patterns, enabling multiple beam patterns for multi-target detection. We characterize a MIS-enabled multi-hop echo signal model with multi-target interference and then formulate a worst-case sensing signal-to-interference-plus-noise ratio (SINR) maximization problem that jointly designs MIS phase shifts and schedules MS2's position. A Riemannian Augmented Lagrangian Method (RALM)-based algorithm is developed to solve the formulated mixed-integer non-convex problem. We also derive a heuristic MIS beam steering design with closed-form phase distribution and position scheduling. Simulations validate MIS's beam pattern reconfiguration capability, show that the RALM-based scheme significantly outperforms the closed-form scheme in improving sensing SINR, and uncover a gain-diversity trade-off in beam patterns that informs the optimal choice of MIS configuration.
[16]
arXiv:2509.15628
[pdf, html, other]
Title:
Rec-RIR: Monaural Blind Room Impulse Response Identification via DNN-based Reverberant Speech Reconstruction in STFT Domain
Pengyu Wang, Xiaofei Li
Comments:
Submitted to ICASSP 2026
Subjects:
Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
Room impulse response (RIR) characterizes the complete propagation process of sound in an enclosed space. This paper presents Rec-RIR for monaural blind RIR identification. Rec-RIR is developed based on the convolutive transfer function (CTF) approximation, which models reverberation effect within narrow-band filter banks in the short-time Fourier transform (STFT) domain. Specifically, we propose a deep neural network (DNN) with cross-band and narrow-band blocks to estimate the CTF filter. The DNN is trained through reconstructing the noise-free reverberant speech spectra. This objective enables stable and straightforward supervised training. Subsequently, a pseudo intrusive measurement process is employed to convert the CTF filter estimate into time-domain RIR by simulating a common intrusive RIR measurement procedure. Experimental results demonstrate that Rec-RIR achieves state-of-the-art (SOTA) performance in both RIR identification and acoustic parameter estimation. Open-source codes are available online at this https URL.
[17]
arXiv:2509.15636
[pdf, other]
Title:
Optimizing Sparse Antenna Arrays for Localization and Sensing using Vector Spherical Wave Functions
Tobias Lafer, Erik Leitinger, Klaus Witrisal
Subjects:
Signal Processing (eess.SP)
In increasing number of electronic devices implement wideband radio technologies for localization and sensing purposes, like ultra-wideband (UWB). Such radio technologies benefit from a large number of antennas, but space for antennas is often limited, especially in devices for mobile and IoT applications. A common challenge is therefore to optimize the placement and orientations of a small number of antenna elements inside a device, leading to the best localization performance. We propose a method for systematically approaching the optimization of such sparse arrays by means of Cramér-Rao lower bounds (CRLBs) and vector spherical wave functions (VSWFs). The VSWFs form the basis of a wideband signal model considering frequency, direction and polarization-dependent characteristics of the antenna array under test (AUT), together with mutual coupling and distortions from surrounding obstacles. We derive the CRLBs for localization parameters like delay and angle-of-arrival for this model under additive white Gaussian noise channel conditions, and formulate optimization problems for determining optimal antenna positions and orientations via minimization of the CRLBs. The proposed optimization procedure is demonstrated by means of an exemplary arrangement of three Crossed Exponentially Tapered Slot (XETS) antennas.
[18]
arXiv:2509.15650
[pdf, html, other]
Title:
Hybrid Baseband Simulation for Single-Channel Radar-Based Indoor Localization System
Sven Hinderer, Zheming Yin, Athanasios Papanikolaou, Jan Hesselbarth, Bin Yang
Journal-ref:
2025 26th International Radar Symposium (IRS)
Subjects:
Signal Processing (eess.SP)
Indoor localization with chirp sequence radar at millimeter wavelength offers high localization accuracy at low system cost. We propose a hybrid radar baseband signal simulator for our novel single-channel radar-based indoor localization system consisting of an active radar and passive reflectors as references. By combining ray tracing channel simulations with real measurements of the two-way antenna gain of the radar and accurate simulation of the radar cross section of chosen reflectors, realistic modeling of the baseband receive signal in complex scenarios is achieved.
[19]
arXiv:2509.15681
[pdf, other]
Title:
Extended k-u Fading Model in mmWave Communication: Statistical Properties and Performance Evaluations
Jiahuan Wu, Xinchun Yu, Xiao-Ping Zhang
Subjects:
Signal Processing (eess.SP)
This study proposes a small-scale fading model, named the extended k-u model, which incorporates the imbalance of multipath clusters by adding a new parameter based on the original k-u model. The extended k-u model outperforms the k-u model in characterizing small-scale fading in the millimeter-wave (mmWave) band and has more accurate modeling capability than the extended n-u model in scenarios with line-of-sight (LoS) paths. And it is mathematically more tractable than the a-k-n-u model. Experiments are conducted for mmWave communication scenarios with LoS paths, covering the outdoor 28 GHz band, the indoor 65 GHz band, and the indoor 92 GHz band. The results demonstrate that the extended k-u model achieves a smaller mean square error in fitting the measured data compared to both the k-u model and the extended n-u model across all scenarios. In addition, through theoretical derivations, closed-form expressions are obtained for the key statistical characteristics of the extended k-u model, including the probability density function, cumulative distribution function, moments of arbitrary order, and moment generating function. Based on these statistics, this study further derives and analyzes the expressions for some performance metrics of the communication system, including the amount of fading, the probability of outage, and the average bit error rate.
[20]
arXiv:2509.15689
[pdf, html, other]
Title:
Interpretable Modeling of Articulatory Temporal Dynamics from real-time MRI for Phoneme Recognition
Jay Park, Hong Nguyen, Sean Foley, Jihwan Lee, Yoonjeong Lee, Dani Byrd, Shrikanth Narayanan
Subjects:
Image and Video Processing (eess.IV); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Real-time Magnetic Resonance Imaging (rtMRI) visualizes vocal tract action, offering a comprehensive window into speech articulation. However, its signals are high dimensional and noisy, hindering interpretation. We investigate compact representations of spatiotemporal articulatory dynamics for phoneme recognition from midsagittal vocal tract rtMRI videos. We compare three feature types: (1) raw video, (2) optical flow, and (3) six linguistically-relevant regions of interest (ROIs) for articulator movements. We evaluate models trained independently on each representation, as well as multi-feature combinations. Results show that multi-feature models consistently outperform single-feature baselines, with the lowest phoneme error rate (PER) of 0.34 obtained by combining ROI and raw video. Temporal fidelity experiments demonstrate a reliance on fine-grained articulatory dynamics, while ROI ablation studies reveal strong contributions from tongue and lips. Our findings highlight how rtMRI-derived features provide accuracy and interpretability, and establish strategies for leveraging articulatory data in speech processing.
[21]
arXiv:2509.15702
[pdf, html, other]
Title:
A Steered Response Power Method for Sound Source Localization With Generic Acoustic Models
Kaspar Müller, Markus Buck, Simon Doclo, Jan Østergaard, Tobias Wolff
Comments:
Accepted for publication in IEEE Transactions on Audio, Speech and Language Processing
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
The steered response power (SRP) method is one of the most popular approaches for acoustic source localization with microphone arrays. It is often based on simplifying acoustic assumptions, such as an omnidirectional sound source in the far field of the microphone array(s), free field propagation, and spatially uncorrelated noise. In reality, however, there are many acoustic scenarios where such assumptions are violated. This paper proposes a generalization of the conventional SRP method that allows to apply generic acoustic models for localization with arbitrary microphone constellations. These models may consider, for instance, level differences in distributed microphones, the directivity of sources and receivers, or acoustic shadowing effects. Moreover, also measured acoustic transfer functions may be applied as acoustic model. We show that the delay-and-sum beamforming of the conventional SRP is not optimal for localization with generic acoustic models. To this end, we propose a generalized SRP beamforming criterion that considers generic acoustic models and spatially correlated noise, and derive an optimal SRP beamformer. Furthermore, we propose and analyze appropriate frequency weightings. Unlike the conventional SRP, the proposed method can jointly exploit observed level and time differences between the microphone signals to infer the source location. Realistic simulations of three different microphone setups with speech under various noise conditions indicate that the proposed method can significantly reduce the mean localization error compared to the conventional SRP and, in particular, a reduction of more than 60% can be archived in noisy conditions.
[22]
arXiv:2509.15710
[pdf, html, other]
Title:
Inverse Source Method for Constrained Phased Array Synthesis through Null-Space Exploitation
Lorenzo Poli, Paolo Rocca, Arianna Benoni, Andrea Massa
Subjects:
Systems and Control (eess.SY); Information Theory (cs.IT)
A versatile approach for the synthesis of phased array (PA) antennas able to fit user-defined power pattern masks, while fulfilling additional geometrical and/or electrical constraints on the geometry of the array aperture and/or on the array excitations is presented. Such a synthesis method is based on the inverse source (IS) formulation and exploits the null-space of the radiation operator that causes the non-uniqueness of the IS problem at hand. More in detail, the unknown element excitations of the PA are expressed as the linear combination of a minimum-norm or radiating (RA) term and a suitable non-radiating (NR) component. The former, computed via the truncated singular value decomposition (SVD) of the array radiation operator, is devoted to generate a far-field power pattern that fulfills user-defined pattern masks. The other one belongs to the null-space of the radiation operator and allows one to fit additional geometrical and/or electrical constraints on the geometry of the array aperture and/or on the beam-forming network (BFN) when determined with a customized global optimization strategy. A set of numerical examples, concerned with various array arrangements and additional design targets, is reported to prove the effectiveness of the proposed approach.
[23]
arXiv:2509.15718
[pdf, html, other]
Title:
Distributed Multi-Task Learning for Joint Wireless Signal Enhancement and Recognition
Hao Zhang, Fuhui Zhou, Qihui Wu, Chau Yuen
Comments:
accepted by Transactions on Cognitive Communications and Networking
Journal-ref:
IEEE Transactions on Cognitive Communications and Networking,2025
Subjects:
Signal Processing (eess.SP)
Wireless signal recognition (WSR) is crucial in modern and future wireless communication networks since it aims to identify the properties of the received signal in a no-collaborative manner. However, it is challenging to accurately classify signals in low signal-to-noise ratio (SNR) conditions and distributed network settings. In this paper, we propose a novel distributed multi-task learning framework for joint wireless signal enhancement and recognition (WSER), addressing the crucial need for non-collaborative signal identification in modern wireless networks. Our approach integrates a wireless signal enhancement and recognition network (WSERNet) with FedProx+, an enhanced federated learning algorithm designed for heterogeneous data distributions. Specifically, WSERNet leverages an asymmetric convolution block (ACBlock) to capture long-range dependencies in the input signal and improve the performance of the deep learning model. FedProx+ introduces a proximal term to the loss function to encourage the model updates to be closer to the previous model, enhancing the convergence speed and robustness of federated learning. Extensive experiments demonstrate the effectiveness of the proposed framework for joint WSER, achieving superior performance compared to state-of-the-art methods under both centralized and distributed settings including independent and identically distributed (IID) and non-IID data distributions.
[24]
arXiv:2509.15758
[pdf, html, other]
Title:
Uncertainty-Gated Deformable Network for Breast Tumor Segmentation in MR Images
Yue Zhang, Jiahua Dong, Chengtao Peng, Qiuli Wang, Dan Song, Guiduo Duan
Comments:
5 pages, 2 figures
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Accurate segmentation of breast tumors in magnetic resonance images (MRI) is essential for breast cancer diagnosis, yet existing methods face challenges in capturing irregular tumor shapes and effectively integrating local and global features. To address these limitations, we propose an uncertainty-gated deformable network to leverage the complementary information from CNN and Transformers. Specifically, we incorporates deformable feature modeling into both convolution and attention modules, enabling adaptive receptive fields for irregular tumor contours. We also design an Uncertainty-Gated Enhancing Module (U-GEM) to selectively exchange complementary features between CNN and Transformer based on pixel-wise uncertainty, enhancing both local and global representations. Additionally, a Boundary-sensitive Deep Supervision Loss is introduced to further improve tumor boundary delineation. Comprehensive experiments on two clinical breast MRI datasets demonstrate that our method achieves superior segmentation performance compared with state-of-the-art methods, highlighting its clinical potential for accurate breast tumor delineation.
[25]
arXiv:2509.15766
[pdf, html, other]
Title:
Explainable Deep Learning Based Adversarial Defense for Automatic Modulation Classification
Peihao Dong, Jingchun Wang, Shen Gao, Fuhui Zhou, Qihui Wu
Comments:
Accepted by IEEE Internet of Things Journal
Subjects:
Signal Processing (eess.SP)
Deep learning (DL) has been widely applied to enhance automatic modulation classification (AMC). However, the elaborate AMC neural networks are susceptible to various adversarial attacks, which are challenging to handle due to the generalization capability and computational cost. In this article, an explainable DL based defense scheme, called SHapley Additive exPlanation enhanced Adversarial Fine-Tuning (SHAP-AFT), is developed in the perspective of disclosing the attacking impact on the AMC network. By introducing the concept of cognitive negative information, the motivation of using SHAP for defense is theoretically analyzed first. The proposed scheme includes three stages, i.e., the attack detection, the information importance evaluation, and the AFT. The first stage indicates the existence of the attack. The second stage evaluates contributions of the received data and removes those data positions using negative Shapley values corresponding to the dominating negative information caused by the attack. Then the AMC network is fine-tuned based on adversarial adaptation samples using the refined received data pattern. Simulation results show the effectiveness of the Shapley value as the key indicator as well as the superior defense performance of the proposed SHAP-AFT scheme in face of different attack types and intensities.
[26]
arXiv:2509.15778
[pdf, html, other]
Title:
All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control
Mohammad Bahari, Amir Hossein Barjini, Pauli Mustalahti, Jouni Mattila
Subjects:
Systems and Control (eess.SY); Robotics (cs.RO)
This paper presents a unified framework that integrates modeling, optimization, and sensorless control of an all-electric heavy-duty robotic manipulator (HDRM) driven by electromechanical linear actuators (EMLAs). An EMLA model is formulated to capture motor electromechanics and direction-dependent transmission efficiencies, while a mathematical model of the HDRM, incorporating both kinematics and dynamics, is established to generate joint-space motion profiles for prescribed TCP trajectories. A safety-ensured trajectory generator, tailored to this model, maps Cartesian goals to joint space while enforcing joint-limit and velocity margins. Based on the resulting force and velocity demands, a multi-objective Non-dominated Sorting Genetic Algorithm II (NSGA-II) is employed to select the optimal EMLA configuration. To accelerate this optimization, a deep neural network, trained with EMLA parameters, is embedded in the optimization process to predict steady-state actuator efficiency from trajectory profiles. For the chosen EMLA design, a physics-informed Kriging surrogate, anchored to the analytic model and refined with experimental data, learns residuals of EMLA outputs to support force and velocity sensorless control. The actuator model is further embedded in a hierarchical virtual decomposition control (VDC) framework that outputs voltage commands. Experimental validation on a one-degree-of-freedom EMLA testbed confirms accurate trajectory tracking and effective sensorless control under varying loads.
[27]
arXiv:2509.15799
[pdf, html, other]
Title:
Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control
Max Studt, Georg Schildbach
Subjects:
Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Robotics (cs.RO); Optimization and Control (math.OC)
Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control.
[28]
arXiv:2509.15802
[pdf, html, other]
Title:
DPC-QA Net: A No-Reference Dual-Stream Perceptual and Cellular Quality Assessment Network for Histopathology Images
Qijun Yang, Boyang Wang, Hujun Yin
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Reliable whole slide imaging (WSI) hinges on image quality,yet staining artefacts, defocus, and cellular degradations are common. We present DPC-QA Net, a no-reference dual-stream network that couples wavelet-based global difference perception with cellular quality assessment from nuclear and membrane embeddings via an Aggr-RWKV module. Cross-attention fusion and multi-term losses align perceptual and cellular cues. Across different datasets, our model detects staining, membrane, and nuclear issues with >92% accuracy and aligns well with usability scores; on LIVEC and KonIQ it outperforms state-of-the-art NR-IQA. A downstream study further shows strong positive correlations between predicted quality and cell recognition accuracy (e.g., nuclei PQ/Dice, membrane boundary F-score), enabling practical pre-screening of WSI regions for computational pathology.
[29]
arXiv:2509.15814
[pdf, html, other]
Title:
QWD-GAN: Quality-aware Wavelet-driven GAN for Unsupervised Medical Microscopy Images Denoising
Qijun Yang, Yating Huang, Lintao Xiang, Hujun Yin
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Image denoising plays a critical role in biomedical and microscopy imaging, especially when acquiring wide-field fluorescence-stained images. This task faces challenges in multiple fronts, including limitations in image acquisition conditions, complex noise types, algorithm adaptability, and clinical application demands. Although many deep learning-based denoising techniques have demonstrated promising results, further improvements are needed in preserving image details, enhancing algorithmic efficiency, and increasing clinical interpretability. We propose an unsupervised image denoising method based on a Generative Adversarial Network (GAN) architecture. The approach introduces a multi-scale adaptive generator based on the Wavelet Transform and a dual-branch discriminator that integrates difference perception feature maps with original features. Experimental results on multiple biomedical microscopy image datasets show that the proposed model achieves state-of-the-art denoising performance, particularly excelling in the preservation of high-frequency information. Furthermore, the dual-branch discriminator is seamlessly compatible with various GAN frameworks. The proposed quality-aware, wavelet-driven GAN denoising model is termed as QWD-GAN.
[30]
arXiv:2509.15820
[pdf, html, other]
Title:
Bandwidth-Constrained Sensor Scheduling: A Trade-off between Fairness and Efficiency
Yuxing Zhong, Yuchi Wu, Daniel E. Quevedo, Ling Shi
Subjects:
Systems and Control (eess.SY)
We address fair sensor scheduling over bandwidth-constrained communication channels. While existing literature on fair scheduling overlooks overall system efficiency, we introduce a novel $q$-fairness framework to balance efficiency and fairness by adjusting the parameter $q$. Specifically, for two communication scenarios, we: (i) derive the optimal schedule under limited communication rates, and (ii) propose two suboptimal algorithms under limited simultaneous sensor transmissions and analyze their performance gaps relative to the optimal strategy. Simulations demonstrate that our algorithms effectively balance efficiency and fairness in both cases.
[31]
arXiv:2509.15845
[pdf, html, other]
Title:
Deep Dubbing: End-to-End Auto-Audiobook System with Text-to-Timbre and Context-Aware Instruct-TTS
Ziqi Dai, Yiting Chen, Jiacheng Xu, Liufei Xie, Yuchen Wang, Zhenchuan Yang, Bingsong Bai, Yangsheng Gao, Wenjiang Zhou, Weifeng Zhao, Ruohua Zhou
Comments:
Submitted to ICASSP this http URL 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, including reprinting/republishing, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work. DOI will be added upon IEEE Xplore publication
Subjects:
Audio and Speech Processing (eess.AS)
The pipeline for multi-participant audiobook production primarily consists of three stages: script analysis, character voice timbre selection, and speech synthesis. Among these, script analysis can be automated with high accuracy using NLP models, whereas character voice timbre selection still relies on manual effort. Speech synthesis uses either manual dubbing or text-to-speech (TTS). While TTS boosts efficiency, it struggles with emotional expression, intonation control, and contextual scene adaptation. To address these challenges, we propose DeepDubbing, an end-to-end automated system for multi-participant audiobook production. The system comprises two main components: a Text-to-Timbre (TTT) model and a Context-Aware Instruct-TTS (CA-Instruct-TTS) model. The TTT model generates role-specific timbre embeddings conditioned on text descriptions. The CA-Instruct-TTS model synthesizes expressive speech by analyzing contextual dialogue and incorporating fine-grained emotional instructions. This system enables the automated generation of multi-participant audiobooks with both timbre-matched character voices and emotionally expressive narration, offering a novel solution for audiobook production.
[32]
arXiv:2509.15864
[pdf, other]
Title:
Data-Driven Uncertainty Modeling for Robust Feedback Active Noise Control in Headphones
Florian Hilgemann, Egke Chatzimoustafa, Peter Jax
Comments:
11 pages, 9 figures, journal
Journal-ref:
Journal of the Audio Engineering Society, vol. 72, no. 12, 2024, pp. 873-883
Subjects:
Systems and Control (eess.SY)
Active noise control (ANC) has become popular for reducing noise and thus enhancing user comfort in headphones. While feedback control offers an effective way to implement ANC, it is restricted by uncertainty of the controlled system that arises, e.g., from differing wearing situations. Widely used unstructured models which capture these variations tend to overestimate the uncertainty and thus restrict ANC performance. As a remedy, this work explores uncertainty models that provide a more accurate fit to the observed variations in order to improve ANC performance for over-ear and in-ear headphones. We describe the controller optimization based on these models and implement an ANC prototype to compare the performances associated with conventional and proposed modeling approaches. Extensive measurements with human wearers confirm the robustness and indicate a performance improvement over conventional methods. The results allow to safely increase the active attenuation of ANC headphones by several decibels.
[33]
arXiv:2509.15899
[pdf, html, other]
Title:
Sound Separation and Classification with Object and Semantic Guidance
Younghoo Kwon, Jung-Woo Choi
Comments:
5 pages, 4 figures, submitted to ICASSP 2026
Subjects:
Audio and Speech Processing (eess.AS)
The spatial semantic segmentation task focuses on separating and classifying sound objects from multichannel signals. To achieve two different goals, conventional methods fine-tune a large classification model cascaded with the separation model and inject classified labels as separation clues for the next iteration step. However, such integration is not ideal, in that fine-tuning over a smaller dataset loses the diversity of large classification models, features from the source separation model are different from the inputs of the pretrained classifier, and injected one-hot class labels lack semantic depth, often leading to error propagation. To resolve these issues, we propose a Dual-Path Classifier (DPC) architecture that combines object features from a source separation model with semantic representations acquired from a pretrained classification model without fine-tuning. We also introduce a Semantic Clue Encoder (SCE) that enriches the semantic depth of injected clues. Our system achieves a state-of-the-art 11.19 dB CA-SDRi and enhanced semantic fidelity on the DCASE 2025 task4 evaluation set, surpassing the top-rank performance of 11.00 dB. These results highlight the effectiveness of integrating separator-derived features and rich semantic clues.
[34]
arXiv:2509.15902
[pdf, html, other]
Title:
Fundamental Limits of THz Inter-Satellite ISAC Under Hardware Impairments
Haofan Dong, Ozgur B. Akan
Subjects:
Signal Processing (eess.SP)
This paper establishes a theoretical framework for analyzing the fundamental performance limits of terahertz (THz) Low Earth Orbit (LEO) inter-satellite link (ISL) Integrated Sensing and Communications (ISAC) systems. We develop a unified, end-to-end signal model that, jointly captures the effects of extreme orbital dynamics, cascaded non-ideal hardware impairments, and micro-radian beam pointing errors. Through Bayesian Cramér-Rao Lower Bound (BCRLB) analysis, we derive the ultimate sensing accuracy for range and range-rate, revealing a quadratic ($1/f_c^2$) improvement in estimation variance with carrier frequency, which is ultimately floored by signal-dependent hardware distortion. For communication, we show that system performance is not power-limited but hardware-limited, deriving a closed-form capacity ceiling under the joint effect of phase noise and PA nonlinearity: $C_{\text{sat}} = \log_2(1 + e^{-\sigma_\phi^2}/\Gamma_{\text{eff}})$, where $\Gamma_{\text{eff}}$ is a proposed hardware quality factor. Our numerical results, based on state-of-the-art component data and the identified trade-offs, suggest that favorable operational conditions may exist in the sub-THz frequency range (200-600 GHz) where the quadratic sensing gain with frequency is balanced against hardware quality degradation. Power Amplifier (PA) nonlinearity emerges as the dominant performance bottleneck, exceeding other impairments by one to two orders of magnitude.
[35]
arXiv:2509.15947
[pdf, html, other]
Title:
The Missing Piece: A Case for Pre-Training in 3D Medical Object Detection
Katharina Eckstein, Constantin Ulrich, Michael Baumgartner, Jessica Kächele, Dimitrios Bounias, Tassilo Wald, Ralf Floca, Klaus H. Maier-Hein
Comments:
MICCAI 2025
Journal-ref:
Medical Image Computing and Computer Assisted Intervention - MICCAI 2025. MICCAI 2025. Lecture Notes in Computer Science, vol 15963. Springer, Cham
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
Large-scale pre-training holds the promise to advance 3D medical object detection, a crucial component of accurate computer-aided diagnosis. Yet, it remains underexplored compared to segmentation, where pre-training has already demonstrated significant benefits. Existing pre-training approaches for 3D object detection rely on 2D medical data or natural image pre-training, failing to fully leverage 3D volumetric information. In this work, we present the first systematic study of how existing pre-training methods can be integrated into state-of-the-art detection architectures, covering both CNNs and Transformers. Our results show that pre-training consistently improves detection performance across various tasks and datasets. Notably, reconstruction-based self-supervised pre-training outperforms supervised pre-training, while contrastive pre-training provides no clear benefit for 3D medical object detection. Our code is publicly available at: this https URL.
[36]
arXiv:2509.15964
[pdf, html, other]
Title:
MoE-CE: Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework
Tianyu Li, Yan Xin, Jianzhong (Charlie)Zhang
Subjects:
Signal Processing (eess.SP); Artificial Intelligence (cs.AI)
Reliable channel estimation (CE) is fundamental for robust communication in dynamic wireless environments, where models must generalize across varying conditions such as signal-to-noise ratios (SNRs), the number of resource blocks (RBs), and channel profiles. Traditional deep learning (DL)-based methods struggle to generalize effectively across such diverse settings, particularly under multitask and zero-shot scenarios. In this work, we propose MoE-CE, a flexible mixture-of-experts (MoE) framework designed to enhance the generalization capability of DL-based CE methods. MoE-CE provides an appropriate inductive bias by leveraging multiple expert subnetworks, each specialized in distinct channel characteristics, and a learned router that dynamically selects the most relevant experts per input. This architecture enhances model capacity and adaptability without a proportional rise in computational cost while being agnostic to the choice of the backbone model and the learning algorithm. Through extensive experiments on synthetic datasets generated under diverse SNRs, RB numbers, and channel profiles, including multitask and zero-shot evaluations, we demonstrate that MoE-CE consistently outperforms conventional DL approaches, achieving significant performance gains while maintaining efficiency.
[37]
arXiv:2509.15969
[pdf, html, other]
Title:
VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency
Nikita Torgashov, Gustav Eje Henter, Gabriel Skantze
Comments:
5 pages, 1 figure, submitted to IEEE ICASSP 2026
Subjects:
Audio and Speech Processing (eess.AS); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Sound (cs.SD)
We present VoXtream, a fully autoregressive, zero-shot streaming text-to-speech (TTS) system for real-time use that begins speaking from the first word. VoXtream directly maps incoming phonemes to audio tokens using a monotonic alignment scheme and a dynamic look-ahead that does not delay onset. Built around an incremental phoneme transformer, a temporal transformer predicting semantic and duration tokens, and a depth transformer producing acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay among publicly available streaming TTS: 102 ms on GPU. Despite being trained on a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several metrics, while delivering competitive quality in both output- and full-streaming settings. Demo and code are available at this https URL.
[38]
arXiv:2509.15973
[pdf, html, other]
Title:
Scalable Hessian-free Proximal Conjugate Gradient Method for Nonconvex and Nonsmooth Optimization
Yiming Zhou, Wei Dai
Comments:
Manuscript for ICASSP 2026 Submission
Subjects:
Signal Processing (eess.SP)
This work studies a composite minimization problem involving a differentiable function q and a nonsmooth function h, both of which may be nonconvex. This problem is ubiquitous in signal processing and machine learning yet remains challenging to solve efficiently, particularly when large-scale instances, poor conditioning, and nonconvexity coincide. To address these challenges, we propose a proximal conjugate gradient method (PCG) that matches the fast convergence of proximal (quasi-)Newton algorithms while reducing computation and memory complexity, and is especially effective for spectrally clustered Hessians. Our key innovation is to form, at each iteration, an approximation to the Newton direction based on CG iterations to build a majorization surrogate. We define this surrogate in a curvature-aware manner and equip it with a CG-derived isotropic weight, guaranteeing majorization of a local second-order model of q along the given direction. To better preserve majorization after the proximal step and enable further approximation refinement, we scale the CG direction by the ratio between the Cauchy step length and a step size derived from the largest Ritz value of the CG tridiagonal. All curvature is accessed via Hessian-vector products computed by automatic differentiation, keeping the method Hessian-free. Convergence to first-order critical points is established. Numerical experiments on CS-MRI with nonconvex regularization and on dictionary learning, against benchmark methods, demonstrate the efficiency of the proposed approach.
[39]
arXiv:2509.15993
[pdf, html, other]
Title:
Wireless Channel Foundation Model with Embedded Noise-Plus-Interference Suppression Structure
Yuwei Wang, Li Sun, Tingting Yang
Subjects:
Signal Processing (eess.SP); Information Theory (cs.IT)
Wireless channel foundation model (WCFM) is a task-agnostic AI model that is pretrained on large-scale wireless channel datasets to learn a universal channel feature representation that can be used for a wide range of downstream tasks related to communications and sensing. While existing works on WCFM have demonstrated its great potentials in various tasks including beam prediction, channel prediction, localization, etc, the models are all trained using perfect (i.e., error-free and complete) channel information state (CSI) data which are generated with simulation tools. However, in practical systems where the WCFM is deployed, perfect CSI is not available. Instead, channel estimation needs to be first performed based on pilot signals over a subset of the resource elements (REs) to acquire a noisy version of the CSI (termed as degraded CSI), which significantly differs from the perfect CSI in some real-world environments with severe noise and interference. As a result, the feature representation generated by the WCFM is unable to reflect the characteristics of the true channel, yielding performance degradation in downstream tasks. To address this issue, in this paper we propose an enhanced wireless channel foundation model architecture with noise-plus-interference (NPI) suppression capability. In our approach, coarse estimates of the CSIs are first obtained. With these information, two projection matrices are computed to extract the NPI terms in the received signals, which are further processed by a NPI estimation and subtraction module. Finally, the resultant signal is passed through a CSI completion network to get a clean version of the CSI, which is used for feature extraction. Simulation results demonstrated that compared to the state-of-the-art solutions, WCFM with NPI suppression structure achieves improved performance on channel prediction task.
[40]
arXiv:2509.16012
[pdf, other]
Title:
Five-Level Common-Ground Inverter Topology Using an Integrated Charge-Pump and Switched-Capacitor Network
Anup Marahatta, Shafiuzzaman Khadem, Sandipan Patra
Comments:
9 Pages
Subjects:
Systems and Control (eess.SY)
This paper presents a novel five-level common-ground (CG) inverter topology designed for transformerless residential photovoltaic (PV) applications.
[41]
arXiv:2509.16019
[pdf, html, other]
Title:
SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI
Bhavesh Sandbhor, Bheeshm Sharma, Balamurugan Palaniappan
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Brain MRI scans are often found in four modalities, consisting of T1-weighted with and without contrast enhancement (T1ce and T1w), T2-weighted imaging (T2w), and Flair. Leveraging complementary information from these different modalities enables models to learn richer, more discriminative features for understanding brain anatomy, which could be used in downstream tasks such as anomaly detection. However, in clinical practice, not all MRI modalities are always available due to various reasons. This makes missing modality generation a critical challenge in medical image analysis. In this paper, we propose SLaM-DiMM, a novel missing modality generation framework that harnesses the power of diffusion models to synthesize any of the four target MRI modalities from other available modalities. Our approach not only generates high-fidelity images but also ensures structural coherence across the depth of the volume through a dedicated coherence enhancement mechanism. Qualitative and quantitative evaluations on the BraTS-Lighthouse-2025 Challenge dataset demonstrate the effectiveness of the proposed approach in synthesizing anatomically plausible and structurally consistent results. Code is available at this https URL.
[42]
arXiv:2509.16023
[pdf, html, other]
Title:
Interpreting the Role of Visemes in Audio-Visual Speech Recognition
Aristeidis Papadopoulos, Naomi Harte
Comments:
Accepted into Automatic Speech Recognition and Understanding- ASRU 2025
Subjects:
Audio and Speech Processing (eess.AS)
Audio-Visual Speech Recognition (AVSR) models have surpassed their audio-only counterparts in terms of performance. However, the interpretability of AVSR systems, particularly the role of the visual modality, remains under-explored. In this paper, we apply several interpretability techniques to examine how visemes are encoded in AV-HuBERT a state-of-the-art AVSR model. First, we use t-distributed Stochastic Neighbour Embedding (t-SNE) to visualize learned features, revealing natural clustering driven by visual cues, which is further refined by the presence of audio. Then, we employ probing to show how audio contributes to refining feature representations, particularly for visemes that are visually ambiguous or under-represented. Our findings shed light on the interplay between modalities in AVSR and could point to new strategies for leveraging visual information to improve AVSR performance.
[43]
arXiv:2509.16044
[pdf, html, other]
Title:
FMD-TransUNet: Abdominal Multi-Organ Segmentation Based on Frequency Domain Multi-Axis Representation Learning and Dual Attention Mechanisms
Fang Lu, Jingyu Xu, Qinxiu Sun, Qiong Lou
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Accurate abdominal multi-organ segmentation is critical for clinical applications. Although numerous deep learning-based automatic segmentation methods have been developed, they still struggle to segment small, irregular, or anatomically complex organs. Moreover, most current methods focus on spatial-domain analysis, often overlooking the synergistic potential of frequency-domain representations. To address these limitations, we propose a novel framework named FMD-TransUNet for precise abdominal multi-organ segmentation. It innovatively integrates the Multi-axis External Weight Block (MEWB) and the improved dual attention module (DA+) into the TransUNet framework. The MEWB extracts multi-axis frequency-domain features to capture both global anatomical structures and local boundary details, providing complementary information to spatial-domain representations. The DA+ block utilizes depthwise separable convolutions and incorporates spatial and channel attention mechanisms to enhance feature fusion, reduce redundant information, and narrow the semantic gap between the encoder and decoder. Experimental validation on the Synapse dataset shows that FMD-TransUNet outperforms other recent state-of-the-art methods, achieving an average DSC of 81.32\% and a HD of 16.35 mm across eight abdominal organs. Compared to the baseline model, the average DSC increased by 3.84\%, and the average HD decreased by 15.34 mm. These results demonstrate the effectiveness of FMD-TransUNet in improving the accuracy of abdominal multi-organ segmentation.
[44]
arXiv:2509.16045
[pdf, html, other]
Title:
Secure Multicast Communications with Pinching-Antenna Systems (PASS)
Shan Shan, Chongjun Ouyang, Yong Li, Yuanwei Liu
Subjects:
Signal Processing (eess.SP)
This article investigates secure multicast communications in pinching-antenna systems (PASS), where pinching beamforming is enabled by adaptively adjusting pinching antenna (PAs) positions along waveguides to improve multicast security. Specifically, a PASS-based secure multicast framework is proposed, in which joint optimization of transmit and pinching beamforming is conducted to maximize the secrecy multicast rate. i) For the single-group multicast scenario, an alternating optimization (AO) framework is employed, where the pinching beamformer is updated via an element-wise sequential optimization method. The transmit beamformer is designed via a semidefinite relaxation (SDR) formulation for an upper-bound solution, while a Dinkelbach-alternating direction method of multipliers (ADMM) offers a low-complexity alternative. ii) For the multi-group multicast scenario, transmit and pinching beamformers are alternately optimized under a majorization-minimization (MM) framework. The transmit beamformer is obtained via SDR or an efficient second-order cone programming (SOCP) method, while the pinching beamformer is updated through MM-based element-wise sequential update strategy. Numerical results are provided to demonstrate that: (i) PASS consistently outperform conventional fixed-location antenna architectures in terms of secrecy performance across various configurations; and (ii) the performance advantage of PASS over fixed-location architectures becomes more significant with increased service region, larger antenna arrays, and higher user and eavesdropper densities.
[45]
arXiv:2509.16077
[pdf, other]
Title:
On the Number of Control Nodes of Threshold and XOR Boolean Networks
Christopher H. Fok, Liangjie Sun, Tatsuya Akutsu, Wai-Ki Ching
Comments:
42 pages, 9 figures
Subjects:
Systems and Control (eess.SY); Optimization and Control (math.OC)
Boolean networks (BNs) are important models for gene regulatory networks and many other biological systems. In this paper, we study the minimal controllability problem of threshold and XOR BNs with degree constraints. Firstly, we derive lower-bound-related inequalities and some upper bounds for the number of control nodes of several classes of controllable majority-type threshold BNs. Secondly, we construct controllable majority-type BNs and BNs involving Boolean threshold functions with both positive and negative coefficients such that these BNs are associated with a small number of control nodes. Thirdly, we derive a linear-algebraic necessary and sufficient condition for the controllability of general XOR-BNs, whose update rules are based on the XOR logical operator, and construct polynomial-time algorithms for computing control-node sets and control signals for general XOR-BNs. Lastly, we use ring theory and linear algebra to establish a few best-case upper bounds for a type of degree-constrainted XOR-BNs called $k$-$k$-XOR-BNs. In particular, we show that for any positive integer $m \geq 2$ and any odd integer $k \in [3, 2^{m} - 1]$, there exists a $2^{m}$-node controllable $k$-$k$-XOR-BN with 1 control node. Our results offer theoretical insights into minimal interventions in networked systems such as gene regulatory networks.
[46]
arXiv:2509.16083
[pdf, html, other]
Title:
On-Policy Reinforcement-Learning Control for Optimal Energy Sharing and Temperature Regulation in District Heating Systems
Xinyi Yi, Ioannis Lestas
Comments:
To appear at CDC 2025
Subjects:
Systems and Control (eess.SY)
We address the problem of temperature regulation and optimal energy sharing in district heating systems (DHSs) where the demand and system parameters are unknown. We propose a temperature regulation scheme that employs data-driven on-policy updates that achieve these objectives. In particular, we show that the proposed control scheme converges to an optimal equilibrium point of the system, while also having guaranteed convergence to an optimal LQR control policy, thus providing good transient performance. The efficiency of our approach is also demonstrated through extensive simulations.
[47]
arXiv:2509.16086
[pdf, html, other]
Title:
In-Situ Fault Detection of Submerged Pump Impellers Using Encapsulated Accelerometers and Machine Learning
Sahil P. Wankhede, Xiangdong Xie, Ali H. Alshehri, Keith W Brashler, Mohammad Ba'adani, Doru C Turcan, Kamal Youcef-Toumi, Xian Du
Comments:
Under review
Subjects:
Signal Processing (eess.SP)
Vertical turbine pumps in oil and gas operations rely on motor-mounted accelerometers for condition monitoring. However, these sensors cannot detect faults at submerged impellers exposed to harsh downhole environments. We present the first study deploying encapsulated accelerometers mounted directly on submerged impeller bowls, enabling in-situ vibration monitoring. Using a lab-scale pump setup with 1-meter oil submergence, we collected vibration data under normal and simulated fault conditions. The data were analyzed using a suite of machine learning models -- spanning traditional and deep learning methods -- to evaluate sensor effectiveness. Impeller-mounted sensors achieved 91.3% average accuracy and 0.973 AUC-ROC, outperforming the best non-submerged sensor. Crucially, encapsulation caused no statistically significant performance loss in sensor performance, confirming its viability for oil-submerged environments. While the lab setup used shallow submergence, real-world pump impellers operate up to hundreds of meters underground -- well beyond the range of surface-mounted sensors. This first-of-its-kind in-situ monitoring system demonstrates that impeller-mounted sensors -- encapsulated for protection while preserving diagnostic fidelity -- can reliably detect faults in critical submerged pump components. By capturing localized vibration signatures that are undetectable from surface-mounted sensors, this approach enables earlier fault detection, reduces unplanned downtime, and optimizes maintenance for downhole systems in oil and gas operations.
[48]
arXiv:2509.16106
[pdf, html, other]
Title:
PRISM: Probabilistic and Robust Inverse Solver with Measurement-Conditioned Diffusion Prior for Blind Inverse Problems
Yuanyun Hu, Evan Bell, Guijin Wang, Yu Sun
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)
Diffusion models are now commonly used to solve inverse problems in computational imaging. However, most diffusion-based inverse solvers require complete knowledge of the forward operator to be used. In this work, we introduce a novel probabilistic and robust inverse solver with measurement-conditioned diffusion prior (PRISM) to effectively address blind inverse problems. PRISM offers a technical advancement over current methods by incorporating a powerful measurement-conditioned diffusion model into a theoretically principled posterior sampling scheme. Experiments on blind image deblurring validate the effectiveness of the proposed method, demonstrating the superior performance of PRISM over state-of-the-art baselines in both image and blur kernel recovery.
[49]
arXiv:2509.16114
[pdf, html, other]
Title:
Real-Time Thermal State Estimation and Forecasting in Laser Powder Bed Fusion
Yukta Pareek, Abdul Malik Al Mardhouf Al Saadi, Amrita Basak, Satadru Dey
Subjects:
Systems and Control (eess.SY)
Laser Powder Bed Fusion (L-PBF) is a widely adopted additive manufacturing process for fabricating complex metallic parts layer by layer. Effective thermal management is essential to ensure part quality and structural integrity, as thermal gradients and residual stresses can lead to defects such as warping and cracking. However, existing experimental or computational techniques lack the ability to forecast future temperature distributions in real time, an essential capability for proactive process control. This paper presents a real-time thermal state forecasting framework for L-PBF, based on a physics-informed reduced-order thermal model integrated with a Kalman filtering scheme. The proposed approach efficiently captures inter-layer heat transfer dynamics and enables accurate tracking and forecasting of spatial and temporal temperature evolution. Validation across multiple part geometries using measured data demonstrates that the method reliably estimates and forecasts peak temperatures and cooling trends. By enabling predictive thermal control, this framework offers a practical and computationally efficient solution for thermal management in L-PBF, paving the way toward closed-loop control in L-PBF.
[50]
arXiv:2509.16134
[pdf, html, other]
Title:
Polymatroidal Representations of Aggregate EV Flexibility Considering Network Constraints
Karan Mukhi, Alessandro Abate
Subjects:
Systems and Control (eess.SY)
The increasing penetration of electric vehicles (EVs) introduces significant flexibility potential to power systems. However, uncoordinated or synchronous charging can lead to overloading of distribution networks. Extending recent approaches that utilize generalized polymatroids, a family of polytopes, to represent the aggregate flexibility of EV populations, we show how to integrate network constraints into this representation to obtain network-constrained aggregate flexibility sets. Furthermore, we demonstrate how to optimize over these network-constrained aggregate flexibility sets, and propose a disaggregation procedure that maps an aggregate load profile to individual EV dispatch instructions, while respecting both device-level and network constraints.
[51]
arXiv:2509.16182
[pdf, html, other]
Title:
Rethinking Cross-Corpus Speech Emotion Recognition Benchmarking: Are Paralinguistic Pre-Trained Representations Sufficient?
Orchid Chetia Phukan, Mohd Mujtaba Akhtar, Girish, Swarup Ranjan Behera, Parabattina Bhagath, Pailla Balakrishna Reddy, Arun Balaji Buduru
Comments:
Accepted to APSIPA-ASC 2025
Subjects:
Audio and Speech Processing (eess.AS)
Recent benchmarks evaluating pre-trained models (PTMs) for cross-corpus speech emotion recognition (SER) have overlooked PTM pre-trained for paralinguistic speech processing (PSP), raising concerns about their reliability, since SER is inherently a paralinguistic task. We hypothesize that PSP-focused PTM will perform better in cross-corpus SER settings. To test this, we analyze state-of-the-art PTMs representations including paralinguistic, monolingual, multilingual, and speaker recognition. Our results confirm that TRILLsson (a paralinguistic PTM) outperforms others, reinforcing the need to consider PSP-focused PTMs in cross-corpus SER benchmarks. This study enhances benchmark trustworthiness and guides PTMs evaluations for reliable cross-corpus SER.
[52]
arXiv:2509.16183
[pdf, other]
Title:
Xona Pulsar Compatibility with GNSS
Tyler G. R. Reid, Matteo Gala, Mathieu Favreau, Argyris Kriezis, Michael O'Meara, Andre Pant, Paul Tarantino, Christina Youn
Comments:
15 pages, 12 figures
Journal-ref:
ION GNSS 2025
Subjects:
Signal Processing (eess.SP)
At least ten emerging providers are developing satellite navigation systems for low Earth orbit (LEO). Compatibility with existing GNSS in L-band is critical to their successful deployment and for the larger ecosystem. Xona is deploying Pulsar, a near 260-satellite LEO constellation offering dual L-band navigation services near L1 and L5. Designed for interoperability, Pulsar provides centimeter-level accuracy, resilience, and authentication, while maintaining a format that existing GNSS receivers can support through a firmware update. This study examines Pulsar's compatibility with GPS and Galileo by evaluating C/N0 degradation caused by the introduction of its X1 and X5 signals. Using spectrally compact QPSK modulation, Pulsar minimizes interference despite higher signal power. Theoretical analysis is supported by hardware testing across a range of commercial GNSS receivers in both lab-based simulation and in-orbit live-sky conditions. The study confirms Pulsar causes no adverse interference effects to existing GNSS, supporting coexistence and integration within the global PNT ecosystem.
[53]
arXiv:2509.16193
[pdf, html, other]
Title:
Are Multimodal Foundation Models All That Is Needed for Emofake Detection?
Mohd Mujtaba Akhtar, Girish, Orchid Chetia Phukan, Swarup Ranjan Behera, Pailla Balakrishna Reddy, Ananda Chandra Nayak, Sanjib Kumar Nayak, Arun Balaji Buduru
Comments:
Accepted to APSIPA-ASC 2025
Subjects:
Audio and Speech Processing (eess.AS)
In this work, we investigate multimodal foundation models (MFMs) for EmoFake detection (EFD) and hypothesize that they will outperform audio foundation models (AFMs). MFMs due to their cross-modal pre-training, learns emotional patterns from multiple modalities, while AFMs rely only on audio. As such, MFMs can better recognize unnatural emotional shifts and inconsistencies in manipulated audio, making them more effective at distinguishing real from fake emotional expressions. To validate our hypothesis, we conduct a comprehensive comparative analysis of state-of-the-art (SOTA) MFMs (e.g. LanguageBind) alongside AFMs (e.g. WavLM). Our experiments confirm that MFMs surpass AFMs for EFD. Beyond individual foundation models (FMs) performance, we explore FMs fusion, motivated by findings in related research areas such synthetic speech detection and speech emotion recognition. To this end, we propose SCAR, a novel framework for effective fusion. SCAR introduces a nested cross-attention mechanism, where representations from FMs interact at two stages sequentially to refine information exchange. Additionally, a self-attention refinement module further enhances feature representations by reinforcing important cross-FM cues while suppressing noise. Through SCAR with synergistic fusion of MFMs, we achieve SOTA performance, surpassing both standalone FMs and conventional fusion approaches and previous works on EFD.
Cross submissions (showing 56 of 56 entries)
[54]
arXiv:2503.13206
(cross-list from quant-ph)
[pdf, html, other]
Title:
Enhanced Quantum Signal Control and Sensing Under Multicolored Noise via Generalized Filter Function Framework
Zhi-Da Zhang, Yao Song, Wen-Zheng Dong, Xiu-Hao Deng
Subjects:
Quantum Physics (quant-ph); Systems and Control (eess.SY)
We introduce a generalized filter-function framework that treats noise coupling strength as a tunable control parameter, enabling target noise suppression across user-defined frequency bands. By optimizing this generalized filter function, we design band-selective control pulses that achieve $0.9999$ fidelity of single- and two-qubit gates under strong noise with diverse spectral profiles. We further extend the method to selectively enhance the signal-to-noise ratio for quantum sensing of AC signals with an enhanced precision of up to $10$ dB. The resulting control pulses are experimentally feasible, offering a practical pathway toward robust quantum operations and high-precision signal processing under spectrally complex noises.
[55]
arXiv:2509.15245
(cross-list from physics.soc-ph)
[pdf, other]
Title:
Post crisis Strategies: Antifragility Principles as Catalysts for Urban Evolution Towards Sustainability
Joseph Uguet, Nicola Tollin, Jordi Morató
Comments:
24 pages, 5 figures, 3 tables, 1 appendix
Subjects:
Physics and Society (physics.soc-ph); Systems and Control (eess.SY)
Urban crises reveal the true essence of cities: their ability to either withstand disorder or collapse under its pressure. This article explores how antifragility principles can transforms urban disruption into levers for reinforcement and innovation. While resilience seeks to restore a lost balance, antifragility goes further: it pushes cities to improve through shocks. Across a critical analysis of post-crisis strategies and the identification of fifteen fundamental theoretical principles, this work proposes a new framework, structuring a proactive and evolutionary approach to urban development. Medellín, Singapore and Fukushima already illustrate this dynamic, showing that adversity can catalyse profound transformations. By integrating institutional flexibility, strategic diversity and self-organization, antifragility poses itself as an alternative to the limits of resilience. Can this model really redefine the way cities adapt to crises? This article paves the way for a decisive reflection to rethink urban planning in an uncertain world.
[56]
arXiv:2509.15253
(cross-list from cs.SD)
[pdf, html, other]
Title:
Emotion-Aware Speech Generation with Character-Specific Voices for Comics
Zhiwen Qian, Jinhua Liang, Huan Zhang
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
This paper presents an end-to-end pipeline for generating character-specific, emotion-aware speech from comics. The proposed system takes full comic volumes as input and produces speech aligned with each character's dialogue and emotional state. An image processing module performs character detection, text recognition, and emotion intensity recognition. A large language model performs dialogue attribution and emotion analysis by integrating visual information with the evolving plot context. Speech is synthesized through a text-to-speech model with distinct voice profiles tailored to each character and emotion. This work enables automated voiceover generation for comics, offering a step toward interactive and immersive comic reading experience.
[57]
arXiv:2509.15258
(cross-list from cs.LG)
[pdf, html, other]
Title:
Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model
Zheng Yang, Guoxuan Chi, Chenshu Wu, Hanyu Liu, Yuchong Gao, Yunhao Liu, Jie Xu, Tony Xiao Han
Subjects:
Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)
Generative Artificial Intelligence (GenAI) has made significant advancements in fields such as computer vision (CV) and natural language processing (NLP), demonstrating its capability to synthesize high-fidelity data and improve generalization. Recently, there has been growing interest in integrating GenAI into wireless sensing systems. By leveraging generative techniques such as data augmentation, domain adaptation, and denoising, wireless sensing applications, including device localization, human activity recognition, and environmental monitoring, can be significantly improved. This survey investigates the convergence of GenAI and wireless sensing from two complementary perspectives. First, we explore how GenAI can be integrated into wireless sensing pipelines, focusing on two modes of integration: as a plugin to augment task-specific models and as a solver to directly address sensing tasks. Second, we analyze the characteristics of mainstream generative models, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and diffusion models, and discuss their applicability and unique advantages across various wireless sensing tasks. We further identify key challenges in applying GenAI to wireless sensing and outline a future direction toward a wireless foundation model: a unified, pre-trained design capable of scalable, adaptable, and efficient signal understanding across diverse sensing tasks.
[58]
arXiv:2509.15278
(cross-list from q-bio.OT)
[pdf, other]
Title:
Assessing metadata privacy in neuroimaging
Emilie Kibsgaard, Anita Sue Jwa, Christopher J Markiewicz, David Rodriguez Gonzalez, Judith Sainz Pardo, Russell A. Poldrack, Cyril R. Pernet
Comments:
19 pages, 7 tables, 2 figures, original analysis of 6 Open Datasets
Subjects:
Other Quantitative Biology (q-bio.OT); Cryptography and Security (cs.CR); Computers and Society (cs.CY); Image and Video Processing (eess.IV)
The ethical and legal imperative to share research data without causing harm requires careful attention to privacy risks. While mounting evidence demonstrates that data sharing benefits science, legitimate concerns persist regarding the potential leakage of personal information that could lead to reidentification and subsequent harm. We reviewed metadata accompanying neuroimaging datasets from six heterogeneous studies openly available on OpenNeuro, involving participants across the lifespan, from children to older adults, with and without clinical diagnoses, and including associated clinical score data. Using metaprivBIDS (this https URL), a novel tool for the systematic assessment of privacy in tabular data, we found that privacy is generally well maintained, with serious vulnerabilities being rare. Nonetheless, minor issues were identified in nearly all datasets and warrant mitigation. Notably, clinical score data (e.g., neuropsychological results) posed minimal reidentification risk, whereas demographic variables (age, sex, race, income, and geolocation) represented the principal privacy vulnerabilities. We outline practical measures to address these risks, enabling safer data sharing practices.
[59]
arXiv:2509.15291
(cross-list from cs.AI)
[pdf, html, other]
Title:
The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI
Federico Taschin, Abderrahmane Lazaraq, Ozan K. Tonguz, Inci Ozgunes
Subjects:
Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart transportation networks has increased significantly in the last few years. Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to be a very promising approach by several authors. However, a problem with using Reinforcement Learning in Traffic Signal Control is the reliability of the trained RL agents due to the dynamically changing distribution of the input data with respect to the distribution of the data used for training. This presents a major challenge and a reliability problem for the trained network of AI agents and could have very undesirable and even detrimental consequences if a suitable solution is not found. Several researchers have tried to address this problem using different approaches. In particular, Meta Reinforcement Learning (Meta RL) promises to be an effective solution. In this paper, we evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and show that, while under certain conditions MetaLight can indeed lead to reasonably good results, under some other conditions it might not perform well (with errors of up to 22%), suggesting that Meta RL schemes are often not robust enough and can even pose major reliability problems.
[60]
arXiv:2509.15333
(cross-list from cs.CV)
[pdf, html, other]
Title:
Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception
Yulin Wang, Yang Yue, Yang Yue, Huanqian Wang, Haojun Jiang, Yizeng Han, Zanlin Ni, Yifan Pu, Minglei Shi, Rui Lu, Qisen Yang, Andrew Zhao, Zhuofan Xia, Shiji Song, Gao Huang
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)
Human vision is highly adaptive, efficiently sampling intricate environments by sequentially fixating on task-relevant regions. In contrast, prevailing machine vision models passively process entire scenes at once, resulting in excessive resource demands scaling with spatial-temporal input resolution and model size, yielding critical limitations impeding both future advancements and real-world application. Here we introduce AdaptiveNN, a general framework aiming to drive a paradigm shift from 'passive' to 'active, adaptive' vision models. AdaptiveNN formulates visual perception as a coarse-to-fine sequential decision-making process, progressively identifying and attending to regions pertinent to the task, incrementally combining information across fixations, and actively concluding observation when sufficient. We establish a theory integrating representation learning with self-rewarding reinforcement learning, enabling end-to-end training of the non-differentiable AdaptiveNN without additional supervision on fixation locations. We assess AdaptiveNN on 17 benchmarks spanning 9 tasks, including large-scale visual recognition, fine-grained discrimination, visual search, processing images from real driving and medical scenarios, language-driven embodied AI, and side-by-side comparisons with humans. AdaptiveNN achieves up to 28x inference cost reduction without sacrificing accuracy, flexibly adapts to varying task demands and resource budgets without retraining, and provides enhanced interpretability via its fixation patterns, demonstrating a promising avenue toward efficient, flexible, and interpretable computer vision. Furthermore, AdaptiveNN exhibits closely human-like perceptual behaviors in many cases, revealing its potential as a valuable tool for investigating visual cognition. Code is available at this https URL.
[61]
arXiv:2509.15362
(cross-list from cs.CL)
[pdf, html, other]
Title:
Speech Language Models for Under-Represented Languages: Insights from Wolof
Yaya Sy, Dioula Doucouré, Christophe Cerisara, Irina Illina
Subjects:
Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)
We present our journey in training a speech language model for Wolof, an underrepresented language spoken in West Africa, and share key insights. We first emphasize the importance of collecting large-scale, spontaneous, high-quality speech data, and show that continued pretraining HuBERT on this dataset outperforms both the base model and African-centric models on ASR. We then integrate this speech encoder into a Wolof LLM to train the first Speech LLM for this language, extending its capabilities to tasks such as speech translation. Furthermore, we explore training the Speech LLM to perform multi-step Chain-of-Thought before transcribing or translating. Our results show that the Speech LLM not only improves speech recognition but also performs well in speech translation. The models and the code will be openly shared.
[62]
arXiv:2509.15382
(cross-list from physics.optics)
[pdf, other]
Title:
OSI-flex: Optimization-Based Shearing Interferometry for Joint Phase and Shear Estimation Using a Flexible Open-Source Framework
Julianna Winnik, Damian Suski, Matyáš Heto, Małgorzata Lenarnik, Michał Ziemczonok, Maciej Trusiak, Piotr Zdańkowski
Subjects:
Optics (physics.optics); Image and Video Processing (eess.IV)
Shearing interferometry is a common-path quantitative phase imaging technique in which an object beam interferes with a laterally shifted replica of itself, providing high temporal stability, reduced sensitivity to environmental noise, compact design, and compatibility with partially coherent illumination that suppresses coherence-related artifacts. Its principal limitation, however, is that it yields only sheared phase-difference measurements rather than the absolute phase, thereby requiring additional reconstruction step. In this work, we introduce OSI-flex, a flexible, open-source computational framework for quantitative phase reconstruction from sheared phase-difference measurements. The method leverages modern machine learning tools, namely automatic differentiation and the advanced ADAM (Adaptive Moment Estimation) optimizer. The method simultaneously estimates the phase and shear values, enabling it to adapt to experimental conditions where the shear cannot be precisely determined. Because defining shear value is inherently difficult in most systems, yet crucial for effective phase reconstruction, this joint optimization leads to robust and reliable phase retrieval. OSI-flex is highly versatile, supporting arbitrary numbers, magnitudes, and orientations of shear vectors. While optimal reconstruction is achieved with two orthogonal shears, the inclusion of regularization - specifically total variation minimization and sign constraint - enables OSI-flex to remain effective with nonorthogonal or even single-shear measurements. Moreover, OSI-flex accommodates a wide range of shear magnitudes, from subpixel (differential configuration) to several dozen pixels (semi-total shear configuration). Validation with simulations and experimental data confirms quantitative accuracy on calibrated phase objects and demonstrates robustness with 3D-printed cell phantom and follicular thyroid cells.
[63]
arXiv:2509.15389
(cross-list from cs.SD)
[pdf, html, other]
Title:
Exploring Fine-Tuning of Large Audio Language Models for Spoken Language Understanding under Limited Speech data
Youngwon Choi, Jaeyoon Jung, Hyeonyu Kim, Huu-Kim Nguyen, Hwayeon Kim
Comments:
4 pages (excluding references), 2 figures, submitted to ICASSP 2026
Subjects:
Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
Large Audio Language Models (LALMs) have emerged as powerful tools for speech-related tasks but remain underexplored for fine-tuning, especially with limited speech data. To bridge this gap, we systematically examine how different fine-tuning schemes including text-only, direct mixing, and curriculum learning affect spoken language understanding (SLU), focusing on scenarios where text-label pairs are abundant while paired speech-label data are limited. Results show that LALMs already achieve competitive performance with text-only fine-tuning, highlighting their strong generalization ability. Adding even small amounts of speech data (2-5%) yields substantial further gains, with curriculum learning particularly effective under scarce data. In cross-lingual SLU, combining source-language speech data with target-language text and minimal target-language speech data enables effective adaptation. Overall, this study provides practical insights into the LALM fine-tuning under realistic data constraints.
[64]
arXiv:2509.15411
(cross-list from cs.IT)
[pdf, html, other]
Title:
Enhancing Physical Layer Security in IoT-Based RF-FSO Integrated Networks: Multi-RIS Structures and their Impact on Secure Communication
Anika Tabassum Biva, Md. Ibrahim, A. S. M. Badrudduza, Imran Shafique Ansari
Subjects:
Information Theory (cs.IT); Signal Processing (eess.SP)
Due to their ability to dynamically control the propagation environment, reconfigurable intelligent surfaces (RISs) offer a promising solution to address the challenges of $6$G wireless communication, especially in the context of Internet of Things (IoT) networks. This paper investigates a mixed communication model with multi-RIS-aided radio frequency (RF)-free space optics (FSO) to enhance the performance of IoT applications in complex environments. An eavesdropper is assumed to be present, attempting to intercept confidential information transmitted over the RF link. All RF links are modeled using Rician fading, while the FSO link accounts for Málaga turbulence with pointing errors, capturing real-world propagation conditions. Closed-form analytical expressions are derived for the secrecy outage probability, average secrecy capacity, and effective secrecy throughput in terms of Meijer's G function. To gain further insight, high signal-to-noise approximations of these metrics are also presented. Numerical results highlight the importance of heterodyne detection in mitigating the adverse effects of pointing errors on the FSO link. Moreover, integrating a multi-RIS structure into the proposed model significantly increases secrecy performance, achieving up to a $47.67\%$ improvement in SOP compared to conventional methods. Finally, the derived analytical results are validated through Monte Carlo simulations.
[65]
arXiv:2509.15412
(cross-list from cs.RO)
[pdf, html, other]
Title:
Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control
Easop Lee, Samuel A. Moore, Boyuan Chen
Subjects:
Robotics (cs.RO); Systems and Control (eess.SY)
We present Sym2Real, a fully data-driven framework that provides a principled way to train low-level adaptive controllers in a highly data-efficient manner. Using only about 10 trajectories, we achieve robust control of both a quadrotor and a racecar in the real world, without expert knowledge or simulation tuning. Our approach achieves this data efficiency by bringing symbolic regression to real-world robotics while addressing key challenges that prevent its direct application, including noise sensitivity and model degradation that lead to unsafe control. Our key observation is that the underlying physics is often shared for a system regardless of internal or external changes. Hence, we strategically combine low-fidelity simulation data with targeted real-world residual learning. Through experimental validation on quadrotor and racecar platforms, we demonstrate consistent data-efficient adaptation across six out-of-distribution sim2sim scenarios and successful sim2real transfer across five real-world conditions. More information and videos can be found at at this http URL
[66]
arXiv:2509.15423
(cross-list from cs.RO)
[pdf, html, other]
Title:
Online Slip Detection and Friction Coefficient Estimation for Autonomous Racing
Christopher Oeltjen, Carson Sobolewski, Saleh Faghfoorian, Lorant Domokos, Giancarlo Vidal, Ivan Ruchkin
Comments:
Equal contribution by the first three authors
Subjects:
Robotics (cs.RO); Systems and Control (eess.SY)
Accurate knowledge of the tire-road friction coefficient (TRFC) is essential for vehicle safety, stability, and performance, especially in autonomous racing, where vehicles often operate at the friction limit. However, TRFC cannot be directly measured with standard sensors, and existing estimation methods either depend on vehicle or tire models with uncertain parameters or require large training datasets. In this paper, we present a lightweight approach for online slip detection and TRFC estimation. Our approach relies solely on IMU and LiDAR measurements and the control actions, without special dynamical or tire models, parameter identification, or training data. Slip events are detected in real time by comparing commanded and measured motions, and the TRFC is then estimated directly from observed accelerations under no-slip conditions. Experiments with a 1:10-scale autonomous racing car across different friction levels demonstrate that the proposed approach achieves accurate and consistent slip detections and friction coefficients, with results closely matching ground-truth measurements. These findings highlight the potential of our simple, deployable, and computationally efficient approach for real-time slip monitoring and friction coefficient estimation in autonomous driving.
[67]
arXiv:2509.15430
(cross-list from cs.CL)
[pdf, html, other]
Title:
BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition
Liuyuan Jiang, Xiaodong Cui, Brian Kingsbury, Tianyi Chen, Lisha Chen
Comments:
5 pages including reference
Subjects:
Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Speech is a rich signal, and labeled audio-text pairs are costly, making self-supervised learning essential for scalable representation learning. A core challenge in speech SSL is generating pseudo-labels that are both informative and efficient: strong labels, such as those used in HuBERT, improve downstream performance but rely on external encoders and multi-stage pipelines, while efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels. We propose BiRQ, a bilevel SSL framework that combines the efficiency of BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key idea is to reuse part of the model itself as a pseudo-label generator: intermediate representations are discretized by a random-projection quantizer to produce enhanced labels, while anchoring labels derived directly from the raw input stabilize training and prevent collapse. Training is formulated as an efficient first-order bilevel optimization problem, solved end-to-end with differentiable Gumbel-softmax selection. This design eliminates the need for external label encoders, reduces memory cost, and enables iterative label refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ while maintaining low complexity and computational efficiency. We validate our method on various datasets, including 960-hour LibriSpeech, 150-hour AMI meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.
[68]
arXiv:2509.15437
(cross-list from cs.SD)
[pdf, html, other]
Title:
Impact of Phonetics on Speaker Identity in Adversarial Voice Attack
Daniyal Kabir Dar, Qiben Yan, Li Xiao, Arun Ross
Comments:
Additional figures for extended visualization: this https URL
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Audio and Speech Processing (eess.AS)
Adversarial perturbations in speech pose a serious threat to automatic speech recognition (ASR) and speaker verification by introducing subtle waveform modifications that remain imperceptible to humans but can significantly alter system outputs. While targeted attacks on end-to-end ASR models have been widely studied, the phonetic basis of these perturbations and their effect on speaker identity remain underexplored. In this work, we analyze adversarial audio at the phonetic level and show that perturbations exploit systematic confusions such as vowel centralization and consonant substitutions. These distortions not only mislead transcription but also degrade phonetic cues critical for speaker verification, leading to identity drift. Using DeepSpeech as our ASR target, we generate targeted adversarial examples and evaluate their impact on speaker embeddings across genuine and impostor samples. Results across 16 phonetically diverse target phrases demonstrate that adversarial audio induces both transcription errors and identity drift, highlighting the need for phonetic-aware defenses to ensure the robustness of ASR and speaker recognition systems.
[69]
arXiv:2509.15449
(cross-list from cs.HC)
[pdf, other]
Title:
In-Ear Electrode EEG for Practical SSVEP BCI
Surej Mouli, Ramaswamy Palaniappan, Emmanuel Molefi, Ian McLoughlin
Comments:
12 pages
Subjects:
Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)
Steady State Visual Evoked Potential (SSVEP) methods for brain computer interfaces (BCI) are popular due to higher information transfer rate and easier setup with minimal training, compared to alternative methods. With precisely generated visual stimulus frequency, it is possible to translate brain signals into external actions or signals. Traditionally, SSVEP data is collected from the occipital region using electrodes with or without gel, normally mounted on a head cap. In this experimental study, we develop an in ear electrode to collect SSVEP data for four different flicker frequencies and compare against occipital scalp electrode data. Data from five participants demonstrates the feasibility of in-ear electrode based SSVEP, significantly enhancing the practicability of wearable BCI applications.
[70]
arXiv:2509.15462
(cross-list from cs.SD)
[pdf, html, other]
Title:
A Novel Semantic Compression Approach for Ultra-low Bandwidth Voice Communication
Ryan Collette, Ross Greenwood, Serena Nicoll
Comments:
5 pages, 2 figures. This work has been submitted to the IEEE for possible publication
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
While existing speech audio codecs designed for compression exploit limited forms of temporal redundancy and allow for multi-scale representations, they tend to represent all features of audio in the same way. In contrast, generative voice models designed for text-to-speech and voice transfer tasks have recently proved effective at factorizing audio signals into high-level semantic representations of fundamentally distinct features. In this paper, we leverage such representations in a novel semantic communications approach to achieve lower bitrates without sacrificing perceptual quality or suitability for specific downstream tasks. Our technique matches or outperforms existing audio codecs on transcription, sentiment analysis, and speaker verification when encoding at 2-4x lower bitrate -- notably surpassing Encodec in perceptual quality and speaker verification while using up to 4x less bitrate.
[71]
arXiv:2509.15491
(cross-list from cs.RO)
[pdf, html, other]
Title:
Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems
Reza Pirayeshshirazinezhad, Nima Fathi
Subjects:
Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)
We present an explainable AI-enhanced supervisory control framework for multi-agent robotics that combines (i) a timed-automata supervisor for safe, auditable mode switching, (ii) robust continuous control (Lyapunov-based controller for large-angle maneuver; sliding-mode controller (SMC) with boundary layers for precision and disturbance rejection), and (iii) an explainable predictor that maps mission context to gains and expected performance (energy, error). Monte Carlo-driven optimization provides the training data, enabling transparent real-time trade-offs.
We validated the approach in two contrasting domains, spacecraft formation flying and autonomous underwater vehicles (AUVs). Despite different environments (gravity/actuator bias vs. hydrodynamic drag/currents), both share uncertain six degrees of freedom (6-DOF) rigid-body dynamics, relative motion, and tight tracking needs, making them representative of general robotic systems. In the space mission, the supervisory logic selects parameters that meet mission criteria. In AUV leader-follower tests, the same SMC structure maintains a fixed offset under stochastic currents with bounded steady error. In spacecraft validation, the SMC controller achieved submillimeter alignment with 21.7% lower tracking error and 81.4% lower energy consumption compared to Proportional-Derivative PD controller baselines. At the same time, in AUV tests, SMC maintained bounded errors under stochastic currents. These results highlight both the portability and the interpretability of the approach for safety-critical, resource-constrained multi-agent robotics.
[72]
arXiv:2509.15492
(cross-list from cs.SD)
[pdf, html, other]
Title:
Beyond Video-to-SFX: Video to Audio Synthesis with Environmentally Aware Speech
Xinlei Niu, Jianbo Ma, Dylan Harper-Harris, Xiangyu Zhang, Charles Patrick Martin, Jing Zhang
Subjects:
Sound (cs.SD); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)
The generation of realistic, context-aware audio is important in real-world applications such as video game development. While existing video-to-audio (V2A) methods mainly focus on Foley sound generation, they struggle to produce intelligible speech. Meanwhile, current environmental speech synthesis approaches remain text-driven and fail to temporally align with dynamic video content. In this paper, we propose Beyond Video-to-SFX (BVS), a method to generate synchronized audio with environmentally aware intelligible speech for given videos. We introduce a two-stage modeling method: (1) stage one is a video-guided audio semantic (V2AS) model to predict unified audio semantic tokens conditioned on phonetic cues; (2) stage two is a video-conditioned semantic-to-acoustic (VS2A) model that refines semantic tokens into detailed acoustic tokens. Experiments demonstrate the effectiveness of BVS in scenarios such as video-to-context-aware speech synthesis and immersive audio background conversion, with ablation studies further validating our design. Our demonstration is available at~\href{this https URL}{BVS-Demo}.
[73]
arXiv:2509.15513
(cross-list from cs.LG)
[pdf, html, other]
Title:
KoopCast: Trajectory Forecasting via Koopman Operators
Jungjin Lee, Jaeuk Shin, Gihwan Kim, Joonho Han, Insoon Yang
Subjects:
Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)
We present KoopCast, a lightweight yet efficient model for trajectory forecasting in general dynamic environments. Our approach leverages Koopman operator theory, which enables a linear representation of nonlinear dynamics by lifting trajectories into a higher-dimensional space. The framework follows a two-stage design: first, a probabilistic neural goal estimator predicts plausible long-term targets, specifying where to go; second, a Koopman operator-based refinement module incorporates intention and history into a nonlinear feature space, enabling linear prediction that dictates how to go. This dual structure not only ensures strong predictive accuracy but also inherits the favorable properties of linear operators while faithfully capturing nonlinear dynamics. As a result, our model offers three key advantages: (i) competitive accuracy, (ii) interpretability grounded in Koopman spectral theory, and (iii) low-latency deployment. We validate these benefits on ETH/UCY, the Waymo Open Motion Dataset, and nuScenes, which feature rich multi-agent interactions and map-constrained nonlinear motion. Across benchmarks, KoopCast consistently delivers high predictive accuracy together with mode-level interpretability and practical efficiency.
[74]
arXiv:2509.15533
(cross-list from cs.LG)
[pdf, html, other]
Title:
Universal Learning of Stochastic Dynamics for Exact Belief Propagation using Bernstein Normalizing Flows
Peter Amorese, Morteza Lahijanian
Comments:
13 pages, 7 figures
Subjects:
Machine Learning (cs.LG); Systems and Control (eess.SY)
Predicting the distribution of future states in a stochastic system, known as belief propagation, is fundamental to reasoning under uncertainty. However, nonlinear dynamics often make analytical belief propagation intractable, requiring approximate methods. When the system model is unknown and must be learned from data, a key question arises: can we learn a model that (i) universally approximates general nonlinear stochastic dynamics, and (ii) supports analytical belief propagation? This paper establishes the theoretical foundations for a class of models that satisfy both properties. The proposed approach combines the expressiveness of normalizing flows for density estimation with the analytical tractability of Bernstein polynomials. Empirical results show the efficacy of our learned model over state-of-the-art data-driven methods for belief propagation, especially for highly non-linear systems with non-additive, non-Gaussian noise.
[75]
arXiv:2509.15554
(cross-list from math.ST)
[pdf, html, other]
Title:
Direct Estimation of Eigenvalues of Large Dimensional Precision Matrix
Jie Zhou, Junhao Xie, Jiaqi Chen
Subjects:
Statistics Theory (math.ST); Signal Processing (eess.SP); Applications (stat.AP)
In this paper, we consider directly estimating the eigenvalues of precision matrix, without inverting the corresponding estimator for the eigenvalues of covariance matrix. We focus on a general asymptotic regime, i.e., the large dimensional regime, where both the dimension $N$ and the sample size $K$ tend to infinity whereas their quotient $N/K$ converges to a positive constant. By utilizing tools from random matrix theory, we construct an improved estimator for eigenvalues of precision matrix. We prove the consistency of the new estimator under large dimensional regime. In order to obtain the asymptotic bias term of the proposed estimator, we provide a theoretical result that characterizes the convergence rate of the expected Stieltjes transform (with its derivative) of the spectra of the sample covariance matrix. Using this result, we prove that the asymptotic bias term of the proposed estimator is of order $O(1/K^2)$. Additionally, we establish a central limiting theorem (CLT) to describe the fluctuations of the new estimator. Finally, some numerical examples are presented to validate the excellent performance of the new estimator and to verify the accuracy of the CLT.
[76]
arXiv:2509.15570
(cross-list from cs.SD)
[pdf, html, other]
Title:
Contrastive Learning with Spectrum Information Augmentation in Abnormal Sound Detection
Xinxin Meng, Jiangtao Guo, Yunxiang Zhang, Shun Huang
Comments:
Accepted CVIPPR 2024 April Xiamen China
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
The outlier exposure method is an effective approach to address the unsupervised anomaly sound detection problem. The key focus of this method is how to make the model learn the distribution space of normal data. Based on biological perception and data analysis, it is found that anomalous audio and noise often have higher frequencies. Therefore, we propose a data augmentation method for high-frequency information in contrastive learning. This enables the model to pay more attention to the low-frequency information of the audio, which represents the normal operational mode of the machine. We evaluated the proposed method on the DCASE 2020 Task 2. The results showed that our method outperformed other contrastive learning methods used on this dataset. We also evaluated the generalizability of our method on the DCASE 2022 Task 2 dataset.
[77]
arXiv:2509.15571
(cross-list from math.OC)
[pdf, html, other]
Title:
Uniform Sampling from the Reachable Set Using Optimal Transport
Karthik Elamvazhuthi, Sachin Shivakumar
Subjects:
Optimization and Control (math.OC); Systems and Control (eess.SY)
Finding the reachable set of a system has a wide range of applications, but is a fundamental challenge in control theory, especially when controls are bounded. Although one can simply integrate the system samples forward in time by applying random admissible control to approximate the reachable set, the samples typically cluster near an attractor (if one is present) -- yielding a poor representation of the reachable set. A better representation can be found by applying controls that specifically lead to a uniform terminal state distribution, however, finding such controls is non-trivial. To find such controls, one must solve an Optimal Transport (OT) problem with uniform measure as the target distribution, which is difficult since the reachable set is not know \emph{a priori}.
We can overcome this difficulty by softening the terminal measure constraint via the introduction of a $L_2$-entropy function in the objective and can further reduce this infinite-dimensional regularized OT to a finite-dimensional particle-based optimal control problem by using a nonlocal kernel regularization of the entropy. This leads to a hierarchy of optimization problems whose solutions converge to the original reachability sampling OT problem, as proved by $\Gamma$-convergence. The effectiveness of this entropy-regularized particle-based approach for uniform sampling of reachable set is demonstrated using numerical examples.
[78]
arXiv:2509.15579
(cross-list from cs.CL)
[pdf, html, other]
Title:
Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization
Yun Tang, Cindy Tseng
Subjects:
Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Low latency speech human-machine communication is becoming increasingly necessary as speech technology advances quickly in the last decade. One of the primary factors behind the advancement of speech technology is self-supervised learning. Most self-supervised learning algorithms are designed with full utterance assumption and compromises have to made if partial utterances are presented, which are common in the streaming applications. In this work, we propose a chunk based self-supervised learning (Chunk SSL) algorithm as an unified solution for both streaming and offline speech pre-training. Chunk SSL is optimized with the masked prediction loss and an acoustic encoder is encouraged to restore indices of those masked speech frames with help from unmasked frames in the same chunk and preceding chunks. A copy and append data augmentation approach is proposed to conduct efficient chunk based pre-training. Chunk SSL utilizes a finite scalar quantization (FSQ) module to discretize input speech features and our study shows a high resolution FSQ codebook, i.e., a codebook with vocabulary size up to a few millions, is beneficial to transfer knowledge from the pre-training task to the downstream tasks. A group masked prediction loss is employed during pre-training to alleviate the high memory and computation cost introduced by the large codebook. The proposed approach is examined in two speech to text tasks, i.e., speech recognition and speech translation. Experimental results on the \textsc{Librispeech} and \textsc{Must-C} datasets show that the proposed method could achieve very competitive results for speech to text tasks at both streaming and offline modes.
[79]
arXiv:2509.15583
(cross-list from cs.RO)
[pdf, other]
Title:
Bench-RNR: Dataset for Benchmarking Repetitive and Non-repetitive Scanning LiDAR for Infrastructure-based Vehicle Localization
Runxin Zhao, Chunxiang Wang, Hanyang Zhuang, Ming Yang
Subjects:
Robotics (cs.RO); Signal Processing (eess.SP)
Vehicle localization using roadside LiDARs can provide centimeter-level accuracy for cloud-controlled vehicles while simultaneously serving multiple vehicles, enhanc-ing safety and efficiency. While most existing studies rely on repetitive scanning LiDARs, non-repetitive scanning LiDAR offers advantages such as eliminating blind zones and being more cost-effective. However, its application in roadside perception and localization remains limited. To address this, we present a dataset for infrastructure-based vehicle localization, with data collected from both repetitive and non-repetitive scanning LiDARs, in order to benchmark the performance of different LiDAR scanning patterns. The dataset contains 5,445 frames of point clouds across eight vehicle trajectory sequences, with diverse trajectory types. Our experiments establish base-lines for infrastructure-based vehicle localization and compare the performance of these methods using both non-repetitive and repetitive scanning LiDARs. This work offers valuable insights for selecting the most suitable LiDAR scanning pattern for infrastruc-ture-based vehicle localization. Our dataset is a signifi-cant contribution to the scientific community, supporting advancements in infrastructure-based perception and vehicle localization. The dataset and source code are publicly available at: this https URL.
[80]
arXiv:2509.15612
(cross-list from cs.SD)
[pdf, html, other]
Title:
Thinking in cocktail party: Chain-of-Thought and reinforcement learning for target speaker automatic speech recognition
Yiru Zhang, Hang Su, Lichun Fan, Zhenbo Luo, Jian Luan
Comments:
submitted to ICASSP 2026
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Target Speaker Automatic Speech Recognition (TS-ASR) aims to transcribe the speech of a specified target speaker from multi-speaker mixtures in cocktail party scenarios. Recent advancement of Large Audio-Language Models (LALMs) has already brought some new insights to TS-ASR. However, significant room for optimization remains for the TS-ASR task within the LALMs architecture. While Chain of Thoughts (CoT) and Reinforcement Learning (RL) have proven effective in certain speech tasks, TS-ASR, which requires the model to deeply comprehend speech signals, differentiate various speakers, and handle overlapping utterances is particularly well-suited to a reasoning-guided approach. Therefore, we propose a novel framework that incorporates CoT and RL training into TS-ASR for performance improvement. A novel CoT dataset of TS-ASR is constructed, and the TS-ASR model is first trained on regular data and then fine-tuned on CoT data. Finally, the model is further trained with RL using selected data to enhance generalized reasoning capabilities. Experiment results demonstrate a significant improvement of TS-ASR performance with CoT and RL training, establishing a state-of-the-art performance compared with previous works of TS-ASR on comparable datasets.
[81]
arXiv:2509.15613
(cross-list from cs.RO)
[pdf, html, other]
Title:
Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization
Sven Hinderer, Pascal Schlachter, Zhibin Yu, Xiaofeng Wu, Bin Yang
Journal-ref:
2023 13th International Conference on Indoor Positioning and Indoor Navigation (IPIN)
Subjects:
Robotics (cs.RO); Signal Processing (eess.SP)
We extend our work on a novel indoor positioning system (IPS) for autonomous mobile robots (AMRs) based on radar sensing of local, passive radar reflectors. Through the combination of simple reflectors and a single-channel frequency modulated continuous wave (FMCW) radar, high positioning accuracy at low system cost can be achieved. Further, a multi-objective (MO) particle swarm optimization (PSO) algorithm is presented that optimizes the 2D placement of radar reflectors in complex room settings.
[82]
arXiv:2509.15622
(cross-list from cs.SD)
[pdf, html, other]
Title:
De-crackling Virtual Analog Controls with Asymptotically Stable Recurrent Neural Networks
Valtteri Kallinen, Lauri Juvela
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Recurrent neural networks are used in virtual analog modeling applications to digitally replicate the sound of analog hardware audio processors. The controls of hardware devices can be used as a conditioning input to these networks. A common method for introducing control conditioning to these models is the direct static concatenation of controls with input audio samples, which we show produces audio artifacts under time-varied conditioning. Here we derive constraints for asymptotically stable variants of commonly used recurrent neural networks and demonstrate that asymptotical stability in recurrent neural networks can eliminate audio artifacts from the model output under zero input and time-varied conditioning. Furthermore, our results suggest a possible general solution to mitigate conditioning-induced artifacts in other audio neural network architectures, such as convolutional and state-space models.
[83]
arXiv:2509.15625
(cross-list from cs.SD)
[pdf, html, other]
Title:
The Rhythm In Anything: Audio-Prompted Drums Generation with Masked Language Modeling
Patrick O'Reilly, Julia Barnett, Hugo Flores García, Annie Chu, Nathan Pruyne, Prem Seetharaman, Bryan Pardo
Comments:
ISMIR 2025
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Musicians and nonmusicians alike use rhythmic sound gestures, such as tapping and beatboxing, to express drum patterns. While these gestures effectively communicate musical ideas, realizing these ideas as fully-produced drum recordings can be time-consuming, potentially disrupting many creative workflows. To bridge this gap, we present TRIA (The Rhythm In Anything), a masked transformer model for mapping rhythmic sound gestures to high-fidelity drum recordings. Given an audio prompt of the desired rhythmic pattern and a second prompt to represent drumkit timbre, TRIA produces audio of a drumkit playing the desired rhythm (with appropriate elaborations) in the desired timbre. Subjective and objective evaluations show that a TRIA model trained on less than 10 hours of publicly-available drum data can generate high-quality, faithful realizations of sound gestures across a wide range of timbres in a zero-shot manner.
[84]
arXiv:2509.15626
(cross-list from cs.SD)
[pdf, html, other]
Title:
LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control
Junki Ohmura, Yuki Ito, Emiru Tsunoo, Toshiyuki Sekiya, Toshiyuki Kumakura
Comments:
Submitted to ICASSP 2026
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Fine-grained control over voice impressions (e.g., making a voice brighter or calmer) is a key frontier for creating more controllable text-to-speech. However, this nascent field faces two key challenges. The first is the problem of impression leakage, where the synthesized voice is undesirably influenced by the speaker's reference audio, rather than the separately specified target impression, and the second is the lack of a public, annotated corpus. To mitigate impression leakage, we propose two methods: 1) a training strategy that separately uses an utterance for speaker identity and another utterance of the same speaker for target impression, and 2) a novel reference-free model that generates a speaker embedding solely from the target impression, achieving the benefits of improved robustness against the leakage and the convenience of reference-free generation. Objective and subjective evaluations demonstrate a significant improvement in controllability. Our best method reduced the mean squared error of 11-dimensional voice impression vectors from 0.61 to 0.41 objectively and from 1.15 to 0.92 subjectively, while maintaining high fidelity. To foster reproducible research, we introduce LibriTTS-VI, the first public voice impression dataset released with clear annotation standards, built upon the LibriTTS-R corpus.
[85]
arXiv:2509.15629
(cross-list from cs.SD)
[pdf, html, other]
Title:
The Singing Voice Conversion Challenge 2025: From Singer Identity Conversion To Singing Style Conversion
Lester Phillip Violeta, Xueyao Zhang, Jiatong Shi, Yusuke Yasuda, Wen-Chin Huang, Zhizheng Wu, Tomoki Toda
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
We present the findings of the latest iteration of the Singing Voice Conversion Challenge, a scientific event aiming to compare and understand different voice conversion systems in a controlled environment. Compared to previous iterations which solely focused on converting the singer identity, this year we also focused on converting the singing style of the singer. To create a controlled environment and thorough evaluations, we developed a new challenge database, introduced two tasks, open-sourced baselines, and conducted large-scale crowd-sourced listening tests and objective evaluations. The challenge was ran for two months and in total we evaluated 26 different systems. The results of the large-scale crowd-sourced listening test showed that top systems had comparable singer identity scores to ground truth samples. However, modeling the singing style and consequently achieving high naturalness still remains a challenge in this task, primarily due to the difficulty in modeling dynamic information in breathy, glissando, and vibrato singing styles.
[86]
arXiv:2509.15637
(cross-list from cs.IT)
[pdf, html, other]
Title:
Interplay Between Belief Propagation and Transformer: Differential-Attention Message Passing Transformer
Chin Wa Lau, Xiang Shi, Ziyan Zheng, Haiwen Cao, Nian Guo
Comments:
6 pages, 4 figures, to be published in ISIT2025
Subjects:
Information Theory (cs.IT); Signal Processing (eess.SP)
Transformer-based neural decoders have emerged as a promising approach to error correction coding, combining data-driven adaptability with efficient modeling of long-range dependencies. This paper presents a novel decoder architecture that integrates classical belief propagation principles with transformer designs. We introduce a differentiable syndrome loss function leveraging global codebook structure and a differential-attention mechanism optimizing bit and syndrome embedding interactions. Experimental results demonstrate consistent performance improvements over existing transformer-based decoders, with our approach surpassing traditional belief propagation decoders for short-to-medium length LDPC codes.
[87]
arXiv:2509.15654
(cross-list from cs.SD)
[pdf, other]
Title:
EMO-RL: Emotion-Rule-Based Reinforcement Learning Enhanced Audio-Language Model for Generalized Speech Emotion Recognition
Pengcheng Li, Botao Zhao, Zuheng Kang, Junqing Peng, Xiaoyang Qu, Yayun He, Jianzong Wang
Comments:
Accpeted by the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Although Large Audio-Language Models (LALMs) have exhibited outstanding performance in auditory understanding, their performance in affective computing scenarios, particularly in emotion recognition, reasoning, and subtle sentiment differentiation, remains suboptimal. Recent advances in Reinforcement Learning (RL) have shown promise in improving LALMs' reasoning abilities. However, two critical challenges hinder the direct application of RL techniques to Speech Emotion Recognition (SER) tasks: (1) convergence instability caused by ambiguous emotional boundaries and (2) limited reasoning ability when using relatively small models (e.g., 7B-parameter architectures). To overcome these limitations, we introduce EMO-RL, a novel framework incorporating reinforcement learning with two key innovations: Emotion Similarity-Weighted Reward (ESWR) and Explicit Structured Reasoning (ESR). Built upon pretrained LALMs, our method employs group-relative policy optimization with emotion constraints. Comprehensive experiments demonstrate that our EMO-RL training strategies can significantly enhance the emotional reasoning capabilities of LALMs, attaining state-of-the-art results on both the MELD and IEMOCAP datasets, and cross-dataset experiments prove the strong superiority of generalization.
[88]
arXiv:2509.15655
(cross-list from cs.CL)
[pdf, html, other]
Title:
Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations
Linyang He, Qiaolin Wang, Xilin Jiang, Nima Mesgarani
Comments:
EMNLP 2025 Main Conference (Oral)
Subjects:
Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
Transformer-based speech language models (SLMs) have significantly improved neural speech recognition and understanding. While existing research has examined how well SLMs encode shallow acoustic and phonetic features, the extent to which SLMs encode nuanced syntactic and conceptual features remains unclear. By drawing parallels with linguistic competence assessments for large language models, this study is the first to systematically evaluate the presence of contextual syntactic and semantic features across SLMs for self-supervised learning (S3M), automatic speech recognition (ASR), speech compression (codec), and as the encoder for auditory large language models (AudioLLMs). Through minimal pair designs and diagnostic feature analysis across 71 tasks spanning diverse linguistic levels, our layer-wise and time-resolved analysis uncovers that 1) all speech encode grammatical features more robustly than conceptual ones.
[89]
arXiv:2509.15661
(cross-list from cs.SD)
[pdf, html, other]
Title:
SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models
Qiaolin Wang, Xilin Jiang, Linyang He, Junkai Wu, Nima Mesgarani
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
While large audio-language models (LALMs) have demonstrated state-of-the-art audio understanding, their reasoning capability in complex soundscapes still falls behind large vision-language models (LVLMs). Compared to the visual domain, one bottleneck is the lack of large-scale chain-of-thought audio data to teach LALM stepwise reasoning. To circumvent this data and modality gap, we present SightSound-R1, a cross-modal distillation framework that transfers advanced reasoning from a stronger LVLM teacher to a weaker LALM student on the same audio-visual question answering (AVQA) dataset. SightSound-R1 consists of three core steps: (i) test-time scaling to generate audio-focused chains of thought (CoT) from an LVLM teacher, (ii) audio-grounded validation to filter hallucinations, and (iii) a distillation pipeline with supervised fine-tuning (SFT) followed by Group Relative Policy Optimization (GRPO) for the LALM student. Results show that SightSound-R1 improves LALM reasoning performance both in the in-domain AVQA test set as well as in unseen auditory scenes and questions, outperforming both pretrained and label-only distilled baselines. Thus, we conclude that vision reasoning can be effectively transferred to audio models and scaled with abundant audio-visual data.
[90]
arXiv:2509.15662
(cross-list from cs.MM)
[pdf, html, other]
Title:
Jamendo-QA: A Large-Scale Music Question Answering Dataset
Junyoung Koh, Soo Yong Kim, Yongwon Choi, Gyu Hyeong Choi
Comments:
4 pages, 8 figures. Submitted to ICASSP 2026
Subjects:
Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)
We introduce Jamendo-QA, a large-scale dataset for Music Question Answering (Music-QA). The dataset is built on freely licensed tracks from the Jamendo platform and is automatically annotated using the Qwen-Omni model. Jamendo-QA provides question-answer pairs and captions aligned with music audio, enabling both supervised training and zero-shot evaluation. Our resource aims to fill the gap of music-specific QA datasets and foster further research in music understanding, retrieval, and generative applications. In addition to its scale, Jamendo-QA covers a diverse range of genres, instruments, and metadata attributes, allowing robust model benchmarking across varied musical contexts. We also provide detailed dataset statistics and highlight potential biases such as genre and gender imbalance to guide fair evaluation. We position Jamendo-QA as a scalable and publicly available benchmark that can facilitate future research in music understanding, multimodal modeling, and fair evaluation of music-oriented QA systems.
[91]
arXiv:2509.15664
(cross-list from q-bio.GN)
[pdf, html, other]
Title:
siDPT: siRNA Efficacy Prediction via Debiased Preference-Pair Transformer
Honggen Zhang, Xiangrui Gao, Lipeng Lai
Subjects:
Genomics (q-bio.GN); Signal Processing (eess.SP); Quantitative Methods (q-bio.QM)
Small interfering RNA (siRNA) is a short double-stranded RNA molecule (about 21-23 nucleotides) with the potential to cure diseases by silencing the function of target genes. Due to its well-understood mechanism, many siRNA-based drugs have been evaluated in clinical trials. However, selecting effective binding regions and designing siRNA sequences requires extensive experimentation, making the process costly. As genomic resources and publicly available siRNA datasets continue to grow, data-driven models can be leveraged to better understand siRNA-mRNA interactions. To fully exploit such data, curating high-quality siRNA datasets is essential to minimize experimental errors and noise. We propose siDPT: siRNA efficacy Prediction via Debiased Preference-Pair Transformer, a framework that constructs a preference-pair dataset and designs an siRNA-mRNA interactive transformer with debiased ranking objectives to improve siRNA inhibition prediction and generalization. We evaluate our approach using two public datasets and one newly collected patent dataset. Our model demonstrates substantial improvement in Pearson correlation and strong performance across other metrics.
[92]
arXiv:2509.15666
(cross-list from cs.SD)
[pdf, html, other]
Title:
TISDiSS: A Training-Time and Inference-Time Scalable Framework for Discriminative Source Separation
Yongsheng Feng, Yuetonghui Xu, Jiehui Luo, Hongjia Liu, Xiaobing Li, Feng Yu, Wei Li
Comments:
submitted to ICASSP 2026
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
Source separation is a fundamental task in speech, music, and audio processing, and it also provides cleaner and larger data for training generative models. However, improving separation performance in practice often depends on increasingly large networks, inflating training and deployment costs. Motivated by recent advances in inference-time scaling for generative modeling, we propose Training-Time and Inference-Time Scalable Discriminative Source Separation (TISDiSS), a unified framework that integrates early-split multi-loss supervision, shared-parameter design, and dynamic inference repetitions. TISDiSS enables flexible speed-performance trade-offs by adjusting inference depth without retraining additional models. We further provide systematic analyses of architectural and training choices and show that training with more inference repetitions improves shallow-inference performance, benefiting low-latency applications. Experiments on standard speech separation benchmarks demonstrate state-of-the-art performance with a reduced parameter count, establishing TISDiSS as a scalable and practical framework for adaptive source separation.
[93]
arXiv:2509.15667
(cross-list from cs.CL)
[pdf, html, other]
Title:
VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion
Dimitrios Damianos, Leon Voukoutis, Georgios Paraskevopoulos, Vassilis Katsouros
Subjects:
Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)
We present a multimodal fusion framework that bridges pre-trained decoder-based large language models (LLM) and acoustic encoder-decoder architectures such as Whisper, with the aim of building speech-enabled LLMs. Instead of directly using audio embeddings, we explore an intermediate audio-conditioned text space as a more effective mechanism for alignment. Our method operates fully in continuous text representation spaces, fusing Whisper's hidden decoder states with those of an LLM through cross-modal attention, and supports both offline and streaming modes. We introduce \textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that our approach effectively aligns representations across modalities. These results highlight continuous space fusion as a promising path for multilingual and low-resource speech LLMs, while achieving state-of-the-art results for Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative improvement across benchmarks.
[94]
arXiv:2509.15680
(cross-list from cs.SD)
[pdf, html, other]
Title:
Mamba-2 audio captioning: design space exploration and analysis
Taehan Lee, Jaehan Jung, Hyukjun Lee
Comments:
Submitted to the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026). Under review
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
We present an audio captioning model built on the Mamba-2 large language model backbone, which is a state-of-the-art (SOTA) state-space model (SSM). We systematically explore the design space: LLM sizes, LoRA ranks, and connector designs leveraging Mamba-2's linear-time complexity with respect to sequence length. Across benchmarks, our models achieve strong captioning performance compared with larger language models trained on the same dataset, despite using fewer parameters. For the first time, we conduct an in-depth analysis of how the number of LLM parameters, audio encoder fine-tuning strategies, audio feature diversity, and different feature reduction or expansion techniques affect performance.
[95]
arXiv:2509.15692
(cross-list from cs.SD)
[pdf, html, other]
Title:
Direct Simultaneous Translation Activation for Large Audio-Language Models
Pei Zhang, Yiming Wang, Jialong Tang, Baosong Yang, Rui Wang, Derek F. Wong, Fei Huang
Subjects:
Sound (cs.SD); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)
Simultaneous speech-to-text translation (Simul-S2TT) aims to translate speech into target text in real time, outputting translations while receiving source speech input, rather than waiting for the entire utterance to be spoken. Simul-S2TT research often modifies model architectures to implement read-write strategies. However, with the rise of large audio-language models (LALMs), a key challenge is how to directly activate Simul-S2TT capabilities in base models without additional architectural changes. In this paper, we introduce {\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA}), a strategy that utilizes LALMs' inherent capabilities to obtain simultaneous data by randomly truncating speech and constructing partially aligned translation. By incorporating them into offline SFT data, SimulSA effectively bridges the distribution gap between offline translation during pretraining and simultaneous translation during inference. Experimental results demonstrate that augmenting only about {\bf 1\%} of the simultaneous data, compared to the full offline SFT data, can significantly activate LALMs' Simul-S2TT capabilities without modifications to model architecture or decoding strategy.
[96]
arXiv:2509.15701
(cross-list from cs.CL)
[pdf, html, other]
Title:
Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment
Ke Wang, Wenning Wei, Yan Deng, Lei He, Sheng Zhao
Comments:
submitted to ICASSP2026
Subjects:
Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Automatic Pronunciation Assessment (APA) is critical for Computer-Assisted Language Learning (CALL), requiring evaluation across multiple granularities and aspects. Large Multimodal Models (LMMs) present new opportunities for APA, but their effectiveness in fine-grained assessment remains uncertain. This work investigates fine-tuning LMMs for APA using the Speechocean762 dataset and a private corpus. Fine-tuning significantly outperforms zero-shot settings and achieves competitive results on single-granularity tasks compared to public and commercial systems. The model performs well at word and sentence levels, while phoneme-level assessment remains challenging. We also observe that the Pearson Correlation Coefficient (PCC) reaches 0.9, whereas Spearman's rank Correlation Coefficient (SCC) remains around 0.6, suggesting that SCC better reflects ordinal consistency. These findings highlight both the promise and limitations of LMMs for APA and point to future work on fine-grained modeling and rank-aware evaluation.
[97]
arXiv:2509.15703
(cross-list from cs.SD)
[pdf, html, other]
Title:
SONAR: Self-Distilled Continual Pre-training for Domain Adaptive Audio Representation
Yizhou Zhang, Yuan Gao, Wangjin Zhou, Zicheng Yuan, Keisuke Imoto, Tatsuya Kawahara
Comments:
Submitted to ICASSP 2026
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Self-supervised learning (SSL) on large-scale datasets like AudioSet has become the dominant paradigm for audio representation learning. While the continuous influx of new, unlabeled audio presents an opportunity to enrich these static representations, a naive approach is to retrain the model from scratch using all available data. However, this method is computationally prohibitive and discards the valuable knowledge embedded in the previously trained model weights. To address this inefficiency, we propose SONAR (Self-distilled cONtinual pre-training for domain adaptive Audio Representation), a continual pre-training framework built upon BEATs. SONAR effectively adapts to new domains while mitigating catastrophic forgetting by tackling three key challenges: implementing a joint sampling strategy for new and prior data, applying regularization to balance specificity and generality, and dynamically expanding the tokenizer codebook for novel acoustic patterns. Experiments across four distinct domains demonstrate that our method achieves both high adaptability and robust resistance to forgetting.
[98]
arXiv:2509.15737
(cross-list from cs.RO)
[pdf, html, other]
Title:
SMART: Scalable Multi-Agent Reasoning and Trajectory Planning in Dense Environments
Heye Huang, Yibin Yang, Wang Chen, Tiantian Chen, Xiaopeng Li, Sikai Chen
Subjects:
Robotics (cs.RO); Systems and Control (eess.SY)
Multi-vehicle trajectory planning is a non-convex problem that becomes increasingly difficult in dense environments due to the rapid growth of collision constraints. Efficient exploration of feasible behaviors and resolution of tight interactions are essential for real-time, large-scale coordination. This paper introduces SMART, Scalable Multi-Agent Reasoning and Trajectory Planning, a hierarchical framework that combines priority-based search with distributed optimization to achieve efficient and feasible multi-vehicle planning. The upper layer explores diverse interaction modes using reinforcement learning-based priority estimation and large-step hybrid A* search, while the lower layer refines solutions via parallelizable convex optimization. By partitioning space among neighboring vehicles and constructing robust feasible corridors, the method decouples the joint non-convex problem into convex subproblems solved efficiently in parallel. This design alleviates the step-size trade-off while ensuring kinematic feasibility and collision avoidance. Experiments show that SMART consistently outperforms baselines. On 50 m x 50 m maps, it sustains over 90% success within 1 s up to 25 vehicles, while baselines often drop below 50%. On 100 m x 100 m maps, SMART achieves above 95% success up to 50 vehicles and remains feasible up to 90 vehicles, with runtimes more than an order of magnitude faster than optimization-only approaches. Built on vehicle-to-everything communication, SMART incorporates vehicle-infrastructure cooperation through roadside sensing and agent coordination, improving scalability and safety. Real-world experiments further validate this design, achieving planning times as low as 0.014 s while preserving cooperative behaviors.
[99]
arXiv:2509.15794
(cross-list from math.OC)
[pdf, html, other]
Title:
Bridging Batch and Streaming Estimations to System Identification under Adversarial Attacks
Jihun Kim, Javad Lavaei
Comments:
15 pages, 2 figures
Subjects:
Optimization and Control (math.OC); Systems and Control (eess.SY)
System identification in modern engineering systems faces emerging challenges from unanticipated adversarial attacks beyond existing detection mechanisms. In this work, we obtain a provably accurate estimate of the Markov parameter matrix of order $k$ to identify partially observed linear systems, in which the probability of having an attack at each time is $O(1/k)$. We show that given the batch data accumulated up to time $T^*$, the $\ell_2$-norm estimator achieves an error decaying exponentially as $k$ grows. We then propose a stochastic projected subgradient descent algorithm on streaming data that produces an estimate at each time $t<T^*$, in which case the expected estimation error proves to be the larger of $O(k/\sqrt{t})$ and an exponentially decaying term in $k$. This stochastic approach illustrates how non-smooth estimators can leverage first-order methods despite lacking recursive formulas. Finally, we integrate batch and streaming estimations to recover the Hankel matrix using the appropriate estimates of the Markov parameter matrix, which enables the synthesis of a robust adaptive controller based on the estimated balanced truncated model under adversarial attacks.
[100]
arXiv:2509.15808
(cross-list from cs.SD)
[pdf, html, other]
Title:
From Independence to Interaction: Speaker-Aware Simulation of Multi-Speaker Conversational Timing
Máté Gedeon, Péter Mihajlik
Comments:
Submitted to ICASSP 2026
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
We present a speaker-aware approach for simulating multi-speaker conversations that captures temporal consistency and realistic turn-taking dynamics. Prior work typically models aggregate conversational statistics under an independence assumption across speakers and turns. In contrast, our method uses speaker-specific deviation distributions enforcing intra-speaker temporal consistency, while a Markov chain governs turn-taking and a fixed room impulse response preserves spatial realism. We also unify pauses and overlaps into a single gap distribution, modeled with kernel density estimation for smooth continuity. Evaluation on Switchboard using intrinsic metrics - global gap statistics, correlations between consecutive gaps, copula-based higher-order dependencies, turn-taking entropy, and gap survival functions - shows that speaker-aware simulation better aligns with real conversational patterns than the baseline method, capturing fine-grained temporal dependencies and realistic speaker alternation, while revealing open challenges in modeling long-range conversational structure.
[101]
arXiv:2509.15827
(cross-list from cs.LG)
[pdf, html, other]
Title:
SolarCrossFormer: Improving day-ahead Solar Irradiance Forecasting by Integrating Satellite Imagery and Ground Sensors
Baptiste Schubnel, Jelena Simeunović, Corentin Tissier, Pierre-Jean Alet, Rafael E. Carrillo
Comments:
15 pages, 17 figures, submitted to IEEE Transactions on Sustainable Energy
Subjects:
Machine Learning (cs.LG); Signal Processing (eess.SP)
Accurate day-ahead forecasts of solar irradiance are required for the large-scale integration of solar photovoltaic (PV) systems into the power grid. However, current forecasting solutions lack the temporal and spatial resolution required by system operators. In this paper, we introduce SolarCrossFormer, a novel deep learning model for day-ahead irradiance forecasting, that combines satellite images and time series from a ground-based network of meteorological stations. SolarCrossFormer uses novel graph neural networks to exploit the inter- and intra-modal correlations of the input data and improve the accuracy and resolution of the forecasts. It generates probabilistic forecasts for any location in Switzerland with a 15-minute resolution for horizons up to 24 hours ahead. One of the key advantages of SolarCrossFormer its robustness in real life operations. It can incorporate new time-series data without retraining the model and, additionally, it can produce forecasts for locations without input data by using only their coordinates. Experimental results over a dataset of one year and 127 locations across Switzerland show that SolarCrossFormer yield a normalized mean absolute error of 6.1 % over the forecasting horizon. The results are competitive with those achieved by a commercial numerical weather prediction service.
[102]
arXiv:2509.15917
(cross-list from cs.RO)
[pdf, html, other]
Title:
An MPC framework for efficient navigation of mobile robots in cluttered environments
Johannes Köhler, Daniel Zhang, Raffaele Soloperto, Andrea Carron, Melanie Zeilinger
Comments:
- Code available at: this https URL - Supplementary video: this https URL
Subjects:
Robotics (cs.RO); Systems and Control (eess.SY); Optimization and Control (math.OC)
We present a model predictive control (MPC) framework for efficient navigation of mobile robots in cluttered environments. The proposed approach integrates a finite-segment shortest path planner into the finite-horizon trajectory optimization of the MPC. This formulation ensures convergence to dynamically selected targets and guarantees collision avoidance, even under general nonlinear dynamics and cluttered environments. The approach is validated through hardware experiments on a small ground robot, where a human operator dynamically assigns target locations. The robot successfully navigated through complex environments and reached new targets within 2-3 seconds.
[103]
arXiv:2509.15933
(cross-list from cs.LG)
[pdf, html, other]
Title:
Bayesian Physics Informed Neural Networks for Reliable Transformer Prognostics
Ibai Ramirez, Jokin Alcibar, Joel Pino, Mikel Sanz, David Pardo, Jose I. Aizpurua
Comments:
Submitted to the Annual Prognostics and Health Management (PHM) Society Conference 2025
Subjects:
Machine Learning (cs.LG); Systems and Control (eess.SY)
Scientific Machine Learning (SciML) integrates physics and data into the learning process, offering improved generalization compared with purely data-driven models. Despite its potential, applications of SciML in prognostics remain limited, partly due to the complexity of incorporating partial differential equations (PDEs) for ageing physics and the scarcity of robust uncertainty quantification methods. This work introduces a Bayesian Physics-Informed Neural Network (B-PINN) framework for probabilistic prognostics estimation. By embedding Bayesian Neural Networks into the PINN architecture, the proposed approach produces principled, uncertainty-aware predictions. The method is applied to a transformer ageing case study, where insulation degradation is primarily driven by thermal stress. The heat diffusion PDE is used as the physical residual, and different prior distributions are investigated to examine their impact on predictive posterior distributions and their ability to encode a priori physical knowledge. The framework is validated against a finite element model developed and tested with real measurements from a solar power plant. Results, benchmarked against a dropout-PINN baseline, show that the proposed B-PINN delivers more reliable prognostic predictions by accurately quantifying predictive uncertainty. This capability is crucial for supporting robust and informed maintenance decision-making in critical power assets.
[104]
arXiv:2509.15946
(cross-list from cs.SD)
[pdf, html, other]
Title:
Differentiable Acoustic Radiance Transfer
Sungho Lee, Matteo Scerbo, Seungu Han, Min Jun Choi, Kyogu Lee, Enzo De Sena
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
Geometric acoustics is an efficient approach to room acoustics modeling, governed by the canonical time-dependent rendering equation. Acoustic radiance transfer (ART) solves the equation through discretization, modeling the time- and direction-dependent energy exchange between surface patches given with flexible material properties. We introduce DART, a differentiable and efficient implementation of ART that enables gradient-based optimization of material properties. We evaluate DART on a simpler variant of the acoustic field learning task, which aims to predict the energy responses of novel source-receiver settings. Experimental results show that DART exhibits favorable properties, e.g., better generalization under a sparse measurement scenario, compared to existing signal processing and neural network baselines, while remaining a simple, fully interpretable system.
[105]
arXiv:2509.15948
(cross-list from cs.SD)
[pdf, html, other]
Title:
Reverse Engineering of Music Mixing Graphs with Differentiable Processors and Iterative Pruning
Sungho Lee, Marco Martínez-Ramírez, Wei-Hsiang Liao, Stefan Uhlich, Giorgio Fabbro, Kyogu Lee, Yuki Mitsufuji
Comments:
JAES, extension of arxiv.org/abs/2408.03204 and arxiv.org/abs/2406.01049
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)
Reverse engineering of music mixes aims to uncover how dry source signals are processed and combined to produce a final mix. We extend the prior works to reflect the compositional nature of mixing and search for a graph of audio processors. First, we construct a mixing console, applying all available processors to every track and subgroup. With differentiable processor implementations, we optimize their parameters with gradient descent. Then, we repeat the process of removing negligible processors and fine-tuning the remaining ones. This way, the quality of the full mixing console can be preserved while removing approximately two-thirds of the processors. The proposed method can be used not only to analyze individual music mixes but also to collect large-scale graph data that can be used for downstream tasks, e.g., automatic mixing. Especially for the latter purpose, efficient implementation of the search is crucial. To this end, we present an efficient batch-processing method that computes multiple processors in parallel. We also exploit the "dry/wet" parameter of the processors to accelerate the search. Extensive quantitative and qualitative analyses are conducted to evaluate the proposed method's performance, behavior, and computational cost.
[106]
arXiv:2509.15950
(cross-list from cs.LG)
[pdf, html, other]
Title:
Targeted Fine-Tuning of DNN-Based Receivers via Influence Functions
Marko Tuononen, Heikki Penttinen, Ville Hautamäki
Comments:
7 pages; 10 figures; 1 table; 19 equations
Subjects:
Machine Learning (cs.LG); Signal Processing (eess.SP)
We present the first use of influence functions for deep learning-based wireless receivers. Applied to DeepRx, a fully convolutional receiver, influence analysis reveals which training samples drive bit predictions, enabling targeted fine-tuning of poorly performing cases. We show that loss-relative influence with capacity-like binary cross-entropy loss and first-order updates on beneficial samples most consistently improves bit error rate toward genie-aided performance, outperforming random fine-tuning in single-target scenarios. Multi-target adaptation proved less effective, underscoring open challenges. Beyond experiments, we connect influence to self-influence corrections and propose a second-order, influence-aligned update strategy. Our results establish influence functions as both an interpretability tool and a basis for efficient receiver adaptation.
[107]
arXiv:2509.16010
(cross-list from cs.SD)
[pdf, html, other]
Title:
Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation
Qi Wang, Shituo Ma, Guoxin Yu, Hanyang Peng, Yue Yu
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
Voice cloning for Text-to-Speech (TTS) aims to generate expressive and personalized speech from text using limited data from a target speaker. Federated Learning (FL) offers a collaborative and privacy-preserving framework for this task, but existing approaches suffer from high communication costs and tend to suppress stylistic heterogeneity, resulting in insufficient personalization. To address these issues, we propose Fed-PISA, which stands for Federated Personalized Identity-Style Adaptation. To minimize communication costs, Fed-PISA introduces a disentangled Low-Rank Adaptation (LoRA) mechanism: the speaker's timbre is retained locally through a private ID-LoRA, while only a lightweight style-LoRA is transmitted to the server, thereby minimizing parameter exchange. To harness heterogeneity, our aggregation method, inspired by collaborative filtering, is introduced to create custom models for each client by learning from stylistically similar peers. Experiments show that Fed-PISA improves style expressivity, naturalness, and speaker similarity, outperforming standard federated baselines with minimal communication costs.
[108]
arXiv:2509.16035
(cross-list from cs.IT)
[pdf, html, other]
Title:
Near-Field Beam Training Through Beam Diverging
Ran Li, Ziyi Xu, Ying-Jun Angela Zhang
Subjects:
Information Theory (cs.IT); Signal Processing (eess.SP)
This paper investigates beam training techniques for near-field (NF) extremely large-scale antenna arrays (ELAAs). Existing NF beam training methods predominantly rely on beam focusing, where the base station (BS) transmits highly spatially selective beams to locate the user equipment (UE). However, these beam-focusing-based schemes suffer from both high beam sweeping overhead and limited accuracy in the NF, primarily due to the narrow beams' high susceptibility to misalignment. To address this, we propose a novel NF beam training paradigm using diverging beams. Specifically, we introduce the beam diverging effect and exploit it for low-overhead, high-accuracy beam training. First, we design a diverging codeword to induce the beam diverging effect with a single radio frequency (RF) chain. Next, we develop a diverging polar-domain codebook (DPC) along with a hierarchical method that enables angular-domain localization of the UE with only 2 log_2(N) pilots, where N denotes the number of antennas. Finally, we enhance beam training performance through two additional techniques: a DPC angular range reduction strategy to improve the effectiveness of beam diverging, and a pilot set expansion method to increase overall beam training accuracy. Numerical results show that our algorithm achieves near-optimal accuracy with a small pilot overhead, outperforming existing methods.
[109]
arXiv:2509.16055
(cross-list from cs.IT)
[pdf, html, other]
Title:
3D Near-Field Beam Training for Uniform Planar Arrays through Beam Diverging
Ran Li, Ziyi Xu, Ying-Jun Angela Zhang
Subjects:
Information Theory (cs.IT); Signal Processing (eess.SP)
In future 6G communication systems, large-scale antenna arrays promise enhanced signal strength and spatial resolution, but they also increase the complexity of beam training. Moreover, as antenna counts grow and carrier wavelengths shrink, the channel model transits from far-field (FF) planar waves to near-field (NF) spherical waves, further complicating the beam training process. This paper focuses on millimeter-wave (mmWave) systems equipped with large-scale uniform planar arrays (UPAs), which produce 3D beam patterns and introduce additional challenges for NF beam training. Existing methods primarily rely on either FF steering or NF focusing codewords, both of which are highly sensitive to mismatches in user equipment (UE) location, leading to high sensitivity to even slight mismatch and excessive training overhead. In contrast, we introduce a novel beam training approach leveraging the beam-diverging effect, which enables adjustable wide-beam coverage using only a single radio frequency (RF) chain. Specifically, we first analyze the spatial characteristics of this effect in UPA systems and leverage them to construct hierarchical codebooks for coarse UE localization. Then, we develop a 3D sampling mechanism to build an NF refinement codebook for precise beam training. Numerical results demonstrate that the proposed algorithm achieves superior beam training performance while maintaining low training overhead.
Replacement submissions (showing 46 of 46 entries)
[110]
arXiv:2406.14740
(replaced)
[pdf, html, other]
Title:
Reachability and Controllability Analysis of the State Covariance for Linear Stochastic Systems
Fengjiao Liu, Panagiotis Tsiotras
Comments:
16 pages, 1 figure
Subjects:
Systems and Control (eess.SY)
This paper studies the set of terminal state covariances that are reachable over a finite time horizon from a given initial state covariance for a linear stochastic system with additive noise. For discrete-time systems, a complete characterization of the set of reachable state covariances is given. For continuous-time systems, we present an upper bound on the set of reachable state covariances. Moreover, for both linear discrete-time and continuous-time systems, necessary and sufficient conditions are provided for the controllability of the state covariance over a finite horizon.
[111]
arXiv:2407.04291
(replaced)
[pdf, html, other]
Title:
Rethinking Speaker Embeddings for Speech Generation: Sub-Center Modeling for Capturing Intra-Speaker Diversity
Ismail Rasim Ulgen, John H. L. Hansen, Carlos Busso, Berrak Sisman
Comments:
Under review for ICASSP
Subjects:
Audio and Speech Processing (eess.AS); Machine Learning (cs.LG)
Modeling the rich prosodic variations inherent in human speech is essential for generating natural-sounding speech. While speaker embeddings are commonly used as conditioning inputs in personalized speech generation, they are typically optimized for speaker recognition, which encourages the loss of intra-speaker variation. This strategy makes them suboptimal for speech generation in terms of modeling the rich variations at the output speech distribution. In this work, we propose a novel speaker embedding network that employs multiple sub-centers per speaker class during training, instead of a single center as in conventional approaches. This sub-center modeling allows the embedding to capture a broader range of speaker-specific variations while maintaining speaker classification performance. We demonstrate the effectiveness of the proposed embeddings on a voice conversion task, showing improved naturalness and prosodic expressiveness in the synthesized speech.
[112]
arXiv:2410.03891
(replaced)
[pdf, html, other]
Title:
MIMO Detection with Spatial Sigma-Delta ADCs: A Variational Bayesian Approach
Toan-Van Nguyen, Sajjad Nassirpour, Italo Atzeni, Antti Tolli, A. Lee Swindlehurst, Duy H. N. Nguyen
Comments:
17 pages, 15 figures, accepted to IEEE Transactions on Signal Processing
Subjects:
Signal Processing (eess.SP)
The spatial Sigma-Delta ($\Sigma\Delta$) architecture can be leveraged to reduce the quantization noise and enhance the effective resolution of few-bit analog-to-digital converters (ADCs) at certain spatial frequencies of interest. Utilizing the variational Bayesian (VB) inference framework, this paper develops novel data detection algorithms tailored for massive multiple-input multiple-output (MIMO) systems with few-bit $\Sigma\Delta$ ADCs and angular channel models, where uplink signals are confined to a specific angular sector. We start by modeling the corresponding Bayesian networks for the $1^{\mathrm{st}}$- and $2^{\mathrm{nd}}$-order $\Sigma\Delta$ receivers. Next, we propose an iterative algorithm, referred to as Sigma-Delta variational Bayes (SD-VB), for MIMO detection, offering low-complexity updates through closed-form expressions of the variational densities of the latent variables. We also study the impact of mutual coupling on the performance of the proposed SD-VB algorithms when the antenna spacing is reduced. Simulation results show that the proposed $2^{\mathrm{nd}}$-order SD-VB algorithm delivers the best symbol error rate (SER) performance while maintaining the same computational complexity as in unquantized systems, matched-filtering VB with conventional quantization, and linear minimum mean-squared error (LMMSE) methods. Moreover, the $1^{\mathrm{st}}$- and $2^{\mathrm{nd}}$-order SD-VB algorithms achieve their lowest SER at an antenna separation of one-fourth wavelength for a fixed number of antenna elements. The effects of mutual coupling, the steering angle of the $\Sigma\Delta$ architecture, the number of ADC resolution bits, and the number of antennas and users are also extensively analyzed.
[113]
arXiv:2411.09279
(replaced)
[pdf, html, other]
Title:
A Comparative Analysis of Electricity Consumption Flexibility in Different Industrial Plant Configurations
Sebastián Rojas-Innocenti, Enrique Baeyens, Alejandro Martín-Crespo, Sergio Saludes-Rodil, Fernando Frechoso
Subjects:
Systems and Control (eess.SY)
The increasing integration of renewable energy sources into power systems is intensifying the demand for greater flexibility among industrial electricity consumers. However, operational constraints, production requirements, and market dynamics pose significant challenges to achieving optimal flexibility. This paper presents an enhanced mixed integer linear programming (MILP) model that directly optimizes electricity consumption flexibility in manufacturing plants. Unlike previous approaches, the proposed model determines optimal transactions with both day-ahead and intraday continuous electricity markets, while ensuring production continuity and adhering to plant-specific operational constraints. The methodology is validated through annual simulations of two real world industrial configurations, cement manufacturing and steel production, using 2023 market data. Comparative results highlight that the steel plant achieved average electricity cost savings through flexibility of 0.41 euro/MWh, whereas the cement plant achieved 0.24 euro/MWh, reflecting differences in storage capacities, production rates, and operational flexibility. A comprehensive sensitivity analysis further identifies key parameters affecting flexibility potential, such as the production to demand ratio, storage capacity, and minimum operation periods. The findings offer valuable insights for industrial operators aiming to reduce energy costs, enhance operational flexibility, and support the decarbonization of electricity systems.
[114]
arXiv:2411.18523
(replaced)
[pdf, other]
Title:
Non-reciprocal Beyond Diagonal RIS: Sum-Rate Maximization in Full-Duplex Communications
Ziang Liu, Hongyu Li, Bruno Clerckx
Comments:
Submitted to IEEE journal
Subjects:
Signal Processing (eess.SP); Systems and Control (eess.SY)
Reconfigurable intelligent surface (RIS) has been envisioned as a key technology in future wireless communication networks to enable smart radio environment. To further enhance the passive beamforming capability of RIS, beyond diagonal (BD)-RIS has been proposed considering reconfigurable interconnections among different RIS elements. BD-RIS has a unique feature that cannot be enabled by conventional diagonal RIS; it can be realized by non-reciprocal circuits and thus enables an asymmetric scattering matrix. This feature provides the capability to break the wireless channel reciprocity, and has the potential to benefit full-duplex (FD) systems. In this paper, we model the BD RIS-assisted FD systems, where the impact of BD-RIS non-reciprocity and that of structural scattering, which refers to the specular reflection generated by RIS when the RIS is turned OFF, are explicitly captured. To assess the benefits of non-reciprocal BD-RIS, we optimise the scattering matrix, precoder and combiner to maximize the DL and UL sum-rates in the FD system. To tackle this optimization problem, we propose an iterative algorithm based on block coordination descent (BCD) and penalty dual decomposition (PDD). Numerical results demonstrate surprising benefits of non-reciprocal BD-RIS that it can achieve much higher DL and UL sum-rates in the FD scenario than reciprocal BD-RIS and conventional diagonal RIS.
[115]
arXiv:2412.05015
(replaced)
[pdf, html, other]
Title:
Perceptually Transparent Binaural Auralization of Simulated Sound Fields
Jens Ahrens
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
Contrary to geometric acoustics-based simulations where the spatial information is available in a tangible form, it is not straightforward to auralize wave-based simulations. A variety of methods have been proposed that compute the ear signals of a virtual listener with known head-related transfer functions from sampling either the sound pressure or the particle velocity (or both) of the simulated sound field. This article summarizes the most common binaural auralization methods with and without intermediate ambisonic representation of volumetrically sampled sound pressure or sound pressure and particle velocity sampled on spherical or cubical surfaces and presents a perceptual validation thereof. A triangular test ($N=19$) confirmed that all evaluated grids resulted in a perceptually transparent auralization for the three tested sound incidence angles under reverberant conditions. Under anechoic conditions, only the high-density spherical and cubical surface grids lead to transparent auralization. All tested methods are available open source in the Chalmers Auralization Toolbox that accompanies this article.
[116]
arXiv:2502.15178
(replaced)
[pdf, html, other]
Title:
Enhancing Speech Large Language Models with Prompt-Aware Mixture of Audio Encoders
Weiqiao Shan, Yuang Li, Yuhao Zhang, Yingfeng Luo, Chen Xu, Xiaofeng Zhao, Long Meng, Yunfei Lu, Min Zhang, Hao Yang, Tong Xiao, Jingbo Zhu
Comments:
16 pages,5 figures, 13 tables, to be published in EMNLP 2025 main conference
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
Connecting audio encoders with large language models (LLMs) allows the LLM to perform various audio understanding tasks, such as automatic speech recognition (ASR) and audio captioning (AC). Most research focuses on training an adapter layer to generate a unified audio feature for the LLM. However, different tasks may require distinct features that emphasize either semantic or acoustic aspects, making task-specific audio features more desirable. In this paper, we propose Prompt-aware Mixture (PaM) to enhance the Speech LLM that uses multiple audio encoders. Our approach involves using different experts to extract different features based on the prompt that indicates different tasks. Experiments demonstrate that with PaM, only one Speech LLM surpasses the best performances achieved by all single-encoder Speech LLMs on ASR, Speaker Number Verification, and AC tasks. PaM also outperforms other feature fusion baselines, such as concatenation and averaging. Our code would be available at: this https URL
[117]
arXiv:2502.19668
(replaced)
[pdf, html, other]
Title:
SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning
Mingsheng Cai, Jiuming Jiang, Wenhao Huang, Che Liu, Rossella Arcucci
Comments:
Findings of The 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025)
Subjects:
Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
Cardiovascular diseases are a leading cause of death and disability worldwide. Electrocardiogram (ECG) is critical for diagnosing and monitoring cardiac health, but obtaining large-scale annotated ECG datasets is labor-intensive and time-consuming. Recent ECG Self-Supervised Learning (eSSL) methods mitigate this by learning features without extensive labels but fail to capture fine-grained clinical semantics and require extensive task-specific fine-tuning. To address these challenges, we propose $\textbf{SuPreME}$, a $\textbf{Su}$pervised $\textbf{Pre}$-training framework for $\textbf{M}$ultimodal $\textbf{E}$CG representation learning. SuPreME is pre-trained using structured diagnostic labels derived from ECG report entities through a one-time offline extraction with Large Language Models (LLMs), which help denoise, standardize cardiac concepts, and improve clinical representation learning. By fusing ECG signals with textual cardiac queries instead of fixed labels, SuPreME enables zero-shot classification of unseen conditions without further fine-tuning. We evaluate SuPreME on six downstream datasets covering 106 cardiac conditions, achieving superior zero-shot AUC performance of $77.20\%$, surpassing state-of-the-art eSSLs by $4.98\%$. Results demonstrate SuPreME's effectiveness in leveraging structured, clinically relevant knowledge for high-quality ECG representations.
[118]
arXiv:2503.09922
(replaced)
[pdf, html, other]
Title:
RIS-Assisted Joint Sensing and Communications via Fractionally Constrained Fractional Programming
Yiming Liu, Kareem M. Attiah, Wei Yu
Comments:
16 pages, 10 figures, accepted for publication in IEEE Transactions on Wireless Communications
Subjects:
Signal Processing (eess.SP)
This paper studies an uplink dual-functional sensing and communication system aided by a reconfigurable intelligent surface (RIS), whose reflection pattern is configured to trade-off sensing and communication functionalities. Specifically, the Bayesian Cramér-Rao lower bound (BCRLB) for estimating the azimuth angle of a sensing user is minimized while ensuring the signal-to-interference-plus-noise ratio constraints for communication users. We show that this problem can be formulated as a novel fractionally constrained fractional programming (FCFP) problem. To deal with this nontrivial optimization problem, we extend a quadratic transform technique, originally proposed to handle optimization problems containing fractional structures only in objectives, to the scenario where the constraints also include ratios. First, we consider the case where the fading coefficient is known. Using the quadratic transform, the FCFP problem can be turned into a sequence of subproblems that are convex except for the constant-modulus constraints which can be tackled using a penalty-based approach. To further reduce the computational complexity, we leverage the constant-modulus conditions and propose a novel linear transform. This new transform enables the FCFP problem to be turned into a sequence of linear programming (LP) subproblems, which can be solved efficiently. Then, we consider the case where the fading coefficient is unknown. A modified BCRLB is used to make the problem more tractable, and the proposed quadratic transform based algorithm is used to solve the problem. Numerical results unveil nontrivial and effective reflection patterns that can be synthesized by the RIS to facilitate both communication and sensing functionalities.
[119]
arXiv:2504.09381
(replaced)
[pdf, html, other]
Title:
DiTSE: High-Fidelity Generative Speech Enhancement via Latent Diffusion Transformers
Heitor R. Guimarães, Jiaqi Su, Rithesh Kumar, Tiago H. Falk, Zeyu Jin
Comments:
Manuscript under review
Subjects:
Audio and Speech Processing (eess.AS); Sound (cs.SD)
Real-world speech recordings suffer from degradations such as background noise and reverberation. Speech enhancement aims to mitigate these issues by generating clean high-fidelity signals. While recent generative approaches for speech enhancement have shown promising results, they still face two major challenges: (1) content hallucination, where plausible phonemes generated differ from the original utterance; and (2) inconsistency, failing to preserve speaker's identity and paralinguistic features from the input speech. In this work, we introduce DiTSE (Diffusion Transformer for Speech Enhancement), which addresses quality issues of degraded speech in full bandwidth. Our approach employs a latent diffusion transformer model together with robust conditioning features, effectively addressing these challenges while remaining computationally efficient. Experimental results from both subjective and objective evaluations demonstrate that DiTSE achieves state-of-the-art audio quality that, for the first time, matches real studio-quality audio from the DAPS dataset. Furthermore, DiTSE significantly improves the preservation of speaker identity and content fidelity, reducing hallucinations across datasets compared to state-of-the-art enhancers. Audio samples are available at: this http URL
[120]
arXiv:2505.06793
(replaced)
[pdf, html, other]
Title:
HistDiST: Histopathological Diffusion-based Stain Transfer
Erik Großkopf, Valay Bundele, Mehran Hosseinzadeh, Hendrik P.A. Lensch
Comments:
Accepted to DAGM GCPR 2025
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Hematoxylin and Eosin (H&E) staining is the cornerstone of histopathology but lacks molecular specificity. While Immunohistochemistry (IHC) provides molecular insights, it is costly and complex, motivating H&E-to-IHC translation as a cost-effective alternative. Existing translation methods are mainly GAN-based, often struggling with training instability and limited structural fidelity, while diffusion-based approaches remain underexplored. We propose HistDiST, a Latent Diffusion Model (LDM) based framework for high-fidelity H&E-to-IHC translation. HistDiST introduces a dual-conditioning strategy, utilizing Phikon-extracted morphological embeddings alongside VAE-encoded H&E representations to ensure pathology-relevant context and structural consistency. To overcome brightness biases, we incorporate a rescaled noise schedule, v-prediction, and trailing timesteps, enforcing a zero-SNR condition at the final timestep. During inference, DDIM inversion preserves the morphological structure, while an eta-cosine noise schedule introduces controlled stochasticity, balancing structural consistency and molecular fidelity. Moreover, we propose Molecular Retrieval Accuracy (MRA), a novel pathology-aware metric leveraging GigaPath embeddings to assess molecular relevance. Extensive evaluations on MIST and BCI datasets demonstrate that HistDiST significantly outperforms existing methods, achieving a 28% improvement in MRA on the H&E-to-Ki67 translation task, highlighting its effectiveness in capturing true IHC semantics.
[121]
arXiv:2505.17093
(replaced)
[pdf, other]
Title:
P2VA: Converting Persona Descriptions into Voice Attributes for Fair and Controllable Text-to-Speech
Yejin Lee, Jaehoon Kang, Kyuhong Shim
Subjects:
Audio and Speech Processing (eess.AS); Computation and Language (cs.CL)
While persona-driven large language models (LLMs) and prompt-based text-to-speech (TTS) systems have advanced significantly, a usability gap arises when users attempt to generate voices matching their desired personas from implicit descriptions. Most users lack specialized knowledge to specify detailed voice attributes, which often leads TTS systems to misinterpret their expectations. To address these gaps, we introduce Persona-to-Voice-Attribute (P2VA), the first framework enabling voice generation automatically from persona descriptions. Our approach employs two strategies: P2VA-C for structured voice attributes, and P2VA-O for richer style descriptions. Evaluation shows our P2VA-C reduces WER by 5% and improves MOS by 0.33 points. To the best of our knowledge, P2VA is the first framework to establish a connection between persona and voice synthesis. In addition, we discover that current LLMs embed societal biases in voice attributes during the conversion process. Our experiments and findings further provide insights into the challenges of building persona-voice systems.
[122]
arXiv:2505.19390
(replaced)
[pdf, html, other]
Title:
A Unified Foundation Model for Wireless Technology Recognition and Localization
Mohammad Cheraghinia, Eli De Poorter, Jaron Fontaine, Merouane Debbah, Adnan Shahid
Comments:
18 pages, 10 Figures, 6 Tables
Subjects:
Signal Processing (eess.SP)
Wireless Technology Recognition (WTR) and localization are essential in modern communication systems, enabling efficient spectrum management, seamless coexistence of diverse technologies, and accurate positioning in dynamic environments. In real-world conditions, solutions must handle signals from various resources with different sampling rates, capturing devices, frequency bands, and propagation conditions. Traditional methods, such as energy detection and conventional Deep Learning (DL) models like Convolutional Neural Networks (CNNs), often lack the robustness to generalize across unseen technologies, environments, or tasks. In this work, we introduce a Transformer-based foundation model for both WTR and localization, pre-trained in a self-supervised manner on large-scale, unlabeled datasets of In-phase and Quadrature (IQ) and Channel Impulse Response (CIR) timeseries. The model leverages input patching for computational efficiency and employs a two-stage pipeline: self-supervised pre-training to learn general-purpose representations, followed by lightweight fine-tuning for task-specific adaptation. This enables the model to generalize to new wireless technologies and unseen environments using minimal labeled samples. Evaluations across short-range and long-range datasets show superior accuracy in WTR (up to 99.99%), Line-Of-Sight (LOS) detection (up to 100%), and ranging error correction (reducing Mean Absolute Error (MAE) by up to 50%), all while maintaining low computational complexity. These results underscore the potential of a reusable wireless foundation model for multi-task applications with minimal retraining.
[123]
arXiv:2505.21461
(replaced)
[pdf, other]
Title:
Quasi Steady-State Frequency
Joan Gutierrez-Florensa, Alvaro Ortega, Lukas Sigrist, Federico Milano
Subjects:
Systems and Control (eess.SY)
Accurate frequency estimation is critical for the control, monitoring and protection of electrical power systems, in particular, of systems with a high penetration of power electronics. This paper introduces the novel concept of Quasi Steady-State (QSS) frequency as a quantity that fills the gap between stationary and instantaneous frequency. QSS frequency coincides with the fundamental frequency of an AC voltage in any stationary conditions, including unbalanced and non-sinusoidal, and is able to capture the time-varying fundamental frequency in transient conditions. The paper also proposes a metric borrowed from fluid dynamics, namely, the time derivative of the circulation, to define the scope of validity of the QSS frequency. Analytical examples as well as a case study based on a fully-fledged EMT model of the IEEE 39-bus system serve to illustrate, respectively, the properties of the QSS frequency and its behavior in transient conditions.
[124]
arXiv:2505.24407
(replaced)
[pdf, html, other]
Title:
Efficient RAW Image Deblurring with Adaptive Frequency Modulation
Wenlong Jiao, Binglong Li, Wei Shang, Ping Wang, Dongwei Ren
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Image deblurring plays a crucial role in enhancing visual clarity across various applications. Although most deep learning approaches primarily focus on sRGB images, which inherently lose critical information during the image signal processing pipeline, RAW images, being unprocessed and linear, possess superior restoration potential but remain underexplored. Deblurring RAW images presents unique challenges, particularly in handling frequency-dependent blur while maintaining computational efficiency. To address these issues, we propose Frequency Enhanced Network (FrENet), a framework specifically designed for RAW-to-RAW deblurring that operates directly in the frequency domain. We introduce a novel Adaptive Frequency Positional Modulation module, which dynamically adjusts frequency components according to their spectral positions, thereby enabling precise control over the deblurring process. Additionally, frequency domain skip connections are adopted to further preserve high-frequency details. Experimental results demonstrate that FrENet surpasses state-of-the-art deblurring methods in RAW image deblurring, achieving significantly better restoration quality while maintaining high efficiency in terms of reduced MACs. Furthermore, FrENet's adaptability enables it to be extended to sRGB images, where it delivers comparable or superior performance compared to methods specifically designed for sRGB data. The code will be available at this https URL .
[125]
arXiv:2506.06566
(replaced)
[pdf, html, other]
Title:
AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition
Chen Bao, Chuanbing Huo, Qinyu Chen, Chang Gao
Comments:
Accepted to 2025 IEEE Biomedical Circuits and Systems Conference (BioCAS)
Subjects:
Audio and Speech Processing (eess.AS); Artificial Intelligence (cs.AI)
This paper proposes AS-ASR, a lightweight aphasia-specific speech recognition framework based on Whisper-tiny, tailored for low-resource deployment on edge devices. Our approach introduces a hybrid training strategy that systematically combines standard and aphasic speech at varying ratios, enabling robust generalization, and a GPT-4-based reference enhancement method that refines noisy aphasic transcripts, improving supervision quality. We conduct extensive experiments across multiple data mixing configurations and evaluation settings. Results show that our fine-tuned model significantly outperforms the zero-shot baseline, reducing WER on aphasic speech by over 30% while preserving performance on standard speech. The proposed framework offers a scalable, efficient solution for real-world disordered speech recognition.
[126]
arXiv:2507.07429
(replaced)
[pdf, html, other]
Title:
Resilient Event-Triggered Control of Vehicle Platoon Under DoS Attacks and Parameter Uncertainty
Qiaoni Han, Jianguo Ma, Zhiqiang Zuo, Xiaocheng Wang, Bo Yang, Xinping Guan
Subjects:
Systems and Control (eess.SY)
This paper investigates the problem of dynamic event-triggered platoon control for intelligent vehicles (IVs) under denial of service (DoS) attacks and parameter uncertainty. DoS attacks disrupt vehicle-to-vehicle (V2V) communications, leading to the destabilization of vehicle formations. To alleviate the burden of the V2V communication network and enhance the tracking performance in the presence of DoS attacks and parameter uncertainty, a resilient and dynamic event-triggered mechanism is proposed. In contrast to the static event-triggering mechanism (STEM), this approach leverages the internal dynamic variable to further save communication resources. Subsequently, a method is developed for designing the desired triggering mechanism. Following this, a co-design framework is constructed to guarantee robust and resilient control against DoS attacks, with the analysis of eliminating Zeno behavior. Lastly, extensive simulations are presented to show the superiority of the proposed method in terms of enhancing platoon resilience and robustness and improving communication efficiency.
[127]
arXiv:2507.23159
(replaced)
[pdf, html, other]
Title:
Full-Duplex-Bench v1.5: Evaluating Overlap Handling for Full-Duplex Speech Models
Guan-Ting Lin, Shih-Yun Shan Kuan, Qirui Wang, Jiachen Lian, Tingle Li, Shinji Watanabe, Hung-yi Lee
Comments:
Work in Progress. Code and Data at this https URL
Subjects:
Audio and Speech Processing (eess.AS)
While full-duplex speech agents promise natural, low-latency human-machine interaction by concurrently processing input and output speech, overlap management remains under-evaluated. We introduce Full-Duplex-Bench v1.5, a modular, fully automated benchmark that simulates four overlap scenarios: user interruption, listener backchannel, side conversation, and ambient speech. Our framework supports both open-sourced and commercial models, offering a comprehensive, extensible metric suite -- categorical dialogue behaviors, stop and response latency, prosodic adaptation, and perceived speech quality -- that can be tailored to application-specific criteria. Benchmarking five state-of-the-art agents reveals two principal strategies: repair-first rapid yielding versus continuity-first sustained flow, and highlights scenario-dependent performance trends. The open-sourced design enables seamless extension with new audio assets, languages, and deployment contexts, empowering practitioners to customize and accelerate the evaluation of robust full-duplex speech systems.
[128]
arXiv:2508.06428
(replaced)
[pdf, html, other]
Title:
Full-Dimensional Beamforming for Multi-User MIMO-OFDM ISAC for Low-Altitude UAV with Zero Sensing Resource Allocation
Zhiwen Zhou, Yong Zeng, Chunguo Li, Fei Yang, Yan Chen, Jingon Joung
Subjects:
Signal Processing (eess.SP)
Low-altitude unmanned aerial vehicles (UAVs) are expected to play an important role for low-altitude economy with a wide range of applications like precise agriculture, aerial delivery and surveillance. Integrated sensing and communication (ISAC) is a key technology to enable the large-scale deployment and routine usage of UAVs by providing both communication and sensing services efficiently. For UAV ISAC systems, as UAV often acts as both a communication user equipment (UE) and a sensing target, traditional ISAC systems that usually allocate dedicated TF resources for sensing are inefficient due to the severe degradation of communication spectral efficiency. To address this issue, in this paper, we propose a novel multiple-input multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM)-based ISAC framework for UAVs that eliminates the need for dedicated sensing TF resources, achieving zero TF sensing overhead. By designing the transmit beamforming to meet the requirements for both communication and sensing tasks, our proposed approach enables the communication TF resources to be fully reused for sensing, thereby enhancing both the communication sum rate and the sensing performance in terms of resolution, unambiguous range, and accuracy. Additionally, we introduce a low-complexity target searching beamforming algorithm and a two-stage super-resolution sensing algorithm, which ensure efficient implementation. Simulation results demonstrate that the proposed MIMO-OFDM-ISAC framework not only improves the communication sum rate but also outperforms traditional ISAC systems in sensing performance, making it a promising solution for future ISAC systems to support low-altitude UAVs.
[129]
arXiv:2508.10215
(replaced)
[pdf, html, other]
Title:
Data-Efficient Learning for Generalizable Surgical Video Understanding
Sahar Nasirihaghighi
Subjects:
Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)
Advances in surgical video analysis are transforming operating rooms into intelligent, data-driven environments. Computer-assisted systems support full surgical workflow, from preoperative planning to intraoperative guidance and postoperative assessment. However, developing robust and generalizable models for surgical video understanding remains challenging due to (I) annotation scarcity, (II) spatiotemporal complexity, and (III) domain gap across procedures and institutions. This doctoral research aims to bridge the gap between deep learning-based surgical video analysis in research and its real-world clinical deployment. To address the core challenge of recognizing surgical phases, actions, and events, critical for analysis, I benchmarked state-of-the-art neural network architectures to identify the most effective designs for each task. I further improved performance by proposing novel architectures and integrating advanced modules. Given the high cost of expert annotations and the domain gap across surgical video sources, I focused on reducing reliance on labeled data. We developed semi-supervised frameworks that improve model performance across tasks by leveraging large amounts of unlabeled surgical video. We introduced novel semi-supervised frameworks, including DIST, SemiVT-Surge, and ENCORE, that achieved state-of-the-art results on challenging surgical datasets by leveraging minimal labeled data and enhancing model training through dynamic pseudo-labeling. To support reproducibility and advance the field, we released two multi-task datasets: GynSurg, the largest gynecologic laparoscopy dataset, and Cataract-1K, the largest cataract surgery video dataset. Together, this work contributes to robust, data-efficient, and clinically scalable solutions for surgical video analysis, laying the foundation for generalizable AI systems that can meaningfully impact surgical care and training.
[130]
arXiv:2508.16601
(replaced)
[pdf, html, other]
Title:
Notes on Deterministic and Stochastic Approaches in Electromagnetic Information Theory
Marco Donald Migliore
Comments:
Missing coefficients added in the G function in Section 2, corrected I(r') in S(r')
Subjects:
Signal Processing (eess.SP); Information Theory (cs.IT)
This paper investigates the relationship between the Number of Degrees of Freedom ($N_{\rm DoF}$) of the field in deterministic and stochastic source models within Electromagnetic Information Theory (EIT). Our findings demonstrate a fundamental connection between these two approaches. Specifically, we show that a deterministic model and a stochastic model with a spatially incoherent and homogeneous source yield not only the same $N_{\rm DoF}$ but also identical eigenvalues and basis functions for field representation. This key equivalence not only explains the effectiveness of deterministic approaches in EIT but also corroborates the use of classical electromagnetic methods within this new discipline.
[131]
arXiv:2509.02598
(replaced)
[pdf, other]
Title:
MIDOG 2025: Mitotic Figure Detection with Attention-Guided False Positive Correction
Andrew Broad, Jason Keighley, Lucy Godson, Alex Wright
Subjects:
Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI)
We present a novel approach which extends the existing Fully Convolutional One-Stage Object Detector (FCOS) for mitotic figure detection. Our composite model adds a Feedback Attention Ladder CNN (FAL-CNN) model for classification of normal versus abnormal mitotic figures, feeding into a fusion network that is trained to generate adjustments to bounding boxes predicted by FCOS. Our network aims to reduce the false positive rate of the FCOS object detector, to improve the accuracy of object detection and enhance the generalisability of the network. Our model achieved an F1 score of 0.655 for mitosis detection on the preliminary evaluation dataset.
[132]
arXiv:2509.11467
(replaced)
[pdf, html, other]
Title:
A Goal-Oriented Approach for Active Object Detection with Exploration-Exploitation Balance
Yalei Yu, Matthew Coombes, Wen-Hua Chen, Cong Sun, Myles Flanagan, Jingjing Jiang, Pramod Pashupathy, Masoud Sotoodeh-Bahraini, Peter Kinnell, Niels Lohse
Comments:
12 pages, 14 figures
Subjects:
Systems and Control (eess.SY)
Active object detection, which aims to identify objects of interest through controlled camera movements, plays a pivotal role in real-world visual perception for autonomous robotic applications, such as manufacturing tasks (e.g., assembly operations) performed in unknown environments. A dual control for exploration and exploitation (DCEE) algorithm is presented within goal-oriented control systems to achieve efficient active object detection, leveraging active learning by incorporating variance-based uncertainty estimation in the cost function. This novel method employs an exploration-exploitation balanced cost function to actively guide the selection of the next viewpoint. Specifically, active object detection is achieved through the development of a reward function that encodes knowledge about the confidence variation of objects as a function of viewpoint position within a given domain. By identifying the unknown parameters of this function, the system generates an optimal viewpoint planning strategy. DCEE integrates parameter estimation of the reward function and view planning, ensuring a balanced trade-off between the exploitation of learned knowledge and active exploration during the planning process. Moreover, it demonstrates remarkable adaptability across diverse scenarios, effectively handling LEGO brick detection at varying locations. Importantly, the algorithm maintains consistent configuration settings and a fixed number of parameters across various scenarios, underscoring its efficiency and robustness. To validate the proposed approach, extensive numerical studies, high-fidelity virtual simulations, and real-world experiments under various scenarios were conducted. The results confirm the effectiveness of DCEE in active object detection, showcasing superior performance compared to existing methods, including model predictive control (MPC) and entropy approaches.
[133]
arXiv:2509.13786
(replaced)
[pdf, html, other]
Title:
Efficient Quantization-Aware Neural Receivers: Beyond Post-Training Quantization
SaiKrishna Saketh Yellapragada, Esa Ollila, Mario Costa
Comments:
Submitted for 51st International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2026
Subjects:
Signal Processing (eess.SP)
As wireless communication systems advance toward Sixth Generation (6G) Radio Access Networks (RAN), Deep Learning (DL)-based neural receivers are emerging as transformative solutions for Physical Layer (PHY) processing, delivering superior Block Error Rate (BLER) performance compared to traditional model-based approaches. Practical deployment on resource-constrained hardware, however, requires efficient quantization to reduce latency, energy, and memory without sacrificing reliability. In this paper, we extend Post-Training Quantization (PTQ) by focusing on Quantization-Aware Training (QAT), which incorporates low-precision simulation during training for robustness at ultra-low bitwidths. In particular, we develop a QAT methodology for a neural receiver architecture and benchmark it against a PTQ approach across diverse 3GPP Clustered Delay Line (CDL) channel profiles under both Line-of-Sight (LoS) and Non-LoS (NLoS) conditions, with user velocities up to 40 m/s. Results show that 4-bit and 8-bit QAT models achieve BLERs comparable to FP32 models at a 10% target BLER. Moreover, QAT models succeed in NLoS scenarios where PTQ models fail to reach the 10% BLER target, while also yielding an 8x compression. These results with respect to full-precision demonstrate that QAT is a key enabler of low-complexity and latency-constrained inference at the PHY layer, facilitating real-time processing in 6G edge devices.
[134]
arXiv:2509.14447
(replaced)
[pdf, html, other]
Title:
Biologically Plausible Online Hebbian Meta-Learning: Two-Timescale Local Rules for Spiking Neural Brain Interfaces
Sriram V.C. Nallani, Gautham Ramachandran, Sahil Shah
Comments:
9 pages, 5 figures, submitted to ICLR 2026; under review. Replacement was made to correct mistakes in metadata and header in PDF
Subjects:
Signal Processing (eess.SP)
Brain-Computer Interfaces face challenges from neural signal instability and memory constraints for real-time implantable applications. We introduce an online SNN decoder using local three-factor learning rules with dual-timescale eligibility traces that avoid backpropagation through time while maintaining competitive performance. Our approach combines error-modulated Hebbian updates, fast/slow trace consolidation, and adaptive learning rate control, requiring only O(1) memory versus O(T) for BPTT methods. Evaluations on two primate datasets achieve comparable decoding accuracy (Pearson $R \geq 0.63$ Zenodo, $R \geq 0.81$ MC Maze) with 28-35% memory reduction and faster convergence than BPTT-trained SNNs. Closed-loop simulations with synthetic neural populations demonstrate adaptation to neural disruptions and learning from scratch without offline calibration. This work enables memory-efficient, continuously adaptive neural decoding suitable for resource-constrained implantable BCI systems.
[135]
arXiv:2003.13733
(replaced)
[pdf, other]
Title:
Lateral oscillation and body compliance help snakes and snake robots stably traverse large, smooth obstacles
Qiyuan Fu, Sean W. Gart, Thomas W. Mitchel, Jin Seob Kim, Gregory S. Chirikjian, Chen Li
Journal-ref:
Integrative and Comparative Biology, 60 (1), 171 (2020)
Subjects:
Biological Physics (physics.bio-ph); Systems and Control (eess.SY); Quantitative Methods (q-bio.QM)
Snakes can move through almost any terrain. Similarly, snake robots hold the promise as a versatile platform to traverse complex environments like earthquake rubble. Unlike snake locomotion on flat surfaces which is inherently stable, when snakes traverse complex terrain by deforming their body out of plane, it becomes challenging to maintain stability. Here, we review our recent progress in understanding how snakes and snake robots traverse large, smooth obstacles that lack anchor points for gripping or bracing. First, we discovered that the generalist variable kingsnake combines lateral oscillation and cantilevering. Regardless of step height and surface friction, the overall gait is preserved. Next, to quantify static stability of the snake, we developed a method to interpolate continuous body in three dimensions (both position and orientation) between discrete tracked markers. By analyzing the base of support using the interpolated continuous body 3-D kinematics, we discovered that the snake maintained perfect stability during traversal, even on the most challenging low friction, high step. Finally, we applied this gait to a snake robot and systematically tested its performance traversing large steps with variable heights to further understand stability principles. The robot rapidly and stably traversed steps nearly as high as a third of its body length. As step height increased, the robot rolled more frequently to the extent of flipping over, reducing traversal probability. The absence of such failure in the snake with a compliant body inspired us to add body compliance to the robot. With better surface contact, the compliant body robot suffered less roll instability and traversed high steps at higher probability, without sacrificing traversal speed. Our robot traversed large step-like obstacles more rapidly than most previous snake robots, approaching that of the animal.
[136]
arXiv:2006.12717
(replaced)
[pdf, other]
Title:
An energy landscape approach to locomotor transitions in complex 3D terrain
Ratan Othayoth, George Thoms, Chen Li
Journal-ref:
Proceedings of the National Academy of Sciences, 117 (26), 14987-14995 (2020)
Subjects:
Biological Physics (physics.bio-ph); Systems and Control (eess.SY); Quantitative Methods (q-bio.QM)
Effective locomotion in nature happens by transitioning across multiple modes (e.g., walk, run, climb). Despite this, far more mechanistic understanding of terrestrial locomotion has been on how to generate and stabilize around near-steady-state movement in a single mode. We still know little about how locomotor transitions emerge from physical interaction with complex terrain. Consequently, robots largely rely on geometric maps to avoid obstacles, not traverse them. Recent studies revealed that locomotor transitions in complex 3-D terrain occur probabilistically via multiple pathways. Here, we show that an energy landscape approach elucidates the underlying physical principles. We discovered that locomotor transitions of animals and robots self-propelled through complex 3-D terrain correspond to barrier-crossing transitions on a potential energy landscape. Locomotor modes are attracted to landscape basins separated by potential energy barriers. Kinetic energy fluctuation from oscillatory self-propulsion helps the system stochastically escape from one basin and reach another to make transitions. Escape is more likely towards lower barrier direction. These principles are surprisingly similar to those of near-equilibrium, microscopic systems. Analogous to free energy landscapes for multi-pathway protein folding transitions, our energy landscape approach from first principles is the beginning of a statistical physics theory of multi-pathway locomotor transitions in complex terrain. This will not only help understand how the organization of animal behavior emerges from multi-scale interactions between their neural and mechanical systems and the physical environment, but also guide robot design, control, and planning over the large, intractable locomotor-terrain parameter space to generate robust locomotor transitions through the real world.
[137]
arXiv:2008.08981
(replaced)
[pdf, other]
Title:
Coordinated appendages accumulate more energy to self-right on the ground
Qihan Xuan, Chen Li
Journal-ref:
IEEE Robotics and Automation Letters, 5 (4), 6137-6144 (2020)
Subjects:
Biological Physics (physics.bio-ph); Systems and Control (eess.SY); Quantitative Methods (q-bio.QM)
Animals and robots must right themselves after flipping over on the ground. The discoid cockroach pushes its wings against the ground in an attempt to dynamically self-right by a somersault. However, because this maneuver is strenuous, the animal often fails to overcome the potential energy barrier and makes continual attempts. In this process, the animal flails its legs, whose lateral perturbation eventually leads it to roll to the side to self-right. Our previous work developed a cockroach-inspired robot capable of leg-assisted, winged self-righting, and a robot simulation study revealed that the outcome of this strategy depends sensitively on wing-leg coordination (measured by the phase between their motions). Here, we further elucidate why this is the case by developing a template to model the complex hybrid dynamics resulting from discontinuous contact and actuation. We used the template to calculate the potential energy barrier that the body must overcome to self-right, mechanical energy contribution by wing pushing and leg flailing, and mechanical energy dissipation due to wing-ground collision. The template revealed that wing-leg coordination (phase) strongly affects self-righting outcome by changing mechanical energy budget. Well-coordinated appendage motions (good phase) accumulate more mechanical energy than poorly-coordinated motions (bad phase), thereby better overcoming the potential energy barrier to self-right more successfully. Finally, we demonstrated practical use of the template for predicting a new control strategy to further increase self-righting performance and informing robot design.
[138]
arXiv:2402.08617
(replaced)
[pdf, html, other]
Title:
Limitations of Fault-Tolerant Quantum Linear System Solvers for Quantum Power Flow
Parikshit Pareek, Abhijith Jayakumar, Carleton Coffrin, Sidhant Misra
Comments:
Only change of the paper title due to you know who
Subjects:
Quantum Physics (quant-ph); Systems and Control (eess.SY)
Quantum computers hold promise for solving problems intractable for classical computers, especially those with high time or space complexity. Practical quantum advantage can be said to exist for such problems when the end-to-end time for solving such a problem using a classical algorithm exceeds that required by a quantum algorithm. Reducing the power flow (PF) problem into a linear system of equations allows for the formulation of quantum PF (QPF) algorithms, which are based on solving methods for quantum linear systems such as the Harrow-Hassidim-Lloyd (HHL) algorithm. Speedup from using QPF algorithms is often claimed to be exponential when compared to classical PF solved by state-of-the-art algorithms. We investigate the potential for practical quantum advantage in solving QPF compared to classical methods on gate-based quantum computers. Notably, this paper does not present a new QPF solving algorithm but scrutinizes the end-to-end complexity of the QPF approach, providing a nuanced evaluation of the purported quantum speedup in this problem. Our analysis establishes a best-case bound for the HHL-based quantum power flow complexity, conclusively demonstrating that the HHL-based method has higher runtime complexity compared to the classical algorithm for solving the direct current power flow (DCPF) and fast decoupled load flow (FDLF) problem. Notably, our analysis and conclusions can be extended to any quantum linear system solver with rigorous performance guarantees, based on the known complexity lower bounds for this problem. Additionally, we establish that for potential practical quantum advantage (PQA) to exist it is necessary to consider DCPF-type problems with a very narrow range of condition number values and readout requirements.
[139]
arXiv:2408.03591
(replaced)
[pdf, html, other]
Title:
FOVAL: Calibration-Free and Subject-Invariant Fixation Depth Estimation Across Diverse Eye-Tracking Datasets
Benedikt W. Hosp
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Signal Processing (eess.SP)
Accurate fixation depth estimation is essential for applications in extended reality (XR), robotics, and human-computer interaction. However, current methods heavily depend on user-specific calibration, which limits their scalability and usability. We introduce FOVAL, a robust calibration-free approach that combines spatiotemporal sequence modelling via Long Short-Term Memory (LSTM) networks with subject-invariant feature engineering and normalisation. Compared to Transformers, Temporal Convolutional Networks (TCNs), and CNNs, FOVAL achieves superior performance, particularly in scenarios with limited and noisy gaze data. Evaluations across three benchmark datasets using Leave-One-Out Cross-Validation (LOOCV) and cross-dataset validation show a mean absolute error (MAE) of 9.1 cm and strong generalisation without calibration. We further analyse inter-subject variability and domain shifts, providing insight into model robustness and adaptation. FOVAL's scalability and accuracy make it highly suitable for real-world deployment.
[140]
arXiv:2409.11760
(replaced)
[pdf, html, other]
Title:
Sound-Based Spin Estimation in Table Tennis: Dataset and Real-Time Classification Pipeline
Thomas Gossard, Julian Schmalzl, Andreas Ziegler, Andreas Zell
Comments:
Accepted to IEEE Star 2025
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Sound can complement vision in ball sports by providing subtle cues about contact dynamics. In table tennis, the brief, high-frequency sounds produced during racket-ball impacts carry information about the racket type, the surface contacted, and whether spin was applied. We address three key problems in this domain: (1) precise bounce detection with millisecond-level temporal accuracy, (2) classification of bounce surface (e.g., racket, table, floor), and (3) spin detection from audio alone. To this end, we propose a real-time-capable pipeline that combines energy-based peak detection with convolutional neural networks trained on a novel dataset of 3,396 bounce samples recorded across 10 racket configurations. The system achieves accurate and low-latency detection of bounces, and reliably classifies both the surface of contact and whether spin was applied. This audio-based approach opens up new possibilities for spin estimation in robotic systems and for real-time feedback in coaching tools. We publicly release both the dataset and code to support further research.
[141]
arXiv:2412.01064
(replaced)
[pdf, html, other]
Title:
FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait
Taekyung Ki, Dongchan Min, Gyeongsu Chae
Comments:
ICCV 2025. Project page: this https URL
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)
With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency.
[142]
arXiv:2501.01642
(replaced)
[pdf, html, other]
Title:
iCBIR-Sli: Interpretable Content-Based Image Retrieval with 2D Slice Embeddings
Shuhei Tomoshige, Hayato Muraki, Kenichi Oishi, Hitoshi Iyatomi
Comments:
8 pages, 2 figures. Accepted at the SPIE Medical Imaging
Journal-ref:
Proceedings of the SPIE Medical Imaging, 16-20 February, 2025, San Diego, California, US
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)
Current methods for searching brain MR images rely on text-based approaches, highlighting a significant need for content-based image retrieval (CBIR) systems. Directly applying 3D brain MR images to machine learning models offers the benefit of effectively learning the brain's structure; however, building the generalized model necessitates a large amount of training data. While models that consider depth direction and utilize continuous 2D slices have demonstrated success in segmentation and classification tasks involving 3D data, concerns remain. Specifically, using general 2D slices may lead to the oversight of pathological features and discontinuities in depth direction information. Furthermore, to the best of the authors' knowledge, there have been no attempts to develop a practical CBIR system that preserves the entire brain's structural information. In this study, we propose an interpretable CBIR method for brain MR images, named iCBIR-Sli (Interpretable CBIR with 2D Slice Embedding), which, for the first time globally, utilizes a series of 2D slices. iCBIR-Sli addresses the challenges associated with using 2D slices by effectively aggregating slice information, thereby achieving low-dimensional representations with high completeness, usability, robustness, and interoperability, which are qualities essential for effective CBIR. In retrieval evaluation experiments utilizing five publicly available brain MR datasets (ADNI2/3, OASIS3/4, AIBL) for Alzheimer's disease and cognitively normal, iCBIR-Sli demonstrated top-1 retrieval performance (macro F1 = 0.859), comparable to existing deep learning models explicitly designed for classification, without the need for an external classifier. Additionally, the method provided high interpretability by clearly identifying the brain regions indicative of the searched-for disease.
[143]
arXiv:2503.11899
(replaced)
[pdf, html, other]
Title:
StFT: Spatio-temporal Fourier Transformer for Long-term Dynamics Prediction
Da Long, Shandian Zhe, Samuel Williams, Leonid Oliker, Zhe Bai
Comments:
23 pages, 11 figures
Subjects:
Machine Learning (cs.LG); Signal Processing (eess.SP)
Simulating the long-term dynamics of multi-scale and multi-physics systems poses a significant challenge in understanding complex phenomena across science and engineering. The complexity arises from the intricate interactions between scales and the interplay of diverse physical processes, which manifest in PDEs through coupled, nonlinear terms that govern the evolution of multiple physical fields across scales. Neural operators have shown potential in short-term prediction of such complex spatio-temporal dynamics; however, achieving stable high-fidelity predictions and providing robust uncertainty quantification over extended time horizons remains an open and unsolved area of research. These limitations often lead to stability degradation with rapid error accumulation, particularly in long-term forecasting of systems characterized by multi-scale behaviors involving dynamics of different orders. To address these challenges, we propose an autoregressive Spatio-temporal Fourier Transformer (StFT), in which each transformer block is designed to learn the system dynamics at a distinct scale through a dual-path architecture that integrates frequency-domain and spatio-temporal representations. By leveraging a structured hierarchy of \ours blocks, the resulting model explicitly captures the underlying dynamics across both macro- and micro- spatial scales. Furthermore, a generative residual correction mechanism is introduced to learn a probabilistic refinement temporally while simultaneously quantifying prediction uncertainties, enhancing both the accuracy and reliability of long-term probabilistic forecasting. Evaluations conducted on three benchmark datasets (plasma, fluid, and atmospheric dynamics) demonstrate the advantages of our approach over state-of-the-art ML methods.
[144]
arXiv:2503.13246
(replaced)
[pdf, html, other]
Title:
Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression
Guoyou Sun, Panagiotis Karras, Qi Zhang
Comments:
This is an extended version of arXiv:2503.13246, with significant additional contributions
Subjects:
Machine Learning (cs.LG); Signal Processing (eess.SP)
Semantic communication has emerged as a promising paradigm to tackle the challenges of massive growing data traffic and sustainable data communication. It shifts the focus from data fidelity to goal-oriented or task-oriented semantic transmission. While deep learning-based methods are commonly used for semantic encoding and decoding, they struggle with the sequential nature of time series data and high computation cost, particularly in resource-constrained IoT environments. Data compression plays a crucial role in reducing transmission and storage costs, yet traditional data compression methods fall short of the demands of goal-oriented communication systems. In this paper, we propose a novel method for direct analytics on time series data compressed by the SHRINK compression algorithm. Through experimentation using outlier detection as a case study, we show that our method outperforms baselines running on uncompressed data in multiple cases, with merely 1% difference in the worst case. Additionally, it achieves four times lower runtime on average and accesses approximately 10% of the data volume, which enables edge analytics with limited storage and computation power. These results demonstrate that our approach offers reliable, high-speed outlier detection analytics for diverse IoT applications while extracting semantics from time-series data, achieving high compression, and reducing data transmission.
[145]
arXiv:2503.23470
(replaced)
[pdf, html, other]
Title:
Evaluation of the Pronunciation of Tajweed Rules Based on DNN as a Step Towards Interactive Recitation Learning
Dim Shaiakhmetov, Gulnaz Gimaletdinova, Kadyrmamat Momunov, Selcuk Cankurt
Journal-ref:
International Conference on Computer Systems and Technologies (CompSysTech), IEEE Xplore, 2025
Subjects:
Sound (cs.SD); Audio and Speech Processing (eess.AS)
Proper recitation of the Quran, adhering to the rules of Tajweed, is crucial for preventing mistakes during recitation and requires significant effort to master. Traditional methods of teaching these rules are limited by the availability of qualified instructors and time constraints. Automatic evaluation of recitation can address these challenges by providing prompt feedback and supporting independent practice. This study focuses on developing a deep learning model to classify three Tajweed rules - separate stretching (Al Mad), tight noon (Ghunnah), and hide (Ikhfaa) - using the publicly available QDAT dataset, which contains over 1,500 audio recordings. The input data consisted of audio recordings from this dataset, transformed into normalized mel-spectrograms. For classification, the EfficientNet-B0 architecture was used, enhanced with a Squeeze-and-Excitation attention mechanism. The developed model achieved accuracy rates of 95.35%, 99.34%, and 97.01% for the respective rules. An analysis of the learning curves confirmed the model's robustness and absence of overfitting. The proposed approach demonstrates high efficiency and paves the way for developing interactive educational systems for Tajweed study.
[146]
arXiv:2504.15756
(replaced)
[pdf, html, other]
Title:
DSDNet: Raw Domain Demoiréing via Dual Color-Space Synergy
Qirui Yang, Fangpu Zhang, Yeying Jin, Qihua Cheng, Peng-Tao Jiang, Huanjing Yue, Jingyu Yang
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
With the rapid advancement of mobile imaging, capturing screens using smartphones has become a prevalent practice in distance learning and conference recording. However, moiré artifacts, caused by frequency aliasing between display screens and camera sensors, are further amplified by the image signal processing pipeline, leading to severe visual degradation. Existing sRGB domain demoiréing methods struggle with irreversible information loss, while recent two-stage raw domain approaches suffer from information bottlenecks and inference inefficiency. To address these limitations, we propose a single-stage raw domain demoiréing framework, Dual-Stream Demoiréing Network (DSDNet), which leverages the synergy of raw and YCbCr images to remove moiré while preserving luminance and color fidelity. Specifically, to guide luminance correction and moiré removal, we design a raw-to-YCbCr mapping pipeline and introduce the Synergic Attention with Dynamic Modulation (SADM) module. This module enriches the raw-to-sRGB conversion with cross-domain contextual features. Furthermore, to better guide color fidelity, we develop a Luminance-Chrominance Adaptive Transformer (LCAT), which decouples luminance and chrominance representations. Extensive experiments demonstrate that DSDNet outperforms state-of-the-art methods in both visual quality and quantitative evaluation and achieves an inference speed $\mathrm{\textbf{2.4x}}$ faster than the second-best method, highlighting its practical advantages. We provide an anonymous online demo at this https URL.
[147]
arXiv:2505.05644
(replaced)
[pdf, other]
Title:
The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction
Tom Sander, Moritz Tenthoff, Kay Wohlfarth, Christian Wöhler
Comments:
48pages
Subjects:
Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
Multimodal learning is an emerging research topic across multiple disciplines but has rarely been applied to planetary science. In this contribution, we propose a single, unified transformer architecture trained to learn shared representations between multiple sources like grayscale images, Digital Elevation Models (DEMs), surface normals, and albedo maps. The architecture supports flexible translation from any input modality to any target modality. Our results demonstrate that our foundation model learns physically plausible relations across these four modalities. We further identify that image-based 3D reconstruction and albedo estimation (Shape and Albedo from Shading) of lunar images can be formulated as a multimodal learning problem. Our results demonstrate the potential of multimodal learning to solve Shape and Albedo from Shading and provide a new approach for large-scale planetary 3D reconstruction. Adding more input modalities in the future will further improve the results and enable tasks such as photometric normalization and co-registration.
[148]
arXiv:2506.04586
(replaced)
[pdf, html, other]
Title:
LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models Using in-the-wild Data
Wen Ding, Fan Qian
Comments:
Submitted to ICASSP 2026
Subjects:
Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Although state-of-the-art Speech Foundation Models can produce high-quality text pseudo-labels, applying Semi-Supervised Learning (SSL) for in-the-wild real-world data remains challenging due to its richer and more complex acoustics compared to curated datasets. To address the challenges, we introduce LESS (Large Language Model Enhanced Semi-supervised Learning), a versatile framework that uses Large Language Models (LLMs) to correct pseudo-labels generated on in-the-wild data. In the LESS framework, pseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic Speech Translation (AST) of the unsupervised data is refined by an LLM, and further improved by a data filtering strategy. Across Mandarin ASR and Spanish-to-English AST evaluations, LESS delivers consistent gains, with an absolute Word Error Rate reduction of 3.8% on WenetSpeech, and BLEU score increase of 0.8 and 0.7, achieving 34.0 on Callhome and 64.7 on Fisher testsets respectively. These results highlight LESS's effectiveness across diverse languages, tasks, and domains. We have released the recipe as open source to facilitate further research in this area.
[149]
arXiv:2507.07318
(replaced)
[pdf, html, other]
Title:
Generating Moving 3D Soundscapes with Latent Diffusion Models
Christian Templin, Yanda Zhu, Hao Wang
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
Spatial audio has become central to immersive applications such as VR/AR, cinema, and music. Existing generative audio models are largely limited to mono or stereo formats and cannot capture the full 3D localization cues available in first-order Ambisonics (FOA). Recent FOA models extend text-to-audio generation but remain restricted to static sources. In this work, we introduce SonicMotion, the first end-to-end latent diffusion framework capable of generating FOA audio with explicit control over moving sound sources. SonicMotion is implemented in two variations: 1) a descriptive model conditioned on natural language prompts, and 2) a parametric model conditioned on both text and spatial trajectory parameters for higher precision. To support training and evaluation, we construct a new dataset of over one million simulated FOA caption pairs that include both static and dynamic sources with annotated azimuth, elevation, and motion attributes. Experiments show that SonicMotion achieves state-of-the-art semantic alignment and perceptual quality comparable to leading text-to-audio systems, while uniquely attaining low spatial localization error.
[150]
arXiv:2507.18352
(replaced)
[pdf, html, other]
Title:
Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation
Zhen Han, Mattias Teye, Derek Yadgaroff, Judith Bütepage
Comments:
Accepted to ACM TOG 2025 (SIGGRAPH journal track); Project page: this https URL
Journal-ref:
ACM Transactions on Graphics, Vol. 44, No. 4, Article 104, July 2025
Subjects:
Graphics (cs.GR); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)
The training of high-quality, robust machine learning models for speech-driven 3D facial animation requires a large, diverse dataset of high-quality audio-animation pairs. To overcome the lack of such a dataset, recent work has introduced large pre-trained speech encoders that are robust to variations in the input audio and, therefore, enable the facial animation model to generalize across speakers, audio quality, and languages. However, the resulting facial animation models are prohibitively large and lend themselves only to offline inference on a dedicated machine. In this work, we explore on-device, real-time facial animation models in the context of game development. We overcome the lack of large datasets by using hybrid knowledge distillation with pseudo-labeling. Given a large audio dataset, we employ a high-performing teacher model to train very small student models. In contrast to the pre-trained speech encoders, our student models only consist of convolutional and fully-connected layers, removing the need for attention context or recurrent updates. In our experiments, we demonstrate that we can reduce the memory footprint to up to 3.4 MB and required future audio context to up to 81 ms while maintaining high-quality animations. This paves the way for on-device inference, an important step towards realistic, model-driven digital characters.
[151]
arXiv:2508.20304
(replaced)
[pdf, html, other]
Title:
Testing and Fault Tolerance Techniques for CNT-Based FPGAs
Siyuan Lu, Kangwei Xu, Peng Xie, Rui Wang, Yuanqing Cheng
Comments:
13 pages
Subjects:
Hardware Architecture (cs.AR); Systems and Control (eess.SY)
As the semiconductor manufacturing process technology node shrinks into the nanometer-scale, the CMOS-based Field Programmable Gate Arrays (FPGAs) face big challenges in scalability of performance and power consumption. Multi-walled Carbon Nanotube (MWCNT) serves as a promising candidate for Cu interconnects thanks to the superior conductivity. Moreover, Carbon Nanotube Field Transistor (CNFET) also emerges as a prospective alternative to the conventional CMOS device because of high power efficiency and large noise margin. The combination of MWCNT and CNFET enables the promising CNT-based FPGAs. However, the MWCNT interconnects exhibit significant process variations due to immature fabrication process, leading to delay faults. Also, the non-ideal CNFET fabrication process may generate a few metallic CNTs (m-CNTs), rendering correlated faulty blocks. In this article, we propose a ring oscillator (RO) based testing technique to detect delay faults due to the process variation of MWCNT interconnects. Furthermore, we propose an effective testing technique for the carry chains in CLBs, and an improved circuit design based on the lookup table (LUT) is applied to speed up the fault testing of CNT-based FPGAs. In addition, we propose a testing algorithm to detect m-CNTs in CLBs. Finally, we propose a redundant spare row sharing architecture to improve the yield of CNT-based FPGA further. Experimental results show that the test time for a 6-input LUT can be reduced by 35.49% compared with conventional testing, and the proposed algorithm can achieve a high test coverage with little overhead. The proposed redundant architecture can repair the faulty segment effectively and efficiently.
[152]
arXiv:2509.14049
(replaced)
[pdf, html, other]
Title:
Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices
Jordi Grau-Haro, Ruben Ribes-Serrano, Javier Naranjo-Alcazar, Marta Garcia-Ballesteros, Pedro Zuccarello
Comments:
Accepted at Computing Conference 2026, London, UK
Subjects:
Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)
Convolutional Neural Networks (CNNs) have demonstrated exceptional performance in audio tagging tasks. However, deploying these models on resource-constrained devices like the Raspberry Pi poses challenges related to computational efficiency and thermal management. In this paper, a comprehensive evaluation of multiple convolutional neural network (CNN) architectures for audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D models from the Pretrained Audio Neural Networks (PANNs) framework, a ConvNeXt-based model adapted for audio classification, as well as MobileNetV3 architectures. In addition, two PANNs-derived networks, CNN9 and CNN13, recently proposed, are also evaluated. To enhance deployment efficiency and portability across diverse hardware platforms, all models are converted to the Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on a single model, our analysis encompasses a broader range of architectures and involves continuous 24-hour inference sessions to assess performance stability. Our experiments reveal that, with appropriate model selection and optimization, it is possible to maintain consistent inference latency and manage thermal behavior effectively over extended periods. These findings provide valuable insights for deploying audio tagging models in real-world edge computing scenarios.
[153]
arXiv:2509.14453
(replaced)
[pdf, html, other]
Title:
Online Learning of Deceptive Policies under Intermittent Observation
Gokul Puthumanaillam, Ram Padmanabhan, Jose Fuentes, Nicole Cruz, Paulo Padrao, Ruben Hernandez, Hao Jiang, William Schafer, Leonardo Bobadilla, Melkior Ornik
Subjects:
Robotics (cs.RO); Multiagent Systems (cs.MA); Systems and Control (eess.SY)
In supervisory control settings, autonomous systems are not monitored continuously. Instead, monitoring often occurs at sporadic intervals within known bounds. We study the problem of deception, where an agent pursues a private objective while remaining plausibly compliant with a supervisor's reference policy when observations occur. Motivated by the behavior of real, human supervisors, we situate the problem within Theory of Mind: the representation of what an observer believes and expects to see. We show that Theory of Mind can be repurposed to steer online reinforcement learning (RL) toward such deceptive behavior. We model the supervisor's expectations and distill from them a single, calibrated scalar -- the expected evidence of deviation if an observation were to happen now. This scalar combines how unlike the reference and current action distributions appear, with the agent's belief that an observation is imminent. Injected as a state-dependent weight into a KL-regularized policy improvement step within an online RL loop, this scalar informs a closed-form update that smoothly trades off self-interest and compliance, thus sidestepping hand-crafted or heuristic policies. In real-world, real-time hardware experiments on marine (ASV) and aerial (UAV) navigation, our ToM-guided RL runs online, achieves high return and success with observed-trace evidence calibrated to the supervisor's expectations.
[154]
arXiv:2509.14905
(replaced)
[pdf, html, other]
Title:
Movable-Antenna Trajectory Optimization for Wireless Sensing: CRB Scaling Laws over Time and Space
Wenyan Ma, Lipeng Zhu, Rui Zhang
Subjects:
Information Theory (cs.IT); Signal Processing (eess.SP)
In this paper, we present a new wireless sensing system utilizing a movable antenna (MA) that continuously moves and receives sensing signals to enhance sensing performance over the conventional fixed-position antenna (FPA) sensing. We show that the angle estimation performance is fundamentally determined by the MA trajectory, and derive the Cramer-Rao bound (CRB) of the mean square error (MSE) for angle-of-arrival (AoA) estimation as a function of the trajectory for both one-dimensional (1D) and two-dimensional (2D) antenna movement. For the 1D case, a globally optimal trajectory that minimizes the CRB is derived in closed form. Notably, the resulting CRB decreases cubically with sensing time in the time-constrained regime, whereas it decreases linearly with sensing time and quadratically with the movement line segment's length in the space-constrained regime. For the 2D case, we aim to achieve the minimum of maximum (min-max) CRBs of estimation MSE for the two AoAs with respect to the horizontal and vertical axes. To this end, we design an efficient alternating optimization algorithm that iteratively updates the MA's horizontal or vertical coordinates with the other being fixed, yielding a locally optimal trajectory. Numerical results show that the proposed 1D/2D MA-based sensing schemes significantly reduce both the CRB and actual AoA estimation MSE compared to conventional FPA-based sensing with uniform linear/planar arrays (ULAs/UPAs) as well as various benchmark MA trajectories. Moreover, it is revealed that the steering vectors of our designed 1D/2D MA trajectories have low correlation in the angular domain, thereby effectively increasing the angular resolution for achieving higher AoA estimation accuracy.
[155]
arXiv:2509.15170
(replaced)
[pdf, other]
Title:
Watermarking and Anomaly Detection in Machine Learning Models for LORA RF Fingerprinting
Aarushi Mahajan, Wayne Burleson
Comments:
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)
Subjects:
Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)
Radio frequency fingerprint identification (RFFI) distinguishes wireless devices by the small variations in their analog circuits, avoiding heavy cryptographic authentication. While deep learning on spectrograms improves accuracy, models remain vulnerable to copying, tampering, and evasion. We present a stronger RFFI system combining watermarking for ownership proof and anomaly detection for spotting suspicious inputs. Using a ResNet-34 on log-Mel spectrograms, we embed three watermarks: a simple trigger, an adversarially trained trigger robust to noise and filtering, and a hidden gradient/weight signature. A convolutional Variational Autoencoders (VAE) with Kullback-Leibler (KL) warm-up and free-bits flags off-distribution queries. On the LoRa dataset, our system achieves 94.6% accuracy, 98% watermark success, and 0.94 AUROC, offering verifiable, tamper-resistant authentication.
Total of 155 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack