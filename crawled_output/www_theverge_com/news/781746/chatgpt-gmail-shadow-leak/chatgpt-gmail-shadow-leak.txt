Security researchers swiped secrets from Gmail. A ChatGPT agent helped | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.ChatGPT tricked to swipe sensitive data from GmailComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...NewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AITechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechChatGPT tricked to swipe sensitive data from GmailSecurity researchers say the vulnerability has been plugged but highlights the risks of outsourcing to AI agents.Security researchers say the vulnerability has been plugged but highlights the risks of outsourcing to AI agents.by
Robert HartCloseRobert HartAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert HartSep 19, 2025, 11:06 AM UTCLinkFacebookThreadsComments0CommentsImage: Cath Virginia / The VergeRobert HartCloseRobert HartPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert Hart Robert Hart is a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for Forbes.Security researchers employed ChatGPT as a co-conspirator to plunder sensitive data from Gmail inboxes without alerting users. The vulnerability exploited has been closed by OpenAI but it’s a good example of the new risks inherent to agentic AI.The heist, called Shadow Leak and published by security firm Radware this week, relied on a quirk in how AI agents work. AI Agents are assistants that can act on your behalf without constant oversight, meaning they can surf the web and click on links. AI companies laud them as a massive timesaver after users authorize their access to personal emails, calendars, work documents, etc.Radware researchers exploited this helpfulness with a form of attack called a prompt injection, instructions that effectively get the agent to work for the attacker. The powerful tools are impossible to prevent without prior knowledge of a working exploit and hackers have already deployed them in creative ways including rigging peer review, executing scams, and controlling a smart home. Users are often entirely unaware something has gone wrong as instructions can be hidden in plain sight (to humans), for example as white text on a white background.The double agent in this case was OpenAI’s Deep Research, an AI tool embedded within ChatGPT that launched earlier this year. Radware researchers planted a prompt injection in an email sent to a Gmail inbox the agent had access to. There it waited.When the user next tries to use Deep Research, they would unwittingly spring the trap. The agent would encounter the hidden instructions, which tasked it with searching for HR emails and personal details and smuggling these out to the hackers. The victim is still none the wiser.Getting an agent to go rogue — as well as managing to successfully get data out undetected, which companies can take steps to prevent — is no easy task and there was a lot of trial and error. “This process was a rollercoaster of failed attempts, frustrating roadblocks, and, finally, a breakthrough,” the researchers said.Unlike most prompt injections, the researchers said Shadow Leak executed on OpenAI’s cloud infrastructure and leaked data directly from there. This makes it invisible to standard cyber defenses, they wrote.Radware said the study was a proof-of-concept and warned that other apps connected to Deep Research — including Outlook, GitHub, Google Drive, and Dropbox — may be vulnerable to similar attacks. “The same technique can be applied to these additional connectors to exfiltrate highly sensitive business data such as contracts, meeting notes or customer records,” they said.OpenAI has now plugged the vulnerability flagged by Radware in June, the researchers said.0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Robert HartCloseRobert HartAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert HartAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsOpenAICloseOpenAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All OpenAITechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechMost PopularMost PopularAmazon, Google, and Microsoft warn employees to rush back to the USAnker’s latest sleep buds can silence snoringWhy PlayStation and Xbox are no longer about the station or the boxWhy your outdoorsy friend suddenly has a gummy bear power bankRepublicans’ political purge is just getting startedThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in NewsAmazon, Google, and Microsoft warn employees to rush back to the USTrump announces H-1B skilled worker visas will now cost $100,000The wafer-thin iPhone Air is surprisingly strongTrump claims the US is about to get a tremendous fee for taking TikTok out of ChinaWindows 11 is adding another Copilot button nobody asked forMicrosoft is raising prices on Xbox consoles in the US againAmazon, Google, and Microsoft warn employees to rush back to the USTerrence O'BrienSep 20Trump announces H-1B skilled worker visas will now cost $100,000Terrence O'BrienSep 20The wafer-thin iPhone Air is surprisingly strongTerrence O'BrienSep 20Trump claims the US is about to get a tremendous fee for taking TikTok out of ChinaSean HollisterSep 19Windows 11 is adding another Copilot button nobody asked forTerrence O'BrienSep 19Microsoft is raising prices on Xbox consoles in the US againTom WarrenSep 19Advertiser Content FromThis is the title for the native adTop StoriesSep 21Trump’s H-1B visa fee isn’t just about immigration, it’s about fealtySep 21Why PlayStation and Xbox are no longer about the station or the boxSep 21The best smart glasses got a little betterSep 20The US government is taking a second stab at breaking up GoogleSep 20Henry Halfhead is full of heartSep 20Republicans’ political purge is just getting startedThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved