Security researchers swiped secrets from Gmail. A ChatGPT agent helped | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.ChatGPT tricked to swipe sensitive data from GmailComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...NewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AITechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechChatGPT tricked to swipe sensitive data from GmailSecurity researchers say the vulnerability has been plugged but highlights the risks of outsourcing to AI agents.Security researchers say the vulnerability has been plugged but highlights the risks of outsourcing to AI agents.by
Robert HartCloseRobert HartAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert HartSep 19, 2025, 11:06 AM UTCLinkFacebookThreadsComments0CommentsImage: Cath Virginia / The VergeRobert HartCloseRobert HartPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert Hart Robert Hart is a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for Forbes.Security researchers employed ChatGPT as a co-conspirator to plunder sensitive data from Gmail inboxes without alerting users. The vulnerability exploited has been closed by OpenAI but it’s a good example of the new risks inherent to agentic AI.The heist, called Shadow Leak and published by security firm Radware this week, relied on a quirk in how AI agents work. AI Agents are assistants that can act on your behalf without constant oversight, meaning they can surf the web and click on links. AI companies laud them as a massive timesaver after users authorize their access to personal emails, calendars, work documents, etc.Radware researchers exploited this helpfulness with a form of attack called a prompt injection, instructions that effectively get the agent to work for the attacker. The powerful tools are impossible to prevent without prior knowledge of a working exploit and hackers have already deployed them in creative ways including rigging peer review, executing scams, and controlling a smart home. Users are often entirely unaware something has gone wrong as instructions can be hidden in plain sight (to humans), for example as white text on a white background.The double agent in this case was OpenAI’s Deep Research, an AI tool embedded within ChatGPT that launched earlier this year. Radware researchers planted a prompt injection in an email sent to a Gmail inbox the agent had access to. There it waited.When the user next tries to use Deep Research, they would unwittingly spring the trap. The agent would encounter the hidden instructions, which tasked it with searching for HR emails and personal details and smuggling these out to the hackers. The victim is still none the wiser.Getting an agent to go rogue — as well as managing to successfully get data out undetected, which companies can take steps to prevent — is no easy task and there was a lot of trial and error. “This process was a rollercoaster of failed attempts, frustrating roadblocks, and, finally, a breakthrough,” the researchers said.Unlike most prompt injections, the researchers said Shadow Leak executed on OpenAI’s cloud infrastructure and leaked data directly from there. This makes it invisible to standard cyber defenses, they wrote.Radware said the study was a proof-of-concept and warned that other apps connected to Deep Research — including Outlook, GitHub, Google Drive, and Dropbox — may be vulnerable to similar attacks. “The same technique can be applied to these additional connectors to exfiltrate highly sensitive business data such as contracts, meeting notes or customer records,” they said.OpenAI has now plugged the vulnerability flagged by Radware in June, the researchers said.0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Robert HartCloseRobert HartAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert HartAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsOpenAICloseOpenAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All OpenAITechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechMost PopularMost PopularApple’s iPhone 17 Pro can be easily scratchedWhy your outdoorsy friend suddenly has a gummy bear power bankWhy PlayStation and Xbox are no longer about the station or the boxAmazon, Google, and Microsoft warn employees to rush back to the USThe foldable iPhone might look like two iPhone Airs stuck togetherThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in NewsJimmy Kimmel’s show will return after censorship outrageFacebook Dating tries using AI to end ‘swipe fatigue’A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policyNvidia is partnering up with OpenAI to offer compute and cashTCL’s Google TVs with an mmWave presence sensor are out nowOracle is replacing CEO Safra Catz with two co-CEOsJimmy Kimmel’s show will return after censorship outrageEmma RothSep 22Facebook Dating tries using AI to end ‘swipe fatigue’Jay PetersSep 22A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policyHayden Field and Elissa WelleSep 22Nvidia is partnering up with OpenAI to offer compute and cashHayden FieldSep 22TCL’s Google TVs with an mmWave presence sensor are out nowJay PetersSep 22Oracle is replacing CEO Safra Catz with two co-CEOsJess WeatherbedSep 22Advertiser Content FromThis is the title for the native adTop StoriesSep 22Jimmy Kimmel’s show will return after censorship outrageTwo hours agoThe AI-energy apocalypse might be a little overblownSep 22This is part of Disney’s legacy nowSep 22Why your next car should be an electric cargo bike﻿VideoSep 22Waiting to buy a game console will cost youSep 22TikTok is tagging videos from Gaza with TikTok Shop productsThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved