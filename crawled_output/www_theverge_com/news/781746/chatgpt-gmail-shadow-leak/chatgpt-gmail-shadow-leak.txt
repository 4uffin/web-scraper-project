Security researchers swiped secrets from Gmail. A ChatGPT agent helped | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.ChatGPT tricked to swipe sensitive data from GmailComments DrawerCommentsLoading commentsGetting the conversation ready...NewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AITechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechChatGPT tricked to swipe sensitive data from GmailSecurity researchers say the vulnerability has been plugged but highlights the risks of outsourcing to AI agents.Security researchers say the vulnerability has been plugged but highlights the risks of outsourcing to AI agents.by
Robert HartCloseRobert HartAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert HartSep 19, 2025, 11:06 AM UTCLinkFacebookThreadsImage: Cath Virginia / The VergeRobert HartCloseRobert HartPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert Hart Robert Hart is a London-based reporter at The Verge covering all things AI and Senior Tarbell Fellow. Previously, he wrote about health, science and tech for Forbes.Security researchers employed ChatGPT as a co-conspirator to plunder sensitive data from Gmail inboxes without alerting users. The vulnerability exploited has been closed by OpenAI but it’s a good example of the new risks inherent to agentic AI.The heist, called Shadow Leak and published by security firm Radware this week, relied on a quirk in how AI agents work. AI Agents are assistants that can act on your behalf without constant oversight, meaning they can surf the web and click on links. AI companies laud them as a massive timesaver after users authorize their access to personal emails, calendars, work documents, etc.Radware researchers exploited this helpfulness with a form of attack called a prompt injection, instructions that effectively get the agent to work for the attacker. The powerful tools are impossible to prevent without prior knowledge of a working exploit and hackers have already deployed them in creative ways including rigging peer review, executing scams, and controlling a smart home. Users are often entirely unaware something has gone wrong as instructions can be hidden in plain sight (to humans), for example as white text on a white background.The double agent in this case was OpenAI’s Deep Research, an AI tool embedded within ChatGPT that launched earlier this year. Radware researchers planted a prompt injection in an email sent to a Gmail inbox the agent had access to. There it waited.When the user next tries to use Deep Research, they would unwittingly spring the trap. The agent would encounter the hidden instructions, which tasked it with searching for HR emails and personal details and smuggling these out to the hackers. The victim is still none the wiser.Getting an agent to go rogue — as well as managing to successfully get data out undetected, which companies can take steps to prevent — is no easy task and there was a lot of trial and error. “This process was a rollercoaster of failed attempts, frustrating roadblocks, and, finally, a breakthrough,” the researchers said.Unlike most prompt injections, the researchers said Shadow Leak executed on OpenAI’s cloud infrastructure and leaked data directly from there. This makes it invisible to standard cyber defenses, they wrote.Radware said the study was a proof-of-concept and warned that other apps connected to Deep Research — including Outlook, GitHub, Google Drive, and Dropbox — may be vulnerable to similar attacks. “The same technique can be applied to these additional connectors to exfiltrate highly sensitive business data such as contracts, meeting notes or customer records,” they said.OpenAI has now plugged the vulnerability flagged by Radware in June, the researchers said.Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Robert HartCloseRobert HartAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Robert HartAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsOpenAICloseOpenAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All OpenAITechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechMost PopularMost PopularXiaomi 17 series arrives with secondary screens and enormous batteriesForza Horizon 6 is set in Japan and arrives in 2026Google reveals its Android for PC is coming next yearLogitech’s new light-powered keyboard doesn’t even need the sunGoogle’s Android for PC: ‘I’ve seen it, it is incredible’The Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in NewsThis Energizer laptop claims to have a battery that keeps going and going and goingTwitch is making it easy to rewind streamsGemini now explains why your Sheets formula failedLG’s new TV is designed to be easier for seniors to useAmazon is bringing back Rick Moranis for the Spaceballs sequelGoogle DeepMind’s new AI models can search the web to help robots complete tasksThis Energizer laptop claims to have a battery that keeps going and going and goingAntonio G. Di BenedettoSep 25Twitch is making it easy to rewind streamsJay PetersSep 25Gemini now explains why your Sheets formula failedElissa WelleSep 25LG’s new TV is designed to be easier for seniors to useAndrew LiszewskiSep 25Amazon is bringing back Rick Moranis for the Spaceballs sequelJay PetersSep 25Google DeepMind’s new AI models can search the web to help robots complete tasksEmma RothSep 25Advertiser Content FromThis is the title for the native adTop StoriesSep 25OpenAI really, really wants you to start your day with ChatGPT PulseSep 25Trump signs ‘Saving TikTok’ order to start resolving its big ban problemSep 25Silicon Valley’s latest argument against regulating AI: that would literally be the AntichristSep 25Ghost of Yōtei is exactly the kind of game PlayStation needsSep 25Microsoft says this new cooling method could enable more powerful chips and efficient data centersSep 25What happens when an AI-generated artist gets a record deal? A copyright messThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved