How chatbots — and their makers — are enabling AI psychosis | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.How chatbots — and their makers — are enabling AI psychosisComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...PodcastsClosePodcastsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PodcastsAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AIDecoderCloseDecoderPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All DecoderHow chatbots — and their makers — are enabling AI psychosisNew York Times reporter Kashmir Hill on AI psychosis, user delusions, and teen safety.by
Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden FieldSep 18, 2025, 2:00 PM UTCLinkFacebookThreadsComments0Comments Image: Alex Parkin / The Verge, ShutterstockPodcastsClosePodcastsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PodcastsAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AIDecoderCloseDecoderPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All DecoderHow chatbots — and their makers — are enabling AI psychosisNew York Times reporter Kashmir Hill on AI psychosis, user delusions, and teen safety.by
Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden FieldSep 18, 2025, 2:00 PM UTCLinkFacebookThreadsComments0CommentsHayden FieldCloseHayden FieldPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden Field is The Verge’s senior AI reporter. An AI beat reporter for more than five years, her work has also appeared in CNBC, MIT Technology Review, Wired UK, and other outlets.The explosive growth of AI chatbots in the past three years, since ChatGPT launched in 2022, has started to have some really noticeable, profound, and honestly disturbing effects on some users. There’s a lot to unpack there — it can be pretty complicated.So I’m very excited to talk with today’s guest, New York Times reporter Kashmir Hill, who has spent the past year writing thought-provoking features about the ways chatbots can affect our mental health.
One of Kashmir’s recent stories was about a teenager, Adam Raine, who died by suicide in April. After his death, his family was shocked to discover that he’d been confiding deeply in ChatGPT for months. They were also pretty surprised to find, in the transcripts, a number of times that ChatGPT seemed to guide him away from telling his loved ones. And it’s not just ChatGPT: Several families have filed wrongful death suits against Character AI, alleging that a lack of safety protocols on the company’s chatbots contributed to their teenage kids’ deaths by suicide.Then there are the AI-induced delusions. You’ll hear us talk about this at length, but pretty much every tech and AI reporter — honestly, maybe every reporter, period — has seen an uptick in the past year of people writing in with some grand or disturbing discovery that they say ChatGPT sparked. Sometimes these emails can be pretty disturbing. And as you’ll hear Kashmir explain, plenty of the people who get into these delusional spirals didn’t seem to suffer from mental illness in the past.It’s not surprising that a lot of people want somebody to do something about it, but the who and the how are hard questions. Regulation of any kind seems to be pretty much off the table right now — we’ll see — so that leaves the companies themselves. You’ll hear us touch on this a bit, but not long after we recorded this conversation, OpenAI CEO Sam Altman wrote a blog post about new features that would theoretically, and eventually, identify users’ ages and stop ChatGPT from discussing suicide with teens.But as you’ll hear us discuss, it seems like a big open question if those guardrails will actually work, how they’ll be developed, and when we’ll see them come to pass.If you’d like to read more on what we talked about in this episode, check out the links below:A teen was suicidal. ChatGPT was the friend he confided in. | New York TimesSam Altman says ChatGPT will stop talking about suicide with teens | The VergeChatbots can go into a delusional spiral. Here’s how. | New York TimesWhy is ChatGPT telling people to email me? | New York TimesThey asked an AI chatbot questions. The answers sent them spiraling. | New York TimesShe is in love with ChatGPT | New York Times‘I feel like I’m going crazy’: ChatGPT fuels delusional spirals | Wall Street JournalMeta, OpenAI face FTC inquiry on chatbots’ impact on kids | BloombergQuestions or comments about this episode? Hit us up at [email protected]. We really do read every email!Decoder with Nilay PatelA podcast from The Verge about big ideas and other problems.SUBSCRIBE NOW!If you or someone you know is considering suicide or is anxious, depressed, upset, or needs to talk, there are people who want to help.In the US:Crisis Text Line: Text HOME to 741-741 from anywhere in the US, at any time, about any type of crisis.988 Suicide & Crisis Lifeline: Call or text 988 (formerly known as the National Suicide Prevention Lifeline). The original phone number, 1-800-273-TALK (8255), is available as well.The Trevor Project: Text START to 678-678 or call 1-866-488-7386 at any time to speak to a trained counselor.Outside the US:The International Association for Suicide Prevention lists a number of suicide hotlines by country. Click here to find them.Befrienders Worldwide has a network of crisis helplines active in 48 countries. Click here to find them.0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden FieldAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AIDecoderCloseDecoderPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All DecoderPodcastsClosePodcastsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PodcastsMost PopularMost PopularNest is dead, long live Google HomeI know why Mark Zuckerberg risked live demo failureFirst look at the Google Home app powered by GeminiAnker’s recent power bank recall involves over 481,000 unitsHere’s the Jimmy Kimmel clip that got him pulled off the airThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in PodcastsMeta’s quest to own your faceWho is the iPhone Air really for?How brands and creators are fighting for your attention — and your moneyOur hottest takes on AI’s wild summerSierra CEO Bret Taylor on why the AI bubble feels like the dotcom boomThe orange iPhone stole the showMeta’s quest to own your faceDavid PierceSep 19Who is the iPhone Air really for?David PierceSep 17How brands and creators are fighting for your attention — and your moneyHank GreenSep 15Our hottest takes on AI’s wild summerDavid PierceSep 12Sierra CEO Bret Taylor on why the AI bubble feels like the dotcom boomAlex HeathSep 11The orange iPhone stole the showDavid PierceSep 10Advertiser Content FromThis is the title for the native adTop StoriesSep 20Republicans’ political purge is just getting startedSep 20Trump announces H-1B skilled worker visas will now cost $100,000Sep 20An ICE raid at an EV factory raises fears about US instabilitySep 20The US government is taking a second stab at breaking up GoogleSep 20Henry Halfhead is full of heartSep 19How I went from an e-bike hater to a believerThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved