Aligning those who align AI, one satirical website at a time | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.Aligning those who align AI, one satirical website at a timeComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...AICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsTechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechAligning those who align AI, one satirical website at a timeA new center uses humor to point out the tangled web of those focused on making AI safe with AI companies themselves. A new center uses humor to point out the tangled web of those focused on making AI safe with AI companies themselves. by
Elissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleSep 11, 2025, 8:24 PM UTCLinkFacebookThreadsComments0CommentsImage: Cath Virginia / The Verge, Getty ImagesElissa WelleCloseElissa WellePosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa Welle is a NYC-based AI reporter and is currently supported by the Tarbell Center for AI Journalism. She covers AI companies, policies, and products.The work of creating artificial intelligence that holds to the guardrails of human values, known in the industry as alignment, has developed into its own (somewhat ambiguous) field of study rife with policy papers and benchmarks to rank models against each other.But who aligns the alignment researchers?Enter the Center for the Alignment of AI Alignment Centers, an organization purporting to coordinate thousands of AI alignment researchers into “one final AI center singularity.”At first glance, CAAAC seems legitimate. The aesthetics of the website are cool and calming, with a logo of converging arrows reminiscent of the idea of togetherness and sets of parallel lines swirling behind black font.But stay on the page for 30 seconds and the swirls spell out “bullshit,” giving away that CAAAC is all one big joke. One second longer and you’ll notice the hidden gems tucked away in every sentence and page of the fantasy center’s website.CAAAC launched Tuesday from the same team that brought us The Box, a literal, physical box that women can wear on dates to avoid the threat of their image being turned into AI-generated deepfake slop.“This website is the most important thing that anyone will read about AI in this millenium or the next,” said CAAAC cofounder Louis Barclay, staying in character when talking to The Verge. (The second founder of CAAAC wished to remain anonymous, according to Barclay.)CAAAC’s vibe is so similar to AI alignment research labs — who are featured on the website’s homepage with working links to their own websites — that even those in the know initially thought it was real, including Kendra Albert, a machine learning researcher and technology attorney, who spoke with The Verge.CAAAC makes fun of the trend, according to Albert, of those who want to make AI safe drifting away from the “real problems happening in the real world” — such as bias in models, exacerbating the energy crisis, or replacing workers — to the “very, very theoretical” risks of AI taking over the world, Albert said in an interview with The Verge.To fix the “AI alignment alignment crisis,” CAAAC will be recruiting its global workforce exclusively from the Bay Area. All are welcome to apply, “as long as you believe AGI will annihilate all humans in the next six months,” according to the jobs page.Those who are willing to take the dive to work with CAAAC — the website urges all readers to bring their own wet gear — need only comment on the LinkedIn post announcing the center to automatically become a fellow. CAAAC also offers a generative AI tool to create your own AI center, complete with an executive director, in “less than a minute, zero AI knowledge required.”The more ambitious job seeker applying to the “AI Alignment Alignment Alignment Researcher” position will, after clicking through the website, eventually find themselves serenaded by Rick Astley’s “Never Gonna Give You Up.”0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Elissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsTechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechMost PopularMost PopularApple’s iPhone 17 Pro can be easily scratchedDropout’s Sam Reich on business, comedy, and keeping the internet weirdWhy your next car should be an electric cargo bikeVideoThe Steam Deck LCD is 20 percent off through October 6thJimmy Kimmel’s show will return after censorship outrageThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in AIThe AI-energy apocalypse might be a little overblownA ‘global call for AI red lines’ sounds the alarm about the lack of international AI policyNvidia is partnering up with OpenAI to offer compute and cashTCL’s Google TVs with an mmWave presence sensor are out nowRecord labels claim AI generator Suno illegally ripped their songs from YouTubeWindows 11 is adding another Copilot button nobody asked forThe AI-energy apocalypse might be a little overblownJustine CalmaSep 22A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policyHayden Field and Elissa WelleSep 22Nvidia is partnering up with OpenAI to offer compute and cashHayden FieldSep 22TCL’s Google TVs with an mmWave presence sensor are out nowJay PetersSep 22Record labels claim AI generator Suno illegally ripped their songs from YouTubeJess WeatherbedSep 22Windows 11 is adding another Copilot button nobody asked forTerrence O'BrienSep 19Advertiser Content FromThis is the title for the native adTop StoriesTwo hours agoGoogle begins its battle for the ‘unofficial currency of the internet’Two hours agoWe’re living in a golden age of affordable mechanical keyboardsTwo hours agoFall into smarter lightingSep 22The AI-energy apocalypse might be a little overblownSep 22This is part of Disney’s legacy nowSep 22TikTok is tagging videos from Gaza with TikTok Shop productsThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved