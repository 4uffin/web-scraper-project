Aligning those who align AI, one satirical website at a time | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.Aligning those who align AI, one satirical website at a timeComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...AICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsTechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechAligning those who align AI, one satirical website at a timeA new center uses humor to point out the tangled web of those focused on making AI safe with AI companies themselves. A new center uses humor to point out the tangled web of those focused on making AI safe with AI companies themselves. by
Elissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleSep 11, 2025, 8:24 PM UTCLinkFacebookThreadsComments0CommentsImage: Cath Virginia / The Verge, Getty ImagesElissa WelleCloseElissa WellePosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa Welle is a NYC-based AI reporter and is currently supported by the Tarbell Center for AI Journalism. She covers AI companies, policies, and products.The work of creating artificial intelligence that holds to the guardrails of human values, known in the industry as alignment, has developed into its own (somewhat ambiguous) field of study rife with policy papers and benchmarks to rank models against each other.But who aligns the alignment researchers?Enter the Center for the Alignment of AI Alignment Centers, an organization purporting to coordinate thousands of AI alignment researchers into “one final AI center singularity.”At first glance, CAAAC seems legitimate. The aesthetics of the website are cool and calming, with a logo of converging arrows reminiscent of the idea of togetherness and sets of parallel lines swirling behind black font.But stay on the page for 30 seconds and the swirls spell out “bullshit,” giving away that CAAAC is all one big joke. One second longer and you’ll notice the hidden gems tucked away in every sentence and page of the fantasy center’s website.CAAAC launched Tuesday from the same team that brought us The Box, a literal, physical box that women can wear on dates to avoid the threat of their image being turned into AI-generated deepfake slop.“This website is the most important thing that anyone will read about AI in this millenium or the next,” said CAAAC cofounder Louis Barclay, staying in character when talking to The Verge. (The second founder of CAAAC wished to remain anonymous, according to Barclay.)CAAAC’s vibe is so similar to AI alignment research labs — who are featured on the website’s homepage with working links to their own websites — that even those in the know initially thought it was real, including Kendra Albert, a machine learning researcher and technology attorney, who spoke with The Verge.CAAAC makes fun of the trend, according to Albert, of those who want to make AI safe drifting away from the “real problems happening in the real world” — such as bias in models, exacerbating the energy crisis, or replacing workers — to the “very, very theoretical” risks of AI taking over the world, Albert said in an interview with The Verge.To fix the “AI alignment alignment crisis,” CAAAC will be recruiting its global workforce exclusively from the Bay Area. All are welcome to apply, “as long as you believe AGI will annihilate all humans in the next six months,” according to the jobs page.Those who are willing to take the dive to work with CAAAC — the website urges all readers to bring their own wet gear — need only comment on the LinkedIn post announcing the center to automatically become a fellow. CAAAC also offers a generative AI tool to create your own AI center, complete with an executive director, in “less than a minute, zero AI knowledge required.”The more ambitious job seeker applying to the “AI Alignment Alignment Alignment Researcher” position will, after clicking through the website, eventually find themselves serenaded by Rick Astley’s “Never Gonna Give You Up.”0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Elissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsTechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechMost PopularMost PopularNest is dead, long live Google HomeI know why Mark Zuckerberg risked live demo failureFirst look at the Google Home app powered by GeminiAnker’s recent power bank recall involves over 481,000 unitsHere’s the Jimmy Kimmel clip that got him pulled off the airThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in AIWindows 11 is adding another Copilot button nobody asked forOpenAI might be developing a smart speaker, glasses, voice recorder, and a pinFirst look at the Google Home app powered by GeminiChatGPT tricked to swipe sensitive data from GmailMeta’s failed smart glasses demos had nothing to do with the Wi-FiNotion’s new AI Agents will basically do your job for youWindows 11 is adding another Copilot button nobody asked forTerrence O'BrienSep 19OpenAI might be developing a smart speaker, glasses, voice recorder, and a pinJess WeatherbedSep 19First look at the Google Home app powered by GeminiJennifer Pattison TuohySep 19ChatGPT tricked to swipe sensitive data from GmailRobert HartSep 19Meta’s failed smart glasses demos had nothing to do with the Wi-FiJess WeatherbedSep 19Notion’s new AI Agents will basically do your job for youElissa WelleSep 18Advertiser Content FromThis is the title for the native adTop StoriesSep 20Republicans’ political purge is just getting startedSep 20Trump announces H-1B skilled worker visas will now cost $100,000Sep 20An ICE raid at an EV factory raises fears about US instabilitySep 20The US government is taking a second stab at breaking up GoogleSep 20Henry Halfhead is full of heartSep 19How I went from an e-bike hater to a believerThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved