A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policy | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policyComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...AICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsPolicyClosePolicyPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PolicyA ‘global call for AI red lines’ sounds the alarm about the lack of international AI policy﻿Signatories included an OpenAI co-founder, Anthropic’s CISO, and Nobel laureate Geoffrey Hinton.﻿Signatories included an OpenAI co-founder, Anthropic’s CISO, and Nobel laureate Geoffrey Hinton.by
Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden Field and
Elissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleSep 22, 2025, 6:33 PM UTCLinkFacebookThreadsComments0CommentsPhoto by Amelia Holowaty Krales / The VergeOn Monday, more than 200 former heads of state, diplomats, Nobel laureates, AI leaders, scientists, and others all agreed on one thing: There should be an international agreement on “red lines” that AI should never cross — for instance, not allowing AI to impersonate a human being or self-replicate.They, along with more than 70 organizations that address AI, have all signed the Global Call for AI Red Lines initiative, a call for governments to reach an “international political agreement on ‘red lines’ for AI by the end of 2026.” Signatories include British Canadian computer scientist Geoffrey Hinton, OpenAI cofounder Wojciech Zaremba, Anthropic CISO Jason Clinton, Google DeepMind research scientist Ian Goodfellow, and others.“The goal is not to react after a major incident occurs… but to prevent large-scale, potentially irreversible risks before they happen,” Charbel-Raphaël Segerie, executive director of the French Center for AI Safety (CeSIA), said during a Monday briefing with reporters.He added, “If nations cannot yet agree on what they want to do with AI, they must at least agree on what AI must never do.”The announcement comes ahead of the 80th United Nations General Assembly high-level week in New York, and the initiative was led by CeSIA, the Future Society, and UC Berkeley’s Center for Human-Compatible Artificial Intelligence.Nobel Peace Prize laureate Maria Ressa mentioned the initiative during her opening remarks at the assembly when calling for efforts to “end Big Tech impunity through global accountability.”Some regional AI red lines do exist. For example, the European Union’s AI Act that bans some uses of AI deemed “unacceptable” within the EU. There is also an agreement between the US and China that nuclear weapons should stay under human, not AI, control. But there is not yet a global consensus.In the long term, more is needed than “voluntary pledges,” Niki Iliadis, director for global governance of AI at The Future Society, said to reporters on Monday. Responsible scaling policies made within AI companies “fall short for real enforcement.” Eventually, an independent global institution “with teeth” is needed to define, monitor, and enforce the red lines, she said.“They can comply by not building AGI until they know how to make it safe,” Stuart Russell, a professor of computer science at UC Berkeley and a leading AI researcher, said during the briefing. “Just as nuclear power developers did not build nuclear plants until they had some idea how to stop them from exploding, the AI industry must choose a different technology path, one that builds in safety from the beginning, and we must know that they are doing it.”Red lines do not impede economic development or innovation, as some critics of AI regulation argue, Russell said. ”You can have AI for economic development without having AGI that we don’t know how to control,” he said. “This supposed dichotomy, if you want medical diagnosis then you have to accept world-destroying AGI — I just think it’s nonsense.”0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden FieldElissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AIAnthropicCloseAnthropicPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AnthropicNewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsOpenAICloseOpenAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All OpenAIPolicyClosePolicyPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PolicyMost PopularMost PopularApple’s iPhone 17 Pro can be easily scratchedWhy your outdoorsy friend suddenly has a gummy bear power bankWhy PlayStation and Xbox are no longer about the station or the boxAmazon, Google, and Microsoft warn employees to rush back to the USThe foldable iPhone might look like two iPhone Airs stuck togetherThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in AINvidia is partnering up with OpenAI to offer compute and cashTCL’s Google TVs with an mmWave presence sensor are out nowRecord labels claim AI generator Suno illegally ripped their songs from YouTubeWindows 11 is adding another Copilot button nobody asked forOpenAI might be developing a smart speaker, glasses, voice recorder, and a pinFirst look at the Google Home app powered by GeminiNvidia is partnering up with OpenAI to offer compute and cashHayden FieldSep 22TCL’s Google TVs with an mmWave presence sensor are out nowJay PetersSep 22Record labels claim AI generator Suno illegally ripped their songs from YouTubeJess WeatherbedSep 22Windows 11 is adding another Copilot button nobody asked forTerrence O'BrienSep 19OpenAI might be developing a smart speaker, glasses, voice recorder, and a pinJess WeatherbedSep 19First look at the Google Home app powered by GeminiJennifer Pattison TuohySep 19Advertiser Content FromThis is the title for the native adTop StoriesSep 22Jimmy Kimmel’s show will return after censorship outrageTwo hours agoThe AI-energy apocalypse might be a little overblownSep 22This is part of Disney’s legacy nowSep 22Why your next car should be an electric cargo bike﻿VideoSep 22Waiting to buy a game console will cost youSep 22TikTok is tagging videos from Gaza with TikTok Shop productsThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved