A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policy | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.A ‘global call for AI red lines’ sounds the alarm about the lack of international AI policyComments DrawerCommentsLoading commentsGetting the conversation ready...AICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsPolicyClosePolicyPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PolicyA ‘global call for AI red lines’ sounds the alarm about the lack of international AI policy﻿Signatories included an OpenAI co-founder, Anthropic’s CISO, and Nobel laureate Geoffrey Hinton.﻿Signatories included an OpenAI co-founder, Anthropic’s CISO, and Nobel laureate Geoffrey Hinton.by
Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden Field and
Elissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleSep 22, 2025, 6:33 PM UTCLinkFacebookThreadsPhoto by Amelia Holowaty Krales / The VergeOn Monday, more than 200 former heads of state, diplomats, Nobel laureates, AI leaders, scientists, and others all agreed on one thing: There should be an international agreement on “red lines” that AI should never cross — for instance, not allowing AI to impersonate a human being or self-replicate.They, along with more than 70 organizations that address AI, have all signed the Global Call for AI Red Lines initiative, a call for governments to reach an “international political agreement on ‘red lines’ for AI by the end of 2026.” Signatories include British Canadian computer scientist Geoffrey Hinton, OpenAI cofounder Wojciech Zaremba, Anthropic CISO Jason Clinton, Google DeepMind research scientist Ian Goodfellow, and others.“The goal is not to react after a major incident occurs… but to prevent large-scale, potentially irreversible risks before they happen,” Charbel-Raphaël Segerie, executive director of the French Center for AI Safety (CeSIA), said during a Monday briefing with reporters.He added, “If nations cannot yet agree on what they want to do with AI, they must at least agree on what AI must never do.”The announcement comes ahead of the 80th United Nations General Assembly high-level week in New York, and the initiative was led by CeSIA, the Future Society, and UC Berkeley’s Center for Human-Compatible Artificial Intelligence.Nobel Peace Prize laureate Maria Ressa mentioned the initiative during her opening remarks at the assembly when calling for efforts to “end Big Tech impunity through global accountability.”Some regional AI red lines do exist. For example, the European Union’s AI Act that bans some uses of AI deemed “unacceptable” within the EU. There is also an agreement between the US and China that nuclear weapons should stay under human, not AI, control. But there is not yet a global consensus.In the long term, more is needed than “voluntary pledges,” Niki Iliadis, director for global governance of AI at The Future Society, said to reporters on Monday. Responsible scaling policies made within AI companies “fall short for real enforcement.” Eventually, an independent global institution “with teeth” is needed to define, monitor, and enforce the red lines, she said.“They can comply by not building AGI until they know how to make it safe,” Stuart Russell, a professor of computer science at UC Berkeley and a leading AI researcher, said during the briefing. “Just as nuclear power developers did not build nuclear plants until they had some idea how to stop them from exploding, the AI industry must choose a different technology path, one that builds in safety from the beginning, and we must know that they are doing it.”Red lines do not impede economic development or innovation, as some critics of AI regulation argue, Russell said. ”You can have AI for economic development without having AGI that we don’t know how to control,” he said. “This supposed dichotomy, if you want medical diagnosis then you have to accept world-destroying AGI — I just think it’s nonsense.”Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Hayden FieldCloseHayden FieldSenior AI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Hayden FieldElissa WelleCloseElissa WelleAI ReporterPosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AIAnthropicCloseAnthropicPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AnthropicNewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsOpenAICloseOpenAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All OpenAIPolicyClosePolicyPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All PolicyMost PopularMost PopularXiaomi 17 series arrives with secondary screens and enormous batteriesForza Horizon 6 is set in Japan and arrives in 2026Google reveals its Android for PC is coming next yearLogitech’s new light-powered keyboard doesn’t even need the sunGoogle’s Android for PC: ‘I’ve seen it, it is incredible’The Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in AIMicrosoft says this new cooling method could enable more powerful chips and efficient data centersGemini now explains why your Sheets formula failedWhat happens when an AI-generated artist gets a record deal? A copyright messOpenAI really, really wants you to start your day with ChatGPT PulseGoogle DeepMind’s new AI models can search the web to help robots complete tasksHow AI safety took a backseat to military moneyMicrosoft says this new cooling method could enable more powerful chips and efficient data centersJustine CalmaSep 25Gemini now explains why your Sheets formula failedElissa WelleSep 25What happens when an AI-generated artist gets a record deal? A copyright messElissa WelleSep 25OpenAI really, really wants you to start your day with ChatGPT PulseHayden FieldSep 25Google DeepMind’s new AI models can search the web to help robots complete tasksEmma RothSep 25How AI safety took a backseat to military moneyHayden FieldSep 25Advertiser Content FromThis is the title for the native adTop StoriesSep 25OpenAI really, really wants you to start your day with ChatGPT PulseSep 25Trump signs ‘Saving TikTok’ order to start resolving its big ban problemSep 25Silicon Valley’s latest argument against regulating AI: that would literally be the AntichristSep 25Ghost of Yōtei is exactly the kind of game PlayStation needsSep 25Microsoft says this new cooling method could enable more powerful chips and efficient data centersSep 25What happens when an AI-generated artist gets a record deal? A copyright messThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved