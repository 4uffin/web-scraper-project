System Performance ¬∑ GitHub
Skip to content
Search Gists
Search Gists
All gists
Back to GitHub
Sign in
Sign up
Sign¬†in
Sign¬†up
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
Dismiss alert
Instantly share code, notes, and snippets.
hieunt79/02-system_performance_02_methodology.md
Last active
September 17, 2025 10:16
Show Gist options
Download ZIP
Star
2
(2)
You must be signed in to star a gist
Fork
0
(0)
You must be signed in to fork a gist
Embed
Embed
Embed this gist in your website.
Share
Copy sharable link for this gist.
Clone via HTTPS
Clone using the web URL.
Learn more about clone URLs
Clone this repository at &lt;script src=&quot;https://gist.github.com/hieunt79/0fba98c39d3f3db52958dc31a0620b92.js&quot;&gt;&lt;/script&gt;
Save hieunt79/0fba98c39d3f3db52958dc31a0620b92 to your computer and use it in GitHub Desktop.
Code
Revisions
28
Stars
2
Embed
Embed
Embed this gist in your website.
Share
Copy sharable link for this gist.
Clone via HTTPS
Clone using the web URL.
Learn more about clone URLs
Clone this repository at &lt;script src=&quot;https://gist.github.com/hieunt79/0fba98c39d3f3db52958dc31a0620b92.js&quot;&gt;&lt;/script&gt;
Save hieunt79/0fba98c39d3f3db52958dc31a0620b92 to your computer and use it in GitHub Desktop.
Download ZIP
System Performance
Raw
02-system_performance_02_methodology.md
2. System Performance: Methodologies
2.1 Terminology
IOPS: Input/output operations per second is a measure of the rate of data transfer operations. For disk I/O, IOPS refers to reads and writes per second.
Throughput: The rate of work performed. Especially in communications, the term is used to refer to the data rate (bytes per second or bits per second). In some contexts (e.g., databases) throughput can refer to the operation rate (operations per second or transactions per second).
Response time: The time for an operation to complete. This includes any time spent waiting and time spent being serviced (service time), including the time to transfer the result.
latency: A measure of time an operation waiting to be serviced. In some contexts, it can refers to the entire time for an operation, equivalent to response time.
Utilization: v·ªõi c√°c resource cung c·∫•p theo ki·ªÉu request, ƒë√¢y l√† c√°ch ƒëo l∆∞·ªùng cho m·ª©c ƒë·ªô resource ƒëc s·ª≠ d·ª•ng (how busy a resource is), d·ª±a tr√™n th·ªùi gian s·ª≠ d·ª•ng chia cho th·ªùi gian l·∫•y m·∫´u. C√≤n v·ªõi resource cung c·∫•p storage, utilization l√† l∆∞·ª£ng capacity ƒë√£ d√πng.
Saturation: M·ª©c ƒë·ªô m√† resource ph·∫£i ƒë∆∞a c√°c request v√†o queue v√¨ ko x·ª≠ l√Ω k·ªãp
Bottleneck: Trong system performance (SP), c√°i n√†y l√† resource m√† l√†m gi·ªõi h·∫°n SP c·ªßa c·∫£ h·ªá th·ªëng. Ph√°t hi·ªán v√† x·ª≠ l√Ω bottleneck l√† ho·∫°t ƒë·ªông ch√≠nh c·ªßa SP.
Workload: ƒê·∫ßu v√†o c·ªßa system, c√°i m√† system x·ª≠ l√Ω.
Cache: M·ªôt khu v·ª±c l∆∞u tr·ªØ t·ªëc ƒë·ªô cao, l∆∞u tr·ªØ data ƒë·ªÉ tr√°nh vi·ªác ph·∫£i g·ªçi t·ªõi nh·ªØng t·∫ßng ch·∫≠m h∆°n, ƒë·ªÉ tƒÉng hi·ªáu nƒÉng
2.3 Concepts
2.3.1 latency
The latency is the tiem spent waiting before an operation is performed.
Performance issues can be quantified using latency and then ranked because they are expressed using the same units (times). T·ª´ ƒë√≥ ƒë√°nh gi√° xem vi·ªác t·ªëi ∆∞u c√≥ ok kh√¥ng, b·∫±ng c√°ch xem x√©t latency tƒÉng l√™n hay gi·∫£m xu·ªëng. Vi·ªác ƒë√°nh gi√° n√†y kh√≥ m√† l√†m ƒëc v·ªõi c√°c th√¥ng s·ªë kh√°c, vd nh∆∞ IOPS metrics.
Khi c√≥ th·ªÉ, hay convert c√°c metric types kh√°c v·ªÅ latency ƒë·ªÉ cho ph√©p so s√°nh. V√≠ d·ª•: n·∫øu ph·∫£i ch·ªçn gi·ªØa 100 network I/O hay 50 disk I/O, ta n√™n ch·ªçn c√°i n√†o? Nh∆∞ng n·∫øu so s√°nh gi·ªØa 100ms network I/O v√† 50ms disk I/O, s·ª± kh√°c bi·ªát l√† r√µ.
2.3.2 Time scales
V√¨ th·ªùi gian ƒëo ƒëc, so s√°nh ƒëc, n√≥ gi√∫p ta c·∫£m nh·∫≠n ƒëc th·ªùi gian (d·ªãch h∆°i ngu t·ª´ "to have an instinct about time"), v√† c√≥ k√¨ v·ªçng ph√π h·ª£p cho latency cho c√°c jobs kh√°c nhau c·ªßa h·ªá th·ªëng
2.3.3 Trade-offs
Ta c·∫ßn bi·∫øt m·ªôt v√†i trade-offs ph·ªï bi·∫øn (c√°c t·∫≠p ti√™u ch√≠ m√† ta ch·ªâ ch·ªçn ƒëc 2/3):
Good / fast / cheap
High performance/ On-time / Inexpensive
C√≥ nh·ªØng ti√™u ch√≠ m√† khi s·ª≠a, ta s·∫Ω ƒë∆∞·ª£c c√°i n√†y m√† m·∫•t c√°i kia, kh√≥ m√† v·∫πn c·∫£ ƒë√¥i ƒë∆∞·ªùng. M·ªôt v√†i v√≠ d·ª•:
File system record size (or block size): Small record sizes, close to the application I/O, gi√∫p random I/O workloads ngon h∆°n, file system cache ƒëc d√πng hi·ªáu qu·∫£ h∆°n (·ª©ng d·ª•ng ch·∫°y ngon h∆°n). Large record will improve streaming workload, including file system backups.
Network buffer size: Small buffer will reduce the the memory overhead per connection, helping the system scale. Large sizes will improve network throughput
2.3.4 Tuning Efforts
Vi·ªác tuning hi·ªáu qu·∫£ nh·∫•t khi ƒë∆∞·ª£c th·ª±c hi·ªán c√†ng g·∫ßn ch·ªó
"the work is performed". Nghƒ©a l√† sao, l·∫•y m·ªôt v√†i v√≠ d·ª• cho d·ªÖ hi·ªÉu:
Layer
Example Tuning Targets
Application
Application logic, request queue sizes, database queries performed
Database
Database table layout, indexes, buffering
System
calls Memory-mapped or read/write, sync or async I/O flags
File
system Record size, cache size, file system tunables, journaling
Storage
RAID level, number and type of disks, storage tunables
V√¨ h·ªá th·ªëng th∆∞·ªùng l√† ƒë·ªÉ cho application ch·∫°y tr√™n ƒë√≥, t·∫≠p trung ph·∫ßn n√†y th∆∞·ªùng mang l·∫°i big wins. Ngo√†i vi·ªác t·ªëi ∆∞u db query, queue, th√¨ vi·ªác ph√°t tri·ªÉn nhanh ch·ªâ ch√∫ √Ω t·ªõi s·ª± ch√≠nh x√°c, khi n√†o c√≥ problem performance th√¨ m·ªõi quay qua fix.
M·ªôt ch√∫ √Ω nh·ªè, vi·ªác quan s√°t ·ªü OS-level c≈©ng gi√∫p nh√¨n ra v·∫•n ƒë·ªÅ ·ªü t·∫ßng application.
2.3.5 Level of Appropriateness
C√†i n√†y l√† s·ª± ph√π h·ª£p, m·ªói t·ªï ch·ª©c hay m√¥i tr∆∞·ªùng c√≥ m·ªôt y√™u c·∫ßu ri√™ng v·ªÅ performance. Ti√™u ch√≠ c·∫ßn ph·∫£i c√≥ ·ªü t·ªï ch·ª©c n√†y c√≥ th·ªÉ kh√¥ng c·∫ßn ·ªü t·ªï ch·ª©c kh√°c, n√≥ kh√¥ng ph·∫£i ƒë√∫ng ho·∫∑c sai m√† ph·ª• thu·ªôc v√†o ROI (return on investment).
Tuy nhi√™n, system performance kh√¥ng ph·∫£i ch·ªâ m·ªói li√™n quan t·ªõi cost, n√≥ c√≤n c√≥ end-user experience. N·∫øu tr·∫£i nghi·ªám kh√°ch h√†ng t·ªá qu√° th√¨ ko hay, n√≥ c≈©ng s·∫Ω ·∫£nh h∆∞·ªüng doanh thu.
Khi th·ª±c hi·ªán ph√¢n t√≠ch performance, c√°i g·ªçi l√† level of appropriateness comes in to play in deciding when to stop analysis.
2.3.6 When to Stop Analysis
When doing performance analysis, ta c·∫ßn bi·∫øt ƒë√¢u n√™n l√† ƒëi·ªÉm d·ª´ng. C√≥ m·ªôt v√†i vd:
Khi ta ƒë√£ gi·∫£i th√≠ch ƒëc kh√° nhi·ªÅu, ph·∫ßn l·ªõn v·∫•n ƒë·ªÅ v·ªÅ performance
Khi potential ROI nh·ªè h∆°n nhi·ªÅu so v·ªõi cost for analysis
Khi bi·∫øt m·ªôt c√°i kh√°c c√≥ th·ªÉ mang l·∫°i nhi·ªÅu gi√° tr·ªã h∆°n
Khi l√† performance engineer, ƒë√°nh gi√° ∆∞u ti√™n cho c√°c v·∫•n ƒë·ªÅ kh√°c nhau ƒë·ªÉ th·ª±c hi·ªán l√† m·ªôt nhi·ªám v·ª• quan tr·ªçng
2.3.7 Point-in-Time Recommendations
C√°c t√≠nh ch·∫•t c·ªßa h·ªá th·ªëng thay ƒë·ªïi theo th·ªùi gian (th√™m user / ph·∫ßn c·ª©ng m·ªõi / updated software). V√¨ v·∫≠y c√°c th√¥ng s·ªë c√≥ th·ªÉ oke t·∫°i m·ªôt th·ªùi ƒëi·ªÉm nh∆∞ng c√≥ th·ªÉ
tr·ªü th√†nh ngh·∫Ωn t·∫°i m·ªôt th·ªùi ƒëi·ªÉm kh√°c.
Khi thay ƒë·ªïi m·ªôt th·ª© g√¨ ƒë√≥, n√™n l∆∞u l·∫°i ƒë·ªÉ xem x√©t sau n√†y. Kh√° l√† ·ªïn khi l∆∞u l·∫°i tr√™n version control system v·ªõi ch√∫ th√≠ch r√µ r√†ng. Ngo√†i ra c√≥ th·ªÉ d√πng c√°c configuration management tools (vd Puppet, Salt, Chef ...)
2.3.8 Load vs. Architecture
·ª®ng d·ª•ng ch·∫°y ngon hay kh√¥ng c√≥ th·ªÉ do architecture ho·∫∑c implementation. Ho·∫∑c c≈©ng c√≥ th·ªÉ do l∆∞·ª£ng t·∫£i ch·∫°y v√†o h·ªá th·ªëng.
T√∫m l·∫°i, c·∫ßn ph·∫£i test t·∫£i cho h·ªá th·ªëng, ƒë·ªÉ
xem h·ªá th·ªëng h√†nh x·ª≠ ntn.
2.3.9 Scalability
Bi·ªÉu ƒë·ªì hi·ªáu nƒÉng c·ªßa h·ªá th·ªëng khi tƒÉng d·∫ßn t·∫£i g·ªçi l√† scalability. ƒêo·∫°n ƒë·∫ßu th√¨ l√† linear nh∆∞ng khi knee point is reached, kh·∫£ nƒÉng x·ª≠ l√Ω gi·∫£m xu·ªëng (thoughput)
ƒêi·ªÉm knee point n√†y x·∫£y ra khi m·ªôt th√†nh ph·∫ßn n√†o ƒë√≥ ƒë·∫°t t·ªõi 100% utilization: the saturation point. Th√†nh ph·∫ßn ƒë√≥ ƒë·∫°t 100% utilization v√† queue c·ªßa th√†nh ph·∫ßn n√†y b·∫Øt ƒë·∫ßu xu·∫•t hi·ªán th∆∞·ªùng xuy√™n v√† d√†i h∆°n.
C√≥ nh·ªØng th√†nh ph·∫ßn m√† khi h·∫øt utilization s·∫Ω l√†m h·ªá th·ªëng "ch·∫≠m" nhanh h∆°n, vd memory ho·∫∑c disk I/O, c≈©ng c√≥ nh·ªØng c√°i m√† khi n√≥ h·∫øt th√¨ h·ªá th·ªëng "ch·∫≠m" ch·∫≠m h∆°n x√≠u, vd CPU utilization.
H·ªá th·ªëng c≈©ng c√≥ th·ªÉ tr√°nh vi·ªác ch·∫≠m ƒëi b·∫±ng c√°ch t·ª´ ch·ªëi ph·ª•c v·ª• khi h·∫øt kh·∫£ nƒÉng x·ª≠ l√Ω. VD: return 503 Service Unavailable.
2.3.10 Performance metrics
L√† nh·ªØng th√¥ng s·ªë ƒë∆∞·ª£c nghi√™n c·ª©u v√† thu th·∫≠p cho vi·ªác performance analysis v√† monitor. M·ªôt v√†i th√¥ng s·ªë c∆° b·∫£n:
Throughput: Either operations or data volume per second. L√† operation n·∫øu ƒë·ªÉ ƒëo database throughput, l√† volume per second n·∫øu l√† network.
IOPS: I/O operations per second
Utilization: How busy a resource is, as a percentage
Latency: Operation time, as an average or percentile
Overhead
Metrics are not free, c≈©ng ph·∫£i d√†nh t√†i nguy√™n ƒë·ªÉ thu th·∫≠p t√≠nh to√°n.
Issues
N√™n nh·ªõ, metrics ƒëc cung c·∫•p c√≥ th·ªÉ ƒë√∫ng, c√≥ th·ªÉ sai, th∆∞·ªùng l√† ph·ª©c t·∫°p v√† thi·∫øu t√†i li·ªáu m√¥ t·∫£, th·∫≠m ch√≠ c√≥ bug.
2.3.11 Utilization
Time-based
Time-based Utilization: th·ªùi gian m√† thi·∫øt b·ªã ƒë∆∞·ª£c s·ª≠ d·ª•ng, ƒëc t√≠nh theo c√¥ng th·ª©c U=B/T v·ªõi U l√† utilization, B t·ªïng th·ªùi gian m√† thi·∫øt b·ªã ƒëc s·ª≠ d·ª•ng, T l√† th·ªùi gian quan s√°t.
Th∆∞·ªùng th√¨ khi ƒë·∫°t 100% utilization th√¨ hi·ªáu nƒÉng s·∫Ω gi·∫£m ƒë√°ng k·ªÉ. Tuy nhi√™n c≈©ng c√≥ nh·ªØng thi·∫øt b·ªã m√† ko b·ªã degrade nh∆∞ th·∫ø v√¨ n√≥ c√≥ th·ªÉ x·ª≠ l√Ω song song.
Capacity-based
M·ªôt c√°ch kh√°c hi·ªÉu kh√°c cho utilization l√† √°m ch·ªâ capacity thay v√¨ time. N·∫øu ƒë·∫ßy 100% th√¨ coi nh∆∞ kh√¥ng ti·∫øp nh·∫≠n x·ª≠ l√Ω ƒëc th√™m n·ªØa. V√≠ d·ª• cho tr∆∞·ªùng h·ª£p n√†y l√† memory ho·∫∑c storage capacity.
2.3.12 Saturation
M·ª©c ƒë·ªô m√† resource kh√¥ng x·ª≠ l√Ω th√™m ƒë∆∞·ª£c n·ªØa ƒë∆∞·ª£c g·ªçi l√† saturation. V·ªõi capacity based, 100% utilization s·∫Ω l√† b·∫Øt ƒë·∫ßu saturation, c√≤n v·ªõi time-based th√¨ ch∆∞a ch·∫Øc, v√¨ c√≤n t√πy thu·ªôc v√†o kh·∫£ nƒÉng x·ª≠ l√Ω song song c·ªßa n√≥.
M·ªçi c√°i saturation l√† m·ªôt c√°i performance issue, l√† m·ªôt c√°i tƒÉng latency, c·∫ßn ph·∫£i ƒëc x·ª≠ l√Ω
2.3.13 Profiling
Profiling cho ta m·ªôt g√≥c nh√¨n t·ªïng qu√°t v·ªÅ h·ªá th·ªëng, cho ph√©p nghi√™n c·ª©u, ph√¢n t√≠ch t∆∞∆°ng quan gi·ªØa c√°c th√†nh ph·∫ßn?
2.3.14 Caching
Caching ƒë∆∞·ª£c d√πng ƒë·ªÉ c·∫£i thi·ªán performance. Cache l√† l∆∞u tr·ªØ k·∫øt qu·∫£ t·ª´ m·ªôt t·∫ßng storage ch·∫≠m ·ªü t·∫ßng storage nhanh h∆°n, vd cache disk blocks in RAM.
Nhi·ªÅu t·∫ßng cache c√≥ th·ªÉ ƒëc d√πng c√πng l√∫c, vd CPU c√≥ nhi·ªÅu cache layer.
M·ªôt th√¥ng s·ªë c≈©ng kh√° quan tr·ªçng l√† cache's hit ratio: hit ratio = hits / (hits + misses)
Hit ratio n√†y c√†ng cao c√†ng t·ªët v√† s·ª± tƒÉng c·ªßa 98% l√™n 99% c√≥ √Ω nghƒ©a v·ªÅ performance nhi·ªÅu h∆°n l√† t·ª´ 10% l√™n 11%. Tuy nhi√™n, vi·ªác so s√°nh cache hits rate c·ªßa hai service ch∆∞a ch·∫Øc l√† oke, v√¨ c√≥ th·ªÉ service A c√≥ hits rate l·ªõn (vd 90%) l·∫°i c√≥ s·ªë l∆∞·ª£ng miss rate nhi·ªÅu (200/s)
Algorithms
Cache management algorithms v√† policies l√† c√°ch ƒë·ªÉ x√°c ƒë·ªãnh xem cache l·∫°i th√¥ng tin ntn.
Hot, cold, warm caches
C√°c t·ª´ tr√™n l√† ƒë·ªÉ mi√™u t·∫£ tr·∫°ng th√°i c·ªßa cache:
Cold: l√† khi cache tr·ªëng, to√†n c√°c th√¥ng tin r√°c. Hit ratio c·ªßa cold cache l√† 0. ƒê√¢y l√† khi cache m·ªõi ch·∫°y, g·∫ßn warm up.
Warm: ƒë√£ c√≥ useful data nh∆∞ng hit rate ch∆∞a ƒë·ªß cao ƒë·ªÉ ƒë∆∞·ª£c coi l√† hot
Hot: c√≥ t·ªâ l·ªá hit rate cao, vd: h∆°n 99%
Warmth: cache warmth mi√™u t·∫£ m·ª©c ƒë·ªô hot warm c·ªßa cache. Vi·ªác improve cache warmth l√† tƒÉng hit ratio.
Khi cache m·ªõi ch·∫°y n√≥ s·∫Ω c·∫ßn th·ªùi gian ƒë·ªÉ warm up. Khi m√† cache c√≥ k√≠ch th∆∞·ªõc l·ªõn, ho·∫∑c storage c√≥ t·ªëc ƒë·ªô ƒë·ªçc ch·∫≠m, th√¨ s·∫Ω c·∫ßn nhi·ªÅu th·ªùi gian ƒë·ªÉ warm up h∆°n.
2.3.15 Known-Unknowns
Vi·ªác bi·∫øt c√°i g√¨ m√¨nh bi·∫øt - bi·∫øt, bi·∫øt - kh√¥ng bi·∫øt, kh√¥ng bi·∫øt - kh√¥ng bi·∫øt l√† kh√° quan tr·ªçng trong SP.
Trong SP c√≥ r·∫•t nhi·ªÅu th√†nh ph·∫ßn, vi·ªác h·ªçc th√™m, h·ªçc s√¢u v·ªÅ system, s·∫Ω gi√∫p ta bi·∫øn nh·ªØng c√°i kh√¥ng bi·∫øt - kh√¥ng bi·∫øt th√†nh nh·ªØng c√°i bi·∫øt - kh√¥ng bi·∫øt, cu·ªëi c√πng l√† bi·∫øt - bi·∫øt. T·ª´ ƒë·∫•y gi√∫p gi·∫£i quy·∫øt nhi·ªÅu v·∫•n ƒë·ªÅ h∆°n.
C√≥ th·ªÉ ƒë·ªçc th√™m v·ªÅ c√°i n√†y: NƒÉm m·ª©c d·ªët & H√†nh tr√¨nh truy c·∫ßu tri th·ª©c
Perspective
C√≥ hai g√≥c nh√¨n v·ªÅ SP v√† s·∫Ω ƒëi k√®m v·ªõi c√°c th√¥ng s·ªë kh√°c nhau c·ªßa h·ªá th·ªëng:
workload analysis (top-down)
resource analysis (bottom-up)
Raw
03-system_performance_03_operating_system.md
Operating system
Table of contents
3.1 Terminology
3.2 Background
3.2.1 Kernel
3.2.2 Kernel and User modes
3.2.3 System Calls
3.2.4 Interrupts
3.2.5 Clock and Idle
3.2.6 Processes
3.2.7 Stacks
3.2.8 Virtual memory
3.2.9 Schedulers
3.2.10 File systems
3.2.11 Caching
3.2.12 Networking
3.2.13 Device drivers
3.2.14 Multiprocessor
3.2.15 Preemption
3.2.16 Resource management
3.2.17 Observability
3.3 Kernel
3.4 Linux
3.4.1 Linux Kernel Developments
3.4.2 systemd
3.4.4 Extended BPF
3.7 Exercises
Hi·ªÉu v·ªÅ OS v√† kernel l√† r·∫•t c·∫ßn thi·∫øt cho vi·ªác ph√¢n t√≠ch SP. Nhi·ªÅu l√∫c ta c·∫ßn ph·∫£i ph√°t tri·ªÉn v√† test c√°c gi·∫£ thuy·∫øt v·ªÅ h√†nh x·ª≠ c·ªßa h·ªá th·ªëng, vd nh∆∞ system call ƒë∆∞·ª£c th·ª±c hi·ªán nh∆∞ n√†o, kernel schedule thread tr√™n CPU nh∆∞ n√†o... N√≥i chung l√† c·∫ßn ph·∫£i hi·ªÉu v·ªÅ OP v√† kernel.
M·ª•c ti√™u c·ªßa chapter n√†y:
Learn kernel terinology: context switching, swapping, paging, preemption, etc.
Hi·ªÉu vai tr√≤ c·ªßa kernel v√† system call.
Ki·∫øn th·ª©c v·ªÅ b√™n trong c·ªßa kernel: interrupts, schedulers, virtual memory, I/O stack.
See how kernel performance features have been added from Unix to Linux.
Develop a basic understanding of extended BPF.
Ch∆∞∆°ng n√†y c√≥ 3 ph·∫ßn:
Terminology li·ªát k√™ c√°c thu·∫≠t ng·ªØ quan tr·ªçng
Background t·ªïng h·ª£p ƒë·ªãnh nghƒ©a quan tr·ªçng
Kernel t·ªïng h·ª£p c√°c c√°ch tri·ªÉn khai ri√™ng c·ªßa Linux v√† c√°c kernel kh√°c
3.1 Terminology
Operating system: l√† software v√† files ƒë∆∞·ª£c c√†i tr√™n h·ªá th·ªëng ƒë·ªÉ n√≥ boot v√† execute programs. Bao g·ªìm kernel, admin tools, system libraries.
Kernel: l√† ch∆∞∆°ng tr√¨nh qu·∫£n l√Ω h·ªá th·ªëng, bao g·ªìm: hardware devices, memory, CPU scheduling. N√≥ ch·∫°y priviledged CPU mode, ƒëc ph√©p access tr·ª±c ti·∫øp v√†o hardware, called kernel mode
Process: OS abstraction and environment for executing a program. Program ch·∫°y trong user mode v√† access to kernel mode (vd th·ª±c hi·ªán device I/O) th√¥ng qua system calls or trap into the kernel.
Thread: An exceutable context that can be scheduled to run on a CPU. Kernel c√≥ nhi·ªÅu threads v√† m·ªói process ch∆∞a m·ªôt ho·∫∑c nhi·ªÅu thread.
Task: A Linux runable entity, which can refer to a process (with a single thread), a thread from a multithreaded process, or kernel threads.
BPF program: A kernel-mode program running in the BPF execution environment (?????)
Main memory: The physical memory of the system (e.g., RAM).
Virtual memory: An abstraction of main memory that supports multitasking and oversubscription. It is, practically, an infinite resource.
Kernel space: The virtual memory address space for the kernel
User space: The virtual memory address space for processes.
User land: User-level programs and libraries (/usr/bin, /usr/lib)
Context switch: A switch from running one thread or process to another. This is a normal function of the kernel CPU scheduler, and involves switching the set of running CPU registers (the thread context) to a new set.
Mode switch: A switch between kernel and user modes
System call (syscall): A well-defined protocol for user programs to request the kernel to perform privileged operations, including device I/O.
Processor: Not to be confused with process, a processor is a physical chip containing one or more CPU
Trap: A signal sent to the kernel to request a system routine (privileged action). Trap types include system calls, processor exceptions, and interrupts
Hardware interrupt: A signal sent by physical devices to the kernel, usually to request servicing of I/O. An interrupt is a type of trap
3.2 Background
Mi√™u t·∫£ chung v·ªÅ OS v√† kernel
3.2.1 Kernel
Kernel l√† core software c·ªßa OS. What it does depends on the kernel model: Unix-like OS (Linux and BSD) have a monolithic kernel. N√≥ qu·∫£ l√Ω CPU scheduling, memory, file systems, network protocols, and system devices (disk, network interfaces, etc)
(Application (System Libraries (System call (Kernel (Hardware))))
System libraries cung c·∫•p interface d·ªÖ d√†ng h∆°n cho application t∆∞∆°ng t√°c v·ªõi kernel, thay v√¨ ph·∫£i d√πng tr·ª±c ti·∫øp system call.
Th·ª±c ra c√≥ th·ªÉ kh√¥ng c·∫ßn ph·∫£i d√πng System libraries, v√≠ d·ª• Golang runtime c√≥ syscall layer ri√™ng m√† ko c·∫ßn system library, libc.
Kernel Excetion
Kernel th∆∞·ªùng ch·ªâ ch·∫°y theo y√™u c·∫ßu (app call system call), c≈©ng c√≥ nh·ªØng t√°c v·ª• kh√¥ng ph·∫£i l√† system call c·∫ßn ti√™u t·ªën CPU nh∆∞ng kh√¥ng ƒë√°ng k·ªÉ. Workload c·∫ßn th·ª±c hi·ªán I/O th∆∞·ªùng xuy√™n (vd web server), execute mostly in kernel context. Workload that are compute-intensive run in user mode, uninterrupted by the kernel.
Kernel c≈©ng c√≥ th·ªÉ ·∫£nh h∆∞·ªüng t·ªõi performance c·ªßa compute-intensive workload. Vd: ch·ªçn nh·ªØng core c√≥ warmer cache th√¨ t·ªëc ƒë·ªô x·ª≠ l√Ω cao h∆°n.
3.2.2 Kernel and User modes
Kernel runs in a special CPU mode called kernel mode, full access t·ªõi t·∫•t c·∫£ thi·∫øt b·ªã, th·ª±c hi·ªán privileged instuctions.
User programs (processes) run in user mode, v√† request c√°c privileged operations th√¥ng qua kernel via system calls, such as I/O.
V√¨ mode v√† context switches t·ªën m·ªôt ch√∫t t√†i nguy√™n, m·ªôt v√†i c√°ch t·ªëi ∆∞u:
User-mode syscalls: implement some syscalls in a user-mode library alone.
Memory mapping: Used for demand paging, it can also be used for data stores and other I/O, avoiding syscall overhead.
Kernel bypass: Cho ph√©p user-mode programs to access hardware directly, vd DPDK
Kernel-mode applications: vd TUX web server
Kernel and user mode have their own software execution contexts, including a stack and registers. Some processor architectures use a separate address space for the kernel, which mean the mode switch must also change the virtual memory context.
3.2.3 System Calls
Nh∆∞ ƒë√£ bi·∫øt ·ªü tr√™n, system call ƒë·ªÉ y√™u c·∫ßu kernel th·ª±c thi t√°c v·ª•. C√≥ kho·∫£ng v√†i trƒÉm c√°i system call, ƒë∆∞·ª£c docs h√≥a ngon l√†nh v√† ship c√πng v·ªõi OS. System call th∆∞·ªùng √≠t thay ƒë·ªïi interface v√† s·ª≠ d·ª•ng error code ƒë·ªÉ mi√™u t·∫£ l·ªói g·∫∑p ph·∫£i.
M·ªôt v√†i syscall quan tr·ªçng c·∫ßn bi·∫øt:
read(2) Read bytes
write(2) Write bytes
open(2) Open a file
close(2) Close a file
fork(2) Create a new process
clone(2) Create a new process or thread
exec(2) Execute a new program
connect(2) Connect to a network host
accept(2) Accept a network connection
stat(2) Fetch file statistics
ioctl(2) Set I/O properties, or other miscellaneous functions
mmap(2) Map a file to the memory address space
brk(2) Extend the heap pointer
futex(2) Fast user-space mutex
N·∫øu kh√¥ng r√µ v·ªÅ c√°i syscall n√†o th√¨ refer man syscalls
3.2.4 Interrupts
Interrupt l√† t√≠n hi·ªáu (signal) b·∫Øn v√†o processor ƒë·ªÉ cho n√≥ bi·∫øt c√≥ m·ªôt c√°i g√¨ ƒë√≥ x·∫£y ra c·∫ßn ph·∫£i ƒë∆∞·ª£c x·ª≠ l√Ω. Khi nh·∫≠n interrupt, processor s·∫Ω b·∫Øt ƒë·∫ßu enter kernel mode, l∆∞u l·∫°i tr·∫°ng th√°i c·ªßa thread hi·ªán t·∫°i, r·ªìi ch·∫°y m·ªôt c√°i interrupt service routinne (ISR) ƒë·ªÉ x·ª≠ l√Ω c√°i interrupt n√†y.
C√≥ hai lo·∫°i interrupt:
Asynchronous interrupt by external hardware
Synchronous interrupt by software instructions
Asynchronous interrupt
Nh∆∞ ƒë√£ n√≥i ·ªü tr√™n hardware devices g·ª≠i IRQs (interrupt service requests) ƒë·∫øn processor, which arrive asynchronously t·ªõi current running software. VD m·ªôt v√†i c√°i hardware interrupts:
Disk devices g·ª≠i signal l√† ƒë√£ finish m·ªôt disk I/O
Hardware indicating a failure condition
Network interface signal the arrival of a packet
Input devices: keyboard and mouse input
Synchronous interrupt
Synchronous interrupt ƒëc sinh b·ªüi software instructions. C√≥ 3 lo·∫°i software interrupt: traps, exceptions, faults; tuy nhi√™n nh·ªØng kh√°i ni·ªám n√†y l·∫°i c√≥ th·ªÉ ho√°n ƒë·ªïi cho nhau:
Traps:
Exception: m·ªôt ngo·∫°i l·ªá x·∫£y ra (exception), vd: divide by zero.
Fault: A term often used for memory events, such as page faults
V·ªõi nh·ªØng c√°i interrupt n√†y, the responsible software v√† instructions v·∫´n n·∫±m tr√™n CPU.
Interrupt threads
ISRs ƒëc thi·∫øt k·∫ø ƒë·ªÉ x·ª≠ l√Ω nhanh nh·∫•t c√≥ th·ªÉ, gi·∫£m thi·ªÉu t√°c ƒë·ªông c·ªßa vi·ªác interrupt t·ªõi threads ƒëang ch·∫°y. N·∫øu m·ªôt interrupt c·∫ßn ph·∫£i ƒëc x·ª≠ l√Ω nhi·ªÅu h∆°n, n√≥ c√≥ th·ªÉ ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng interrupt thread v√† scheduled ƒë·ªÉ ch·∫°y b·ªüi kernel.
Trong Linux, device drivers chia l√†m 2 n·ª≠a, n·ª≠a tr√™n (top half) x·ª≠ l√Ω interrupt th·∫≠t nhanh, v√† scheduling work xu·ªëng n·ª≠a d∆∞·ªõi (bottom half) ƒë·ªÉ x·ª≠ l√Ω sau. Top half th∆∞·ªùng ch·∫°y ·ªü ch·∫ø ƒë·ªô interrupt-disable mode ƒë·ªÉ tr√¨ ho√£n c√°c interrupt kh√°c. Bottom half can either be tasklet or work queues; the latter are threads that can be scheduled by the kernel and can sleep when necessary.
E.g: Linux network drivers. Top half d√πng ƒë·ªÉ handle IRQs for inbound packet, which call the bottom half to push the packet up the network stack. The bottom half is implemented as a softirq (software interrupt).
Interrupt masking
Some code paths in the kernel cannot be interrupted safely. ƒê·ªÉ tr√°nh nh·ªØng tr∆∞·ªùng h·ª£p n√†y, kernel c√≥ th·ªÉ t·∫°m th·ªùi mask interrupt b·∫±ng c√°ch set CPU's interrupt mask register. Th·ªùi gian interrupt disable time n√™n nh·ªü nh·∫•t c√≥ th·ªÉ.
3.2.5 Clock and Idle
M·ªôt th√†nh ph·∫ßn quan tr·ªçng c·ªßa Linux kernel l√† clock() routine, ƒëc ch·∫°y b·ªüi timer interrupt. Th∆∞·ªùng ƒëc ch·∫°y m·ªói 60, 100, 1000 l·∫ßn m·ªói gi√¢y, m·ªói excecution c·ªßa clock g·ªçi l√† m·ªôt tick C√°i n√†y d√πng ƒë·ªÉ update system time, expiring timers v√† time slices for thread scheduling, maintaining CPU statistics...
M·ªôt v√†i problem v·ªõi c√°i clock n√†y (ƒë√£ ƒëc improved trong nh·ªØng b·∫£n kernel hi·ªán t·∫°i)
Tick latency: v·ªõi 100Hz clock, t∆∞∆°ng ƒë∆∞∆°ng ƒë·ªô tr·ªÖ 10ms. C√°i n√†y ƒëc fix b·∫±ng high-resolution real-time interrupts
Tick overhead: Ticks d√πng nhi·ªÅu CPU cycle v√† l√†m ·ª©ng d·ª•ng h∆°i ƒë∆° m·ªôt ch√∫t
Modern kernels have moved much functionality out of the clock routine to on-demand interrupt, in an effort to create a tickless kernel. Nh·∫±m gi·∫£m thi·ªÉu overhead v√† c·∫£i thi·ªán power efficiency by allowing processor to remain sleep state longer.
When there is no work to perform, kernel schedules a placeholder thread that wait for work, called the idle thread.
3.2.6 Processes
A process is an environment for executing a user-level program. It consists of a memory address space, file descriptors, thread stacks, and registers.
Processes are multitasked by kernel. They are individually identified by their unique process ID (PID).
A process contains one or more threads, which operate in the process address space and share the same file descriptors. A thread is an executable context consisting of a stack, registers, and an instruction pointer (also called a program counter). Multiple threads allow a single process to execute in parallel across multiple CPUs. On Linux, threads and processes are both tasks.
The first process launched by the kernel is called "init" and have PID 1.
Process Creation
Processes are normally created using the fork(2) system call on Unix systems.
The fork(2) or clone(2) syscall may use a copy-on-write (COW) strategy to improve performance.
This strategy either defers or eliminates the need to copy memory, reducing memory and CPU usage.
Process Life Cycle
H√¨nh b√™n d∆∞·ªõi show m·ªôt life cycle of a process.
Figure 3.8 Process life cycle
On-Proc l√† tr·∫°ng th√°i m√† process ƒëang ƒëc ch·∫°y tr√™n processor. Tr·∫°ng th√°i ready-to-run l√† ƒë√£ s·∫µn s√†ng nh∆∞ng m√† ƒëang ch·ªù ·ªü queue ƒë·ªÉ ƒëc processor x·ª≠ l√Ω. H·∫ßu h·∫øt I/O will block, ƒë·∫∑t process v√† tr·∫°ng th√°i sleep, cho t·ªõi khi I/O xong. Zombie state l√† process ƒë√£ xong v√† ch·ªù parent process ho·∫∑c kernel remove n√≥ ƒëi.
Process environment
Process environment bao g·ªìm data tr√™n user address space c·ªßa process v√† metadata (context) tr√™n kernel.
Figure 3.9 Process environment
M·ªói kernel context c·ªßa process g·ªìm: PID, UID, PPID ... C≈©ng nh∆∞ file descriptors (refer v·ªÅ file m√† process ƒëang s·ª≠ d·ª•ng)
3.2.7 Stacks
Stack l√† v√πng nh·ªõ tr√™n memory d√πng cho c√°c d·ªØ li·ªáu t·∫°m th·ªùi, t·ªï ch·ª©c ki·ªÉu LIFO (v√†o sau ra tr∆∞·ªõc). N√≥ ƒë∆∞·ª£c d√πng ƒë·ªÉ ch·ª©a c√°c d·ªØ li·ªáu √≠t quan tr·ªçng ...... Khi m·ªôt function ƒë∆∞·ª£c g·ªçi, ƒë·ªãa ch·ªâ ƒë·ªÉ tr·∫£ v·ªÅ gi√° tr·ªã ƒë∆∞·ª£c l∆∞u v√†o stack (the return address is saved to the stack). M·ªôt v√†i registers (thanh ghi) c≈©ng ƒëc l∆∞u v√†o stack n·∫øu gi√° tr·ªã c·ªßa n√≥ ƒë∆∞·ª£c d√πng ngay sau khi g·ªçi (?)... T·∫≠p data tr√™n stack li√™n quan t·ªõi m·ªôt function ƒë∆∞·ª£c th·ª±c thi g·ªçi l√† stack frame.
Ch√∫ng ta c√≥ th·ªÉ xu·∫•t ra ƒë∆∞·ª£c c√°c fucntion ƒë√£ ƒë∆∞·ª£c excute (stack walking). Action n√†y g·ªçi l√† stack back trace ho·∫∑c stack trace. ƒê√¢y l√† m·ªôt c√¥ng c·ª• r·∫•t hi·ªáu qu·∫£ trong system performance.
How to read the stack
Stack th∆∞·ªùng ƒëc print theo ki·ªÉu leaf-to-root, nghƒ©a l√† fucntion m·ªõi nh·∫•t quay ng∆∞·ª£c v·ªÅ c√°c fucntion tr∆∞·ªõc n√≥ (hay g·ªçi ra n√≥).
V√¨ stack n√†y l√† c√°c h√†m trong source code n√™n th∆∞·ªùng s·∫Ω kh√¥ng c√≥ document n√†o ngo√†i code, tr·ª´ m·ªôt s·ªë tr∆∞·ªùng h·ª£p l√† c√°c h√†m l√† API ho·∫∑c ƒë∆∞·ª£c document ri√™ng.
User and Kernel stacks
Khi th·ª±c thi m·ªôt system call, process's thread c√≥ hai stack: user-level stack v√† kernel level stack.
Figure 3.10 User and Kernel stacks
...
3.2.8 Virtual memory
Virtual memory l√† m·ªôt tr·ª´u t∆∞·ª£ng h√≥a c·ªßa main memory, cung c·∫•p m·ªôt g√≥c nh√¨n ri√™ng bi·ªát, ko chung ch·∫° v√† g·∫ßn nh∆∞ kh√¥ng gi·ªõi h·∫°n cho c√°c ti·∫øn tr√¨nh v√† kernel. Vi·ªác n√†y c≈©ng gi√∫p cho ph√©p mapping nhi·ªÅu v√πng nh·ªõ b√™n d∆∞·ªõi (main memory v√† secondary storage (disks) n·∫øu c·∫ßn).
Figure 3.11 Virtual memory
Memory management
V√¨ virtual memory cho ph√©p d√πng c·∫£ hai v√πng storage l√†m mem (c·∫£ main memory v√† disks), kernel s·∫Ω c·ªë g·∫Øng gi·ªØ nh·ªØng c√°i ti·∫øn tr√¨nh hay d√πng ·ªü main memory cho hi·ªáu qu·∫£. C√≥ hai c√°ch kernel d√πng:
Process swapping move c·∫£ c·ª•c process gi·ªØa secondary v√† main lu√¥n
Paging move t·ª´ng ph·∫ßn nh·ªè c·ªßa memory (called pages) (v.d 4 KBytes)
Process swapping l√†m hi·ªáu nƒÉng t·ª•t, c√≤n Paging th√¨ hi·ªáu qu·∫£ h∆°n. C·∫£ hai c√°ch ƒë·ªÅu d√πng thu·∫≠t to√°n least recently used. Trong Linux t·ª´ swapping th∆∞·ªùng ƒë∆∞·ª£c d√πng ƒë·ªÉ ch·ªâ t·ªõi paging.
3.2.9 Schedulers
Unix v√† derivative c·ªßa n√≥ th∆∞·ªùng chia m·ªôt kho·∫£ng th·ªùi gian th√†nh nhi·ªÅu ph·∫ßn nh·ªè v√† ph√¢n b·ªë cho c√°c process kh√°c nhau ƒë·ªÉ ch·∫°y nhi·ªÅu process c√πng l√∫c. Vi·ªác chia th·ªùi gian s·ª≠ d·ª•ng processor cho c√°c process ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi scheduler, key component c·ªßa OS kernel.
Vi·ªác ph√¢n b·ªï CPU time gi·ªØa c√°c process c√≤n ph·∫£i c√¢n nh·∫Øc y·∫øu t·ªë priority sao cho important work ƒë∆∞·ª£c th·ª±c thi s·ªõm h∆°n. Scheduler track t·∫•t c·∫£ c√°c thread trong tr·∫°ng th√°i ready-to-run, c√°c thread ƒë·∫∑t tr·ªçng c√°c queue chia theo priority, g·ªçi l√† run queues.
Khi c√≥ nhi·ªÅu threads c√πng mu·ªën ƒë∆∞·ª£c th·ª±c thi, priority cao h∆°n s·∫Ω ƒëc th·ª±c thi tr∆∞·ªõc. Kernel threads c√≥ priority cao h∆°n so v·ªõi user-level process.
Priority c√≥ th·ªÉ ƒëc edit ƒë·ªÉ c·∫£i thi·ªán hi·ªáu nƒÉng c·ªßa workload. Workload ƒëc chia l√†m hai lo·∫°i:
CPU-bound: Application c·∫ßn nhi·ªÅu t·∫£i t√≠nh to√°n, vd scientific and mathematical analysis, nh·ªØng c√°i c·∫ßn d√πng nhi·ªÅu CPU time. Nh·ªØng ·ª©ng d·ª•ng n√†y b·ªã gi·ªõi h·∫°n b·ªüi t√†i nguy√™n CPU
I/O-bound: Application th∆∞·ªùng th·ª±c hi·ªán I/O, d√πng √≠t compute, v.d web servers, file servers... nh·ªØng c√°i m√† mong mu·ªën ƒë·ªô tr·ªÖ th·∫•p. Khi t·∫£i tƒÉng th√¨ I/O storage ho·∫∑c network resource l√† nh·ªØng c√°i ƒë∆∞·ª£c s·ª≠ d·ª•ng nhi·ªÅu h∆°n.
Policy th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong UNIX l√† x√°c ƒë·ªãnh c√°c CPU-bound workload v√† gi·∫£m priority t·ª•i n√†y xu·ªëng, cho ph√©p I/O-bound ch·∫°y tr∆∞·ªõc.
3.2.10 File systems
File systems l√† c√°ch t·ªï ch·ª©c d·ªØ li·ªáu d∆∞·ªõi d·∫°ng file v√† th∆∞ m·ª•c. File systems cung c·∫•p file-based interface ƒë·ªÉ truy c·∫≠p d·ªØ li·ªáu, th∆∞·ªùng d·ª±a tr√™n chu·∫©n POSIX. The operating system provides a global file namespace, t·ªï ch·ª©c theo ki·ªÉu top-down tree topology b·∫Øt ƒë·∫ßu v·ªõi root level ("/"). C√°c file system kh√°c join tree b·∫±ng c√°ch mount v√†o c√°c mount point.
ƒêa s·ªë file systems l∆∞u data d∆∞·ªõi disks, m·ªôt s·ªë file systems ƒë∆∞·ª£c gen ra b·ªüi kernel, such as /proc and /dev
Kernel cung c·∫•p nhi·ªÅu ph∆∞∆°ng ph√°p ƒë·ªÉ isolate process kh·ªèi file namespace, chroot(8) v√† tr√™n Linux l√† mount namespaces (c√°i n√†y th∆∞·ªùng d√πng cho containers).
VFS
Virtual file system l√† m·ªôt kernel interface d√πng ƒë·ªÉ tr·ª´u t∆∞·ª£ng c√°c lo·∫°i file system, ƒë·ªÉ cho nhi·ªÅu lo·∫°i file system c√πng ho·∫°t ƒë·ªông song song, vd Sun Microsystem v·ª´a c√≥ UFS v√† NFS (network file system)
VFS interface cho ph√©p th√™m m·ªõi file system type v√†o kernel d·ªÖ d√†ng h∆°n. V√† c≈©ng cho ph√©p user program v√† application truy c·∫≠p file system d·ªÖ d√†ng h∆°n.
I/O stack
V·ªõi c√°c storage-device-based file system, the path t·ª´ user-level software t·ªõi storage device g·ªçi l√† I/O stack.
H√¨nh b√™n d∆∞·ªõi m√¥ t·∫£ I/O stack. C√≥ m·ªôt ƒë∆∞·ªùng b√™n tr√°i cho ph√©p th·∫≥ng xu·ªëng block device, bypassing file system. Path n√†y thi tho·∫£ng ƒëc d√πng b·ªüi administrative tools v√† databases.
+---------------------------+
|
Application
|
+------------------+--------+
|
|
+------------------v--------+
|
System Calls
|
+----+-------------+--------+
|
|
|
+--------v--------+
|
|
VFS
|
|
+--------+--------+
|
|
|
+--------v--------+
|
|
File system
|
|
+--------+--------+
|
|
+----v-------------v--------+
| Block Device Interface
|
+------------+--------------+
|
+------------v--------------+
|
Volume manager
|
+------------+--------------+
|
|
+------------v--------------+
| Host Bus Adapter Driver
|
+------------+--------------+
|
+------------v--------------+
|
Disk devices
|
+---------------------------+
Figure 3.15 Generic I/O stacks
3.2.11 Caching
Disk I/O th∆∞·ªùng c√≥ latency cao n√™n c√°c software stack th∆∞·ªùng c·ªë g·∫Øng ƒë·ªÉ cache l·∫°i read and write ƒë·ªÉ tr√°nh latency n√†y.
Cache
Examples
Client cache
Web browser cache
Application cache
‚Äî
Web server cache
Apache cache
Database cache
memcached
Caching server
MySQL buffer cache
Directory cache
dcache
File metadata cache
inode cache
Operating system buffer cache
Buffer cache
File system primary cache
Page cache, ZFS ARC
File system secondary cache
ZFS L2ARC
Device cache
ZFS vdev
Block cache
Buffer cache
Disk controller cache
RAID card cache
Storage array cache
‚Äî
On-disk cache
‚Äî
V.d, buffer cache l√† m·ªôt khu v·ª±c tr√™n main memory t·∫°m th·ªùi store recently used disk block. Disk read ƒë∆∞·ª£c ph·ª•c v·ª• ngay t·ª´ ch·ªó cache n√†y thay v√¨ ph·∫£i g·ªçi xu·ªëng disk.
3.2.12 Networking
Modern kernel cung c·∫•p m·ªôt stack c√°c giao th·ª©c network, ƒë√£ ƒëc t√≠ch h·ª£p s·∫µn. Giao th·ª©c th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† TCP/IP. User-level program truy c·∫≠p network b·∫±ng endpoint m√† kernel c·∫•p, endpoint n√†y g·ªçi l√† socket.
3.2.13 Device drivers
Device drivers l√† c√°c kernel software cho vi·ªác qu·∫£n l√Ω device v√† I/O, th∆∞·ªùng ƒëc cung c·∫•p b·ªüi device vendors. Some kernel h·ªó tr·ª£ pluggable device drivers, cho ph√©p loaded or unloaded driver m√† ko c·∫ßn ph·∫£i restart l·∫°i.
Device drivers chia hai lo·∫°i:
Character device hay raw device, c≈©ng c·∫•p ph∆∞∆°ng ph√°p truy c·∫≠p tu·∫ßn t·ª± sequential v√† kh√¥ng c√≥ buffer, vd: keyboard, mouse
Block devices: th·ª±c hi·ªán I/O theo units of blocks, th∆∞·ªùng th√¨ l√† 512b m·ªói block. Truy c·∫≠p randomly d·ª±a theo block offset. Trong original Unix, block device cung c·∫•p caching (cache tr√™n main memory, g·ªçi l√† buffer cache).
3.2.14 Multiprocessor
3.2.15 Preemption
Kernel preemption cho ph√©p thread ·ªü user-level c√≥ priority cao h∆°n kernel v√† ƒëc th·ª±c thi tr∆∞·ªõc. Kernel support preemption g·ªçi l√† fully preemption, m·∫∑c d√π c√≥ m·ªôt v√†i code path v·∫´n ko th·ªÉ b·ªã interrupt.
M·ªôt c√°ch ti·∫øp c·∫≠n kh√°c ƒëc h·ªó tr·ª£ l√† voluntary kernel preemption, where logical stopping points in the kernel code can check and perform preemption (don't understand this :D).
3.2.16 Resource management
Linux cung c·∫•p nhi·ªÅu c√¥ng c·ª• ƒë·ªÉ c·∫•u h√¨nh tunning access t·ªõi c√°c resource. Linux c√≥ control groups (cgroups) v√† nhi·ªÅu c√°i kh√°c ƒë∆∞·ª£c ph√°t tri·ªÉn ƒë·ªÉ cung c·∫•p vi·ªác x·ª≠ l√Ω.
3.2.17 Observability
3.3 Kernel
Ph·∫ßn n√†y m√¥ t·∫£ chi ti·∫øt Unix-like kernel implementation v√† focus v√†o performance.
3.4 Linux
Linux ƒë∆∞·ª£c t·∫°o b·ªüi Linus Torvards v√†o nƒÉm 1991 v·ªõi m·ª•c ti√™u l√† m·ªôt free OS cho Intel personal computers.
Linux k·∫ø th·ª´a v·ªõi nhi·ªÅu √Ω t∆∞·ªüng t·ª´ c√°c OS tr∆∞·ªõc ƒë√≥: Unix, BSD, Solaris, Plan 9
3.4.1 Linux Kernel Developments
3.4.2 systemd
suser@desktop:~$ systemd-analyze
Startup finished in 2.531s (kernel) + 23.513s (userspace) = 26.044s
graphical.target reached after 23.503s in userspace
suser@desktop:~$ systemd-analyze critical-chain
The time when unit became active or started is printed after the "@" character.
The time the unit took to start is printed after the "+" character.
graphical.target @23.503s
‚îî‚îÄmulti-user.target @23.503s
‚îî‚îÄtelegraf.service @6.998s +144ms
‚îî‚îÄnetwork.target @2.322s
‚îî‚îÄNetworkManager.service @1.856s +466ms
‚îî‚îÄdbus.service @1.853s
‚îî‚îÄbasic.target @1.843s
‚îî‚îÄsockets.target @1.842s
‚îî‚îÄsnapd.socket @1.842s +850us
‚îî‚îÄsysinit.target @1.835s
‚îî‚îÄsnapd.apparmor.service @1.787s +47ms
‚îî‚îÄapparmor.service @1.641s +144ms
‚îî‚îÄlocal-fs.target @1.640s
‚îî‚îÄrun-snapd-ns-snap\x2dstore.mnt.mount @11.531s
‚îî‚îÄrun-snapd-ns.mount @10.989s
‚îî‚îÄlocal-fs-pre.target @620ms
‚îî‚îÄkeyboard-setup.service @467ms +153ms
‚îî‚îÄsystemd-journald.socket @456ms
‚îî‚îÄ-.mount @452ms
‚îî‚îÄsystem.slice @452ms
‚îî‚îÄ-.slice @452ms
suser@desktop:~$ systemd-analyze blame
21.111s plymouth-quit-wait.service
3.496s apt-daily-upgrade.service
2.084s docker.service
1.305s snapd.service
3.4.4 Extended BPF
BPF stand for Berkerly Packet Filter, ban ƒë·∫ßu l√† ƒë·ªÉ c·∫£i thi·ªán hi·ªáu nƒÉng c·ªßa packet capture tools. NƒÉm 2013 ƒë∆∞·ª£c vi·∫øt l·∫°i v√† tr·ªü th√†nh engine ƒëa m·ª•c ƒë√≠ch, d√πng cho networking, Observability, v√† security.
BPF kh√° l√† quan tr·ªçng trong SP analysis. N√≥ cung c·∫•p kh·∫£ nƒÉng l·∫≠p tr√¨nh v·ªõi c√°c event resource c·ªßa kernel: tracepoints, kprobes, uprobes, v√† perf_events. Vd: BPF program c√≥ th·ªÉ ghi l·∫°i timestamp khi start v√† end khi I/O ƒë·ªÉ t√≠nh I/O duration.
3.7 Exercises
Answer the following questions about OS terminology:
What is the difference between a process, a thread, and a task?
V·∫´n ch∆∞a ph√¢n bi·ªát ƒë∆∞·ª£c s·ª± kh√°c bi·ªát. Process th√¨ l√† ch∆∞∆°ng tr√¨nh c·ªßa ng∆∞·ªùi d√πng ch·∫°y tr√™n user-mode
What is a mode switch and a context switch?
Mode switch l√† vi·ªác CPU chuy·ªÉn vi·ªác x·ª≠ l√Ω t·ª´ user-mode sang kernel mode ho·∫∑c ng∆∞·ª£c l·∫°i.
Context switch l√† CPU chuy·ªÉn t·ª´ x·ª≠ l√Ω process (ho·∫∑c thread) n√†y sang process (thread) kh√°c
What is the difference between paging and process swapping?
Paging l√† chia virtual memory cho c√°c process
Process swapping l√† chuy·ªÉn memory c·ªßa process sang ph·∫ßn swap v√¨ √≠t s·ª≠ d·ª•ng.
What is the difference between I/O-bound and CPU-bound workloads?
I/O bound l√† c√°c ·ª©ng d·ª•ng c·∫ßn nhi·ªÅu towng t√°c ƒë·ªçc ghi v·ªõi c√°c thi·∫øt b·ªã b√™n ngo√†i, gi·ªõi h·∫°n b·ªüi t·ªëc ƒë·ªô I/O
CPU bound l√† ·ª©ng d·ª•ng c·∫ßn th·ª±c hi·ªán t√≠nh to√°n nhi·ªÅu, gi·ªõi h·∫°n b·ªüi s·ªë l∆∞·ª£ng t√†i nguy√™n compute
Th∆∞·ªùng ta s·∫Ω tunning cho I/O ƒëc CPU th·ª±c hi·ªán tr∆∞·ªõc ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω c·ªßa I/O bound
Answer the following conceptual questions:
Describe the role of the kernel.
Th·ª±c hi·ªán qu·∫£n c√°c t√†i nguy√™n b√™n d∆∞·ªõi
Cung c·∫•p giao di·ªán t∆∞∆°ng t√°c th√¥ng qua system call
Describe the role of system calls.
Cho ph√©p ·ª©ng d·ª•ng t∆∞∆°ng t√°c v·ªõi c√°c thi·∫øt b·ªã m√† kernel qu·∫£n l√Ω th√¥ng qua system call
Describe the role of VFS and its location in the I/O stack
VFS n·∫±m tr√™n c√°c file system kh√°c ƒë·ªÉ cung c·∫•p m·ªôt interface th·ªëng nh·∫•t cho c√°c ·ª©ng d·ª•ng d·ªÖ giao ti·∫øp v·ªõi nhi·ªÅu lo·∫°i interface b√™n d∆∞·ªõi, cho ph√©p nhi·ªÅu fs c√πng t·ªìn t·∫°i nh∆∞ m·ªôt th·ªÉ th·ªëng nh·∫•t v·ªõi g√≥c nh√¨n t·ª´ app.
VFS > FSs > syscall > kernel > device controller > device
Answer the following deeper questions:
List the reasons why a thread would leave the current CPU.
Thread c·∫ßn ƒë·ªçc m·ªôt s·ªë th√¥ng tin t·ª´ disk, ho·∫∑c ch·ªù t·ª´ I/O t∆∞∆°ng t√°c t·ª´ b√™n ngo√†i
C√≥ thread c√≥ ƒë·ªô ∆∞u ti√™n cao h∆°n thread hi·ªán t·∫°i
Describe the advantages of virtual memory and demand paging.
Virtual memory t∆∞∆°ng t·ª± nh∆∞ VFS ·ªü tr√™n, t·∫°o th√†nh m·ªôt m·ª©c tr·ª´u t∆∞·ª£ng gi·ªØa main memory, secondary memory v·ªõi memory cung c·∫•p cho c√°c process, thread b√™n tr√™n
Cho ph√©p ·ª©ng d·ª•ng ch·∫°y v·ªõi l∆∞·ª£ng memory ·∫£o g·∫ßn nh∆∞ v√¥ h·∫°n
Swap c√°c process ko th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ cho ph√©p ch·∫°y nhi·ªÅu ·ª©ng d·ª•ng h∆°n.
V·ªõi demand paging, th√¨ m√¨nh ch∆∞a bi·∫øt
Raw
13-apparmor.md
AppArmor
AppArmor l√† g√¨?
C√≥ c√°c ch·ª©c nƒÉng g√¨?
C·∫•u h√¨nh nh∆∞ th·∫ø n√†o?
AppArmor
AppArmor l√† m·ªôt c√¥ng c·ª• cho ph√©p qu·∫£n l√Ω c√°c ch∆∞∆°ng tr√¨nh, cho ph√©p gi·ªõi h·∫°n quy·ªÅn truy c·∫≠p v√†o c√°c file tr√™n h·ªá th·ªëng v·ªõi m·ªôt program.
Kh√°c v·ªõi window's UAC, trao quy·ªÅn cho user, AppArmor gi·ªõi h·∫°n kh·∫£ nƒÉng truy c·∫≠p cho c√°c program
Usage
AppArmor
Ch·∫°y d∆∞·ªõi kernel
Qu·∫£n l√Ω program theo Profile. c√≥ 2 mode v·ªõi Profile
Enforcement: gi·ªõi h·∫°n file truy c·∫≠p v√† th√¥ng b√°o n·∫øu c√≥ s·ª± vi ph·∫°m
Complain: ch·ªâ th√¥ng b√°o vi ph·∫°m, nh∆∞ng v·∫´n cho truy c·∫≠p
Ngo√†i c√°c c√°i ch·∫°y m·∫∑c ƒë·ªãnh l√∫c kh·ªüi ƒë·ªông, c√≥ nh·ªØng c√°i b·ªã disable (trong /etc/apparmor.d/disable). VD v·ªõi firefox:
ƒê·ªÉ enable: sudo aa-enforce /etc/apparmor.d/usr.bin.firefox
Disable again:
sudo ln -s /etc/apparmor.d/usr.bin.firefox /etc/apparmor.d/disable/
sudo apparmor_parser -R /etc/apparmor.d/usr.bin.firefox
Create AppArmor Profile
Install AppArmor utils
apt-get install apparmor-utils
T·∫°o Profile:
aa-genprof /path/to/application
Edit Profile
sudo aa-logprof /path/to/application
Stop & restart
sysstemctl stop apparmor
sysstemctl restart apparmor
K·∫øt lu·∫≠n
AppArmor gi·ªõi h·∫°n quy·ªÅn truy c·∫≠p c·ªßa program v√†o c√°c file. Cung c·∫•p c√¥ng c·ª• ki·ªÉm tra c√°c file ·ª©ng d·ª•ng truy c·∫≠p, log vi ph·∫°m.
N·∫øu c√≥ l·ªói v·ªÅ quy·ªÅn th√¨ n√™n check c√°i n√†y.
Copy link
ntk148v
commented
Sep 27, 2022
Thank th·∫ßy üôá
Sorry, something went wrong.
Uh oh!
There was an error while loading. Please reload this page.
Copy link
eveningcafe
commented
Oct 3, 2022
thank thay
Sorry, something went wrong.
Uh oh!
There was an error while loading. Please reload this page.
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Footer
¬© 2025 GitHub,¬†Inc.
Footer navigation
Terms
Privacy
Security
Status
Community
Docs
Contact
Manage cookies
Do not share my personal information
You can‚Äôt perform that action at this time.