Nvidia wants 10Gbps HBM4 to blunt AMD’s MI450, report claims — company said to be pushing suppliers for more bandwidth | Tom's Hardware
Skip to main content
Open menu
Close main menu
Tom's Hardware
US EditionUKUSAustraliaCanada
RSS
Sign in
View Profile
Sign out
Search
Search Tom's Hardware
Best Picks
CPUs
GPUs
SSDs
News
Laptops
Premium
Coupons
More
Newsletter
Reviews
PC Components
PC Building
Motherboards
Cases
Cooling
Power Supplies
RAM
Desktops
3D Printers
Peripherals
Monitors
Windows 11
Gaming
Overclocking
About Us
Forums
TrendingIntel+NvidiaBorderlands 4Apple A19 vs Ryzen 9RTX 5090Inside Panther Lake-H
Don't miss these
GPUs
SK hynix confirms 3GB GDDR7 memory modules are in the works
GPUs
Nvidia shares Blackwell Ultra's secrets — NVFP4 boost detailed and PCIe 6.0 support
GPUs
Kioxia’s new 5TB, 64 GB/s flash module puts NAND toward the memory bus for AI GPUs
RAM
New 3D-stacked memory tech seeks to dethrone HBM in AI inference
Tech Industry
Sandisk and SK hynix join forces to standardize High Bandwidth Flash memory
GPUs
Samsung reportedly slashes HBM3 prices to woo Nvidia
GPUs
AMD preps Mega Pod with 256 Instinct MI500 AI GPUs, Verano CPUs
Semiconductors
Nvidia rumored to ditch its first-gen custom memory form factor for newer version
Semiconductors
Nvidia Rubin CPX forms one half of new, "disaggregated" AI inference architecture
Tech Industry
According to a Linkedin profile, AMD is working on another chiplet-based GPU
Artificial Intelligence
Intel jumps to HBM4 with Jaguar Shores, 2nd Gen MRDIMMs with Diamond Rapids
GPUs
Nvidia reportedly preparing RTX 6000D for Chinese market to comply with U.S. export controls
Networking
Nvidia outlines plans for using silicon photonics and co-packaged optics in AI clusters by 2026
GPUs
Nvidia’s RTX 50 Super lineup leak hints at increased VRAM of up to 24GB and 415W TGP
Semiconductors
Nvidia tipped to be TSMC's first A16 customer, ahead of Apple — Feynman GPUs could make full use of GAA transistors and backside power
PC Components
GPUs
Nvidia wants 10Gbps HBM4 to blunt AMD’s MI450, report claims — company said to be pushing suppliers for more bandwidth
News
By
Luke James
published
19 September 2025
Nvidia’s Rubin platform bets big on 10Gb/s HBM4, but speed brings supply risk, and AMD’s MI450 is around the corner.
Comments (1)
When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.
(Image credit: Nvidia)
Nvidia is pressing its memory vendors to push beyond JEDEC’s official HBM4 baseline. According to TrendForce, the company has requested 10Gb/s-per-pin stacks for its 2026 Vera Rubin platform, a move designed to raise per-GPU bandwidth ahead of AMD’s next-generation MI450 Helios systems.At 8Gb/s per pin — the rate JEDEC specifies for HBM4 — a single stack delivers just under 2 TB/s across the new 2,048-bit interface. Raising that to 10Gb/s bumps the total to 2.56 TB/s per stack. With six stacks, a single GPU clears 15 TB/s of raw bandwidth. Rubin CPX, Nvidia's compute-optimized config built to handle the most demanding inference workloads, is advertised with 1.7 petabytes per second across a full NVL144 rack. The higher the pin speed, the less margin Nvidia needs elsewhere to hit those numbers.But driving 10Gb/s HBM4 isn’t a given. Faster I/O brings higher power, tighter timing, and more strain on the base die. TrendForce notes that Nvidia may segment Rubin SKUs by HBM tier if costs or thermals spike. That means 10Gb/s parts for Rubin CPX and lower-speed stacks for the standard Rubin configuration. The fallback is already in view: staggered supplier qualification and extended validation windows to stretch yield.
You may like
SK hynix confirms 3GB GDDR7 memory modules are in the works
Nvidia shares Blackwell Ultra's secrets — NVFP4 boost detailed and PCIe 6.0 support
Kioxia’s new 5TB, 64 GB/s flash module puts NAND toward the memory bus for AI GPUs
SK hynix remains Nvidia’s dominant HBM supplier and says it has completed HBM4 development and is ready for mass production. The company has referenced “over 10Gb/s” capability but hasn’t published die specs, power targets, or process details.Samsung, by contrast, is more aggressive on node migration. Its HBM4 base die is moving to 4nm FinFET, a logic-class node intended to support higher clock speeds and lower switching power. That could give Samsung an edge at the high end, even if SK hynix ships more volume. Micron has confirmed sampling of HBM4 with a 2,048-bit interface and bandwidth exceeding 2 TB/s, but hasn’t said whether 10Gb/s is in scope.AMD’s MI450 is still on the horizon, but the memory spec is already known. Helios racks are expected to support up to 432GB of HBM4 per GPU, giving AMD a route to match or exceed Nvidia on raw capacity. With CDNA 4, it also gains architectural upgrades that aim squarely at Rubin’s inference advantage.Nvidia clearly wants to make memory faster. But the more it leans on 10Gb/s HBM4, the more exposed it becomes to supplier variation, yield risks, and rack-level power constraints at a time when the margin for error is shrinking.Stay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!
See more GPUs News
TOPICS
Nvidia
See all comments (1)
Luke JamesSocial Links NavigationContributorLuke James is a freelance writer and journalist.  Although his background is in legal, he has a personal interest in all things tech, especially hardware and microelectronics, and anything regulatory.
Read more
SK hynix confirms 3GB GDDR7 memory modules are in the works
Nvidia shares Blackwell Ultra's secrets — NVFP4 boost detailed and PCIe 6.0 support
Kioxia’s new 5TB, 64 GB/s flash module puts NAND toward the memory bus for AI GPUs
New 3D-stacked memory tech seeks to dethrone HBM in AI inference
Sandisk and SK hynix join forces to standardize High Bandwidth Flash memory
Samsung reportedly slashes HBM3 prices to woo Nvidia
Latest in GPUs
Asus teases new concept that boosts motherboard GPU slot power to 250W
AMD silently launches RX 7700 non-XT with 16 GB VRAM
GeForce RTX 50-series GPUs are finally selling at and below MSRP
Alibaba’s AI chip goes head-to-head with Nvidia H20 in state-backed benchmark demo
Latest FSR 4 source code 'leak' lets you run AMD's AI upscaling tech on nearly any GPU
Nvidia's unreleased 'GTX 2080 Ti' surfaces online with 12 GB VRAM and 384-bit memory bus
Latest in News
OpenAI is reportedly poaching Apple talent to build its first consumer hardware device
GPU sales skyrocketed 27% last quarter
Nvidia CEO Huang says upcoming DGX Spark systems are powered by N1 silicon
Intel says it remains committed to its Arc graphics project
Researchers 3D print lightweight ceramic fuel cell
Nvidia wants 10Gbps HBM4 to blunt AMD’s MI450, report claims
1 Comment
Comment from the forums
richardvday
This means Nvidia feels threatened, maybe not a lot but that's a good thing. Competition is what we need not monopolies. Nvidia owns way too much market share. AMD needs to continue to compete at the high end. Consumer graphics would be nice if amd would choose to compete.
Reply
View All 1 Comment
Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site.
Terms and conditions
Contact Future's experts
Privacy policy
Cookies policy
Accessibility Statement
Advertise with us
About us
Coupons
Careers
©
Future US, Inc. Full 7th Floor, 130 West 42nd Street,
New York,
NY 10036.