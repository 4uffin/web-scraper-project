Huawei unveils Atlas 950 SuperCluster — promises 1 ZettaFLOPS FP4 performance and features hundreds of thousands of 950DT APUs | Tom's Hardware
Skip to main content
Open menu
Close main menu
Tom's Hardware
US Edition
UK
US
Australia
Canada
RSS
Sign in
View Profile
Sign out
Search
Search Tom's Hardware
Best Picks
CPUs
GPUs
SSDs
News
Laptops
Premium
Coupons
More
Newsletter
Reviews
PC Components
PC Building
Motherboards
Cases
Cooling
Power Supplies
RAM
Desktops
3D Printers
Peripherals
Monitors
Windows 11
Gaming
Overclocking
About Us
Forums
TrendingIntel+NvidiaBorderlands 4Apple A19 vs Ryzen 9RTX 5090Inside Panther Lake-H
Don't miss these
Semiconductors
Huawei reveals long-range Ascend chip roadmap
Artificial Intelligence
China's chip champions ramp up production of AI accelerators at domestic fabs, but HBM and fab production capacity are towering bottlenecks
GPUs
Alibaba’s AI chip goes head-to-head with Nvidia H20 in state-backed benchmark demo
Artificial Intelligence
Elon Musk says xAI is targeting 50 million 'H100 equivalent' AI GPUs in five years
Supercomputers
Nvidia GPUs and Fujitsu Arm CPUs will power Japan's next $750M zetta-scale supercomputer
Artificial Intelligence
Nvidia's newest top-tier AI supercomputers deployed for the first time
GPUs
AMD preps Mega Pod with 256 Instinct MI500 AI GPUs, Verano CPUs
Artificial Intelligence
Huawei releases new tool to get Chinese firms around crushing HBM export blacklist
Artificial Intelligence
DeepSeek reportedly urged by Chinese authorities to train new model on Huawei hardware, met with multiple failures
GPUs
Nvidia claims software and hardware upgrades allow Blackwell Ultra GB300 to dominate MLPerf benchmarks
Artificial Intelligence
Positron AI says its Atlas accelerator beats Nvidia H200 on inference in just 33% of the power
GPUs
Nvidia could be readying Blackwell B30A accelerator for the Chinese market
GPUs
TensorWave just deployed 8,192 Instinct MI325X accelerators, forming the largest AMD training cluster in NA
GPUs
China plans 39 AI data centers with 115,000 restricted Nvidia Hopper GPUs
GPUs
Asus brings Nvidia’s GB300 Blackwell Ultra 'desktop superchip' to workstations
Tech Industry
Artificial Intelligence
Huawei unveils Atlas 950 SuperCluster — promises 1 ZettaFLOPS FP4 performance and features hundreds of thousands of 950DT APUs
News
By
Anton Shilov
published
19 September 2025
More powerful systems yet to come.
Comments (15)
When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works.
(Image credit: Huawei)
Huawei has unveiled its next-generation data-center scale AI solution that can offer 1 FP4 ZettaFLOPS performance for AI inference and 524 FP8 ExaFLOPS for AI training at its Huawei Connect 2025 conference on Thursday. The new SuperCluster 950 system runs hundreds of thousands of the company's Ascend 950DT neural processing units (NPUs) and promises to be one of the most powerful supercomputers for artificial intelligence on the planet. Huawei expects its SuperCluster to compete with Nvidia's Rubin-based systems in late 2026.Massive performanceHuawei's Atlas 950 SuperCluster will consist of 64 Atlas 950 SuperPoDs, which are the company's rack-scale AI solutions akin to Nvidia's GB300 NVL72 or the next-generation Vera Rubin NVL144. The Atlas 950 SuperCluster will be built upon 524,288 Ascend 950DT AI accelerators distributed across over 10,240 optically interconnected cabinets.The supercomputer purportedly offers up to 524 FP8 ExaFLOPS for AI training and up to 1 FP4 ZettaFLOPS for AI inference (MXFP4 to be more specific), which puts it just behind leading-edge AI supercomputers, such as Oracle's OCI Supercluster running 131,072 B200 GPUs and offering peak performance of up to 2.4 FP4 ZettaFLOPS for inference introduced last year. Keep in mind these figures pertain to peak performance numbers, so it remains to be seen whether they can be achieved in real life.
You may like
Huawei reveals long-range Ascend chip roadmap
China's chip champions ramp up production of AI accelerators at domestic fabs, but HBM and fab production capacity are towering bottlenecks
Alibaba’s AI chip goes head-to-head with Nvidia H20 in state-backed benchmark demo
This SuperCluster is designed to support both RoCE (Remote Direct Memory Access over Converged Ethernet) and Huawei's proprietary UBoE (UnifiedBus over Ethernet) protocols, though it remains to be seen how fast the latter will be adopted. According to Huawei, UBoE offers lower idle-state latency, higher hardware reliability, and requires fewer switches and optical modules than traditional RoCE setups.Huawei positions its Atlas 950 SuperCluster to support training and inference workloads for AI models with hundreds of billions to tens of trillions of parameters. Huawei believes this platform is well-suited for the next wave of large-scale dense and sparse models, thanks to its combination of compute throughput, interconnect bandwidth, and system stability. Though given its size, it is unclear how many companies will be able to accommodate the system.Massive footprintHuawei admits that it cannot build processors that would challenge Nvidia's GPUs in terms of performance. Therefore, to achieve 1 ZettaFLOPS with the Atlas 950 SuperCluster, it intends to use a brute force approach, utilizing hundreds of thousands of AI accelerators to compete against Nvidia Rubin-based clusters in 2026–2027.A common building block of Huawei's Atlas 950 SuperCluster is the Atlas 950 SuperPoD that integrates 8,192 Ascend 950DT chips, representing a 20-fold increase in processing units compared to the Atlas 900 A3 SuperPoD (also known as the CloudMatrix 384) and a massive increase in compute performance — 8 FP8 ExaFLOPS and 16 FP4 ExaFLOPS.Stay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.Performance of the Atlas 950 SuperCluster is truly impressive on paper; it is said to be massively higher compared to Nvidia's Vera Rubin NVL144 (1.2 FP8 ExaFLOPS, 3.6 NVFP4 ExaFLOPS), a product that the company compares it to. However, that performance comes at a price, namely size. The Atlas 950 SuperCluster setup includes 160 total cabinets — 128 for computation and 32 for communications — spread across 1,000 square meters, which is about the size of two basketball courts. By contrast, Nvidia's Vera Rubin NVL144 is a rack-scale solution that consists of one compute rack and one cable and switch rack that requires just several square meters of space.As for Huawei's Atlas 950 SuperCluster — which consists of 64 Atlas 950 SuperPoDs and should measure around 64,000 m2 — its size is comparable to 150 basketball courts, or nine regulation soccer fields. Keep in mind, though, that a real campus would likely require additional space for power rooms, chillers/cooling towers, battery/UPS systems, and support offices, so the total site footprint could be significantly larger than 64,000 m².The road aheadOne of the things about selling server hardware is that customers always want to know what is next, so in addition to having a good product, it is vital to have a roadmap. So at the Huawei Connect, the company disclosed plans to launch the Atlas 960 SuperCluster alongside the Atlas 960 SuperPoD in the fourth quarter of 2027.This next-generation system will scale up to more than 1 million Ascend 960 NPUs and will provide 2 FP8 ZettaFLOPS and 4 MXFP4 ZettaFLOPS of performance. It will also support both UBoE and RoCE, with the former expected to deliver improved latency and uptime metrics while continuing to rely on Ethernet.Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!
TOPICS
Huawei
See all comments (15)
Anton ShilovSocial Links NavigationContributing WriterAnton Shilov is a contributing writer at Tom’s Hardware. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends.
Read more
Huawei reveals long-range Ascend chip roadmap
China's chip champions ramp up production of AI accelerators at domestic fabs, but HBM and fab production capacity are towering bottlenecks
Alibaba’s AI chip goes head-to-head with Nvidia H20 in state-backed benchmark demo
Elon Musk says xAI is targeting 50 million 'H100 equivalent' AI GPUs in five years
Nvidia GPUs and Fujitsu Arm CPUs will power Japan's next $750M zetta-scale supercomputer
Nvidia's newest top-tier AI supercomputers deployed for the first time
Latest in Artificial Intelligence
Nvidia's $100 billion investment in OpenAI raises big antitrust concerns
OpenAI makes flurry of deals in drive towards for-profit model
China is converting farmland into data centers as part of $37 billion effort to centralize AI compute power
Microsoft announces 'world's most powerful' AI data center
China foes get worse results using DeepSeek, research suggests
China bans its biggest tech companies from acquiring Nvidia chips, says report
Latest in News
Intel might be working on its own multi-frame generation tech — "XeSS MFG" appears in Arc driver files
GPD Win 5 handheld soars above the competition with Strix Halo inside
China's latest GPU arrives with claims of CUDA compatibility and RT support
AI buildouts need $2 trillion in annual revenue to sustain growth, but massive cash shortfall looms
The end of EU-imposed cookie consent pop-ups could be nigh
Intel drops day zero game driver support for chips released last year
15 Comments
Comment from the forums
Pierce2623
Yay another product with terrible performance and even worse performance per watt
Reply
EyadSoftwareEngineer
It's becoming clear that the era of Nvidia's unchallenged dominance is over. While everyone was watching Blackwell, Huawei was executing a masterclass in vertical integration and innovation under pressure. Developing competitive in-house HBM and outlining a roadmap with specs that not only meet but exceed current market leaders is a staggering achievement, especially considering the constraints they've operated under.
Their ability to deploy massive-scale domestic clusters like the Atlas 950 signals a seismic shift. The conversation is no longer about if there is a competitor, but how decisively the landscape has changed. Nvidia's software lead is significant, but it's no longer an insurmountable moat. Huawei has demonstrated it has the vision, the political backing, and now the hardware to not just compete, but to lead the next chapter of AI compute. The torch is being passed.
Reply
pug_s
Pierce2623 said:Yay another product with terrible performance and even worse performance per wattIts clusters goes toe to toe with Nvidia AI Cluster. Despite that it takes up more power than a comparable Nvidia cluster, it does not have backdoors which can screw Chinese companies over.
Reply
bit_user
pug_s said:it does not have backdoors which can screw Chinese companies over.Please post evidence of back doors in Nvidia products, if there are any.
Reply
zsydeepsky
bit_user said:Please post evidence of back doors in Nvidia products, if there are any.The safety concerns mostly came from the US gov, namely, the Chip Security Act (H.R. 3447), which has not passed Congress yet, but according to it, any American company has to embed a location identification feature based on network latency detection within their GPUs (the detailed method is not included in the act itself, I read it somewhere else, mentioned by some US congressman).
Anyone investing billions in long-term projects would naturally want to avoid this kind of risk. To the record though, Nvidia did oppose this act since this harms their business model; they look more like a victim here.
Reply
bit_user
zsydeepsky said:embed a location identification feature based on network latency detection within their GPUsThat enables usage restrictions, while a backdoor is something which grants unauthorized access. So, they're not the same thing. However, thanks for the detailed citation.
Maybe that's what pug_s meant, and yes I could see why having such a built-in limiter would be problematic.
Reply
nookoool
Pierce2623 said:Yay another product with terrible performance and even worse performance per watt
I have seen this tortoise and hare race multiple times from telecom to military tech over the past 25 years. The tortoise has nearly always caught up or sometime surpass.
Some parts of the article seems weird, but it seems they are able to compete on raw performance but it will take a larger amount of space and power. Rumor is that Huawei is printing DUV litography machines, so we will see how that goes in terms of wafer counts.
Reply
pug_s
bit_user said:That enables usage restrictions, while a backdoor is something which grants unauthorized access. So, they're not the same thing. However, thanks for the detailed citation.
Maybe that's what pug_s meant, and yes I could see why having such a built-in limiter would be problematic.usage restrictions are restrictions, and someone can exploit those restrictions.
Reply
tamalero
bit_user said:That enables usage restrictions, while a backdoor is something which grants unauthorized access. So, they're not the same thing. However, thanks for the detailed citation.
Maybe that's what pug_s meant, and yes I could see why having such a built-in limiter would be problematic.That sounds literally like a kill switch.
Reply
bit_user
tamalero said:That sounds literally like a kill switch.Effectively, yes. That's the point. But it's not a back door, which was the original claim.
And it hasn't been implemented, as per @zsydeepsky 's post. I mean, you can claim anyone has done anything, but there's no evidence it's been implemented.
Reply
View All 15 Comments
Show more comments
Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site.
Terms and conditions
Contact Future's experts
Privacy policy
Cookies policy
Accessibility Statement
Advertise with us
About us
Coupons
Careers
©
Future US, Inc. Full 7th Floor, 130 West 42nd Street,
New York,
NY 10036.