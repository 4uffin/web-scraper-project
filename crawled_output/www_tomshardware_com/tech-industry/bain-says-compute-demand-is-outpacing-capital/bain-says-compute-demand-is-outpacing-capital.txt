AI buildouts need $2 trillion in annual revenue to sustain growth, but massive cash shortfall looms â€” even generous forecasts highlight $800 billion black hole, says report | Tom's Hardware
Skip to main content
Open menu
Close main menu
Tom's Hardware
US Edition
UK
US
Australia
Canada
RSS
Sign in
View Profile
Sign out
Search
Search Tom's Hardware
Best Picks
CPUs
GPUs
SSDs
News
Laptops
Premium
Coupons
More
Newsletter
Reviews
PC Components
PC Building
Motherboards
Cases
Cooling
Power Supplies
RAM
Desktops
3D Printers
Peripherals
Monitors
Windows 11
Gaming
Overclocking
About Us
Forums
TrendingIntel+NvidiaBorderlands 4Apple A19 vs Ryzen 9RTX 5090Inside Panther Lake-H
Don't miss these
Artificial Intelligence
U.S. AI boom is completely upending the electricity market
Tech Industry
AI's soaring energy consumption causing skyrocketing power bills for households across the US
Artificial Intelligence
EU readies $30 billion investment in gigawatt AI data centers
Tech Industry
Nvidia and OpenAI forge $100 billion alliance to deliver 10 gigawatts of Nvidia hardware for AI datacenters
Tech Industry
Elon Musk says xAI will deploy 50 million H100 GPUs in the next 5 years, doubles down on goal as Grok 2.5 goes open source
Artificial Intelligence
Elon Musk says xAI is targeting 50 million 'H100 equivalent' AI GPUs in five years
Artificial Intelligence
OpenAI's gargantuan data center is even bigger than Elon Musk's xAI Colossus, threatens grid stability
Tech Industry
Sam Altman says OpenAI will own 'well over 1 million GPUs' by the end of the year
Storage
Expect HDD, SSD shortages as AI rewrites the rules of storage hierarchy
Artificial Intelligence
Nvidia's $100 billion investment in OpenAI raises big antitrust concerns
Artificial Intelligence
AI experts warn that China is miles ahead of the US in electricity generation
Artificial Intelligence
Nvidia's next-gen AI chip could double the price of H20 if China export is approved
Servers
Nvidia's Arm chips rapidly gain share in server market as AI booms
Artificial Intelligence
Elon Musk confirms xAI is buying an overseas power plant and is shipping the whole thing to the U.S.
Artificial Intelligence
Power usage in Wyoming AI data center could eclipse consumption of the state's human residents by 5x
Tech Industry
AI buildouts need $2 trillion in annual revenue to sustain growth, but massive cash shortfall looms â€” even generous forecasts highlight $800 billion black hole, says report
News
By
Luke James
published
23 September 2025
A new Bain report says AI buildout will need $2 trillion in annual revenue just to sustain its growth, and the shortfall could keep GPUs scarce and energy grids strained through 2030.
Comments (14)
When you purchase through links on our site, we may earn an affiliate commission. Hereâ€™s how it works.
(Image credit: Meta)
AIâ€™s insatiable power appetite is both expensive and unsustainable. Thatâ€™s the main takeaway from a new report by Bain & Company, which puts a staggering number on what it will cost to keep feeding AIâ€™s compute appetite â€” more than $500 billion per year in global data-center investment by 2030, with $2 trillion in annual revenue required to make that capex viable. Even under generous assumptions, Bain estimates the AI industry will come up $800 billion short.Itâ€™s a sobering reality check for the narrative currently surrounding AI, one that cuts through the trillion-parameter hype cycles and lands squarely in the physics and economics of infrastructure. If Bain is right, the industry is hurtling toward a wall where power constraints, limited GPU availability, and capital bottlenecks converge.The crux of Bainâ€™s argument is that compute demand is scaling faster than the tools that supply it. While Mooreâ€™s Law has slowed to a crawl, AI workloads havenâ€™t. Bain estimates that inference and training requirements have grown at more than twice the rate of transistor density, forcing data center operators to brute-force scale rather than rely on per-chip efficiency gains. The result is a global AI compute footprint that could hit 200 GW by 2030, with half of it in the U.S. alone.
You may like
U.S. AI boom is completely upending the electricity market
AI's soaring energy consumption causing skyrocketing power bills for households across the US
EU readies $30 billion investment in gigawatt AI data centers
That kind of headache is going to require massive, borderline inconceivable upgrades to local grids, years-long lead times on electrical gear, and thousands of tons of high-end cooling. Worse, many of the core enabling silicon, like HBM and CoWoS, are already supply-constrained. Nvidiaâ€™s own commentary this year, echoed in Bainâ€™s report, suggests that demand is outstripping the industryâ€™s ability to deliver on every axis except pricing.If capital dries up or plateaus, hyperscalers will double down on systems that offer the best return per watt and per square foot. That elevates full-rack GPU platforms like Nvidiaâ€™s GB200 NVL72 or AMDâ€™s Instinct MI300X pods, where thermal density and interconnect efficiency dominate the BOM. It also deprioritizes lower-volume configs, especially those based on mainstream workstation parts and, by extension, cuts down the supply of chips that couldâ€™ve made their way into high-end desktops.There are also implications on the PC side. If training remains cost-bound and data-center inference runs into power ceilings, more of the workload shifts to the edge. That plays directly into the hands of laptop and desktop OEMs now shipping NPUs in the 40 to 60 TOPS range, and Bainâ€™s framing helps explain why: Inference at the edge isnâ€™t just faster, itâ€™s also cheaper and less capital-intensive.Meanwhile, the race continues. Microsoft recently bumped its Wisconsin AI data-center spend to more than $7 billion. Amazon, Meta, and Google are each committing billions more, as is xAI, but most of that funding is already spoken for in terms of GPU allocation and model development. As Bain points out, even those aggressive numbers may not be enough to bridge the cost-to-revenue delta.Stay On the Cutting Edge: Get the Tom's Hardware NewsletterGet Tom's Hardware's best news and in-depth reviews, straight to your inbox.Contact me with news and offers from other Future brandsReceive email from us on behalf of our trusted partners or sponsorsBy submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over.If anything, this report reinforces the tension at the heart of the current AI cycle. On one side, you have infrastructure that takes years to build, staff, and power. On the other hand, you have models that double in size and cost every six months, giving credence to the fears of an AI bubble that, if it continues to grow, will mean high-end silicon and the memory and cooling that come with it could stay both scarce and expensive well into the next decade.Follow Tom's Hardware on Google News, or add us as a preferred source, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!
TOPICS
Data Center
See all comments (14)
Luke JamesSocial Links NavigationContributorLuke James is a freelance writer and journalist.Â  Although his background is in legal, he has a personal interest in all things tech, especially hardware and microelectronics, and anything regulatory.
Read more
U.S. AI boom is completely upending the electricity market
AI's soaring energy consumption causing skyrocketing power bills for households across the US
EU readies $30 billion investment in gigawatt AI data centers
Nvidia and OpenAI forge $100 billion alliance to deliver 10 gigawatts of Nvidia hardware for AI datacenters
Elon Musk says xAI will deploy 50 million H100 GPUs in the next 5 years, doubles down on goal as Grok 2.5 goes open source
Elon Musk says xAI is targeting 50 million 'H100 equivalent' AI GPUs in five years
Latest in Tech Industry
Entire website dedicated to helping San Francisco motorists avoid parking tickets goes live
Nvidia's $100 billion investment in OpenAI raises big antitrust concerns
Nvidia promises its $100 billion OpenAI deal won't impact GPU supply
OpenAI makes flurry of deals in drive towards for-profit model
MediaTek reportedly mulling US chip production
Nvidia and OpenAI forge $100 billion alliance to deliver 10 gigawatts of Nvidia hardware for AI datacenters
Latest in News
Intel might be working on its own multi-frame generation tech â€” "XeSS MFG" appears in Arc driver files
GPD Win 5 handheld soars above the competition with Strix Halo inside
China's latest GPU arrives with claims of CUDA compatibility and RT support
AI buildouts need $2 trillion in annual revenue to sustain growth, but massive cash shortfall looms
The end of EU-imposed cookie consent pop-ups could be nigh
Intel drops day zero game driver support for chips released last year
14 Comments
Comment from the forums
S58_is_the_goat
Ai this ai that... but how does ai make money? No clue... ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£
Reply
Marlin1975
File that under "no kidding".
It the same as the internet bubble. Most will fail and maybe a couple will survive in some form.
Just another bubble holding up a hollow market.
Reply
blitzkrieg316
Exactly. Supply, both chip and power, will be the ultimate bottleneck. The worst part is that this inevitably drives up costs which are ALWAYS passed onto the end consumer. Right now everyone is seeing the WOW factor and are using "older" hardware. The wall will come in the next 2-3 years when costs are so astronomical to upgrade that end users and startups can't compete... we need a massive improvement or risk catastrophe... All we can hope for is that China crashes first or we are screwed
Reply
DougMcC
This is kind of the opposite of bubble though. Bubble is -> no fundamental market demand, hype driving investment. AI is -> so much market demand the infrastructure investment can't keep up. Companies are trying to buy a LOT more AI than is currently available, to do real work.
Reply
bill001g
We need to take these AI entrepreneur into a room and ask them if they are underpants gnomes. I suspect many are too young to have seen that episode of south park.
Not even something new. They always said you made more money selling shovels to gold miners during the gold rush than actually mining. You would think NVIDIA themselves would have AI data centers if they thought there was a way to make more profit than just selling the chips.
Reply
DavidM012
That's like saying there's money in computers but only Bill Gates really made big money while in reality there are jobs in warehouses packing boxes or assembling components for insufferable wages.
Why did they say money doesn't grow on trees if you could actually harvest fruit from an orchard? If you grow apple or pear trees you get a slight seasonal payoff in conference pears or such. or even quince and damson jam that you don't have to buy in the supermarket. Not a fortune but frees up a bit of resource to invest somewhere else.
Compared to AI the thing we wanted was some sort of automation to do precision work or some sort of problem solving companion like a walking calculator that could process real world input without fiddly programming and understand human language(s), interpret, converse, contain a database, and easy to use, portable or assist in survival situations like K.I.T.T. from knight rider who still only exists in the realms of sci fi in terms of the versatility in spite of a desire for automated driverless vehicles even if the AI is a good driver it still doesn't account for every variable in traffic collisions eg. landslides, missiles, sinkholes, floods or earthquakes.
Or have an em warfare suite and laser cannon for the *rare eventuality that it might be required on a typical commute.
AI and automation is a bit like a tape recorder then. It simply records the thoughts of the engineer like the robot chef records the movements of the chef and plays them back. Where it is still not clear that it is really thinking for itself and adapting to real world disruptions in it's programmed routine .
Well the 4 legged robot things that can be kicked and pushed around sort of adapt to quite a strong disruptive force and continue walking. and can get up off the floor. But in essence, that is what they have been designed to do and that design does not automatically transfer to other AI applications.
Just like most products different tools are made for different purposes and tools can be made to make more finer tools which is how they make microscopic tools.
Where it's able to look at a scenario and then assemble various components for a specific purpose? Like a crow can get stones into a jar to raise the water level or a stick to poke a morsel out of a tube.. the AI does not need food. Does it apprehend that it needs power to function and must behave in a certain manner to obtain it?
Does it have a will to live? But the investors have a will to turn a coin. So of that investment some people are getting paid to create tools and software but I don't see where they're making a tool that can automatically make tools without any user input if presented with a problem.
In any case K.I.T.T's armored shell was not intelligent that was the engineer contributing to K.I.T.T's survivability while K.I.T.T might have been able to use it intelligently by knowing how tolerant it is still got dinged 2 or 3 times in the course of the season arcs.
So in the end it's basically engineers teaching machines their skills and placing them in situations where the engineer can't be . eg. in two places at once so then it's basically the same as teaching people skills and putting them in situations where the skilled engineer can't be as proxies.
You basically just want more cheap skilled workers to maximize YOUR profit and free up YOUR time. Without all the colds' flu sick attitude and sass. That simply does what it's told. And actually can do what it's told.
Still you have to break down the tasks into chunks and procedures to follow.. someone has to do the groundwork programming like you need kindling to start a fire.
Reply
SomeoneElse23
There is no 'thinking' in AI as we have it today. There's a whole lot of 'A' and not much 'I'.
What I think we want is more of Star Trek's "Computer, ...".
We certainly don't want, "I'm sorry, I can't do that Dave."
And we really really don't want replicators from SG1.
What we have today nowhere near any of those. Just a regurgitation of existing data, all data as we know it (whether it's true or not), in a more usable human interface than search engines.
But still a whole lot of 'A' and not much 'I'.
And, so far, I'm not convinced we'll ever see anymore than that.
Reply
logainofhades
SomeoneElse23 said:There is no 'thinking' in AI as we have it today. There's a whole lot of 'A' and not much 'I'.
What I think we want is more of Star Trek's "Computer, ...".
We certainly don't want, "I'm sorry, I can't do that Dave."
And we really really don't want replicators from SG1.
What we have today nowhere near any of those. Just a regurgitation of existing data, all data as we know it (whether it's true or not), in a more usable human interface than search engines.
But still a whole lot of 'A' and not much 'I'.
And, so far, I'm not convinced we'll ever see anymore than that.
I am more worried about Skynet.
Reply
DavidM012
but we do want factories and we don't want miserable repetitive jobs but so will always need engineers to design tools so maybe other applications like assisting the engineer in 3d design that's simply using more cpu and so more cpus are being produced in the form of npus and that's simply requiring more power so basically it's where a certain supply chain or sector of the economy is getting a boost but not necessarily every sector and also producing more pollutants as a by product of industry basically it's like the difference between infantry and fighter pilots.
The infantry takes the flak in the grime and mud while the fighter pilots soar overhead although also can be at risk in a dogfight while artillery is a good ranged weapon that can be automated there are probably one or two rare machines that can lob 10 rounds a minute where the artillerymen have to struggle with shells weighing hundreds of pounds maybe as well as assembling and lugging guns around.
It is supposed to be about leveraging the strength of machines with brainpower to do heavy work to replace manpower basically and so reduce their risk profile and remove them from threatening environments.
So what's useful in a domestic environment? If you combine some technologies like the robot chef hands and facial recognition for example? You could be inadvertently creating a murder weapon if it could be hacked and triggered by proximity to a recognized face.
If it shipped with typically lackadaisical industry defaults. The first aeroplanes crashed but they didn't abandon air travel they refined it. Until the concorde. Then they abandoned the Concorde. But not aeroplanes in general.
Reply
DavidM012
So if the problem you want to solve is unforseen consequences or uncontrolled, program one that cares enough about quality.. not obsessive.. but dedicated.
Reply
View All 14 Comments
Show more comments
Tom's Hardware is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site.
Terms and conditions
Contact Future's experts
Privacy policy
Cookies policy
Accessibility Statement
Advertise with us
About us
Coupons
Careers
Â©
Future US, Inc. Full 7th Floor, 130 West 42nd Street,
New York,
NY 10036.