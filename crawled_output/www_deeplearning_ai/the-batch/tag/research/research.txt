Machine Learning Research | The Batch✨ New course! Enroll in Building and Evaluating Data AgentsExplore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlog✨ AI Dev x NYCCommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeMachine Learning Research485 PostsMachine Learning ResearchTransformers Energized: Energy-Based Transformers (EBTs) use gradient descent to gradually predict the next tokenA new type of transformer can check its work. Instead of guessing the next output token in one shot like a typical transformer, it starts with a rough version of the token and improves it step by step.Sep 17, 2025Machine Learning ResearchQwen3-Next Accelerates: Alibaba’s new model uses hybrid attention layers and a sparse MoE architecture for speed and performanceAlibaba updated its popular Qwen3 open-weights models with a number of fresh, speed-boosting tweaks.Sep 17, 2025Machine Learning Research10 Million Tokens of Input Context: ATLAS, a transformer-like architecture, can process a context window as large as ten million tokensAn alternative to attention enables large language models to track relationships among words across extraordinarily wide spans of text.Sep 10, 2025Machine Learning ResearchCybersecurity for Agents: Meta releases LlamaFirewall, an open-source defense against AI hijackingAutonomous agents built on large language models introduce distinct security concerns. Researchers designed a system to protect agents from common vulnerabilities.Sep 3, 2025Machine Learning ResearchBetter Image Processing Through Self-Supervised Learning: Meta’s DINOv3 gets an updated loss term and improved vision performanceDINOv2 showed that a vision transformer pretrained on unlabeled images could produce embeddings that are useful for a wide variety of tasks. Now it has been updated to improve the performance of its embeddings in segmentation and other vision tasks.Aug 27, 2025Machine Learning ResearchDoes Your Model Generalize or Memorize: Researchers find models with more parameters copy more bits from training setsBenchmarks can measure how well large language models apply what they’ve learned from their training data to new data, but it’s harder to measure the degree to which they simply memorized their training data. New work proposes a way to gauge memorization.Aug 20, 2025Machine Learning ResearchMixture of Video Experts: Alibaba’s Wan 2.2 video models adopt a new architecture to sort noisy from less-noisy inputsThe mixture-of-experts approach that has boosted the performance of large language models may do the same for video generation.Aug 20, 2025Machine Learning ResearchTraining Data for Coding Assistants: Stanford and Alibaba build bug fixing dataset and pipeline to train AIA bottleneck in fine-tuning large language models for software engineering is building a dataset that can show them how to edit code, search for subroutines, write test scripts, control a terminal, manage a file system, and so on. Researchers built a pipeline that produces such data automatically.Aug 13, 2025Machine Learning ResearchGPT-5 Takeoff Encounters Turbulence: OpenAI's new model hits turbulence with cost, performance, and API complaintsOpenAI launched GPT-5, the highly anticipated successor to its groundbreaking series of large language models, but glitches in the rollout left many early users disappointed and frustrated.Aug 13, 2025Machine Learning ResearchRobot Surgeon Cuts and Clips: Doctors at Stanford, Johns Hopkins, and Optosurgical operate on animal organs without human interventionAn autonomous robot performed intricate surgical operations without human intervention.Aug 6, 2025Machine Learning ResearchGLM-4.5, an Open, Agentic Contender: Zhipu AI (Z.ai) releases open-weights GLM-4.5 models that perform comparably to the latest from Claude and DeepSeekThe race is on to develop large language models that can drive agentic interactions. Following the one-two punch of Moonshot’s Kimi K2 and Alibaba’s Qwen3-235B-A22B update, China’s Z.ai aims to one-up the competition.Aug 6, 2025Machine Learning ResearchThe Re-Opening of OpenAI: GPT-OSS, OpenAI’s first open-weights models since GPT-2, arrives in 120 billion and 20 billion parameter versionsThe “open” is back in play at OpenAI.Aug 6, 2025Machine Learning ResearchPeople With AI Friends Feel Worse: Study shows heavy use of AI companions correlates with lower emotional well-beingPeople who turn to chatbots for companionship show indications of lower self-reported well-being, researchers found.Jul 30, 2025Machine Learning ResearchQwen3’s Agentic Advance: Inside Alibaba's new open-weights models, including the 480 billion parameter Qwen3-CoderLess than two weeks after Moonshot’s Kimi K2 bested other open-weights, non-reasoning models in tests related to agentic behavior, Alibaba raised the bar yet again.Jul 30, 2025Machine Learning ResearchAgentic System for Harder Problems: Google’s AlphaEvolve uses LLMs and evolutionary code to solve complex math and speed up Gemini trainingLLMs can struggle with difficult algorithmic or scientific challenges when asked to solve them in a single attempt. An agentic workflow improved one-shot performance on hard problems both theoretical and practical.Jul 23, 2025Load MoreSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout