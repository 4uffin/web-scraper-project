2-agent architecture: Separating context from execution in AI systems | InfoWorld
Topics
Spotlight: IT CareersVideosNewslettersResources
AboutAbout UsAdvertiseContact UsEditorial Ethics PolicyFoundry CareersNewslettersContribute to InfoWorldReprintsPoliciesTerms of ServicePrivacy PolicyCookie PolicyCopyright NoticeMember PreferencesAbout AdChoicesYour California Privacy RightsOur NetworkCIOComputerworldCSONetwork WorldMoreNewsFeaturesBlogsBrandPostsEventsVideosEnterprise Buyer’s Guides
Close
AnalyticsArtificial IntelligenceGenerative AICareersCloud ComputingData ManagementDatabasesEmerging TechnologyTechnology IndustrySecuritySoftware Development Microsoft .NETDevelopment ToolsDevopsOpen SourceProgramming LanguagesJavaJavaScriptPythonIT LeadershipEnterprise Buyer’s Guides
Back
Close
Back
Close
Popular Topics
Artificial IntelligenceCloud ComputingData ManagementSoftware Development
Search
Topics
Spotlight: IT CareersVideosNewslettersResourcesAboutPoliciesOur NetworkMore
Back
Topics
AnalyticsArtificial IntelligenceGenerative AICareersCloud ComputingData ManagementDatabasesEmerging TechnologyTechnology IndustrySecuritySoftware DevelopmentMicrosoft .NETDevelopment ToolsDevopsOpen SourceProgramming LanguagesJavaJavaScriptPythonIT LeadershipEnterprise Buyer’s Guides
Back
AboutAbout UsAdvertiseContact UsEditorial Ethics PolicyFoundry CareersNewslettersContribute to InfoWorldReprints
Back
PoliciesTerms of ServicePrivacy PolicyCookie PolicyCopyright NoticeMember PreferencesAbout AdChoicesYour California Privacy Rights
Back
Our NetworkCIOComputerworldCSONetwork World
Back
MoreNewsFeaturesBlogsBrandPostsEventsVideosEnterprise Buyer’s Guides
Home
Blogs
New Tech Forum
2-agent architecture: Separating context from execution in AI systems
by									Jenil Shah
Contributor
2-agent architecture: Separating context from execution in AI systems
feature
Sep 15, 20258 minsArtificial IntelligenceGenerative AISoftware Development
AI works better when one agent thinks and another acts — splitting context from execution makes conversations smoother and smarter.
Credit: 															Lightspring / Shutterstock
When I first started experimenting with voice AI agents for real-world tasks like restaurant reservations and customer service calls, I quickly ran into a fundamental problem. My initial monolithic agent was trying to do everything at once: understand complex customer requests, research restaurant availability, handle real-time phone conversations and adapt to unexpected responses from human staff. The result was an AI that performed poorly at everything.
After days of experimentation with my voice AI prototype — which handles booking dinner reservations — I discovered that the most robust and scalable approach employs two specialized agents working in concert: a context agent and an execution agent. This architectural pattern fundamentally changes how we think about AI task automation by separating concerns and optimizing each component for its specific role.
The problem with monolithic AI agents
My early attempts at building voice AI used a single agent that tried to handle everything. When a user wanted to book a restaurant reservation, this monolithic agent had to simultaneously analyze the request (“book a table for four at a restaurant with vegan options”), formulate a conversation strategy and then execute a real-time phone call with dynamic human staff.
This created two critical challenges that I experienced firsthand:
Missing context during live calls. The most painful problem was when new information surfaced during phone conversations that my agent wasn’t prepared for. A restaurant staff member would ask, “Do you have any allergies we should know about?” and my agent would freeze because they didn’t know the user’s dietary restrictions unless the user was actively listening to provide that information in real-time. I watched calls fail repeatedly because the agent couldn’t access crucial user preferences when humans asked unexpected but reasonable questions.
Conflicting processing speeds. Voice agents need to provide real-time responses during phone calls to feel natural in conversation. But gathering comprehensive context, analyzing user preferences and executing tasks with updated information takes significant processing time. The agent couldn’t simultaneously do deep context analysis and maintain the sub-two-second response times required for natural phone conversations.
The 2-agent architecture pattern
After rebuilding my system, I developed what I call the two-agent architecture. This approach creates specialized agents with distinct responsibilities that mirror how humans actually handle complex tasks.
Context agent: The strategic planner
The context agent operates like a research analyst, taking time to thoroughly understand the situation before any action occurs. In my restaurant reservation system, this agent performs deep analysis through a multi-stage pipeline.
The context agent engages in a natural conversation with the user to gather comprehensive information before any phone calls are made. Here’s how this typically unfolds:
Initial request gathering. When a user says, “I want to book dinner tonight,” the context agent asks clarifying questions: “How many people will be dining? What type of cuisine are you in the mood for? Any dietary restrictions I should know about? What time works best for you?”
Preference refinement. As the conversation develops, the agent digs deeper. If the user mentions “something healthy,” it might ask, “Are you looking for high-carb options, or do you prefer high-protein dishes? Any specific cuisines you’re avoiding?” This back-and-forth continues until the agent has a complete picture.
Research and validation. Using web search and other MCP tools, the context agent researches local restaurants that match the criteria, checks their current availability and reviews their menus for dietary accommodations. It might come back to the user with: “I found three restaurants with excellent vegan options. Would you prefer Thai or Italian cuisine?”
Strategy formulation. Once the agent determines it has sufficient context — knowing the party size, cuisine preference, dietary restrictions, preferred time, backup times and even backup restaurant options — it creates a detailed execution plan for the phone call.
The key insight is that this entire context-gathering conversation happens before any restaurant is called, ensuring the execution agent has everything it needs for a successful phone interaction.
Execution agent: the real-time performer
While the context agent thinks deeply, the execution agent handles the actual phone conversation. In my system, this agent receives the enriched context and immediately begins the call, making split-second decisions during the interaction.
I’ve watched this agent handle scenarios like:
Restaurant staff saying “We’re fully booked at 6pm” → immediately offering alternative times from the context plan.
Being asked “What’s your phone number?” → providing the customer’s number from the context.
Getting transferred to a manager → re-establishing rapport and context without missing a beat.
Discovering the restaurant doesn’t have good vegan options → politely ending the call and moving to the backup restaurant
The key insight I learned is that real-time conversation requires a completely different type of intelligence than strategic planning. The execution agent needs to be fast, adaptive and focused solely on the immediate interaction.
Implementation patterns from the field
Through building and testing my voice AI system, I’ve identified two primary implementation patterns:
Sequential processing
This is the approach I use for complex scenarios. The context agent has a complete conversation with the user, gathers all necessary information, researches options using web search tools and creates a comprehensive execution plan. Only after this entire process is finished does the execution agent begin making phone calls. This ensures maximum context quality but takes more time upfront.
Continuous collaboration
For long-running customer service calls, both agents work together throughout the interaction. The context agent provides ongoing analysis while the execution agent handles the conversation and provides real-time feedback about what’s working.
Real-world benefits I’ve observed
The two-agent architecture has delivered measurable improvements in my voice AI system:
Specialized optimization. My context agent now uses a deliberate, accuracy-focused model configuration, while my execution agent uses a faster, conversation-optimized setup. This specialization improved both context quality and conversation naturalness.
Independent scaling. During peak dinner reservation hours, I can scale up execution agents to handle more simultaneous calls while maintaining fewer context agents for the research-heavy work.
Improved reliability. When my context agent fails to find restaurant information, the execution agent can still make the call and gather information directly. When the execution agent encounters an unexpected conversation flow, it doesn’t break the entire system.
Enhanced debugging. I can now easily identify whether failures stem from poor context analysis (wrong restaurant information) or execution problems (awkward conversation flow). This separation has dramatically reduced my debugging time.
Monitoring what matters
I track different metrics for each agent to understand system performance:
For the context agent, I monitor processing time (how long context analysis takes), context quality scores (completeness of restaurant research) and strategy complexity (how detailed the execution plan is).
For the execution agent, I track conversation success rates, call duration and how often backup strategies are needed. This separation allows me to optimize each agent independently – improving context quality doesn’t affect conversation speed and vice versa.
The path forward
The two-agent architecture represents a fundamental shift in how we design AI systems for complex, real-world tasks. I’ve learned that separating context analysis from execution creates systems that are more reliable, scalable and maintainable than traditional monolithic approaches.
The key to success lies in clearly defining the boundaries between context and execution, implementing robust communication protocols and optimizing each agent for its specific role. When done correctly, the result is an AI system that combines thoughtful analysis with responsive execution, much like how humans naturally approach complex tasks.
For any developer building AI systems that need to handle real-world complexity, I recommend starting with this architectural pattern. The separation of concerns will save you countless hours of debugging and create a foundation that scales as your use cases grow.
This article is published as part of the Foundry Expert Contributor Network.Want to join?
Related content
news
Microsoft Marketplace opens for AI apps, agents By Paul Krill
Sep 25, 2025 2 mins
Generative AI
Microsoft .NET
Microsoft Azure
news
GitHub Copilot-backed app modernization available for Java, .NET By Paul Krill
Sep 25, 2025 1 min
Generative AI
GitHub
Java
how-to
Introduction to Java records: Simplified data-centric programming in Java By Rafael del Nero
Sep 25, 2025 10 mins
Java
Programming Languages
Software Development
analysis
Spec-driven AI coding with GitHub’s Spec Kit By Simon Bisson
Sep 25, 2025 9 mins
Artificial Intelligence
Development Tools
Software Development
Other Sections
Resources
Videos
Spotlight: IT Careers
by
Jenil Shah
Contributor
Follow Jenil Shah on LinkedIn
Jenil Shah is a software engineering manager for Amazon, specializing in recommendation systems, personalization and generative AI applications. He has more than a decade of experience applying machine learning and AI in real-world systems. The views expressed are his own and do not represent those of his employer.
More from this author
featureThe shift from AI code generation to true development partnership Aug 21, 2025 9 mins
Show me morePopularArticlesVideos
feature
The best new features in Postgres 18 By Tom KincaidSep 25, 20256 mins
DatabasesPostgreSQLRelational Databases
news
Google releases MCP server to Data Commons public data sets By Paul KrillSep 24, 20252 mins
Artificial IntelligenceDevelopment ToolsGenerative AI
news
Open source registries signal shift toward paid models as AI strains infrastructure By Gyana SwainSep 24, 20255 mins
Artificial IntelligenceOpen Source
video
Python 3.14's live debugging interface Sep 23, 20254 mins
Python
video
Easier Chrome browser automation with PyDoll Sep 16, 20254 mins
Python
video
How to use Rust workspaces to speed up compile times Sep 9, 20253 mins
Python
Sponsored Links
Secure AI by Design: Unleash the power of AI and keep applications, usage and data secure.
Solve your most complex IT challenges with solutions that simplify your modernization journey.
Empower your cybersecurity team with expert insights from Palo Alto Networks.
About
About Us
Advertise
Contact Us
Editorial Ethics Policy
Foundry Careers
Reprints
Newsletters
BrandPosts
Policies
Terms of Service
Privacy Policy
Cookie Policy
Copyright Notice
Member Preferences
About AdChoices
Your California Privacy Rights
Privacy Settings
Our Network
CIO
Computerworld
CSO
Network World
FacebookXYouTubeGoogle NewsLinkedIn
© 2025
FoundryCo, Inc. All Rights Reserved.