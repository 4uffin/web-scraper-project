AI-generated 'workslop' is destroying productivity and teams, researchers saySkip NavigationSuccessStartupsSide HustlesPower PlayersLeadershipMoneyEarnSpendSave and InvestBecome Debt-FreeWorkLand the JobGet AheadLevel UpScience of SuccessLifePop Culture and MediaPsychology and RelationshipsHealth and WellnessReal EstateVideoMost PopularCNBC TVCoursesMenuSEARCHCNBC.COMRelated StoriesWork3 strategies that help this job seeker stand out and land interviewsLand the JobDon't make these AI mistakes on your resume, career experts sayLeadershipEx-Google exec: The idea that AI will create new jobs is '100% crap'—even CEOs are at riskAI at WorkThese 10 jobs are the least AI-safe, according to new Microsoft reportWorkLaid off managers are fighting for shrinking pool of jobsWorkAI-generated 'workslop' is here. It's killing teamwork and causing a multimillion dollar productivity problem, researchers sayPublished Tue, Sep 23 20252:28 PM EDTJennifer LiuShareShare Article via FacebookShare Article via TwitterShare Article via LinkedInShare Article via EmailJose Luis Pelaez Inc | Digitalvision | Getty ImagesSomething strange was happening at Jeff Hancock's work.It was 2022, just after OpenAI's release of ChatGPT to the masses, and the Stanford professor noticed something was off in the research assignments he was grading. "They looked pretty good, but not quite right," Hancock tells CNBC Make It. "And then because I had 100 students, I could see that 10 other assignments looked exactly the same with the same sort of not-quite-rightness."The papers in question seemed to have a lot of text without saying anything substantive to "advance the work," and they all did so in the same overly wordy style.Kate Niederhoffer felt the same sinking feeling of suspicion when she was once asked to speak about her research, but the request summarized her studies in a way that revealed they didn't actually know her work.Reading messages that missed the mark "felt like deep effort," Niederhoffer says. "I'm a quick reader, normally, so I [thought] 'Why is this feeling so effortful? Also this is so confusing?'"Niederhoffer and Hancock now have a name for this phenomenon, the feeling you get when you're reading a message or document that's so convoluted or incomplete in thought that you start to wonder, "Wait, did a human even write this, or is this AI?"It's called workslop, and it's killing teams and productivity across all kinds of businesses, they say.40% of people have received workslop in the last monthWorkslop refers to "AI-generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task."That's according to new research from BetterUp, where Niederhoffer is vice president of their research labs, and Stanford Social Media Lab, where Hancock is the founding director.It created a situation where I had to decide whether I would rewrite it myself, make him rewrite it, or just call it good enough.Finance workerLike AI art or features of the so-called slop life that came before it, workslop looks familiar in an off-kilter, uncanny way but at its core is devoid of meaning. Think: long, fancy-sounding, copy-pasted language that doesn't say anything.Some 40% of people say they've received workslop in the last month, according to a recent BetterUp and Stanford survey of 1,150 full-time U.S. workers. These staffers estimate an average of 15% of the content they receive qualifies as low-effort, unhelpful, AI-generated work; it's happening across industries but is especially prominent in professional services and technology.One survey respondent, a finance worker, recalled how receiving AI-generated work from a colleague led to more work for them: "It created a situation where I had to decide whether I would rewrite it myself, make him rewrite it, or just call it good enough."Another respondent, a director in retail, said they wasted time following up on information they were sent and doing their own research. "I then had to waste even more time setting up meetings with other supervisors to address the issue. Then I continued to waste my own time having to redo the work myself."There are tell-tale signs of workslop, Hancock says, including "purple prose," like using three paragraphs of text when one bullet point would suffice.It may appear in different forms, from bad code to decks with incomplete information or just strangely worded emails, but it all has the same effect of adding work onto the recipient to make sense of it all. Ultimately, it can erode trust and productivity.Niederhoffer has herself judged the people who send her workslop. "Why did they do this?" she'd wonder. "Can they not complete the job themselves? I don't trust them. I don't want to work with them again."The end result is "confusion, annoyance, wasted effort and then some serious layers of judgment," she says.The $9 million workslop productivity taxAI use has doubled at work since 2023 from 21% to 40%, per Gallup, yet 95% of organizations don't see a measurable return on their investment in the tech, according to a recent MIT Media Lab report. Workslop could be a big reason why, BetterUp and Stanford researchers say.People who've encountered it say they spend an average of one hour and 56 minutes dealing with the aftermath of it; that adds up to a roughly $186 invisible tax per month, based on their self-reported salaries.For an organization of 10,000 workers, that's a $9 million hit to productivity in a year, researchers say.(Worth noting, this doesn't account for any productivity gains reported by companies or employees.)Now that [the effort] piece is gone, I can generate a lot of useless or unproductive content very easily.Jeff HancockFounding director of the Stanford Social Media LabBeyond the financial cost, there's an emotional one. Recipients of workslop say it takes time and mental energy to figure out how to diplomatically address the subpar work with their colleagues; 53% report being annoyed, 38% confused and 22% offended.Receiving it makes people rethink their colleagues' abilities: Roughly half of workers say they consider their co-workers less creative, capable and reliable after receiving workslop from them. About 1 in 3 say they notify their teammates or bosses after receiving confusing AI-generated work, and a similar share are less likely to want to work with the other person afterward.And though sloppy work has been around forever, AI takes it to another level."For me to produce sloppy work, I still have to put in a fair bit of effort. I have to write it. It can be thoughtless, but it still requires effort," Hancock says. "Now that [the effort] piece is gone, I can generate a lot of useless or unproductive content very easily."The phenomenon's human cost is driven by "shifting the burden onto the other person without recognizing that impact implicitly," Niederhoffer says. "People forget that because we're thinking of [AI] as a tool with which we alone work, but it's actually mediating human-to-human work."Reducing workslopMinimizing low-quality AI-generated work, and all the consequences that come with it, is up to organizations that bring AI into the fold, researchers say.Businesses should focus on an organized approach to adopting and promoting AI at work, Hancock says. Without guidance and leadership, he says, workers may act out of fear that if they don't use AI they'll be replaced, but if they do, they'll be judged for it.What reduces workslop is "a team's commitment to task quality," Hancock says. Teams should spend time talking to one another about how they use AI and critiquing the best applications for their needs.[AI] can be incredible, but it's in stark contrast to this really copy-and-paste mode, where you just let the tool do all the work for you, and you forget to let it augment your human competencies.Kate NiederhofferVP of BetterUp LabsThat also requires being forthcoming about when and where you're using AI. Say you were pressed for time and used a generative AI chatbot to complete a presentation deck, for example. If you tell your colleague that the work you're sending is AI-generated, they can have a better sense of what prompts you were working with and what your goal was and fill in any missing gaps, Hancock says.Leaders should focus on human agency and encourage a "pilot mindset" to see how tools can give them more control in their workplace, Niederhoffer says. Managers should be able to provide specific reasons why they want to use certain AI tools for certain projects, and have clear messages on the guidelines, policies and training that will accompany usage, she says.Having high agency over AI "can be incredible," Niederhoffer says, "but it's in stark contrast to this really copy-and-paste mode, where you just let the tool do all the work for you, and you forget to let it augment your human competencies."Want to be your own boss? Sign up for Smarter by CNBC Make It's new online course, How To Start A Business: For First-Time Founders. Find step-by-step guidance for launching your first business, from testing your idea to growing your revenue. Sign up today with coupon code EARLYBIRD for an introductory discount of 30% off the regular course price of $127 (plus tax). Offer valid September 16 through September 30, 2025.Plus, sign up for CNBC Make It's newsletter to get tips and tricks for success at work, with money and in life, and request to join our exclusive community on LinkedIn to connect with experts and peers.VIDEO7:0307:03I left the U.S. for Lisbon – and work only 20 hours a weekMillennial MoneyStay in the loopGet Make It newsletters delivered to your inboxSign UpAbout UsLearn more about the world of CNBC Make ItLearn MoreFollow UsCNBC.COMJoin the CNBC Panel© 2025 CNBC LLC. All Rights Reserved. A Division of NBC UniversalPrivacy PolicyAd ChoicesCA NoticeTerms of ServiceContact