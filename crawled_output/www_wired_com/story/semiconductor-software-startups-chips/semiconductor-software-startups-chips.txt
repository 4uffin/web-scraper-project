A Former Apple Luminary Sets Out to Create the Ultimate GPU Software | WIREDSkip to main contentMenuSECURITYPOLITICSTHE BIG STORYBUSINESSSCIENCECULTUREREVIEWSMenuAccountAccountNewslettersSecurityPoliticsThe Big StoryBusinessScienceCultureReviewsChevronMoreExpandThe Big InterviewMagazineThe New Era of Business TravelEventsWIRED InsiderWIRED ConsultingNewslettersPodcastsVideoMerchSearchSearchSign InSign InLauren GoodeBusinessSep 24, 2025 12:00 PMA Former Apple Luminary Sets Out to Create the Ultimate GPU SoftwareDemand for AI chips is booming—and so is the need for software to run them. Chris Lattner’s startup Modular just raised $250 million to build the best developer tools for AI hardware.FacebookXEmailSave StoryModular cofounders Chris Lattner, CEO, and Tim Davis, president.Photograph: Carolyn Fong; Courtesy of ModularSave StorySave this storySave StorySave this storyAt a certain point between building Apple’s developer tools, leading a core part of Google’s AI infrastructure team, and clashing with Elon Musk during a stint as Tesla’s Autopilot chief, Chris Lattner’s vision for his life’s work started to come into focus. AI was taking over the world, and demand was growing for the chips that powered it. But the software stack for those chips was dominated by just a few big companies. Would developers be able to easily run their code across all the different chips dotting the AI landscape?Lattner’s answer to that question is Modular, a software startup he founded in 2022 with his former Google colleague Tim Davis. Modular makes a unifying software layer that helps cloud businesses squeeze as much juice as possible out of GPUs and CPUs—the high-powered chips that underpin generative AI. The startup has also built a new coding language, based on Python, that lets developers use a single language to build AI apps that run across multiple GPUs and CPUs. Modular’s basic premise is that if a developer builds an app for one chip, they shouldn’t have to jump through hoops in order to run it on another vendor’s chip.But Modular’s long-term goal is even more ambitious: to loosen the software choke hold that companies like Nvidia and AMD have on the industry, and become the de facto software for AI chips.“Our thesis is that the need for compute power is just exploding, but there is no unified compute platform,” Lattner says. “Sovereign AI will be everywhere. There will be many Stargates. But there will be different types of chips optimized for different use cases, and there needs to be a unified layer for that.”There are early signs that Modular’s thesis bears out. AI giants like Nvidia, AMD, and Amazon have partnered with the startup to test the waters. The GPU cluster company SF Compute also worked with Modular to build what they claim is the world’s cheapest API for large AI models. As of this week, Modular’s developer platform now supports Apple Silicon GPUs, in addition to Nvidia and AMD chips.Building on this momentum, Modular just raised $250 million in venture capital funding, its third round of financing in three years, bringing its total valuation to $1.6 billion. The round was led by the Pittsburgh-based US Innovative Technology Fund. DFJ Growth also invested, along with existing investors General Catalyst, Greylock, and GV (formerly known as Google Ventures).“We’ve spent a bunch of time and energy trying to figure out what makes a startup in this space interesting, and with every company that has tried to build their own chip—and even the big players, like AMD and Nvidia—it all comes back to the software,” says Dave Munichiello, managing partner at GV. “Chris convinced me that the software was the most interesting and valuable problem to address.”It might be valuable—but it’s also extremely complicated. Part of that complication stems from Nvidia’s closed ecosystem. Nvidia’s chips make up the vast majority of the GPU market, but the company’s 20-year-old proprietary software platform, CUDA, keeps developers locked in. AMD’s software platform for high-performance computing, called ROCm, differs in that it’s open source. This allows developers to more easily move code to different chips.Still, developers say that bringing code from Nvidia’s CUDA to ROCm isn’t a smooth process, which means they typically focus on building for just one chip vendor.“ROCm is amazing, it’s open source, but it runs on one vendor’s hardware,” Lattner told the crowd at AMD’s Advancing AI event in June. Then he made his pitch for why Modular’s software is more portable and makes GPUs that much faster.Lattner’s talk at AMD is representative of the kind of dance that Lattner and Davis need to do as they spread the Modular gospel. Today, Nvidia and AMD are both crucial partners for the firm. In a future universe, they’re also direct competitors. Part of Modular’s value proposition is that it can ship software for optimizing GPUs even faster than Nvidia, as there might be a months-long gap between when Nvidia ships a new GPU and when it releases an “attention kernel”—a critical part of the GPU software.“Right now Modular is complimentary to AMD and Nvidia, but over time you could see both of those companies feeling threatened by ROCm or CUDA not being the best software that sits on top of their chips,” says Munichiello. He also worries that potential cloud customers may balk at having to pay for an additional software layer like Modular’s.Writing software for GPUs is also something of a “dark art,” says Waleed Atallah, the cofounder and CEO of Mako, a GPU kernel optimization company. “Mapping an algorithm to a GPU is an insanely difficult thing to do. There are a hundred million software devs, 10,000 who write GPU kernels, and maybe a hundred who can do it well.”Mako is building AI agents to optimize coding for GPUs. Some developers think that’s the future for the industry, rather than building a universal compiler or a new programming language like Modular. Mako just raised $8.5 million in seed funding from Flybridge Capital and the startup accelerator Neo.“We’re trying to take an iterative approach to coding and automate it with AI,” Atallah says. “By making it easier to write the code, you exponentially grow the number of people who can do that. Making another compiler is more of a fixed solution.”Lattner notes that Modular also uses AI coding tools. But the company is intent on addressing the whole coding stack, not just kernels.There are roughly 250 million reasons why investors think this approach is viable. Lattner is something of a luminary in the coding world, having previously built the open source compiler infrastructure project LLVM, as well as Apple’s Swift programming language. He and Davis are both convinced that this is a software problem that must be solved outside of a Big Tech environment, where most companies focus on building software for their own technology stack."When I left Google I was a little bit depressed, because I really wanted to solve this,” Lattner says. “What we realized is that it’s not about smart people, it’s not about money, it’s not about capability. It’s a structural problem.”Munichiello shared a mantra common in the tech investing world: He says he’s betting on the founders themselves as much as their product. “He’s highly opinionated and impatient, and also right a lot of the time,” Munichiello said of Lattner. “Steve Jobs was also like that—he didn’t make decisions based on consensus, but he was often right.”You Might Also Like …In your inbox: Will Knight's AI Lab explores advances in AITesla's trillion-dollar bet that it's more than just carsBig Interview: Hasan Piker will never run for officeThe doomers who insist AI will kill us allWatch: Uncanny Valley live with Jack Conte, CEO of PatreonLauren Goode is a senior correspondent at WIRED covering all things Silicon Valley, including artificial intelligence, venture capital, startups, workplace culture, and the Bay Area's most interesting people and trends. She previously worked at The Verge, Recode, and The Wall Street Journal. Please send story tips (no PR pitches) to ... Read MoreSenior CorrespondentXTopicschipsSemiconductorsNVIDIAStartupsAMDRead MoreMeet the Guys Betting Big on AI Gambling AgentsOnline gambling is a massive industry. The AI boom keeps booming. It was only a matter of time before people tried to put them together.Distillation Can Make AI Models Smaller and CheaperA fundamental technique lets researchers use a big, expensive model to train another model for less.The United Arab Emirates Releases a Tiny But Powerful AI ModelK2 Think compares well with reasoning models from OpenAI and DeepSeek but is smaller and more efficient, say researchers based in Abu Dhabi.AI Is Eliminating Jobs for Younger WorkersNew research from Stanford provides the clearest available evidence that AI is reshaping the workforce—but it’s complicated.OpenAI Teams Up With Oracle and SoftBank to Build 5 New Stargate Data CentersThe new sites will boost Stargate’s planned capacity to nearly 7 gigawatts—about equal to the output of seven large nuclear reactors.US Tech Giants Race to Spend Billions in UK AI PushMicrosoft and Nvidia unveiled plans to invest up to $45 billion in the UK during US President Donald Trump’s state visit.OpenAI Ramps Up Robotics Work in Race Toward AGIThe company behind ChatGPT is putting together a team capable of developing algorithms to control robots and appears to be hiring roboticists who work specifically on humanoids.Researchers Are Already Leaving Meta’s New Superintelligence LabCEO Mark Zuckerberg went on a recruiting blitz to lure top AI researchers to Meta. WIRED has confirmed that three recent hires have now resigned.Microsoft’s AI Chief Says Machine Consciousness Is an ‘Illusion’Mustafa Suleyman says that designing AI systems to exceed human intelligence—and to mimic behavior that suggests consciousness—would be “dangerous and misguided.”This AI-Powered Robot Keeps Going Even if You Attack It With a ChainsawA single AI model trained to control numerous robotic bodies can operate unfamiliar hardware and adapt eerily well to serious injuries.Inside the Man vs. Machine HackathonAt a weekend hackathon in San Francisco, more than 100 coders gathered to test whether they could beat AI—and win a $12,500 cash prize.YouTube Thinks AI Is Its Next Big BangOn its 20th anniversary, YouTube is venturing into an era of AI-generated video, and may never be the same.WIRED is where tomorrow is realized. It is the essential source of information and ideas that make sense of a world in constant transformation. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The breakthroughs and innovations that we uncover lead to new ways of thinking, new connections, and new industries.SubscribeNewslettersTravelFAQWIRED StaffWIRED EducationEditorial StandardsArchiveRSSAccessibility HelpReviewsBuying GuidesMattressesElectric BikesSoundbarsStreaming GuidesWearablesTVsCouponsGift GuidesAdvertiseContact UsManage AccountJobsPress CenterCondé Nast StoreUser AgreementPrivacy PolicyYour California Privacy Rights© 2025 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad ChoicesSelect international siteUnited StatesLargeChevronItaliaJapónCzech Republic & SlovakiaFacebookXPinterestYouTubeInstagramTiktok