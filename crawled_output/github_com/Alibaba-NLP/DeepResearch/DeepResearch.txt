GitHub - Alibaba-NLP/DeepResearch: Tongyi Deep Research, the Leading Open-source Deep Research Agent
Skip to content
Navigation Menu
Toggle navigation
Sign in
Appearance settings
Platform
GitHub Copilot
Write better code with AI
GitHub Spark
New
Build and deploy intelligent apps
GitHub Models
New
Manage and compare prompts
GitHub Advanced Security
Find and fix vulnerabilities
Actions
Automate any workflow
Codespaces
Instant dev environments
Issues
Plan and track work
Code Review
Manage code changes
Discussions
Collaborate outside of code
Code Search
Find more, search less
Explore
Why GitHub
Documentation
GitHub Skills
Blog
Integrations
GitHub Marketplace
MCP Registry
View all features
Solutions
By company size
Enterprises
Small and medium teams
Startups
Nonprofits
By use case
DevSecOps
DevOps
CI/CD
View all use cases
By industry
Healthcare
Financial services
Manufacturing
Government
View all industries
View all solutions
Resources
Topics
AI
DevOps
Security
Software Development
View all
Explore
Learning Pathways
Events & Webinars
Ebooks & Whitepapers
Customer Stories
Partners
Executive Insights
Open Source
GitHub Sponsors
Fund open source developers
The ReadME Project
GitHub community articles
Repositories
Topics
Trending
Collections
Enterprise
Enterprise platform
AI-powered developer platform
Available add-ons
GitHub Advanced Security
Enterprise-grade security features
Copilot for business
Enterprise-grade AI features
Premium Support
Enterprise-grade 24/7 support
Pricing
Search or jump to...
Search code, repositories, users, issues, pull requests...
Search
Clear
Search syntax tips
Provide feedback
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel
Submit feedback
Saved searches
Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our documentation.
Cancel
Create saved search
Sign in
Sign up
Appearance settings
Resetting focus
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
Dismiss alert
Alibaba-NLP
/
DeepResearch
Public
Notifications
You must be signed in to change notification settings
Fork
932
Star
12.6k
Tongyi Deep Research, the Leading Open-source Deep Research Agent
tongyi-agent.github.io/blog/introducing-tongyi-deep-research/
12.6k
stars
932
forks
Branches
Tags
Activity
Star
Notifications
You must be signed in to change notification settings
Code
Issues
28
Pull requests
5
Actions
Projects
0
Security
Uh oh!
There was an error while loading. Please reload this page.
Insights
Additional navigation options
Code
Issues
Pull requests
Actions
Projects
Security
Insights
Alibaba-NLP/DeepResearch
mainBranchesTagsGo to fileCodeOpen more actions menuFolders and filesNameNameLast commit messageLast commit dateLatest commit¬†History226 CommitsAgentAgent¬†¬†WebAgentWebAgent¬†¬†assetsassets¬†¬†evaluationevaluation¬†¬†inferenceinference¬†¬†.env.example.env.example¬†¬†.gitignore.gitignore¬†¬†README.mdREADME.md¬†¬†requirements.txtrequirements.txt¬†¬†View all filesRepository files navigationREADME
ü§ó HuggingFace ÔΩú
ModelScope
Introduction
We present
Tongyi DeepResearch, an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for long-horizon, deep information-seeking tasks. Tongyi DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA,xbench-DeepSearch, FRAMES and SimpleQA.
Tongyi DeepResearch builds upon our previous work on the
WebAgent project.
More details can be found in our üì∞¬†Tech Blog.
Features
‚öôÔ∏è Fully automated synthetic data generation pipeline: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.
üîÑ Large-scale continual pre-training on agentic data: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.
üîÅ End-to-end reinforcement learning: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples to stabilize training in a non‚Äëstationary environment.
ü§ñ Agent Inference Paradigm Compatibility: At inference, Tongyi DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode, which uses a test-time scaling strategy to unlock the model's maximum performance ceiling.
Model Download
You can directly download the model by following the links below.
Model
Download Links
Model Size
Context Length
Tongyi-DeepResearch-30B-A3B
ü§ó HuggingFace ü§ñ ModelScope
30B-A3B
128K
News
[2025/09/17]üî• We have released Tongyi-DeepResearch-30B-A3B.
Deep Research Benchmark Results
Quick Start
This guide provides instructions for setting up the environment and running inference scripts located in the inference folder.
1. Environment Setup
Recommended Python version: 3.10.0 (using other versions may cause dependency issues).
It is strongly advised to create an isolated environment using conda or virtualenv.
# Example with Conda
conda create -n react_infer_env python=3.10.0
conda activate react_infer_env
2. Installation
Install the required dependencies:
pip install -r requirements.txt
3. Environment Configuration and Prepare Evaluation Data
Environment Configuration
Configure your API keys and settings by copying the example environment file:
# Copy the example environment file
cp .env.example .env
Edit the .env file and provide your actual API keys and configuration values:
SERPER_KEY_ID: Get your key from Serper.dev for web search and Google Scholar
JINA_API_KEYS: Get your key from Jina.ai for web page reading
API_KEY/API_BASE: OpenAI-compatible API for page summarization from OpenAI
DASHSCOPE_API_KEY: Get your key from Dashscope for file parsing
SANDBOX_FUSION_ENDPOINT: Python interpreter sandbox endpoints (see SandboxFusion)
MODEL_PATH: Path to your model weights
DATASET: Name of your evaluation dataset
OUTPUT_PATH: Directory for saving results
Note: The .env file is gitignored, so your secrets will not be committed to the repository.
Prepare Evaluation Data
The system supports two input file formats: JSON and JSONL.
Supported File Formats:
Option 1: JSONL Format (recommended)
Create your data file with .jsonl extension (e.g., my_questions.jsonl)
Each line must be a valid JSON object with question and answer keys:
{"question": "What is the capital of France?", "answer": "Paris"}
{"question": "Explain quantum computing", "answer": ""}
Option 2: JSON Format
Create your data file with .json extension (e.g., my_questions.json)
File must contain a JSON array of objects, each with question and answer keys:
[
{"question": "What is the capital of France?", "answer": "Paris"},
{"question": "Explain quantum computing", "answer": ""}
]
Important Note: The answer field contains the ground truth/reference answer used for evaluation. The system generates its own responses to the questions, and these reference answers are used to automatically judge the quality of the generated responses during benchmark evaluation.
File References for Document Processing:
If using the file parser tool, prepend the filename to the question field
Place referenced files in eval_data/file_corpus/ directory
Example: {"question": "report.pdf What are the key findings?", "answer": "..."}
File Organization:
project_root/
‚îú‚îÄ‚îÄ eval_data/
‚îÇ
‚îú‚îÄ‚îÄ my_questions.jsonl
# Your evaluation data
‚îÇ
‚îî‚îÄ‚îÄ file_corpus/
# Referenced documents
‚îÇ
‚îú‚îÄ‚îÄ report.pdf
‚îÇ
‚îî‚îÄ‚îÄ data.xlsx
4. Configure the Inference Script
Open run_react_infer.sh and modify the following variables as instructed in the comments:
MODEL_PATH
- path to the local or remote model weights.
DATASET
- full path to your evaluation file, e.g. eval_data/my_questions.jsonl or /path/to/my_questions.json.
OUTPUT_PATH - path for saving the prediction results, e.g. ./outputs.
Depending on the tools you enable (retrieval, calculator, web search, etc.), provide the required API_KEY, BASE_URL, or other credentials. Each key is explained inline in the bash script.
5. Run the Inference Script
bash run_react_infer.sh
With these steps, you can fully prepare the environment, configure the dataset, and run the model. For more details, consult the inline comments in each script or open an issue.
6. You can use OpenRouter's API to call our model
Tongyi-DeepResearch-30B-A3B is now available at OpenRouter. You can run the inference without any GPUs.
You need to modify the following in the file inference/react_agent.py:
In the call_server function: Set the API key and URL to your OpenRouter account‚Äôs API and URL.
Change the model name to alibaba/tongyi-deepresearch-30b-a3b.
Adjust the content concatenation way as described in the comments on lines 88‚Äì90.
Benchmark Evaluation
We provide benchmark evaluation scripts for various datasets. Please refer to the evaluation scripts directory for more details.
Deep Research Agent Family
Tongyi DeepResearch also has an extensive deep research agent family. You can find more information in the following paper:
[1] WebWalker: Benchmarking LLMs in Web Traversal (ACL 2025)
[2] WebDancer: Towards Autonomous Information Seeking Agency (NeurIPS 2025)
[3] WebSailor: Navigating Super-human Reasoning for Web Agent
[4] WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization
[5] WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent
[6] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents
[7] ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization
[8] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research
[9] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning
[10] Scaling Agents via Continual Pre-training
[11] Towards General Agentic Intelligence via Environment Scaling
üåü Misc
üö© Talent Recruitment
üî•üî•üî• We are hiring! Research intern positions are open (based in Hangzhou„ÄÅBeijing„ÄÅShanghai)
üìö Research AreaÔºöWeb Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG
‚òéÔ∏è ContactÔºöyongjiang.jy@alibaba-inc.com
Contact Information
For communications, please contact Yong Jiang (yongjiang.jy@alibaba-inc.com).
Citation
@misc{tongyidr,
author={Tongyi DeepResearch Team},
title={Tongyi-DeepResearch},
year={2025},
howpublished={\url{https://github.com/Alibaba-NLP/DeepResearch}}
}
About
Tongyi Deep Research, the Leading Open-source Deep Research Agent
tongyi-agent.github.io/blog/introducing-tongyi-deep-research/
Topics
agent
artificial-intelligence
alibaba
web-agent
information-seeking
llm
tongyi
deep-research
deepresearch
Resources
Readme
Uh oh!
There was an error while loading. Please reload this page.
Activity
Custom properties
Stars
12.6k
stars
Watchers
109
watching
Forks
932
forks
Report repository
Releases
No releases published
Packages
0
No packages published
Uh oh!
There was an error while loading. Please reload this page.
Contributors
23
+ 9 contributors
Languages
Python
97.6%
Shell
2.4%
Footer
¬© 2025 GitHub,¬†Inc.
Footer navigation
Terms
Privacy
Security
Status
Community
Docs
Contact
Manage cookies
Do not share my personal information
You can‚Äôt perform that action at this time.