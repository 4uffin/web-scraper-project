‘Red Lines’ call to regulate AI could complicate enterprise compliance – Computerworld
Topics
Spotlight: IT CareersNewsEventsNewslettersResources
AboutAbout UsAdvertiseContact UsEditorial Ethics PolicyFoundry CareersReprintsNewslettersContribute to ComputerworldPoliciesTerms of ServicePrivacy PolicyCookie PolicyCopyright NoticeMember PreferencesAbout AdChoicesYour California Privacy RightsOur NetworkCIOCSOInfoWorldNetwork WorldMoreNewsFeaturesOpinionBlogsBrandPostsEventsPodcastsVideosEnterprise Buyer’s Guides
Close
Generative AIOffice SuitesCollaboration SoftwareProductivity SoftwareWindowsAndroidAppleAugmented RealityEmerging TechnologyMobileRemote WorkArtificial IntelligenceOperating SystemsCareers IT LeadershipIT ManagementIT OperationsIndustryCloud ComputingComputers and PeripheralsAnalyticsData CenterEnterprise ApplicationsNetworkingSecurityVendors and ProvidersEnterprise Buyer’s Guides
Back
Close
Americas
United States
Asia
India
Korea (대한민국)
Europe
Netherlands
United Kingdom
Germany (Deutschland)
Poland (Polska)
Spain (España)
Sweden (Sverige)
Oceania
Australia
New Zealand
Back
Close
Popular Topics
Generative AIProductivity SoftwareWindowsAndroidAppleRemote Work
Search
US-EN
Topics
Spotlight: IT CareersNewsEventsNewslettersResourcesAboutPoliciesOur NetworkMore
Back
Topics
Generative AIOffice SuitesCollaboration SoftwareProductivity SoftwareWindowsAndroidAppleAugmented RealityEmerging TechnologyMobileRemote WorkArtificial IntelligenceOperating SystemsCareersIT LeadershipIT ManagementIT OperationsIndustryCloud ComputingComputers and PeripheralsAnalyticsData CenterEnterprise ApplicationsNetworkingSecurityVendors and ProvidersEnterprise Buyer’s Guides
Back
AboutAbout UsAdvertiseContact UsEditorial Ethics PolicyFoundry CareersReprintsNewslettersContribute to Computerworld
Back
PoliciesTerms of ServicePrivacy PolicyCookie PolicyCopyright NoticeMember PreferencesAbout AdChoicesYour California Privacy Rights
Back
Our NetworkCIOCSOInfoWorldNetwork World
Back
MoreNewsFeaturesOpinionBlogsBrandPostsEventsPodcastsVideosEnterprise Buyer’s Guides
Home
Industry
‘Red Lines’ call to regulate AI could complicate enterprise compliance
by									Evan Schuman
Contributor
Updated
‘Red Lines’ call to regulate AI could complicate enterprise compliance
news
Sep 23, 20256 minsArtificial IntelligenceGenerative AIRegulation
An open letter signed by Nobel Laureates and prominent AI researchers calls for regulating AI vendors, but enterprise IT too may have to deal with expanded AI regulations if governments heed the call made before the United Nations General Assembly.
Credit: 															Shutterstock
In a speech to United Nations General Assembly, Nobel Peace Prize Laureate Maria Ressa launched “a global call for AI red lines,” urging governments “to establish clear, international boundaries to prevent universally unacceptable risks for AI,” and, “At the very least, define what AI should never be allowed to do.”
The Global Call for AI Red Lines she referred to, signed by over 200 prominent industry figures, Nobel laureates and former heads of state, said, “We urge governments to reach an international agreement on red lines for AI — ensuring they are operational, with robust enforcement mechanisms — by the end of 2026.”
In a Q&A document about the initiative, the organizers of the AI Red Lines campaign offered a wide range of possible AI bans, including barring its use in nuclear command and control, lethal autonomous weapons, mass surveillance, human impersonation involving “AI systems that deceive users into believing they are interacting with a human without disclosing their AI nature,” and cyber malicious use, which it defined as “prohibiting the uncontrolled release of cyberoffensive agents capable of disrupting critical infrastructure.”
The campaign group also wants prohibitions against autonomous self-replication, which it said is the “deployment of AI systems capable of replicating or significantly improving themselves without explicit human authorization,” as well blocking “the development of AI systems that cannot be immediately terminated if meaningful human control over them is lost.”
And, it emphasized, “any future treaty should be built on three pillars: a clear list of prohibitions; robust, auditable verification mechanisms; and the appointment of an independent body established by the Parties to oversee implementation.”
Many analysts and observers, however, have concerns about whether such global restrictions are practical, enforceable, or even in time to limit damages.
Analyst concerns focused not on what the campaign group is attempting, but on whether enough countries would support it, whether its end of 2026 target implementation is soon enough to make a difference, and whether it’s meaningfully enforceable.
They noted that the applicability/enforceability of the rules would have an impact on enterprises, mostly via compliance rules, but the group’s requirements are really intended to impact hyperscalers and other AI vendors, as opposed to their customers.
AI rules that could impact enterprises might include limits on using AI to screen job applicants, make loan decisions or on training models on confidential customer data.
Enterprises would still have to comply if they are operating in any country that signed any proposed agreement. Then again, those countries, such as Germany, Canada, Switzerland or Japan, would likely have their own AI compliance rules, making any new mandate potentially irrelevant.
Valence Howden, an advisory fellow at Info-Tech Research Group, said that he understands and applauds the intent behind the group’s effort, even if he questions how viable it would be.
“How do we protect organizations [given that] the risks are not tied to country boundaries?” Howden asked. “There is more general agreement that it is necessary than people think. America is an outlier; they don’t want to regulate or control where AI can go. Even China is saying the right things.”
“A lot of the players that I thought would oppose it didn’t,” he noted.
In fact, the only country other than the United States that expressed strong hesitation was France, Howden said, “because they have the same concern [as the US] that innovation will be stifled,” but he added that France is likely supportive, but it said those things because of other delegates in the room.
Howden also expressed concern about the campaign group’s target of implementing these restrictions by the end of next year.
“A lot of this has to happen, and it has to happen quickly,” he said, but, “the governance and protections are moving at the speed of bureaucracy.”
Howden said that the AI vendor space is approaching what he called “the point of ungovernability,” and that the industry is “very close to that state right now, being beyond the point of no return.”
He noted that even if the Red Line proposals passed, it’s doubtful that the major hyperscalers, who offer most of the genAI models, would comply.
“Can we trust the large scale enterprise vendors to do this? No. They don’t do it now,” Howden said.
Brian Levine is a former federal prosecutor who today serves as the executive director of a directory of former government and military specialists called FormerGov. His US Justice Department role included involvement in many global standards efforts, including work with Interpol on international ransomware coordination and serving on the law enforcement Joint Liaison Group (JLG) with China.
Levine said that he expects the measure Ressa called for at the UN General Assembly will likely happen because most members will agree on the fundamental principles. “But,” he said, “those principles will be so high level that they won’t really move the ball forward in any meaningful way.”
Levine added that agreeing to the proposal is fairly low risk, as countries will likely think, “Don’t worry. It isn’t enforceable anyway.”
The UN has engaged in similar efforts before, with little to show for it. About 11 years ago, the UN tried to ban autonomous killing robots.
Peter Salib, an assistant professor of law at the University of Houston Law Center, said that the real world deployments of genAI systems today make the threat of AI harm much more concrete than was the threat of autonomous killer robots back in 2014.
But as for the effort announced this week, Salib said that he doubts much will come from it.
“Probably nothing happens that matters,” Salib said. “The countries don’t care very much and don’t care enough to give up their sovereignty.”
Editor’s note: An earlier version of this article mischaracterized the group behind the Global Call for AI Red Lines. The article has been corrected throughout.
Related content
news analysis
Apple: Europe’s DMA should be repealed By Jonny Evans
Sep 25, 2025 5 mins
Apple
Mac
Regulation
news
Asana puts ‘AI teammate’ agents to work By Matthew Finnegan
Sep 25, 2025 3 mins
Artificial Intelligence
Generative AI
Productivity Software
news
Microsoft adds Claude to Copilot, but cross-cloud AI could raise new governance challenges By Nidhi Singal
Sep 25, 2025 5 mins
Generative AI
how-to
A beginner’s guide to Google Gemini Gems By Howard Wen
Sep 25, 2025 14 mins
G Suite
Generative AI
Google
Other Sections
Podcasts
Videos
Resources
Events
Spotlight: IT Careers
SUBSCRIBE TO OUR NEWSLETTER
From our editors straight to your inbox
Get started by entering your email address below.
Please enter a valid email address
Subscribe
by
Evan Schuman
Contributor
Follow Evan Schuman on X
Follow Evan Schuman on LinkedIn
Evan Schuman has covered IT issues for a lot longer than he'll ever admit. The founding editor of retail technology site StorefrontBacktalk, he's been a columnist for CBSNews.com, RetailWeek, Computerworld, and eWeek, and his byline has appeared in titles ranging from BusinessWeek, VentureBeat, and Fortune to The New York Times, USA Today, Reuters, The Philadelphia Inquirer, The Baltimore Sun, The Detroit News, and The Atlanta Journal-Constitution. Evan is a frequent contributor to CIO, CSO, Network World and InfoWorld.
Evan won a gold 2025 AZBEE award in the Enterprise News category for this story: Design flaw has Microsoft Authenticator overwriting MFA accounts, locking users out
He can be reached at eschuman@thecontentfirm.com and he can be followed on LinkedIn.
More from this author
newsIntel will design CPUs with Nvidia NVLink in return for $5 billion investment Sep 18, 2025 1 minnewsProposed $1.5 billion Anthropic copyright settlement raises questions about generative AI costs Sep 10, 2025 7 minsnewsGoogle’s €2.95 billion EC antitrust fine is just the beginning Sep 5, 2025 5 minsopinionHow to prepare for an AI bubble burst Sep 3, 2025 7 minsnewsGoogle’s estimate of AI resource consumption leaves out too much Aug 28, 2025 5 minsopinionDevelopers who don’t document code? Blame the bosses Aug 22, 2025 7 minsopinionWords have meaning, even in IT Aug 15, 2025 6 minsnewsIs Perplexity’s $34 billion offer to buy Chrome real or a marketing stunt? Aug 13, 2025 6 mins
Show me morePopularArticlesPodcastsVideos
news
Google exec sets Android OS for PCs plans in motion By Paul BarkerSep 25, 20255 mins
AndroidWindowsWindows PCs
feature
Microsoft 365: A guide to the updates By Preston GrallaSep 25, 202533 mins
Microsoft 365Microsoft OfficeOffice Suites
feature
Windows 11: A guide to the updates By Preston GrallaSep 25, 202551 mins
MicrosoftSmall and Medium BusinessWindows 11
podcast
First Person Meets... Stephen Kaufman: Solving problems with technology and people Sep 22, 202527 mins
CareersCloud ManagementIT Leadership
podcast
First Person Meets.... Magan Naidoo: Using data to do good Sep 15, 202535 mins
Big DataCareers
podcast
Why AI is entering physical security and threat protection spaces Sep 9, 202534 mins
Generative AIPhysical SecurityThreat and Vulnerability Management
video
How agentic AI is expanding the attack surface Sep 23, 202544 mins
CyberattacksGenerative AISecurity Practices
video
First Person Meets... Stephen Kaufman: Solving problems with technology and people Sep 22, 202527 mins
CareersCloud ManagementIT Leadership
video
Why are so many AI projects failing? Sep 17, 202538 mins
Artificial IntelligenceEnterprise ArchitectureGenerative AI
Sponsored Links
Empower your cybersecurity team with expert insights from Palo Alto Networks.
Secure AI by Design: Unleash the power of AI and keep applications, usage and data secure.
About
About Us
Advertise
Contact Us
Editorial Ethics Policy
Foundry Careers
Reprints
Newsletters
BrandPosts
News
Features
Opinions
How-to
Blogs
Policies
Terms of Service
Privacy Policy
Cookie Policy
Copyright Notice
Member Preferences
About AdChoices
Your California Privacy Rights
Privacy Settings
Our Network
CIO
CSO
Infoworld
Network World
FacebookXYouTubeGoogle NewsLinkedIn
© 2025
FoundryCo, Inc. All Rights Reserved.