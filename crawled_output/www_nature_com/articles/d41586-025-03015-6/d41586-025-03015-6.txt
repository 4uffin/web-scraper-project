Secrets of DeepSeek AI model revealed in landmark paper
Skip to main content
Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
and JavaScript.
Advertisement
View all journals
Search
Log in
Explore content
About the journal
Publish with us
Subscribe
Sign up for alerts
RSS feed
nature
news
article
NEWS
17 September 2025
Secrets of DeepSeek AI model revealed in landmark paper
First peer-reviewed study shows how a Chinese start-up firm made the market-shaking LLM for US$300,000.
By
Elizabeth Gibney
Elizabeth Gibney
View author publications
Search author on:
PubMed
Google Scholar
Twitter
Facebook
Email
DeepSeek says its R1 model did not learn by copying examples generated by other LLMs.Credit: David Talukdar/ZUMA via AlamyThe success of DeepSeek’s powerful artificial intelligence (AI) model R1 — which made the US stock market plummet when it was released in January — did not hinge on being trained on the output of its rivals, researchers at the Chinese firm have said. The statement came in documents released alongside a peer-reviewed version of the R1 model, published today in Nature1.How China created AI model DeepSeek and shocked the worldR1 is designed to excel at ‘reasoning’ tasks such as mathematics and coding, and is a cheaper rival to tools developed by US technology firms. As an ‘open weight’ model, it is available for anyone to download, and it is the most popular such model on the AI community platform Hugging Face to date, having been downloaded 10.9 million times.The paper updates a preprint released in January2, which describes how DeepSeek augmented a standard large language model (LLM) to tackle reasoning tasks. Its supplementary material reveals for the first time how much R1 cost to train: the equivalent of just US$294,000. This comes on top of the $6 million or so that the company, based in Hangzhou, spent to make the base LLM that R1 is built on, but the total amount is still substantially less than the tens of millions of dollars that rival models are thought to have cost. DeepSeek says R1 was trained mainly on Nvidia’s H800 chips, which in 2023 became forbidden from being sold to China under US export controls.Rigorous reviewR1 is thought to be the first major LLM to undergo the peer-review process. “This is a very welcome precedent,” says Lewis Tunstall, a machine-learning engineer at Hugging Face who reviewed the Nature paper. “If we don't have this norm of sharing a large part of this process publicly, it becomes very hard to evaluate whether these systems pose risks or not.”In response to peer-review comments, the DeepSeek team reduced anthropomorphizing in its descriptions and added clarifications of technical details, including the kinds of data the model was trained on, and its safety. “Going through a rigorous peer-review process certainly helps verify the validity and usefulness of the model,” says Huan Sun, an AI researcher at Ohio State University in Columbus. “Other firms should do the same.”Scientists flock to DeepSeek: how they’re using the blockbuster AI modelDeepSeek’s major innovation was to use an automated kind of the trial-and-error approach known as pure reinforcement learning to create R1. The process rewarded the model for reaching correct answers, rather than teaching it to follow human-selected reasoning examples. The company says that this is how its model learnt its own reasoning-like strategies, such as how to verify its workings without following human-prescribed tactics. To boost efficiency, the model also scored its own attempts using estimates, rather than using a separate algorithm to do so, a technique known as group relative policy optimization.The model has been “quite influential” among AI researchers, says Sun. “Almost all work in 2025 so far that conducts reinforcement learning in LLMs might have been inspired by R1 one way or another.”
Enjoying our latest content?
Login or create an account to continue
Access the most recent journalism from Nature's award-winning team
Explore the latest features & opinion covering groundbreaking research
Access through your institution
or
Sign in or create an account
Continue with Google
Continue with ORCiD
doi: https://doi.org/10.1038/d41586-025-03015-6Read the related News & Views: ‘AI can learn to show its workings through trial and error’.
ReferencesGuo, D. et al. Nature 645, 633–638 (2025).Article
Google Scholar
DeepSeek-AI et al. Preprint at arXiv https://doi.org/10.48550/arXiv.2501.12948 (2025).Download references
Reprints and permissions
Related Articles
How China created AI model DeepSeek and shocked the world
China’s cheap, open AI model DeepSeek thrills scientists
‘Another DeepSeek moment’: Chinese AI model Kimi K2 stirs excitement
Scientists flock to DeepSeek: how they’re using the blockbuster AI model
OpenAI’s ‘deep research’ tool: is it useful for scientists?
Rise of ChatGPT and other tools raises major questions for research
Subjects
Machine learning
Computer science
Latest on:
Machine learning
Computer science
Robotic system takes chemistry into hyperspace
News & Views 24 SEP 25
Journals infiltrated with ‘copycat’ papers that can be written by AI
News 23 SEP 25
Can AI chatbots trigger psychosis? What the science says
News 18 SEP 25
Python, the movie! The programming language’s origin story comes to the silver screen
Career Q&A 25 SEP 25
Low-overhead transversal fault tolerance for universal quantum computation
Article 24 SEP 25
Bring us your LLMs: why peer review is good for AI models
Editorial 17 SEP 25
Jobs
The Sixth International Youth Scholars Forum Series Activity of Capital Medical University
The Sixth International Youth Scholars Forum Series Activity of Capital Medical University October 20-24, 2025, Beijing, China
Beijing (CN)
Capital Medical University
Physician-Scientist Positions in Research Hospital, ShanghaiTech University
Invites visionary Physician-Scientists and Clinicians across all disciplines and career stages to join our foundational team.
Shanghai (CN)
ShanghaiTech University
Faculty Positions (School of Biomedical Engineering (BME))
School of Biomedical Engineering invites highly qualified candidates to apply for multiple tenure-track/tenured faculty positions.
Shanghai (CN)
ShanghaiTech University
Faculty Positions (School of Creativity and Art (SCA))
School of Creativity and Art (SCA) calls for candidates with exceptional academic records or demonstrated potential.
Shanghai (CN)
ShanghaiTech University
Faculty Positions (Information & Mathematical Science)
School of Information Science and Technology invites highly qualified candidates to fill multiple tenure-track/tenured faculty positions.
Shanghai (CN)
ShanghaiTech University
Related Articles
How China created AI model DeepSeek and shocked the world
China’s cheap, open AI model DeepSeek thrills scientists
‘Another DeepSeek moment’: Chinese AI model Kimi K2 stirs excitement
Scientists flock to DeepSeek: how they’re using the blockbuster AI model
OpenAI’s ‘deep research’ tool: is it useful for scientists?
Rise of ChatGPT and other tools raises major questions for research
Subjects
Machine learning
Computer science
Sign up to Nature Briefing
An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.
Email address
Yes! Sign me up to receive the daily Nature Briefing email. I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.
Sign up
Close banner
Close
Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.
Email address
Sign up
I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.
Close banner
Close
Get the most important science stories of the day, free in your inbox.
Sign up for Nature Briefing
Explore content
Research articles
News
Opinion
Research Analysis
Careers
Books & Culture
Podcasts
Videos
Current issue
Browse issues
Collections
Subjects
Follow us on Facebook
Follow us on Twitter
Subscribe
Sign up for alerts
RSS feed
About the journal
Journal Staff
About the Editors
Journal Information
Our publishing models
Editorial Values Statement
Journal Metrics
Awards
Contact
Editorial policies
History of Nature
Send a news tip
Publish with us
For Authors
For Referees
Language editing services
Open access funding
Submit manuscript
Search
Search articles by subject, keyword or author
Show results from
All journals
Search
Advanced search
Quick links
Explore articles by subject
Find a job
Guide to authors
Editorial policies
Nature
(Nature)
ISSN 1476-4687 (online)
ISSN 0028-0836 (print)
nature.com sitemap
About Nature Portfolio
About us
Press releases
Press office
Contact us
Discover content
Journals A-Z
Articles by subject
protocols.io
Nature Index
Publishing policies
Nature portfolio policies
Open access
Author & Researcher services
Reprints & permissions
Research data
Language editing
Scientific editing
Nature Masterclasses
Research Solutions
Libraries & institutions
Librarian service & tools
Librarian portal
Open research
Recommend to library
Advertising & partnerships
Advertising
Partnerships & Services
Media kits
Branded
content
Professional development
Nature Awards
Nature Careers
Nature
Conferences
Regional websites
Nature Africa
Nature China
Nature India
Nature Japan
Nature Middle East
Privacy
Policy
Use
of cookies
Your privacy choices/Manage cookies
Legal
notice
Accessibility
statement
Terms & Conditions
Your US state privacy rights
© 2025 Springer Nature Limited