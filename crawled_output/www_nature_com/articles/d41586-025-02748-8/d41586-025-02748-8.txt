What research might be lost after the NIH’s cuts? Nature trained a bot to find out
Skip to main content
Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
and JavaScript.
Advertisement
View all journals
Search
Log in
Explore content
About the journal
Publish with us
Subscribe
Sign up for alerts
RSS feed
nature
nature index
article
NATURE INDEX
24 September 2025
What research might be lost after the NIH’s cuts? Nature trained a bot to find out
We used machine-learning tools in an attempt to recreate the method for cutting funding, and then applied it to past US National Institutes of Health grants to reveal the broad-reaching consequences of such action.
By
Vera Nienaber0 &
Jack Leeming
Vera Nienaber
Vera Nienaber is a data scientist at Springer Nature in London.
View author publications
Search author on:
PubMed
Google Scholar
Jack Leeming
View author publications
Search author on:
PubMed
Google Scholar
Twitter
Facebook
Email
Credit: adapted from GettySoon after US President Donald Trump came to office in January, his administration began cutting funding for scientific research in areas it sees as related to ‘woke’ ideologies. Grants related to transgender health care, diversity, equity and inclusion (DEI) and health disparities in minority groups have been some of the most targeted.It’s impossible to know what the impact of these cuts will be on the science of the future: the research that might have emerged but that will now not exist. The administration would argue that’s a good thing; tax dollars are no longer being spent on projects it sees as antithetical to the US way of life.A machine-learning analysis by Nature Index attempts to give a sense of the value of the research that might have been lost, by trying to reproduce the rationale the National Institutes of Health (NIH) used to cancel grants, then applying that method to science that was in the pipeline around ten years ago.Machine learning reveals potential consequences of cuts to US researchThere are, of course, limitations to the insights that such an analysis can provide. A decade ago, science was done in a different political context: it’s impossible to know what grants the Trump administration would have cancelled if it were in power back then. The model used was also trained on a relatively small amount of data and simply considers patterns and associations in grants cancelled this year.The work suggests, however, that some highly impactful science — from breakthroughs in mapping the human genome to life-saving cancer-screening techniques — might have been at risk of not being funded had a similar process been followed a decade ago.The exact method that the Trump administration has used to identify which research grants to cancel is a mystery. But, however the decisions have been made, the cuts have been deep, amounting to at least US$4 billion so far from just the NIH and National Science Foundation (NSF), the two largest federal research funders in the United States.Many of these cancellations have been tracked by Grant Witness, a website set up for this purpose. They have generally focused on research related to topics around DEI, race equity and gender studies, although other tranches of cancellations have targeted institutions — such as Harvard University in Cambridge, Massachusetts. Grants related to other topics but were awarded as part of a racial-justice or equality initiative were also targeted.For grants cancelled on the basis of their research topic, bibliometrics researchers have suggested that the administration circulated a list of 200 or so words or phrases — including ‘transgender’, ‘DEI’ and ‘disparities’ — that automatically flag grants for review. A similar list has been circulated to federal departments and these terms have been removed from messaging and websites, as reported by The New York Times in March.More clues might be found in an account given by an ex-employee at the Department of Government Efficiency (DOGE) — the body set up by the Trump administration to cut public spending seen as excessive. The employee told investigative website ProPublica in June that he had used generative artificial intelligence (AI) to assess contracts for cancellation at the US Department of Veterans Affairs.At scaleThe lack of a transparent methodology for identifying grants for review was discussed in a June court hearing, at which a federal judge ordered the government to restore some of the cancelled grants (that ruling has since been superseded by a Supreme Court decision that allows the cuts to go ahead).“I think what may have been happening is that somebody, not a scientist, was sitting behind their computer and searching for keywords that they didn’t like,” says Scott Delaney, an environmental-health researcher and one of the founders of Grant Witness. Then they were cancelling grants without regard to the research involved or the impact that the grant might have, he adds. Until last week, Delaney worked at Harvard but he has now resigned because of the impact of the cancellations on his research. Nature Index 2025 Research LeadersIn an attempt to reproduce the methodology for identifying NIH grants to cut, Nature Index’s editorial team worked with data scientists at Nature Research Intelligence, which manages the Nature Index database. The idea was to train a machine-learning algorithm using information on cancelled grants from the NIH’s Reporter database, Digital Science’s Dimensions database and Grant Witness. (Nature Index’s editorial team is editorially independent of Nature Research Intelligence, which is part of Springer Nature.)The machine-learning model looked at keywords in the titles and abstracts of cancelled grants listed on Grant Witness to get an idea of what sorts of grant were targeted (see Supplementary information for methodology). It also considered the size of the grant and how much of the funding period was left.After training and evaluation, we deleted the training data and applied the model to all active NIH grants listed in the Dimensions database at the start of the year, assigning each a predicted risk of cancellation on the basis of these features. It predicted with an overall accuracy of 90%: nine out of ten times, it correctly predicted whether a grant was or wasn’t cancelled. Of those grants that we know were cancelled, it correctly predicted cancellation 70% of the time. According to the model, the phrases and words that were most likely to lead to cancellation included ‘gender-affirming care’, ‘assigned male at birth’, ‘affirming care’, ‘racial justice’, ‘LGBTQ’ and ‘hate speech’.History in the makingTo get an idea of how such cuts can affect science, we applied the model to NIH grants that were active in 2014. We then identified papers that were funded by those grants and ranked them by the number of citations that they had accumulated (see ‘Lost effort’ and Supplementary information). The algorithm found 1,287 grants — worth $1.9 billion — that it considered likely to be cancelled, of a total of around 48,000. Around 53,000 publications are related to those flagged grants. Although the grants were active in 2014, some had begun several years before that, and many of the associated papers were therefore published before 2014. The oldest grant — to train postdocs in translational neuroscience — started in 1977, and some of the papers date back to 2002.The results show the damage that cuts in funding can do to research, and the unpredictable nature of the research process. Although the model was trained on grants that were ostensibly cancelled for ideological reasons, papers that ensued from similar grants that were active in 2014 were not all about transgender health or health inequities. Rather, they encompassed a wide range of research fields and topics.For example, one grant that the model predicted would have been cancelled, partly on the basis of its repeated mentions of ‘diversity’, led to a paper1 that described a software technique to help genetics researchers to identify chimaeras — DNA sequences that can confound analyses of large pools of genetic material. The paper was among the most-cited in the analysis, with 10,400 citations.“It is quite common in biology for rather ho-hum methods to be more highly cited than important discovery papers. Everyone needs test tubes and pipettes,” according to Robert Edgar, an independent scientist and lead author of the chimaera paper.Other highly cited studies that might not have existed if their grant had been cancelled include a seminal paper showcasing the results of the Human Microbiome Project2, the result of a $10-million package over five years to increase the understanding of the human microbiome. The work was probably flagged by the algorithm because three of its supporting grants referenced the diversity of genetic populations.Lost effortThese NIH grants that were active in 2014 were identified by a machine-learning model as likely to have been cancelled had a similar process to this year’s grant cuts been followed in the past. They are ordered by the total citations achieved by their associated research publications. Many grants share a name with the institute they were used to set up.Grant titleFunding amount (US$)Grant start dateNumber of publications associated with grantTotal citations collected by publications UCLA* Clinical and Translational Science Institute$57 million20113,316258,520Colorado Clinical and Translational Sciences Institute$48 million20132,358131,852Louisiana Clinical and Translational Science Center$58 million20122,22276,882North Carolina Translational & Clinical Sciences Institute$44 million20131,20376,356Michigan Center for Diabetes Translational Research$9 million20111,59170,076Framingham Heart Study/Fox$7 million201023762,735Center for Studies in Demography and Ecology$9 million200290356,430Defining the Human Microbiome$10 million20093847,094UCLA* Clinical and Translational Science Institute$15 million201148042,901San Diego Center for Systems Biology: From Maps to Models$23 million201027442,364*University of California, Los Angeles“It’s our whole field! Dammit,” says Ruth Ley, one of the co-authors of the human-microbiome paper and now the director of the department of microbiome science at the University of Tübingen in Germany.“That particular grant was a big multicentre thing, but it had amazing trickle-down effects,” she says. “The Human Microbiome Project was an enormous consortium — anyone who wanted to work with the data could.”This meant, Ley says, that they needed to build a standardization process for how the data were shared and stored, what analysis techniques were used, and how the papers were written and published — all funded by that grant. “What came out of it for the whole field was how we should be doing this stuff,” she says.“It wouldn't have happened without that grant. No way. No way.”Wider impactAnother grant flagged by the model was one that, in 2009, funded the long-term running of the Clinical and Translational Science Institute, part of the University of California, Los Angeles (UCLA), to the tune of $57 million. The institute aims to train clinical scientists to run studies and ultimately to bring research into health care. The model found keywords in the grant, such as ‘expression’, that increased the chances of cancellation, as did the size of the grant.The institute went on to produce more than 3,000 publications. Among the most highly cited of them, with 9,674 citations, was a 2011 study3 that found that lung-cancer screening using low-dose computed tomography (CT) scans was more effective than use of conventional radiography, and reduced death rates by 20%.
Enjoying our latest content?
Login or create an account to continue
Access the most recent journalism from Nature's award-winning team
Explore the latest features & opinion covering groundbreaking research
Access through your institution
or
Sign in or create an account
Continue with Google
Continue with ORCiD
doi: https://doi.org/10.1038/d41586-025-02748-8Nature Index’s news and supplement content is editorially independent of its publisher, Springer Nature. For more information about Nature Index, see the homepage.
ReferencesEdgar, R. C., Haas, B. J., Clemente, J. C., Quince, C. & Knight, R. Bioinformatics 27, 2194–2200 (2011).Article
PubMed
Google Scholar
The Human Microbiome Project Consortium. Nature 486, 207–214 (2012). Article
PubMed
Google Scholar
The National Lung Screening Trial Research Team. N. Engl. J .Med. 365, 395–409 (2011).Article
PubMed
Google Scholar
Macosko, E. Z. et al. Cell 161, 1202–1214 (2015).Article
PubMed
Google Scholar
Download references
Supplementary Information
Methodology for analysis
nature-nih-bot-predicted-grants
Related Articles
Machine learning reveals potential consequences of cuts to US research
Subjects
Funding
Government
Medical research
Politics
Policy
Latest on:
Funding
Government
Medical research
Machine learning reveals potential consequences of cuts to US research
Editorial 24 SEP 25
Exclusive: RFK Jr cancelled mRNA research — but the US military is still funding it
News 24 SEP 25
How can universities train the skilled workers of tomorrow?
World View 23 SEP 25
Machine learning reveals potential consequences of cuts to US research
Editorial 24 SEP 25
Trump’s $100K visa fee for foreign talent: how will it affect researchers?
News 24 SEP 25
Exclusive: RFK Jr cancelled mRNA research — but the US military is still funding it
News 24 SEP 25
Swapping old immune cells in the brain with fresh ones could treat disease
News 25 SEP 25
Huntington’s disease treated for first time using gene therapy
News 25 SEP 25
Boosting immune cells to combat cancer using CRISPR engineering and large-scale in vivo testing
News & Views 24 SEP 25
Jobs
The Sixth International Youth Scholars Forum Series Activity of Capital Medical University
The Sixth International Youth Scholars Forum Series Activity of Capital Medical University October 20-24, 2025, Beijing, China
Beijing (CN)
Capital Medical University
Physician-Scientist Positions in Research Hospital, ShanghaiTech University
Invites visionary Physician-Scientists and Clinicians across all disciplines and career stages to join our foundational team.
Shanghai (CN)
ShanghaiTech University
Faculty Positions (School of Biomedical Engineering (BME))
School of Biomedical Engineering invites highly qualified candidates to apply for multiple tenure-track/tenured faculty positions.
Shanghai (CN)
ShanghaiTech University
Faculty Positions (School of Creativity and Art (SCA))
School of Creativity and Art (SCA) calls for candidates with exceptional academic records or demonstrated potential.
Shanghai (CN)
ShanghaiTech University
Faculty Positions (Information & Mathematical Science)
School of Information Science and Technology invites highly qualified candidates to fill multiple tenure-track/tenured faculty positions.
Shanghai (CN)
ShanghaiTech University
Related Articles
Machine learning reveals potential consequences of cuts to US research
Subjects
Funding
Government
Medical research
Politics
Policy
Sign up to Nature Briefing
An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.
Email address
Yes! Sign me up to receive the daily Nature Briefing email. I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.
Sign up
Close banner
Close
Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.
Email address
Sign up
I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.
Close banner
Close
Get the most important science stories of the day, free in your inbox.
Sign up for Nature Briefing
Explore content
Research articles
News
Opinion
Research Analysis
Careers
Books & Culture
Podcasts
Videos
Current issue
Browse issues
Collections
Subjects
Follow us on Facebook
Follow us on Twitter
Subscribe
Sign up for alerts
RSS feed
About the journal
Journal Staff
About the Editors
Journal Information
Our publishing models
Editorial Values Statement
Journal Metrics
Awards
Contact
Editorial policies
History of Nature
Send a news tip
Publish with us
For Authors
For Referees
Language editing services
Open access funding
Submit manuscript
Search
Search articles by subject, keyword or author
Show results from
All journals
Search
Advanced search
Quick links
Explore articles by subject
Find a job
Guide to authors
Editorial policies
Nature
(Nature)
ISSN 1476-4687 (online)
ISSN 0028-0836 (print)
nature.com sitemap
About Nature Portfolio
About us
Press releases
Press office
Contact us
Discover content
Journals A-Z
Articles by subject
protocols.io
Nature Index
Publishing policies
Nature portfolio policies
Open access
Author & Researcher services
Reprints & permissions
Research data
Language editing
Scientific editing
Nature Masterclasses
Research Solutions
Libraries & institutions
Librarian service & tools
Librarian portal
Open research
Recommend to library
Advertising & partnerships
Advertising
Partnerships & Services
Media kits
Branded
content
Professional development
Nature Awards
Nature Careers
Nature
Conferences
Regional websites
Nature Africa
Nature China
Nature India
Nature Japan
Nature Middle East
Privacy
Policy
Use
of cookies
Your privacy choices/Manage cookies
Legal
notice
Accessibility
statement
Terms & Conditions
Your US state privacy rights
© 2025 Springer Nature Limited